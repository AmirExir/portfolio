[
  {
    "id": "chunk_001",
    "text": "\n\n--- Area Data \u2014 .txt ---\n\nArea Data \u2014 \n\nArea Data\u00b6\n\n\n\n\n\naareachar\n\n return an array of character values for subsystem areas.\n\naareacount\n\n return the number of array entries required to accommodate the data to be returned by the remaining members of the area data family.\n\naareacplx\n\n return an array of complex values for subsystem areas.\n\naareaint\n\n return an array of integer values for subsystem areas.\n\naareareal\n\n return an array of real values for subsystem areas.\n\naareatypes\n\n return an ar"
  },
  {
    "id": "chunk_002",
    "text": "es for subsystem areas.\n\naareatypes\n\n return an array of character values indicating the data types corresponding to a set of specified STRING values that are valid input values to any of the data retrieval routines of the area data family (aAreaInt, aAreaReal, aAreaCplx and aAreaChar).\n\n--- Area Subsystems \u2014 .txt ---\n\nArea Subsystems \u2014 \n\nArea Subsystems\u00b6\n\n\n\n\n\nasys\n\n define an area subsystem.\n\nasysdef\n\n set the definition of an area subsystem.\n\nasysinit\n\n initialize or re-initialize an area subs"
  },
  {
    "id": "chunk_003",
    "text": "sysinit\n\n initialize or re-initialize an area subsystem.\n\n--- Assign Branch Quantities To Output Channels \u2014 .txt ---\n\nAssign Branch Quantities To Output Channels \u2014 \n\nAssign Branch Quantities To Output Channels\u00b6\n\n\n\n\n\nbranch_app_r_x_channel\n\n add a pair of output channels containing the apparent impedance, as seen at the from bus of a specified branch, along with a corresponding call to the RELAY2 monitoring model.\n\nbranch_mva_channel\n\n add an output channel containing the MVA flow at the from bus"
  },
  {
    "id": "chunk_004",
    "text": "ut channel containing the MVA flow at the from bus of a specified branch, along with a corresponding call to the FLOW1 monitoring model.\n\nbranch_p_and_q_channel\n\n add a pair of output channels containing the active and reactive power flow at the from bus of a specified branch, along with a corresponding call to the FLOW1 monitoring model.\n\nbranch_p_channel\n\n add an output channel containing the active power flow at the from bus of a specified branch, along with a corresponding call to the FLOW1 "
  },
  {
    "id": "chunk_005",
    "text": "nch, along with a corresponding call to the FLOW1 monitoring model.\n\nthree_wnd_app_r_x_channel\n\n add a pair of output channels containing the apparent impedance as seen at the from bus of a specified three-winding transformer, along with a corresponding call to the RELAY3 monitoring model.\n\nthree_wnd_mva_channel\n\n add an output channel containing the MVA flow at the from bus of a specified three-winding transformer, along with a corresponding call to the FLOW3 monitoring model.\n\nthree_wnd_p_and_"
  },
  {
    "id": "chunk_006",
    "text": "l to the FLOW3 monitoring model.\n\nthree_wnd_p_and_q_channel\n\n add a pair of output channels containing the active and reactive power flow at the from bus of a specified three-winding transformer, along with a corresponding call to the FLOW3 monitoring model.\n\nthree_wnd_p_channel\n\n add an output channel containing the active power flow at the from bus of a specified three-winding transformer, along with a corresponding call to the FLOW3 monitoring model.\n\n--- Assign Machine Quantities To Output C"
  },
  {
    "id": "chunk_007",
    "text": " model.\n\n--- Assign Machine Quantities To Output Channels \u2014 .txt ---\n\nAssign Machine Quantities To Output Channels \u2014 \n\nAssign Machine Quantities To Output Channels\u00b6\n\n\n\n\n\nmachine_app_r_x_channel\n\n add a pair of output channels containing the apparent impedance of the system, as seen from the terminals of a specified machine, along with a corresponding call to the GENTMZ monitoring model.\n\nmachine_array_channel\n\n add an output channel containing a plant related model variable of a designated type "
  },
  {
    "id": "chunk_008",
    "text": "plant related model variable of a designated type for a specified machine.\n\nmachine_iterm_channel\n\n add an output channel containing the terminal current of a specified machine, along with a corresponding call to the GENTMC monitoring model.\n\n--- Assign Other Quantities To Output Channels \u2014 .txt ---\n\nAssign Other Quantities To Output Channels \u2014 \n\nAssign Other Quantities To Output Channels\u00b6\n\n\n\n\n\nbus_frequency_channel\n\n add an output channel containing the per unit frequency deviation at a specifi"
  },
  {
    "id": "chunk_009",
    "text": "ning the per unit frequency deviation at a specified bus.\n\nstate_channel\n\n add an output channel containing the value of a specified STATE.\n\nvar_channel\n\n add an output channel containing the value of a specified VAR.\n\nvoltage_and_angle_channel\n\n add a pair of output channels containing the voltage magnitude in per unit and phase angle in degrees of a specified bus, along with a corresponding call to the VOLMAG monitoring model.\n\nvoltage_channel\n\n add an output channel containing the voltage mag"
  },
  {
    "id": "chunk_010",
    "text": "\n add an output channel containing the voltage magnitude in per unit of a specified bus, along with a corresponding call to the VOLMAG monitoring model.\n\n--- Auxiliary Signal Models \u2014 .txt ---\n\nAuxiliary Signal Models \u2014 \n\nAuxiliary Signal Models\u00b6\n\n\n\n\n\nadd_fctsauxsignal_model\n\n add a FACTS device auxiliary signal model at the specified injection point of the designated FACTS device.\n\nadd_mtdcauxsignal_model\n\n add a multi-terminal dc line auxiliary signal model at the specified auxiliary signal in"
  },
  {
    "id": "chunk_011",
    "text": " signal model at the specified auxiliary signal index of the designated multi-terminal dc line.\n\nadd_ttdcauxsignal_model\n\n add a two-terminal dc line auxiliary signal model at the specified injection point of the designated two-terminal dc line.\n\nadd_vsdcauxsignal_model\n\n add a VSC dc line auxiliary signal model at the specified injection point of the designated VSC dc line.\n\nauxmod_pack\n\n remove entries that are marked as unused from the auxiliary signal model connection tables and the auxiliar"
  },
  {
    "id": "chunk_012",
    "text": "ry signal model connection tables and the auxiliary signal array allocation tables.\n\nauxmod_unconnected\n\n list or remove from dynamics working memory those auxiliary signal models that are assigned to dc lines or FACTS devices that are not present in the current power flow working case (unconnected).\n\nauxmod_user\n\n list user-written auxiliary signal model definitions or to remove user-written auxiliary signal model definitions that are not assigned to any dc lines or FACTS devices (unused) from "
  },
  {
    "id": "chunk_013",
    "text": "ed to any dc lines or FACTS devices (unused) from the user model definition tables.\n\nchange_fctsauxmod_chricn\n\n change the value of a character ICON (i.e., an element of the CHRICN array) of an auxiliary signal model of a specified FACTS device.\n\nchange_fctsauxmod_con\n\n change the value of a CON of an auxiliary signal model of a specified FACTS device.\n\nchange_fctsauxmod_data\n\n\n\nchange_fctsauxmod_icon\n\n change the value of an integer ICON of an auxiliary signal model of a specified FACTS device."
  },
  {
    "id": "chunk_014",
    "text": "uxiliary signal model of a specified FACTS device.\n\nchange_fctsauxmod_var\n\n change the value of a VAR of an auxiliary signal model of a specified FACTS device.\n\nchange_mtdcauxmod_chricn\n\n change the value of a character ICON (i.e., an element of the CHRICN array) of an auxiliary signal model of a specified multi-terminal dc line.\n\nchange_mtdcauxmod_con\n\n change the value of a CON of an auxiliary signal model of a specified multi- terminal dc line.\n\nchange_mtdcauxmod_data\n\n\n\nchange_mtdcauxmod_ico"
  },
  {
    "id": "chunk_015",
    "text": ".\n\nchange_mtdcauxmod_data\n\n\n\nchange_mtdcauxmod_icon\n\n change the value of an integer ICON of an auxiliary signal model of a specified multi-terminal dc line.\n\nchange_mtdcauxmod_var\n\n change the value of a VAR of an auxiliary signal model of a specified multi- terminal dc line.\n\nchange_ttdcauxmod_chricn\n\n change the value of a character ICON (i.e., an element of the CHRICN array) of an auxiliary signal model of a specified two-terminal dc line.\n\nchange_ttdcauxmod_con\n\n change the value of a CON o"
  },
  {
    "id": "chunk_016",
    "text": "hange_ttdcauxmod_con\n\n change the value of a CON of an auxiliary signal model of a specified two- terminal dc line.\n\nchange_ttdcauxmod_data\n\n\n\nchange_ttdcauxmod_icon\n\n change the value of an integer ICON of an auxiliary signal model of a specified two-terminal dc line.\n\nchange_ttdcauxmod_var\n\n change the value of a VAR of an auxiliary signal model of a specified two- terminal dc line.\n\nchange_vsdcauxmod_chricn\n\n change the value of a character ICON (i.e., an element of the CHRICN array) of an au"
  },
  {
    "id": "chunk_017",
    "text": "ON (i.e., an element of the CHRICN array) of an auxiliary signal model of a specified VSC dc line.\n\nchange_vsdcauxmod_con\n\n change the value of a CON of an auxiliary signal model of a specified VSC dc line.\n\nchange_vsdcauxmod_data\n\n\n\nchange_vsdcauxmod_icon\n\n change the value of an integer ICON of an auxiliary signal model of a specified VSC dc line.\n\nchange_vsdcauxmod_var\n\n change the value of a VAR of an auxiliary signal model of a specified VSC dc line.\n\nfctsauxmod_remove\n\n remove an auxiliary"
  },
  {
    "id": "chunk_018",
    "text": " dc line.\n\nfctsauxmod_remove\n\n remove an auxiliary signal model from the specified injection point of a designated FACTS device.\n\nfctsauxmod_status\n\n change the status of the auxiliary signal model at the specified injection point of a designated FACTS device.\n\nmtdcauxmod_remove\n\n remove an auxiliary signal model from the specified auxiliary signal index of the designated multi-terminal dc line.\n\nmtdcauxmod_status\n\n change the status of the auxiliary signal model at the specified auxiliary signa"
  },
  {
    "id": "chunk_019",
    "text": "iary signal model at the specified auxiliary signal index of the designated multi-terminal dc line.\n\nttdcauxmod_remove\n\n remove an auxiliary signal model from the specified injection point of the designated two-terminal dc line.\n\nttdcauxmod_status\n\n change the status of the auxiliary signal model at the specified injection point of the designated two-terminal dc line.\n\nvsdcauxmod_remove\n\n remove an auxiliary signal model from the specified injection point of the designated VSC dc line.\n\nvsdcauxm"
  },
  {
    "id": "chunk_020",
    "text": "ion point of the designated VSC dc line.\n\nvsdcauxmod_status\n\n change the status of the auxiliary signal model at the specified injection point of the designated VSC dc line.\n\n--- Branch Data \u2014 .txt ---\n\nBranch Data \u2014 \n\nBranch Data\u00b6\n\n\n\n\n\nabrnchar\n\n return an array of character values for subsystem branches.\n\nabrncount\n\n return the number of array entries required to accommodate the data to be returned by the remaining members of the branch data family.\n\nabrncplx\n\n return an array of complex value"
  },
  {
    "id": "chunk_021",
    "text": "mily.\n\nabrncplx\n\n return an array of complex values for subsystem branches.\n\nabrnint\n\n return an array of integer values for subsystem branches.\n\nabrnreal\n\n return an array of real values for subsystem branches.\n\nabrntypes\n\n return an array of character values indicating the data types corresponding to a set of specified STRING values that are valid input values to any of the data retrieval routines of the branch data family (aBrnInt, aBrnReal, aBrnCplx and aBrnChar).\n\n--- Branch Flow Data \u2014 .tx"
  },
  {
    "id": "chunk_022",
    "text": "BrnCplx and aBrnChar).\n\n--- Branch Flow Data \u2014 .txt ---\n\nBranch Flow Data \u2014 \n\nBranch Flow Data\u00b6\n\n\n\n\n\naflowchar\n\n return an array of character values for subsystem branches.\n\naflowcount\n\n return the number of array entries required to accommodate the data to be returned by the remaining members of the branch flow data family.\n\naflowcplx\n\n return an array of complex values for subsystem branches.\n\naflowint\n\n return an array of integer values for subsystem branches.\n\naflowreal\n\n return an array of "
  },
  {
    "id": "chunk_023",
    "text": "bsystem branches.\n\naflowreal\n\n return an array of real values for subsystem branches.\n\naflowtypes\n\n return an array of character values indicating the data types corresponding to a set of specified STRING values that are valid input values to any of the data retrieval routines of the branch flow data family (aFlowInt, aFlowReal, aFlowCplx and aFlowChar).\n\n--- Bus Data \u2014 .txt ---\n\nBus Data \u2014 \n\nBus Data\u00b6\n\n\n\n\n\nabuschar\n\n return an array of character values for subsystem buses.\n\nabuscount\n\n return t"
  },
  {
    "id": "chunk_024",
    "text": " values for subsystem buses.\n\nabuscount\n\n return the number of array entries required to accommodate the data to be returned by the remaining members of the bus data family.\n\nabuscplx\n\n return an array of complex values for subsystem buses.\n\nabusint\n\n return an array of integer values for subsystem buses.\n\nabusreal\n\n return an array of real values for subsystem buses.\n\nabustypes\n\n return an array of character values indicating the data types corresponding to a set of specified STRING values that"
  },
  {
    "id": "chunk_025",
    "text": "esponding to a set of specified STRING values that are valid input values to any of the data retrieval routines of the bus data family (aBusInt, aBusReal, aBusCplx and aBusChar).\n\n--- Bus Subsystems \u2014 .txt ---\n\nBus Subsystems \u2014 \n\nBus Subsystems\u00b6\n\n\n\n\n\nbsys\n\n define a bus subsystem.\n\nbsysadd\n\n add elements to an existing bus subsystem.\n\nbsysdef\n\n set the definition of a bus subsystem.\n\nbsysdelo\n\n delete a single bus from a bus subsystem.\n\nbsysinit\n\n initialize or re-initialize a bus subsystem.\n\nbs"
  },
  {
    "id": "chunk_026",
    "text": "\n initialize or re-initialize a bus subsystem.\n\nbsysmem\n\n replicate the specified bus subsystem in a bus subsystem file.\n\nbsyso\n\n build a bus subsystem one bus at a time.\n\nbsysrcl\n\n recall a specified bus subsystem saved in a bus subsystem file.\n\n--- Cct Models \u2014 .txt ---\n\nCct Models \u2014 \n\nCct Models\u00b6\n\n\n\n\n\nadd_cct2dco_model\n\n add an \u201cother\u201d type model attached to a 2-terminal dc line.\n\nadd_cct2wtd_model\n\n add a 2-winding transformer device model to the specified 2-winding transformer.\n\nadd_cct3wtd"
  },
  {
    "id": "chunk_027",
    "text": " the specified 2-winding transformer.\n\nadd_cct3wtd_model\n\n add a 3-winding transformer device model to the specified 3-winding transformer.\n\nadd_cctbrnd_model\n\n add a branch device model to the specified branch.\n\nadd_cctbrno_model\n\n add a branch \u201cother\u201d model to the specified branch.\n\nadd_cctbuso_model\n\n add an \u201cother\u201d type model attached to a bus.\n\nadd_cctmcno_model\n\n add a machine other model to the specified machine.\n\nadd_cctmcnp_model\n\n add a machine protection model to the specified machine"
  },
  {
    "id": "chunk_028",
    "text": " machine protection model to the specified machine.\n\nadd_cctmsco_model\n\n add a miscellaneous \u201cother\u201d type model with the specified model instance.\n\nadd_cctswso_model\n\n\n\nadd_cctswso_model_2\n\n add a switched shunt \u201cother\u201d model to the specified bus.\n\ncct2dco_list\n\n list \u201cother\u201d type models attached to 2-terminal dc lines.\n\ncct2dcomod_remove\n\n remove an \u201cother\u201d type model attached to a 2-terminal dc line.\n\ncct2dcomod_status\n\n change status of an \u201cother\u201d type model attached to a 2-terminal dc line.\n"
  },
  {
    "id": "chunk_029",
    "text": "her\u201d type model attached to a 2-terminal dc line.\n\ncct2wtd_list\n\n list \u201cother\u201d type models attached to 2-winding transformers.\n\ncct2wtdmod_remove\n\n remove a 2-winding transformer device model attached to the specified 2-winding transformer.\n\ncct2wtdmod_status\n\n change the status of a 2-winding transformer device model attached to the specified 2-winding transformer.\n\ncct3wtd_list\n\n list \u201cother\u201d type models attached to 3-winding transformers.\n\ncct3wtdmod_remove\n\n remove a 3-winding transformer de"
  },
  {
    "id": "chunk_030",
    "text": "3wtdmod_remove\n\n remove a 3-winding transformer device model attached to the specified 3-winding transformer.\n\ncct3wtdmod_status\n\n change the status of a 3-winding transformer device model attached to the specified 3-winding transformer.\n\ncctbrnd_list\n\n list device type models attached to branches.\n\ncctbrndmod_remove\n\n remove a branch device model attached to the specified branch.\n\ncctbrndmod_status\n\n change the status of a branch device model attached to the specified branch.\n\ncctbrno_list\n\n li"
  },
  {
    "id": "chunk_031",
    "text": "tached to the specified branch.\n\ncctbrno_list\n\n list \u201cother\u201d type models attached to branches.\n\ncctbrnomod_remove\n\n remove a branch \u201cother\u201d model attached to the specified branch.\n\ncctbrnomod_status\n\n change the status of a branch \u201cother\u201d model attached to the specified branch.\n\ncctbuso_list\n\n list \u201cother\u201d type models attached to buses.\n\ncctbusomod_remove\n\n remove an \u201cother\u201d type model attached to a bus.\n\ncctbusomod_status\n\n change status of an \u201cother\u201d type model attached to a bus.\n\ncctmcno_list"
  },
  {
    "id": "chunk_032",
    "text": "other\u201d type model attached to a bus.\n\ncctmcno_list\n\n list \u201cother\u201d type models attached to machines.\n\ncctmcnomod_remove\n\n remove a machine \u201cother\u201d model attached to the specified machine.\n\ncctmcnomod_status\n\n change status of a machine \u201cother\u201d model attached to the specified machine.\n\ncctmcnp_list\n\n list protection models attached to machines.\n\ncctmcnpmod_remove\n\n remove a machine protection model attached to the specified machine.\n\ncctmcnpmod_status\n\n change status of a machine protection model "
  },
  {
    "id": "chunk_033",
    "text": "tus\n\n change status of a machine protection model attached to the specified machine.\n\ncctmod_pack\n\n pack CCT model definition tables.\n\ncctmod_user\n\n list or remove user-written CCT model definitions.\n\ncctmsco_list\n\n list miscellaneous \u201cother\u201d type models.\n\ncctmscomod_remove\n\n remove a miscellaneous \u201cother\u201d type model with the specified model instance.\n\ncctmscomod_status\n\n change status of a miscellaneous \u201cother\u201d type model with the specified model instance.\n\ncctswso_list\n\n list \u201cother\u201d type mode"
  },
  {
    "id": "chunk_034",
    "text": "l instance.\n\ncctswso_list\n\n list \u201cother\u201d type models attached to switched shunts.\n\ncctswsomod_remove\n\n\n\ncctswsomod_remove_2\n\n remove an \u201cother\u201d type model attached to a switched shunt.\n\ncctswsomod_status\n\n\n\ncctswsomod_status_2\n\n change status of an \u201cother\u201d type model attached to a switched shunt.\n\nchange_cct2dcomod_chricn\n\n change the value of a character ICON (i.e., an element of the CHRICN array) of the \u201cother\u201d type model attached to a specified 2-terminal dc line.\n\nchange_cct2dcomod_con\n\n cha"
  },
  {
    "id": "chunk_035",
    "text": "d 2-terminal dc line.\n\nchange_cct2dcomod_con\n\n change the value of a real constant (CON) of the \u201cother\u201d type model attached to a specified 2-terminal dc line.\n\nchange_cct2dcomod_icon\n\n change the value of an integer ICON of the \u201cother\u201d type model attached to a specified 2-terminal dc line.\n\nchange_cct2dcomod_var\n\n change the value of VAR of the \u201cother\u201d type model attached to a specified 2-terminal dc line.\n\nchange_cct2wtdmod_chricn\n\n change the value of a character ICON (i.e., an element of the "
  },
  {
    "id": "chunk_036",
    "text": "alue of a character ICON (i.e., an element of the CHRICN array) of the 2-winding transformer device model of a specified branch.\n\nchange_cct2wtdmod_con\n\n change the value of a real constant (CON) of the 2-winding transformer device model of a specified branch.\n\nchange_cct2wtdmod_icon\n\n change the value of an integer ICON of the 2-winding transformer device model of a specified branch.\n\nchange_cct2wtdmod_var\n\n change the value of VAR of the 2-winding transformer device model of a specified branch"
  },
  {
    "id": "chunk_037",
    "text": "ing transformer device model of a specified branch.\n\nchange_cct3wtdmod_chricn\n\n change the value of a character ICON (i.e., an element of the CHRICN array) of the 3-winding transformer device model of a specified branch.\n\nchange_cct3wtdmod_con\n\n change the value of a real constant (CON) of the 3-winding transformer device model of a specified branch.\n\nchange_cct3wtdmod_icon\n\n change the value of an integer ICON of the 3-winding transformer device model of a specified branch.\n\nchange_cct3wtdmod_v"
  },
  {
    "id": "chunk_038",
    "text": " model of a specified branch.\n\nchange_cct3wtdmod_var\n\n change the value of VAR of the 3-winding transformer device model of a specified branch.\n\nchange_cctbrndmod_chricn\n\n change the value of a character ICON (i.e., an element of the CHRICN array) of the branch device model of a specified branch.\n\nchange_cctbrndmod_con\n\n change the value of a real constant (CON) of the branch device model of a specified branch.\n\nchange_cctbrndmod_icon\n\n change the value of an integer ICON of the branch device mo"
  },
  {
    "id": "chunk_039",
    "text": "e value of an integer ICON of the branch device model of a specified branch.\n\nchange_cctbrndmod_var\n\n change the value of VAR of the branch device model of a specified branch.\n\nchange_cctbrnomod_chricn\n\n change the value of a character ICON (i.e., an element of the CHRICN array) of the branch \u201cother\u201d model of a specified branch.\n\nchange_cctbrnomod_con\n\n change the value of a real constant (CON) of the branch \u201cother\u201d model of a specified branch.\n\nchange_cctbrnomod_icon\n\n change the value of an in"
  },
  {
    "id": "chunk_040",
    "text": "change_cctbrnomod_icon\n\n change the value of an integer ICON of the branch \u201cother\u201d model of a specified branch.\n\nchange_cctbrnomod_var\n\n change the value of VAR of the branch \u201cother\u201d model of a specified branch.\n\nchange_cctbusomod_chricn\n\n change the value of a character ICON (i.e., an element of the CHRICN array) of the \u201cother\u201d type model attached to a specified bus.\n\nchange_cctbusomod_con\n\n change the value of a real constant (CON) of the \u201cother\u201d type model attached to a specified bus.\n\nchange"
  },
  {
    "id": "chunk_041",
    "text": "r\u201d type model attached to a specified bus.\n\nchange_cctbusomod_icon\n\n change the value of an integer ICON of the \u201cother\u201d type model attached to a specified bus.\n\nchange_cctbusomod_var\n\n change the value of VAR of the \u201cother\u201d type model attached to a specified bus.\n\nchange_cctmcnomod_chricn\n\n change the value of a character ICON (i.e., an element of the CHRICN array) of the machine \u201cother\u201d model for a specified machine.\n\nchange_cctmcnomod_con\n\n change the value of a real constant (CON) of the mach"
  },
  {
    "id": "chunk_042",
    "text": "nge the value of a real constant (CON) of the machine \u201cother\u201d model for a specified machine.\n\nchange_cctmcnomod_icon\n\n change the value of an integer ICON of the machine \u201cother\u201d model for a specified machine.\n\nchange_cctmcnomod_var\n\n change the value of VAR of the machine \u201cother\u201d model for a specified machine.\n\nchange_cctmcnpmod_chricn\n\n change the value of a character ICON (i.e., an element of the CHRICN array) of the machine protection model of a specified machine.\n\nchange_cctmcnpmod_con\n\n cha"
  },
  {
    "id": "chunk_043",
    "text": " a specified machine.\n\nchange_cctmcnpmod_con\n\n change the value of a real constant (CON) of the machine protection model of a specified machine.\n\nchange_cctmcnpmod_icon\n\n change the value of an integer ICON of the machine protection model of a specified machine.\n\nchange_cctmcnpmod_var\n\n change the value of VAR of the machine protection model of a specified machine.\n\nchange_cctmscomod_chricn\n\n change the value of a character ICON (i.e., an element of the CHRICN array) of the miscellaneous \u201cother\u201d"
  },
  {
    "id": "chunk_044",
    "text": " of the CHRICN array) of the miscellaneous \u201cother\u201d type model with the specified model instance.\n\nchange_cctmscomod_con\n\n change the value of a real constant (CON) of the miscellaneous \u201cother\u201d type model with the specified model instance.\n\nchange_cctmscomod_icon\n\n change the value of an integer ICON of the miscellaneous \u201cother\u201d type model with the specified model instance.\n\nchange_cctmscomod_var\n\n change the value of VAR of the miscellaneous \u201cother\u201d type model with the specified model instance.\n"
  },
  {
    "id": "chunk_045",
    "text": "er\u201d type model with the specified model instance.\n\nchange_cctswsomod_chricn\n\n\n\nchange_cctswsomod_chricn_2\n\n change the value of a character ICON (i.e., an element of the CHRICN array) of the \u201cother\u201d type model attached to a specified switched shunt.\n\nchange_cctswsomod_con\n\n\n\nchange_cctswsomod_con_2\n\n change the value of a real constant (CON) of the \u201cother\u201d type model attached to a specified switched shunt.\n\nchange_cctswsomod_icon\n\n\n\nchange_cctswsomod_icon_2\n\n change the value of an integer ICON "
  },
  {
    "id": "chunk_046",
    "text": "omod_icon_2\n\n change the value of an integer ICON of the \u201cother\u201d type model attached to a specified switched shunt.\n\nchange_cctswsomod_var\n\n\n\nchange_cctswsomod_var_2\n\n change the value of VAR of the \u201cother\u201d type model attached to a specified switched shunt.\n\n--- Character Data \u2014 .txt ---\n\nCharacter Data \u2014 \n\nCharacter Data\u00b6\n\n\n\n\n\nget_char_length\n\n return the number of characters required to accommodate the data corresponding to the specified STRING entries, which can be for any of the a*Char data "
  },
  {
    "id": "chunk_047",
    "text": " entries, which can be for any of the a*Char data retrieval functions.\n\n--- Dc Line Related Models \u2014 .txt ---\n\nDc Line Related Models \u2014 \n\nDc Line Related Models\u00b6\n\n\n\n\n\nadd_mtdcline_model\n\n add a multi-terminal dc line model to the specified multi-terminal dc line.\n\nadd_ttdcline_model\n\n add a two-terminal dc line model to the specified two-terminal dc line.\n\nadd_vsdcline_model\n\n add a VSC dc line model to the specified VSC dc line.\n\nchange_mtdclmod_chricn\n\n change the value of a character ICON (i."
  },
  {
    "id": "chunk_048",
    "text": "_chricn\n\n change the value of a character ICON (i.e., an element of the CHRICN array) of the multi-terminal dc line model of a specified multi-terminal dc line.\n\nchange_mtdclmod_con\n\n change the value of a CON of the multi-terminal dc line model of a specified multi-terminal dc line.\n\nchange_mtdclmod_data\n\n\n\nchange_mtdclmod_icon\n\n change the value of an integer ICON of the multi-terminal dc line model of a specified multi-terminal dc line.\n\nchange_mtdclmod_var\n\n change the value of a VAR of the "
  },
  {
    "id": "chunk_049",
    "text": "e_mtdclmod_var\n\n change the value of a VAR of the multi-terminal dc line model of a specified multi-terminal dc line.\n\nchange_ttdclmod_chricn\n\n change the value of a character ICON (i.e., an element of the CHRICN array) of the two-terminal dc line model of a specified two-terminal dc line.\n\nchange_ttdclmod_con\n\n change the value of a CON of the two-terminal dc line model of a specified two- terminal dc line.\n\nchange_ttdclmod_data\n\n\n\nchange_ttdclmod_icon\n\n change the value of an integer ICON of t"
  },
  {
    "id": "chunk_050",
    "text": "od_icon\n\n change the value of an integer ICON of the two-terminal dc line model of a specified two-terminal dc line.\n\nchange_ttdclmod_var\n\n change the value of a VAR of the two-terminal dc line model of a specified two- terminal dc line.\n\nchange_vsdclmod_chricn\n\n change the value of a character ICON (i.e., an element of the CHRICN array) of the VSC dc line model of a specified VSC dc line.\n\nchange_vsdclmod_con\n\n change the value of a CON of the VSC dc line model of a specified VSC dc line.\n\nchan"
  },
  {
    "id": "chunk_051",
    "text": "SC dc line model of a specified VSC dc line.\n\nchange_vsdclmod_data\n\n\n\nchange_vsdclmod_icon\n\n change the value of an integer ICON of the VSC dc line model of a specified VSC dc line.\n\nchange_vsdclmod_var\n\n change the value of a VAR of the VSC dc line model of a specified VSC dc line.\n\ndclmod_pack\n\n remove entries that are marked as unused from the dc line model connection tables and the dc line array allocation tables.\n\ndclmod_unconnected\n\n list or remove from dynamics working memory those dc lin"
  },
  {
    "id": "chunk_052",
    "text": "r remove from dynamics working memory those dc line models that are assigned to dc lines that are not present in the current power flow working case (unconnected).\n\ndclmod_user\n\n list user-written dc line model definitions or to remove user-written dc line model definitions that are not assigned to any dc lines (unused) from the user model definition tables.\n\nmtdclmod_remove\n\n remove the multi-terminal dc line model from a specified multi-terminal dc line.\n\nmtdclmod_status\n\n change the status of"
  },
  {
    "id": "chunk_053",
    "text": "l dc line.\n\nmtdclmod_status\n\n change the status of the multi-terminal dc line model at a specified multi- terminal dc line.\n\nttdclmod_remove\n\n remove the two-terminal dc line model from a specified two-terminal dc line.\n\nttdclmod_status\n\n change the status of the two-terminal dc line model at a specified two-terminal end line.\n\nvsdclmod_remove\n\n remove the VSC dc line model from a specified VSC dc line.\n\nvsdclmod_status\n\n change the status of the VSC dc line model at a specified VSC dc line.\n\n--"
  },
  {
    "id": "chunk_054",
    "text": " VSC dc line model at a specified VSC dc line.\n\n--- Diagram View \u2014 .txt ---\n\nDiagram View \u2014 \n\nDiagram View\u00b6\n\n\n\n\n\nchangediagcontour\n\n change the contour parameters for the contour in the active Slider diagram in the GUI.\n\ncheckdiagfile\n\n check the active Slider Diagram in the GUI against the current network case.\n\nclosediagfile\n\n close the active Slider Diagram in the GUI without prompting to save the Diagram.\n\ndeletediagcontour\n\n delete the contour from the active Slider Diagram in the GUI.\n\nena"
  },
  {
    "id": "chunk_055",
    "text": "ur from the active Slider Diagram in the GUI.\n\nenablediagcontour\n\n specify the contour parameters and display a contour in the active Slider Diagram in the GUI.\n\nexportbuslocfile\n\n\n\nexportbuslocfile_2\n\n export the bus location from the active Slider Diagram in the GUI to a file.\n\nexportimagefile\n\n\n\nexportimagefile_2\n\n export an image of the active Slider Diagram in the GUI to a file.\n\ngexmbus\n\n create a GEXM/GOUT display of a bus in an active Slider diagram in the GUI.\n\ngrowbus\n\n GROW a bus in a"
  },
  {
    "id": "chunk_056",
    "text": "der diagram in the GUI.\n\ngrowbus\n\n GROW a bus in an active Slider diagram in the GUI.\n\ngrowbuslevels\n\n GROW a bus and all the connected buses up to the specified number of levels away in an active Slider diagram in the GUI.\n\ngrowdiagram\n\n\n\ngrowdiagram_2\n\n GROW a bus and all the connected buses in an active Slider diagram in the GUI.\n\ngrowstation\n\nThis API routine was first introduced in release 34.\n\ngrpg\n\n produce a GRPG report in the active Slider diagram in the GUI.\n\nimportdrawfile\n\n import a "
  },
  {
    "id": "chunk_057",
    "text": "er diagram in the GUI.\n\nimportdrawfile\n\n import a Draw Data File into an active Slider diagram in the GUI.\n\nimportimagefile\n\n import an image into the background layer of the active Slider diagram in the GUI.\n\nnewdiagfile\n\n open a new Slider diagram in the GUI.\n\nnextdiagfiledataset\n\nThis API is used to display the next element in the active data set on the active Slider diagram.\n\nopenaccfile\n\n\n\nopenaccfile_2\n\nThis API is used to open an existing ACC results file for displaying results on diagram"
  },
  {
    "id": "chunk_058",
    "text": "ACC results file for displaying results on diagram.\n\nopenbuslocfile\n\n open an existing bus location file in the GUI.\n\nopendiagfile\n\n open an existing Slider diagram in the GUI.\n\nprevdiagfiledataset\n\nThis API is used to display the previous element in the active data set on the active Slider diagram.\n\nprintdiagfile\n\n\n\nprintdiagfile_2\n\n print the active Slider diagram in the GUI.\n\nrefreshdiagcontour\n\n refresh the contour in the active Slider diagram in the GUI.\n\nrefreshdiagfile\n\n refresh the resul"
  },
  {
    "id": "chunk_059",
    "text": "m in the GUI.\n\nrefreshdiagfile\n\n refresh the results and styles in the active Slider diagram in the GUI.\n\nrenumdiagfile\n\n renumber buses in the active Slider diagram in the GUI.\n\nsavediagfile\n\n save the active Slider diagram in the GUI.\n\nsetdiagautofile\n\n specify an automation file that is run each time results are updated on the active Slider diagram.\n\nsetdiagfont\n\n specify the default text font in the active Slider diagram.\n\nsetdiagprec\n\n\n\nsetdiagprec_2\n\n specify the precision of results displ"
  },
  {
    "id": "chunk_060",
    "text": "iagprec_2\n\n specify the precision of results displayed in Slider Diagrams.\n\nsetdiagprop\n\n\n\nsetdiagprop_2\n\n\n\nsetdiagprop_3\n\n\n\nsetdiagprop_4\n\n\n\nsetdiagprop_5\n\n specify basic properties in the active Slider diagram.\n\nsetdiagresaccc\n\n\n\nsetdiagresaccc_2\n\n\n\nsetdiagresaccc_3\n\n set the ACCC analysis annotation options in the active Slider diagram.\n\nsetdiagresascc\n\n\n\nsetdiagresascc_2\n\n\n\nsetdiagresascc_3\n\nThis API is used to set the ASCC short circuit analysis annotation options in the active Slider diagr"
  },
  {
    "id": "chunk_061",
    "text": "ysis annotation options in the active Slider diagram.\n\nsetdiagresdata\n\n\n\nsetdiagresdata_2\n\n\n\nsetdiagresdata_3\n\n specify the basic Power Flow annotation options in the active Slider Diagram.\n\nsetdiagresdyn\n\n\n\nsetdiagresdyn_2\n\nThis API is used to set the dynamic simulation annotation options in the active Slider diagram.\n\nsetdiagresgdif\n\n specify the case comparison voltage and range checking annotation options in the active Slider diagram.\n\nsetdiagresiec\n\n\n\nsetdiagresiec_2\n\n\n\nsetdiagresiec_3\n\n sp"
  },
  {
    "id": "chunk_062",
    "text": "gresiec\n\n\n\nsetdiagresiec_2\n\n\n\nsetdiagresiec_3\n\n specify the IEC annotation options in the active Slider diagram.\n\nsetdiagresmust\n\nThis API is used to set the MUST simulation annotation options in the active Slider diagram.\n\nsetdiagresopf\n\n\n\nsetdiagresopf_2\n\n\n\nsetdiagresopf_3\n\n specify the OPF annotation options in the active Slider diagram.\n\nsetdiagrespflowcheck\n\n\n\nsetdiagrespflowcheck_2\n\n\n\nsetdiagrespflowcheck_3\n\n specify the Power Flow voltage and range checking annotation options in the activ"
  },
  {
    "id": "chunk_063",
    "text": "and range checking annotation options in the active Slider Diagram.\n\nsetdiagrespflowoptions\n\n\n\nsetdiagrespflowoptions_2\n\n\n\nsetdiagrespflowoptions_3\n\n specify the basic Power Flow annotation options in the active Slider diagram.\n\nsetdiagresrel\n\n\n\nsetdiagresrel_2\n\n\n\nsetdiagresrel_3\n\n specify the reliability annotation options in the active Slider diagram.\n\nsetdiagresscgr\n\n specify the short circuit analysis voltage and range checking annotation options in the active Slider diagram.\n\nsetdiagrestype"
  },
  {
    "id": "chunk_064",
    "text": "ions in the active Slider diagram.\n\nsetdiagrestypeacc\n\n set the type of results displayed in the active Slider diagram to ACCC results.\n\nsetdiagrestypeascc\n\n set the type of results displayed in the active Slider diagram to ASCC fault calculation results.\n\nsetdiagrestypedata\n\n set the type of results displayed in the active Slider diagram to impedance data values.\n\nsetdiagrestypedyn\n\n set the type of results displayed in the active Slider diagram to Dynamics data results.\n\nsetdiagrestypegdif\n\n s"
  },
  {
    "id": "chunk_065",
    "text": " to Dynamics data results.\n\nsetdiagrestypegdif\n\n set the type of results displayed in the active Slider diagram to the differences in values between the current network case and a supplied comparison case.\n\nsetdiagrestypegic\n\n set the type of results displayed in the active Slider diagram to GIC solution results.\n\nsetdiagrestypeharm\n\n set the type of results displayed in the active Slider diagram to Harmonics solution results.\n\nsetdiagrestypeiec\n\n set the type of results displayed in the active "
  },
  {
    "id": "chunk_066",
    "text": "\n set the type of results displayed in the active Slider diagram to IEC Fault calculation results.\n\nsetdiagrestypemust\n\n set the type of results displayed in the active Slider diagram to MUST solution results.\n\nsetdiagrestypeopf\n\n set the type of results displayed in the active Slider diagram to OPF solution results.\n\nsetdiagrestypepflow\n\n set the type of results displayed in the active Slider diagram to Power Flow results.\n\nsetdiagrestyperel\n\n set the type of results displayed in the active Sli"
  },
  {
    "id": "chunk_067",
    "text": "et the type of results displayed in the active Slider diagram to reliability analysis results.\n\nsetdiagrestypescgr\n\n set the type of results displayed in the active Slider diagram to the results of a short circuit analysis.\n\nsetdiagrestypetspf\n\n set the type of results displayed in the active Slider diagram to TSPF solution results.\n\nsetdiagresvrcs\n\n\n\nsetdiagresvrcs_2\n\n specify the system diagram defaults for Voltage coloring and style, Out of Service coloring and style etc.\n\nsetdiagtitle\n\n set "
  },
  {
    "id": "chunk_068",
    "text": "rvice coloring and style etc.\n\nsetdiagtitle\n\n set the title of the active Slider diagram.\n\nswitchdiagfiledataset\n\nThis API is used to rotate through values for the current element in the active data set on the active Slider diagram.\n\nupdatebuslocdiagfile\n\n update bus locations in the active Slider diagram in the GUI using the positions found in the current bus location file.\n\n--- Dynamic Simulation Operation \u2014 .txt ---\n\nDynamic Simulation Operation \u2014 \n\nDynamic Simulation Operation\u00b6\n\n\n\n\n\naddmodel"
  },
  {
    "id": "chunk_069",
    "text": "on \u2014 \n\nDynamic Simulation Operation\u00b6\n\n\n\n\n\naddmodellibrary\n\n add a library to the list to be searched for library models.\n\nastr\n\n calculate and replicates the state variable system matrices in the form required by the Linear Dynamic Analysis Program, LSYSAN (activity ASTR).\n\naulist\n\n list auxiliary signal models that inject signals into dc lines or FACTS devices connected to subsystem buses, along with their storage locations in the dynamics data arrays.\n\nchange_channel_out_file\n\n modify the dyna"
  },
  {
    "id": "chunk_070",
    "text": "arrays.\n\nchange_channel_out_file\n\n modify the dynamic simulation channel output filename in dynamics working memory (see PSSE Program Operation Manual, activity ALTR).\n\nchange_chricn\n\n change the value of an element of the CHRICN array (a character ICON).\n\nchange_con\n\n change the value of an element of the CON array.\n\nchange_gref\n\n change the value of the element of the GREF (governor reference) array associated with a specified machine.\n\nchange_icon\n\n change the value of an element of the ICON "
  },
  {
    "id": "chunk_071",
    "text": "icon\n\n change the value of an element of the ICON array (an integer ICON).\n\nchange_state\n\n change the value of an element of the STATE array, as well as the values of the corresponding time derivative (DSTATE) and the associated memory cell used in the integration algorithm (STORE).\n\nchange_swsref\n\n\n\nchange_swsref_2\n\n change the value of the element of the SWREF array associated with a specified switched shunt.\n\nchange_var\n\n change the value of an element of the VAR array.\n\nchange_vref\n\n change "
  },
  {
    "id": "chunk_072",
    "text": "n element of the VAR array.\n\nchange_vref\n\n change the value of the element of the VREF array associated with a specified machine.\n\ncrctrun\n\n run critical clearing time calculation in dynamic simulations.\n\ndclist\n\n list dc line models connected to subsystem buses along with their storage locations in the dynamics data arrays.\n\ndlst\n\n tabulate specified portions of one or more of the PSSE dynamics data storage arrays.\n\ndocu\n\n tabulate the data associated with equipment models referenced in the use"
  },
  {
    "id": "chunk_073",
    "text": "ciated with equipment models referenced in the user\u2019s simulation setup.\n\ndropmodellibrary\n\n remove a library from the list being searched for library models.\n\ndropmodelprogram\n\n remove a model from the list of known library models; library models are added to this list the first time that they are called.\n\ndyda\n\n replicate dynamics model data in the form of a Dynamics Data Input file.\n\ndynamics_solution_param_2\n\n modify the dynamic simulation solution parameters (except the channel output filena"
  },
  {
    "id": "chunk_074",
    "text": "ution parameters (except the channel output filename) in dynamics working memory (see PSSE Program Operation Manual, activity ALTR).\n\ndynamics_solution_params\n\n\n\ndynamicsmode\n\n return PSSE to dynamics mode following the use of the POWERFLOWMODE API while in dynamics mode.\n\ndynexportcsv\n\n export dynamics engine and dynamics model messages that are displayed after running a dynamics simulation to CSV file format.\n\ndyre_add\n\n read a Dynamics Model Raw Data File and append the model references speci"
  },
  {
    "id": "chunk_075",
    "text": "aw Data File and append the model references specified in its data records to the simulation data already contained in dynamics working memory (activity DYRE,ADD).\n\ndyre_new\n\n clear dynamics working memory, read a Dynamics Data File, and place the model references specified on its data records into dynamics working memory.\n\nerun\n\n calculate PSSE state-space dynamic simulations of excitation system response tests.\n\nestr_open_circuit_test\n\n initialize a PSSE dynamic simulation for excitation syste"
  },
  {
    "id": "chunk_076",
    "text": "ize a PSSE dynamic simulation for excitation system open circuit response simulations (i.e., in preparation for activity ERUN) and to specify the Channel Output File into which the output channel values are to be recorded during the simulation.\n\nestr_response_ratio_test\n\n initialize a PSSE dynamic simulation for excitation system response ratio test simulations (i.e., in preparation for activity ERUN) and to specify the Channel Output File into which the output channel values are to be recorded "
  },
  {
    "id": "chunk_077",
    "text": "hich the output channel values are to be recorded during the simulation.\n\nfclist\n\n list FACTS device models connected to subsystem buses along with their storage locations in the dynamics data arrays.\n\ngrun\n\n calculate PSSE state-space dynamic simulations of turbine-governor response tests.\n\ngstr\n\n initialize a PSSE dynamic simulation for governor response simulations and to specify the Channel Output File into which the output channel values are to be recorded during the simulation.\n\nincrement_"
  },
  {
    "id": "chunk_078",
    "text": " to be recorded during the simulation.\n\nincrement_gref\n\n add a specified value to the value of the element of the GREF (governor reference) array associated with a specified machine.\n\nincrement_swsref\n\n\n\nincrement_swsref_2\n\n add a specified value to the value of the element of the SWREF (switched shunt reference) array associated with a specified switched shunt.\n\nincrement_vref\n\n add a specified value to the value of the element of the VREF (voltage reference) array associated with a specified m"
  },
  {
    "id": "chunk_079",
    "text": "age reference) array associated with a specified machine.\n\nldclist\n\n list load models connected to subsystem loads along with their storage locations in the dynamics data arrays.\n\nldlist\n\n list load models connected to subsystem loads along with their storage locations in the dynamics data arrays.\n\nload_array_channel\n\n add an output channel containing the active or reactive component of a designated load.\n\nmlst\n\n list plant models connected to subsystem machines along with their storage location"
  },
  {
    "id": "chunk_080",
    "text": "bsystem machines along with their storage locations in the dynamics data arrays.\n\nmrun\n\n calculate PSSE extended term dynamic simulations.\n\nmstr\n\n initialize a PSSE dynamic simulation for extended term simulations and to specify the Channel Output File into which the output channel values are to be recorded during the dynamic simulation.\n\npowerflowmode\n\n switch PSSE from dynamics mode to power flow mode.\n\npsas\n\n convert a PSAS Command File into a PSSE Response File.\n\nrllist\n\n list line relay mod"
  },
  {
    "id": "chunk_081",
    "text": " PSSE Response File.\n\nrllist\n\n list line relay models connected to subsystem buses along with their storage locations in the dynamics data arrays.\n\nrstr\n\n read a dynamics Snapshot File into PSSE working memory.\n\nrun\n\n calculate PSSE state-space dynamic simulations.\n\nrwdy\n\n replicate portions of dynamics model data in the form of either a breaker duty data file, unit inertia and governor data file, or PSSPLT relay characteristic data file.\n\nset_chnfil_type\n\n set/Get the channel output file type ("
  },
  {
    "id": "chunk_082",
    "text": "nfil_type\n\n set/Get the channel output file type (extended type or not).\n\nset_disable_run\n\n enable or disable the simulation option setting that precludes dynamic simulation runs in the event there are fatal errors in the model data.\n\nset_freq_relay_v_thresh\n\nThis API is used to set voltage threshold for use in frequency relay models.\n\nset_genang\n\n\n\nset_genang_2\n\n\n\nset_genang_3\n\n enable or disable the simulation option setting that scans for generators for which the angle differs from the angula"
  },
  {
    "id": "chunk_083",
    "text": "rators for which the angle differs from the angular average by more than a specified threshold.\n\nset_genang_subsys_flag\n\nUse this API api for get/set the flag that is used for the subsystem defintion for performing scan for generators exceeding angle threshold.\n\nset_genpwr\n\n enable or disable the simulation option setting that scans for generators for which the mechanical power differs from its electrical power by more than a specified threshold.\n\nset_genspdev\n\n enable or disable the simulation "
  },
  {
    "id": "chunk_084",
    "text": "\n\nset_genspdev\n\n enable or disable the simulation option setting that scans for generators for which the speed deviation is more than a specified threshold.\n\nset_genspdev_subsys_flag\n\nUse this API api for get/set the flag that is used for the subsystem defintion for performing scans for generators for which the speed deviation is more than a specified threshold.\n\nset_load_model_thresh\n\nThis API is used to set the MW, P over Q, and load bus voltage thresholds for load models.\n\nset_model_debug_out"
  },
  {
    "id": "chunk_085",
    "text": "e thresholds for load models.\n\nset_model_debug_output_flag\n\n enable or disable the simulation option setting for dynamic model debug output.\n\nset_netfrq\n\n enable or disable the simulation option setting that models the frequency dependence of network parameters.\n\nset_next_channel\n\n assign the next available channel index value.\n\nset_next_icon\n\n assign the next available ICON index value.\n\nset_next_var\n\n assign the next available VAR index value.\n\nset_osscan\n\n enable or disable the simulation opt"
  },
  {
    "id": "chunk_086",
    "text": "\nset_osscan\n\n enable or disable the simulation option setting that scans for out-of-step conditions using a generic relay.\n\nset_osscan_2\n\n\n\nset_osscan_subsys_flag\n\nUse this API api for get/set the flag that is used for the subsystem defintion for performing scans for out-of-step conditions using a generic relay.\n\nset_relang\n\n enable or disable the simulation option setting that expresses the ANGLE array relative to a designated reference angle.\n\nset_relscn\n\n enable or disable the simulation opti"
  },
  {
    "id": "chunk_087",
    "text": "set_relscn\n\n enable or disable the simulation option setting that scans branches using a generic branch relay.\n\nset_relscn_subsys_flag\n\nUse this API api for get/set the flag that is used for the subsystem defintion for performing scans of branches using a generic branch relay.\n\nset_vltscn\n\n enable or disable the simulation option setting that scans buses for high or low values of voltage magnitude.\n\nset_vltscn_subsys_flag\n\nUse this API api for get/set the flag that is used for the subsystem defi"
  },
  {
    "id": "chunk_088",
    "text": "t/set the flag that is used for the subsystem definition for performing scans of buses for high or low voltage magnitudes.\n\nset_volt_viol_subsys_flag\n\nThis API is used to set the flag to denote the bus subsystem to be used for voltage violation (voltage recovery and voltage dip) checks.\n\nset_voltage_dip_check\n\nThis API is used to enable or disable the simulation option setting which scans buses for voltage dip (back-swing).\n\nset_voltage_rec_check\n\nThis API is used to enable or disable the simula"
  },
  {
    "id": "chunk_089",
    "text": "\n\nThis API is used to enable or disable the simulation option setting which scans buses for voltage recovery (primary and secondary recovery).\n\nset_zsorce_reconcile_flag\n\n enable or disable the simulation option setting for automatic ZSORCE reconciliation.\n\nsize_ds\n\n obtain a summary of utilization in the general purpose dynamics data storage arrays as well as in the various model connection and allocation tables contained in dynamics working memory.\n\nsnap\n\n save PSSE dynamics working memory int"
  },
  {
    "id": "chunk_090",
    "text": "ory.\n\nsnap\n\n save PSSE dynamics working memory into a Snapshot file.\n\nstrt\n\n\n\nstrt_2\n\nThis API routine is the second release of the dynamic simulation initialization function.\n\nswslist\n\n list switched shunt models connected to subsystem buses along with their storage locations in the dynamics data arrays.\n\ntrig_volt_violation_check\n\nThis API is used to trigger voltage violation (voltage recovery, voltage dip) checks.\n\nwnlist\n\n list wind models connected to subsystem buses along with their storag"
  },
  {
    "id": "chunk_091",
    "text": "nnected to subsystem buses along with their storage locations in the dynamics data arrays.\n\n--- Dynamic Simulation Output Channel Operation \u2014 .txt ---\n\nDynamic Simulation Output Channel Operation \u2014 \n\nDynamic Simulation Output Channel Operation\u00b6\n\n\n\n\n\nchange_channel\n\n change the channel address and the channel identifier of a specified output channel.\n\nchsb\n\n specify, on a subsystem basis, the simulation variables to monitor during dynamic simulation runs (activity CHSB).\n\ncrt_plot_channel\n\n  assi"
  },
  {
    "id": "chunk_092",
    "text": "on runs (activity CHSB).\n\ncrt_plot_channel\n\n  assign one of the main simulation output channels to a designated CRT plot channel.\n\ndelete_all_plot_channels\n\n delete all the plot channels in the working case.\n\ndmpc\n\n replicate the output channel specifications from dynamics working memory in the form of a response file suitable for transferring them to another snapshot that models essentially the same system.\n\nlist_channel_models\n\n tabulate the output channel monitoring models referenced in the d"
  },
  {
    "id": "chunk_093",
    "text": "tput channel monitoring models referenced in the dynamic model.\n\nremove_unused_chan_models\n\n delete from the output channel monitoring model table those model references indicating equipment that is not present in the power flow working case.\n\n--- Event Studies \u2014 .txt ---\n\nEvent Studies \u2014 \n\nEvent Studies\u00b6\n\n\n\n\n\ncloseeventstudyfile\n\n close an open Event Study file.\n\nopeneventstudyfile\n\n open a new or existing event study file in the GUI.\n\nrundynamiceventstudy\n\n run a dynamic study using the active"
  },
  {
    "id": "chunk_094",
    "text": "ceventstudy\n\n run a dynamic study using the active event study in the open event study file.\n\nrunpowerfloweventstudy\n\n run a power flow study using the active event study in the open event study file.\n\nsaveeventstudyfile\n\n save existing event studies in an event study file.\n\nsetactiveeventstudy\n\n select an Event Study in an Event file as the active Event Study for running dynamic or power flow event studies.\n\n--- Extension Data Access \u2014 .txt ---\n\nExtension Data Access \u2014 \n\nExtension Data Access\u00b6\n"
  },
  {
    "id": "chunk_095",
    "text": "\nExtension Data Access \u2014 \n\nExtension Data Access\u00b6\n\n\n\n\n\nget_ext_acline_char\n\n get ac line character extension data.\n\nget_ext_acline_int\n\n get ac line integer extension data.\n\nget_ext_acline_logical\n\n get ac line logical extension data.\n\nget_ext_acline_real\n\n get ac line real extension data.\n\nget_ext_area_char\n\n get area character extension data.\n\nget_ext_area_int\n\n get area integer extension data.\n\nget_ext_area_logical\n\n get area logical extension data.\n\nget_ext_area_real\n\n get area real extensio"
  },
  {
    "id": "chunk_096",
    "text": " data.\n\nget_ext_area_real\n\n get area real extension data.\n\nget_ext_bus_char\n\n get bus character extension data.\n\nget_ext_bus_int\n\n get bus integer extension data.\n\nget_ext_bus_logical\n\n get bus logical extension data.\n\nget_ext_bus_real\n\n get bus real extension data.\n\nget_ext_char\n\n get character extension data.\n\nget_ext_facts_char\n\n get facts device character extension data.\n\nget_ext_facts_int\n\n get facts device integer extension data.\n\nget_ext_facts_logical\n\n get facts device logical extension "
  },
  {
    "id": "chunk_097",
    "text": "acts_logical\n\n get facts device logical extension data.\n\nget_ext_facts_real\n\n get facts device real extension data.\n\nget_ext_fixshunt_char\n\n get fixed shunt character extension data.\n\nget_ext_fixshunt_int\n\n get fixed shunt integer extension data.\n\nget_ext_fixshunt_logical\n\n get fixed shunt logical extension data.\n\nget_ext_fixshunt_real\n\n get fixed shunt real extension data.\n\nget_ext_generator_char\n\n get generator character extension data.\n\nget_ext_generator_int\n\n get generator integer extension "
  },
  {
    "id": "chunk_098",
    "text": "t_generator_int\n\n get generator integer extension data.\n\nget_ext_generator_logical\n\n get generator logical extension data.\n\nget_ext_generator_real\n\n get generator real extension data.\n\nget_ext_gne_char\n\n get general network element device character extension data.\n\nget_ext_gne_int\n\n get general network element device integer extension data.\n\nget_ext_gne_logical\n\n get general network element device logical extension data.\n\nget_ext_gne_real\n\n get general network element device real extension data."
  },
  {
    "id": "chunk_099",
    "text": "eneral network element device real extension data.\n\nget_ext_iatrans_char\n\n get inter-area transfer character extension data.\n\nget_ext_iatrans_int\n\n get inter-area transfer integer extension data.\n\nget_ext_iatrans_logical\n\n get inter-area transfer logical extension data.\n\nget_ext_iatrans_real\n\n get inter-area transfer real extension data.\n\nget_ext_indmach_char\n\n get induction machine character extension data.\n\nget_ext_indmach_int\n\n get induction machine integer extension data.\n\nget_ext_indmach_lo"
  },
  {
    "id": "chunk_100",
    "text": "achine integer extension data.\n\nget_ext_indmach_logical\n\n get induction machine logical extension data.\n\nget_ext_indmach_real\n\n get induction machine real extension data.\n\nget_ext_int\n\n get integer extension data.\n\nget_ext_load_char\n\n get load character extension data.\n\nget_ext_load_int\n\n get load integer extension data.\n\nget_ext_load_logical\n\n get load logical extension data.\n\nget_ext_load_real\n\n get load real extension data.\n\nget_ext_logical\n\n get logical extension data.\n\nget_ext_msline_char\n\n"
  },
  {
    "id": "chunk_101",
    "text": "get logical extension data.\n\nget_ext_msline_char\n\n get multi-section line character extension data.\n\nget_ext_msline_int\n\n get multi-section line integer extension data.\n\nget_ext_msline_logical\n\n get multi-section line logical extension data.\n\nget_ext_msline_real\n\n get multi-section line real extension data.\n\nget_ext_ntermdc_char\n\n get multi-terminal dc line character extension data.\n\nget_ext_ntermdc_int\n\n get multi-terminal dc line integer extension data.\n\nget_ext_ntermdc_logical\n\n get multi-ter"
  },
  {
    "id": "chunk_102",
    "text": "ion data.\n\nget_ext_ntermdc_logical\n\n get multi-terminal dc line logical extension data.\n\nget_ext_ntermdc_real\n\n get multi-terminal dc line real extension data.\n\nget_ext_owner_char\n\n get owner character extension data.\n\nget_ext_owner_int\n\n get owner integer extension data.\n\nget_ext_owner_logical\n\n get owner logical extension data.\n\nget_ext_owner_real\n\n get owner real extension data.\n\nget_ext_rating_char\n\n get rating character extension data.\n\nget_ext_rating_int\n\n get rating integer extension data"
  },
  {
    "id": "chunk_103",
    "text": "ext_rating_int\n\n get rating integer extension data.\n\nget_ext_rating_logical\n\n get rating logical extension data.\n\nget_ext_rating_real\n\n get rating real extension data.\n\nget_ext_real\n\n get real extension data.\n\nget_ext_rowcount\n\n get extension data table row count.\n\nget_ext_sub_char\n\n get substation character extension data.\n\nget_ext_sub_int\n\n get substation integer extension data.\n\nget_ext_sub_logical\n\n get substation logical extension data.\n\nget_ext_sub_real\n\n get substation real extension data"
  },
  {
    "id": "chunk_104",
    "text": "_ext_sub_real\n\n get substation real extension data.\n\nget_ext_subnode_char\n\n get substation node character extension data.\n\nget_ext_subnode_int\n\n get substation node integer extension data.\n\nget_ext_subnode_logical\n\n get substation node logical extension data.\n\nget_ext_subnode_real\n\n get substation node real extension data.\n\nget_ext_subswd_char\n\n get substation switching device character extension data.\n\nget_ext_subswd_int\n\n get substation switching device integer extension data.\n\nget_ext_subswd_"
  },
  {
    "id": "chunk_105",
    "text": "ng device integer extension data.\n\nget_ext_subswd_logical\n\n get substation switching device logical extension data.\n\nget_ext_subswd_real\n\n get substation switching device real extension data.\n\nget_ext_swshunt_char\n\n get switched shunt character extension data.\n\nget_ext_swshunt_int\n\n get switched shunt integer extension data.\n\nget_ext_swshunt_logical\n\n get switched shunt logical extension data.\n\nget_ext_swshunt_real\n\n get switched shunt real extension data.\n\nget_ext_sysswd_char\n\n get system switc"
  },
  {
    "id": "chunk_106",
    "text": "sion data.\n\nget_ext_sysswd_char\n\n get system switching device character extension data.\n\nget_ext_sysswd_int\n\n get system switching device integer extension data.\n\nget_ext_sysswd_logical\n\n get system switching device logical extension data.\n\nget_ext_sysswd_real\n\n get system switching device real extension data.\n\nget_ext_transformer_char\n\n get transformer character extension data.\n\nget_ext_transformer_int\n\n get transformer integer extension data.\n\nget_ext_transformer_logical\n\n get transformer logi"
  },
  {
    "id": "chunk_107",
    "text": "get_ext_transformer_logical\n\n get transformer logical extension data.\n\nget_ext_transformer_real\n\n get transformer real extension data.\n\nget_ext_twotermdc_char\n\n get two-terminal dc line character extension data.\n\nget_ext_twotermdc_int\n\n get two-terminal dc line integer extension data.\n\nget_ext_twotermdc_logical\n\n get two-terminal dc line logical extension data.\n\nget_ext_twotermdc_real\n\n get two-terminal dc line real extension data.\n\nget_ext_vscdc_char\n\n get voltage source converter dc line chara"
  },
  {
    "id": "chunk_108",
    "text": "_char\n\n get voltage source converter dc line character extension data.\n\nget_ext_vscdc_int\n\n get voltage source converter dc line integer extension data.\n\nget_ext_vscdc_logical\n\n get voltage source converter dc line logical extension data.\n\nget_ext_vscdc_real\n\n get voltage source converter dc line real extension data.\n\nget_ext_zone_char\n\n get zone character extension data.\n\nget_ext_zone_int\n\n get zone integer extension data.\n\nget_ext_zone_logical\n\n get zone logical extension data.\n\nget_ext_zone_r"
  },
  {
    "id": "chunk_109",
    "text": "\n get zone logical extension data.\n\nget_ext_zone_real\n\n get zone real extension data.\n\nset_ext_acline_char\n\n set ac line character extension data.\n\nset_ext_acline_int\n\n set ac line integer extension data.\n\nset_ext_acline_logical\n\n set ac line logical extension data.\n\nset_ext_acline_real\n\n set ac line real extension data.\n\nset_ext_area_char\n\n set area character extension data.\n\nset_ext_area_int\n\n set area integer extension data.\n\nset_ext_area_logical\n\n set area logical extension data.\n\nset_ext_ar"
  },
  {
    "id": "chunk_110",
    "text": "cal\n\n set area logical extension data.\n\nset_ext_area_real\n\n set area real extension data.\n\nset_ext_bus_char\n\n set bus character extension data.\n\nset_ext_bus_int\n\n set bus integer extension data.\n\nset_ext_bus_logical\n\n set bus logical extension data.\n\nset_ext_bus_real\n\n set bus real extension data.\n\nset_ext_char\n\n set character extension data.\n\nset_ext_facts_char\n\n set facts device character extension data.\n\nset_ext_facts_int\n\n set facts device integer extension data.\n\nset_ext_facts_logical\n\n set"
  },
  {
    "id": "chunk_111",
    "text": "teger extension data.\n\nset_ext_facts_logical\n\n set facts device logical extension data.\n\nset_ext_facts_real\n\n set facts device real extension data.\n\nset_ext_fixshunt_char\n\n set fixed shunt character extension data.\n\nset_ext_fixshunt_int\n\n set fixed shunt integer extension data.\n\nset_ext_fixshunt_logical\n\n set fixed shunt logical extension data.\n\nset_ext_fixshunt_real\n\n set fixed shunt real extension data.\n\nset_ext_generator_char\n\n set generator character extension data.\n\nset_ext_generator_int\n\n "
  },
  {
    "id": "chunk_112",
    "text": "haracter extension data.\n\nset_ext_generator_int\n\n set generator integer extension data.\n\nset_ext_generator_logical\n\n set generator logical extension data.\n\nset_ext_generator_real\n\n set generator real extension data.\n\nset_ext_gne_char\n\n set general network element device character extension data.\n\nset_ext_gne_int\n\n set general network element device integer extension data.\n\nset_ext_gne_logical\n\n set general network element device logical extension data.\n\nset_ext_gne_real\n\n set general network ele"
  },
  {
    "id": "chunk_113",
    "text": " data.\n\nset_ext_gne_real\n\n set general network element device real extension data.\n\nset_ext_iatrans_char\n\n set inter-area transfer character extension data.\n\nset_ext_iatrans_int\n\n set inter-area transfer integer extension data.\n\nset_ext_iatrans_logical\n\n set inter-area transfer logical extension data.\n\nset_ext_iatrans_real\n\n set inter-area transfer real extension data.\n\nset_ext_indmach_char\n\n set induction machine character extension data.\n\nset_ext_indmach_int\n\n set induction machine integer ext"
  },
  {
    "id": "chunk_114",
    "text": "xt_indmach_int\n\n set induction machine integer extension data.\n\nset_ext_indmach_logical\n\n set induction machine logical extension data.\n\nset_ext_indmach_real\n\n set induction machine real extension data.\n\nset_ext_int\n\n set integer extension data.\n\nset_ext_load_char\n\n set load character extension data.\n\nset_ext_load_int\n\n set load integer extension data.\n\nset_ext_load_logical\n\n set load logical extension data.\n\nset_ext_load_real\n\n set load real extension data.\n\nset_ext_logical\n\n set logical extens"
  },
  {
    "id": "chunk_115",
    "text": "ension data.\n\nset_ext_logical\n\n set logical extension data.\n\nset_ext_msline_char\n\n set multi-section line character extension data.\n\nset_ext_msline_int\n\n set multi-section line integer extension data.\n\nset_ext_msline_logical\n\n set multi-section line logical extension data.\n\nset_ext_msline_real\n\n set multi-section line real extension data.\n\nset_ext_ntermdc_char\n\n set multi-terminal dc line character extension data.\n\nset_ext_ntermdc_int\n\n set multi-terminal dc line integer extension data.\n\nset_ext"
  },
  {
    "id": "chunk_116",
    "text": "-terminal dc line integer extension data.\n\nset_ext_ntermdc_logical\n\n set multi-terminal dc line logical extension data.\n\nset_ext_ntermdc_real\n\n set multi-terminal dc line real extension data.\n\nset_ext_owner_char\n\n set owner character extension data.\n\nset_ext_owner_int\n\n set owner integer extension data.\n\nset_ext_owner_logical\n\n set owner logical extension data.\n\nset_ext_owner_real\n\n set owner real extension data.\n\nset_ext_rating_char\n\n set rating character extension data.\n\nset_ext_rating_int\n\n s"
  },
  {
    "id": "chunk_117",
    "text": " character extension data.\n\nset_ext_rating_int\n\n set rating integer extension data.\n\nset_ext_rating_logical\n\n set rating logical extension data.\n\nset_ext_rating_real\n\n set rating real extension data.\n\nset_ext_real\n\n set real extension data.\n\nset_ext_sub_char\n\n set substation character extension data.\n\nset_ext_sub_int\n\n set substation integer extension data.\n\nset_ext_sub_logical\n\n set substation logical extension data.\n\nset_ext_sub_real\n\n set substation real extension data.\n\nset_ext_subnode_char\n"
  },
  {
    "id": "chunk_118",
    "text": "tation real extension data.\n\nset_ext_subnode_char\n\n set substation node character extension data.\n\nset_ext_subnode_int\n\n set substation node integer extension data.\n\nset_ext_subnode_logical\n\n set substation node logical extension data.\n\nset_ext_subnode_real\n\n set substation node real extension data.\n\nset_ext_subswd_char\n\n set substation switching device character extension data.\n\nset_ext_subswd_int\n\n set substation switching device integer extension data.\n\nset_ext_subswd_logical\n\n set substation"
  },
  {
    "id": "chunk_119",
    "text": "ion data.\n\nset_ext_subswd_logical\n\n set substation switching device logical extension data.\n\nset_ext_subswd_real\n\n set substation switching device real extension data.\n\nset_ext_swshunt_char\n\n set switched shunt character extension data.\n\nset_ext_swshunt_int\n\n set switched shunt integer extension data.\n\nset_ext_swshunt_logical\n\n set switched shunt logical extension data.\n\nset_ext_swshunt_real\n\n set switched shunt real extension data.\n\nset_ext_sysswd_char\n\n set system switching device character ex"
  },
  {
    "id": "chunk_120",
    "text": "wd_char\n\n set system switching device character extension data.\n\nset_ext_sysswd_int\n\n set system switching device integer extension data.\n\nset_ext_sysswd_logical\n\n set system switching device logical extension data.\n\nset_ext_sysswd_real\n\n set system switching device real extension data.\n\nset_ext_transformer_char\n\n set transformer character extension data.\n\nset_ext_transformer_int\n\n set transformer integer extension data.\n\nset_ext_transformer_logical\n\n set transformer logical extension data.\n\nset"
  },
  {
    "id": "chunk_121",
    "text": "cal\n\n set transformer logical extension data.\n\nset_ext_transformer_real\n\n set transformer real extension data.\n\nset_ext_twotermdc_char\n\n set two-terminal dc line character extension data.\n\nset_ext_twotermdc_int\n\n set two-terminal dc line integer extension data.\n\nset_ext_twotermdc_logical\n\n set two-terminal dc line logical extension data.\n\nset_ext_twotermdc_real\n\n set two-terminal dc line real extension data.\n\nset_ext_vscdc_char\n\n set voltage source converter dc line character extension data.\n\nse"
  },
  {
    "id": "chunk_122",
    "text": "ce converter dc line character extension data.\n\nset_ext_vscdc_int\n\n set voltage source converter dc line integer extension data.\n\nset_ext_vscdc_logical\n\n set voltage source converter dc line logical extension data.\n\nset_ext_vscdc_real\n\n set voltage source converter dc line real extension data.\n\nset_ext_zone_char\n\n set zone character extension data.\n\nset_ext_zone_int\n\n set zone integer extension data.\n\nset_ext_zone_logical\n\n set zone logical extension data.\n\nset_ext_zone_real\n\n set zone real exte"
  },
  {
    "id": "chunk_123",
    "text": "sion data.\n\nset_ext_zone_real\n\n set zone real extension data.\n\n--- Facts Device Bus Data \u2014 .txt ---\n\nFacts Device Bus Data \u2014 \n\nFacts Device Bus Data\u00b6\n\n\n\n\n\nafactsbuschar\n\n return an array of character values for subsystem FACTS device buses.\n\nafactsbuscount\n\n return the number of array entries required to accommodate the data to be returned by the remaining members of the FACTS device bus data family.\n\nafactsbuscplx\n\n return an array of complex values for subsystem FACTS device buses.\n\nafactsbusi"
  },
  {
    "id": "chunk_124",
    "text": "lues for subsystem FACTS device buses.\n\nafactsbusint\n\n return an array of integer values for subsystem FACTS device buses.\n\nafactsbusreal\n\n return an array of real values for subsystem FACTS device buses.\n\nafactsbustypes\n\n return an array of character values indicating the data types corresponding to a set of specified STRING values that are valid input values to any of the data retrieval routines of the FACTS device bus data family (aFactsBusInt, aFactsBusReal, aFactsBusCplx and aFactsBusChar)."
  },
  {
    "id": "chunk_125",
    "text": ", aFactsBusReal, aFactsBusCplx and aFactsBusChar).\n\n--- Facts Device Data \u2014 .txt ---\n\nFacts Device Data \u2014 \n\nFacts Device Data\u00b6\n\n\n\n\n\nafactschar\n\n return an array of character values for subsystem FACTS devices.\n\nafactscount\n\n return the number of array entries required to accommodate the data to be returned by the remaining members of the FACTS device data family.\n\nafactscplx\n\n return an array of complex values for subsystem FACTS devices.\n\nafactsint\n\n return an array of integer values for subsys"
  },
  {
    "id": "chunk_126",
    "text": "int\n\n return an array of integer values for subsystem FACTS devices.\n\nafactsreal\n\n return an array of real values for subsystem FACTS devices.\n\nafactstypes\n\n return an array of character values indicating the data types corresponding to a set of specified STRING values that are valid input values to any of the data retrieval routines of the FACTS device data family (aFactsInt, aFactsReal, aFactsCplx and aFactsChar).\n\n--- Facts Device Models \u2014 .txt ---\n\nFacts Device Models \u2014 \n\nFacts Device Models"
  },
  {
    "id": "chunk_127",
    "text": "t ---\n\nFacts Device Models \u2014 \n\nFacts Device Models\u00b6\n\n\n\n\n\nadd_facts_device_model\n\n add a FACTS device model to the specified FACTS device.\n\nchange_fctmod_chricn\n\n change the value of a character ICON (i.e., an element of the CHRICN array) of the FACTS device model of a specified FACTS device.\n\nchange_fctmod_con\n\n change the value of a CON of the FACTS device model of a specified FACTS device.\n\nchange_fctmod_data\n\n\n\nchange_fctmod_icon\n\n change the value of an integer ICON of the FACTS device model"
  },
  {
    "id": "chunk_128",
    "text": "value of an integer ICON of the FACTS device model of a specified FACTS device.\n\nchange_fctmod_var\n\n change the value of a VAR of the FACTS device model of a specified FACTS device.\n\nfctmod_pack\n\n remove entries that are marked as unused from the FACTS device model connection tables and the FACTS device model array allocation tables.\n\nfctmod_remove\n\n remove the FACTS device model from a specified FACTS device.\n\nfctmod_status\n\n change the status of the FACTS device model at a specified FACTS devi"
  },
  {
    "id": "chunk_129",
    "text": "f the FACTS device model at a specified FACTS device.\n\nfctmod_unconnected\n\n list or remove from dynamics working memory those FACTS device models that are assigned to FACTS device that are not present in the current power flow working case (unconnected).\n\nfctmod_user\n\n list user-written FACTS device model definitions or to remove user-written FACTS device model definitions that are not assigned to any FACTS devices (unused) from the user model definition tables.\n\ngmb_add_facts_dev_model\n\n add a "
  },
  {
    "id": "chunk_130",
    "text": "finition tables.\n\ngmb_add_facts_dev_model\n\n add a GMB FACTS device model to the specified FACTS device.\n\n--- Fault Analysis Data \u2014 .txt ---\n\nFault Analysis Data \u2014 \n\nFault Analysis Data\u00b6\n\n\n\n\n\nmbidncs\n\n change the table name of the specified non-conventional source fault contribution table in the working case.\n\nseq_3_wind_grounding_data\n\n modify the zero sequence grounding data of an existing three-winding transformer in the working case (see PSSE Program Operation Manual, Zero Sequence Transforme"
  },
  {
    "id": "chunk_131",
    "text": "Program Operation Manual, Zero Sequence Transformer Data).\n\nseq_3_wind_winding_data\n\n modify the zero sequence impedance data of one winding of an existing three- winding transformer in the working case (see PSSE Program Operation Manual, Zero Sequence Transformer Data).\n\nseq_branch_data\n\n\n\nseq_branch_data_3\n\n modify the zero sequence data of an existing non-transformer branch in the working case (see PSSE Program Operation Manual, Zero Sequence Non-Transformer Branch Data).\n\nseq_bus_data\n\nBus l"
  },
  {
    "id": "chunk_132",
    "text": "Non-Transformer Branch Data).\n\nseq_bus_data\n\nBus load sequence data is now accessible as load sequence data.\n\nseq_fixed_shunt_data\n\n modify the zero sequence data of an existing fixed bus shunt in the working case (see PSSE Program Operation Manual, Zero Sequence Fixed Shunt Data).\n\nseq_induction_mach_data\n\n\n\nseq_induction_mach_data_2\n\nUse this API routine to modify the sequence data of an existing induction machine in the working case (see PSSE Program Operation Manual, Induction Machine Impeda"
  },
  {
    "id": "chunk_133",
    "text": "Program Operation Manual, Induction Machine Impedance Data).\n\nseq_load_data\n\nUse this API routine to modify the sequence data of an existing load in the working case (see PSSE Program Operation Manual, Load Data).\n\nseq_machine_data\n\n\n\nseq_machine_data_3\n\n\n\nseq_machine_data_4\n\nUse this API routine to modify the sequence data of an existing machine in the working case (see PSSE Program Operation Manual, Positive Sequence Generator Impedance Data, Negative Sequence Generator Impedance Data and Zero"
  },
  {
    "id": "chunk_134",
    "text": "egative Sequence Generator Impedance Data and Zero Sequence Generator Impedance Data).\n\nseq_machine_ncs_data\n\nUse this API routine to modify a machine\u2019s existing non-conventional source fault current contribution (NCSFCC) data or to add NCSFCC data to an existing machine in the working case.\n\nseq_machine_ncs_data_purg\n\nUse this API routine to delete a machine\u2019s existing non-conventional source fault current contribution (NCSFCC) data.\n\nseq_mutual_data\n\n modify existing zero sequence mutual imped"
  },
  {
    "id": "chunk_135",
    "text": "_data\n\n modify existing zero sequence mutual impedance data in the working case or to add a new zero sequence mutual coupling to the working case (see PSSE Program Operation Manual, Zero Sequence Mutual Impedance Data).\n\nseq_ncs_flt_cntrb_chng\n\nThis API routine was first introduced in release 34.\n\nseq_ncs_flt_cntrb_data\n\n\n\nseq_ncs_flt_cntrb_purg\n\n\n\nseq_ncs_table_data\n\n modify the data of an existing non-conventional source fault contribution table in the working case or to add a new non-conventi"
  },
  {
    "id": "chunk_136",
    "text": "e in the working case or to add a new non-conventional source fault contribution table to the working case.\n\nseq_ncs_table_onept\n\n modify the one data point of an existing non-conventional source fault contribution table in the working case or to add a new one data point to non-conventional source fault contribution table to the working case.\n\nseq_ncs_table_purg\n\n delete an existing non-conventional source fault contribution table from the working case.\n\nseq_ncs_table_purg_onept\n\n delete specifi"
  },
  {
    "id": "chunk_137",
    "text": "g case.\n\nseq_ncs_table_purg_onept\n\n delete specified data point in an existing non-conventional source fault contribution table.\n\nseq_ncs_table_type\n\n get NCS table type.\n\nseq_switched_shunt_data\n\n\n\nseq_switched_shunt_data_3\n\n modify the zero sequence data of an existing switched shunt in the working case (see PSSE Program Operation Manual, Zero Sequence Switched Shunt Data).\n\nseq_three_winding_data\n\n\n\nseq_three_winding_data_3\n\n modify the zero sequence data of an existing three-winding transfor"
  },
  {
    "id": "chunk_138",
    "text": "equence data of an existing three-winding transformer in the working case.\n\nseq_two_winding_data\n\n\n\nseq_two_winding_data_3\n\n modify the zero sequence data of an existing two-winding transformer in the working case (see PSSE Program Operation Manual, Zero Sequence Transformer Data).\n\n--- Fault Analysis Operation \u2014 .txt ---\n\nFault Analysis Operation \u2014 \n\nFault Analysis Operation\u00b6\n\n\n\n\n\nansi\n\n\n\nansi_2\n\n\n\nansi_3\n\nThis API routine executes the third release of the ANSI fault calculation function.\n\nascc"
  },
  {
    "id": "chunk_139",
    "text": "ease of the ANSI fault calculation function.\n\nascc\n\n\n\nascc_1a\n\n\n\nascc_2\n\n\n\nascc_3\n\nThis API is used to apply a series of faults at various locations in the working case.\n\nascc_scfile\n\nThis API reads ASCC short circuit results from SCFILE and produces same ASCC output report that was generated when SCFILE was created.\n\nbkdy\n\n calculate and report circuit breaker interrupting duty for 3-phase faults at all buses in a specified subsystem of the working case (activity BKDY).\n\ncheck_sequence_data\n\nUs"
  },
  {
    "id": "chunk_140",
    "text": "ing case (activity BKDY).\n\ncheck_sequence_data\n\nUse this API routine to perform data checks on the selected categories of sequence data for all buses in the working case or for all buses in a specified subsystem.\n\nflat\n\n\n\nflat_2\n\nThis API routine is the second release of the flat conditions function.\n\niecs\n\n\n\niecs_2\n\n\n\niecs_3\n\n\n\niecs_4\n\nThis API executes the fourth release of the IEC short circuit calculations function.\n\niecs_scfile\n\nThis API reads IECS short circuit results from SCFILE and prod"
  },
  {
    "id": "chunk_141",
    "text": "ds IECS short circuit results from SCFILE and produces same IECS output report that was generated when SCFILE was created.\n\nnewseq\n\n initialize the fault analysis data arrays, set them to default values, and set the flag indicating that sequence data is present in the working case.\n\nsceq\n\n construct network equivalents of the positive and zero sequence networks and calculates source impedances at equivalent source nodes for all three sequences in preparation for the unbalanced fault analysis act"
  },
  {
    "id": "chunk_142",
    "text": " preparation for the unbalanced fault analysis activities of PSSE.\n\nscgr\n\n\n\nscmu\n\n\n\nscmu_2\n\n calculate simultaneous unbalances.\n\nscop\n\n tabulate unbalanced fault solution output.\n\nseqd\n\n\n\nseqd_2\n\nUse this API routine to factorize the sequence matrices in preparation for unbalanced fault calculations SCMU and SPCB.\n\nsequence_network_setup\n\n specify or return the option to enable or disable automatic fault analysis sequence network setup.\n\nsqex\n\n tabulate all fault analysis data pertaining to a sp"
  },
  {
    "id": "chunk_143",
    "text": "abulate all fault analysis data pertaining to a specified bus.\n\n--- Fixed Shunt Bus Data \u2014 .txt ---\n\nFixed Shunt Bus Data \u2014 \n\nFixed Shunt Bus Data\u00b6\n\n\n\n\n\nafxshntbuschar\n\n return an array of character values for subsystem buses.\n\nafxshntbuscount\n\n return the number of array entries required to accommodate the data to be returned by the remaining members of the fixed shunt bus data family.\n\nafxshntbuscplx\n\n return an array of complex values for subsystem buses.\n\nafxshntbusint\n\n return an array of i"
  },
  {
    "id": "chunk_144",
    "text": "ystem buses.\n\nafxshntbusint\n\n return an array of integer values for subsystem buses.\n\nafxshntbusreal\n\n return an array of real values for subsystem buses.\n\nafxshntbustypes\n\n return an array of character values indicating the data types corresponding to a set of specified STRING values that are valid input values to any of the data retrieval routines of the fixed shunt bus data family (aFxShntBusInt, aFxShntBusReal, aFxShntBusCplx and aFxShntBusChar).\n\n--- Fixed Shunt Data \u2014 .txt ---\n\nFixed Shunt"
  },
  {
    "id": "chunk_145",
    "text": "ar).\n\n--- Fixed Shunt Data \u2014 .txt ---\n\nFixed Shunt Data \u2014 \n\nFixed Shunt Data\u00b6\n\n\n\n\n\nafxshuntchar\n\n return an array of character values for subsystem fixed shunts.\n\nafxshuntcount\n\n return the number of array entries required to accommodate the data to be returned by the remaining members of the fixed shunt data family.\n\nafxshuntcplx\n\n return an array of complex values for subsystem fixed shunts.\n\nafxshuntint\n\n return an array of integer values for subsystem fixed shunts.\n\nafxshuntreal\n\n return an "
  },
  {
    "id": "chunk_146",
    "text": "subsystem fixed shunts.\n\nafxshuntreal\n\n return an array of real values for subsystem fixed shunts.\n\nafxshunttypes\n\n return an array of character values indicating the data types corresponding to a set of specified STRING values that are valid input values to any of the data retrieval routines of the fixed shunt data family (aFxShuntInt, aFxShuntReal, aFxShuntCplx and aFxShuntChar).\n\n--- Gic Data \u2014 .txt ---\n\nGic Data \u2014 \n\nGic Data\u00b6\n\n\n\n\n\ngic_2tdc\n\n modify or add new two terminal dc GIC shunt data t"
  },
  {
    "id": "chunk_147",
    "text": "modify or add new two terminal dc GIC shunt data to the working case.\n\ngic_2tdc_chng\n\n modify new two terminal dc GIC shunt data from the working case.\n\ngic_2tdc_purg\n\n purge new two terminal dc GIC shunt data from the working case.\n\ngic_brn\n\n modify or add new GIC branch data to the working case.\n\ngic_brn_chng\n\n modify new GIC branch data from the working case.\n\ngic_brn_purg\n\n purge GIC branch data from the working case.\n\ngic_earth1d_usr\n\n modify or add new GIC User 1D Earth Model data to the w"
  },
  {
    "id": "chunk_148",
    "text": "y or add new GIC User 1D Earth Model data to the working case.\n\ngic_earth1d_usr_chng\n\n modify GIC User 1D Earth Model data from the working case.\n\ngic_facts\n\n modify or add new FACTS device GIC shunt data to the working case.\n\ngic_facts_chng\n\n modify new FACTS device GIC shunt data from the working case.\n\ngic_facts_purg\n\n purge new FACTS device GIC shunt data from the working case.\n\ngic_fxsh\n\n modify or add new fixed shunt GIC shunt data to the working case.\n\ngic_fxsh_chng\n\n modify fixed shunt G"
  },
  {
    "id": "chunk_149",
    "text": "orking case.\n\ngic_fxsh_chng\n\n modify fixed shunt GIC shunt data from the working case.\n\ngic_fxsh_purg\n\n purge fixed shunt GIC shunt data from the working case.\n\ngic_load\n\n modify or add new load GIC shunt data to the working case.\n\ngic_load_chng\n\n modify load GIC shunt data from the working case.\n\ngic_load_purg\n\n purge load GIC shunt data from the working case.\n\ngic_mtdc\n\n modify or add new multi terminal dc GIC shunt data to the working case.\n\ngic_mtdc_chng\n\n modify new multi terminal dc GIC sh"
  },
  {
    "id": "chunk_150",
    "text": "ic_mtdc_chng\n\n modify new multi terminal dc GIC shunt data from the working case.\n\ngic_mtdc_purg\n\n purge new multi terminal dc GIC shunt data from the working case.\n\ngic_substn\n\n modify or add new GIC sub station data to the working case.\n\ngic_substn_chng\n\n modify GIC sub station data to the working case.\n\ngic_substn_purg\n\n purge GIC sub station data to the working case.\n\ngic_swsh\n\n modify or add new GIC switched shunt data to the working case.\n\ngic_swsh_chng\n\n modify GIC switched shunt data fro"
  },
  {
    "id": "chunk_151",
    "text": "gic_swsh_chng\n\n modify GIC switched shunt data from the working case.\n\ngic_swsh_purg\n\n purge GIC switched shunt data from the working case.\n\ngic_trn\n\n modify or add new GIC transformer data to the working case.\n\ngic_trn_chng\n\n modify GIC transformer data to the working case.\n\ngic_trn_purg\n\n purge GIC transformer data from the working case.\n\ngic_vscdc\n\n modify or add new vscdc GIC shunt data to the working case.\n\ngic_vscdc_chng\n\n modify new vscdc GIC shunt data from the working case.\n\ngic_vscdc_p"
  },
  {
    "id": "chunk_152",
    "text": "GIC shunt data from the working case.\n\ngic_vscdc_purg\n\n purge new vscdc GIC shunt data from the working case.\n\n--- Gic Operation \u2014 .txt ---\n\nGic Operation \u2014 \n\nGic Operation\u00b6\n\n\n\n\n\ngic\n\n\n\ngic_2\n\n\n\ngic_3\n\n\n\ngic_4\n\n\n\ngic_5\n\n\n\ngic_6\n\n\n\ngic_7\n\n\n\ngic_8\n\n calculate Geomagnetically Induced Currents (GIC) in electric power system network as a result of Geomagnetic Disturbance (GMD).\n\ngic_branch_efield_nn\n\n calculate geoelectric efield induced in the network branches from specified geoelectric efield grid "
  },
  {
    "id": "chunk_153",
    "text": "k branches from specified geoelectric efield grid data using nearest neigbor (NN) alogorithm.\n\ngic_earth1d_usr_purg\n\n purge GIC User 1D Earth Model data from the working case.\n\ngic_efield_waveshape\n\nFor Transformer Thermal Impact assessement due to geomagnetic disturbance event, set the geoelectric field waveshape as provided in EFLDFILE.\n\ngic_efield_waveshape_ref\n\nFor Transformer Thermal Impact assessement due to geomagnetic disturbance event, set the geoelectric field waveshape as NERC TPL-007"
  },
  {
    "id": "chunk_154",
    "text": "et the geoelectric field waveshape as NERC TPL-007-2 benhcmark event.\n\ngic_efield_waveshape_supp\n\nFor Transformer Thermal Impact assessement due to geomagnetic disturbance event, set the geoelectric field waveshape as NERC TPL-007-2 supplemental event.\n\ngic_mvarloss_scaling_factors\n\nSpecify KFACTORS to determine transformer reactive power losses due to geomagnetic currents (GICs) flow.\n\ngic_new\n\n initialize all data records required for GIC analysis.\n\ngic_pf_options\n\n specify the Newton-Raphson "
  },
  {
    "id": "chunk_155",
    "text": "sis.\n\ngic_pf_options\n\n specify the Newton-Raphson power flow solution options used in GIC.\n\ngic_purg\n\n purge all GIC data from the working case.\n\ngic_read\n\n read GIC Data Text (.gic) File into the working case memory.\n\ngic_read_efield_grid\n\n read Geoelectric Efield Grid Data File into the working case memory.\n\ngic_thermal_impact\n\n\n\ngic_thermal_impact_1\n\n calculate Transformer Thermal Impact assessement GIC(t) curve using specified effective Eastward GIC(E) and Nortward GIC(N) for one specific tr"
  },
  {
    "id": "chunk_156",
    "text": "ard GIC(E) and Nortward GIC(N) for one specific transformer.\n\ngic_write\n\n write working case GIC Data to text (.gic) file.\n\ngic_write_stn\n\n write working case GIC Data to text (.gic) file version 4 that has substation data.\n\n--- Graphical Analysis Output \u2014 .txt ---\n\nGraphical Analysis Output \u2014 \n\nGraphical Analysis Output\u00b6\n\n\n\n\n\npoly_print\n\n print the results of activity POLY from a .pol results file.\n\npv_print\n\n print the results of PV analysis from the .pv results file\n\nqv_print\n\n print the resu"
  },
  {
    "id": "chunk_157",
    "text": "om the .pv results file\n\nqv_print\n\n print the results of QV analysis from a .qv resultsfile.\n\nsetfullviewgrapharea\n\n specify the parameters of the scales used for plotting the results of PV and QV analysis.\n\nsetfullviewscale\n\n specify the parameters of the scales used for plotting the results of PV and QV analysis.\n\n--- Harmonics Data \u2014 .txt ---\n\nHarmonics Data \u2014 \n\nHarmonics Data\u00b6\n\n\n\n\n\nhar_2tdc\n\n modify or add new harmonics Two Terminal DC data to the working case.\n\nhar_2tdc_chng\n\n modify harmon"
  },
  {
    "id": "chunk_158",
    "text": "o the working case.\n\nhar_2tdc_chng\n\n modify harmonics Two Terminal DC data in the working case.\n\nhar_2tdc_purg\n\n purge specified harmonics Two Terminal DC data from the working case.\n\nhar_brn\n\n modify or add new harmonics branch data to the working case.\n\nhar_brn_chng\n\n modify harmonics branch data to the working case.\n\nhar_brn_purg\n\n purge specified harmonics branch data from the working case.\n\nhar_cursrc\n\n modify or add new harmonics current source table data to the working case.\n\nhar_cursrc_c"
  },
  {
    "id": "chunk_159",
    "text": "urce table data to the working case.\n\nhar_cursrc_chng\n\n change harmonics current source table data in the working case.\n\nhar_cursrc_chng_name\n\n change harmonics current source table name in the working case.\n\nhar_cursrc_chng_onept\n\n modify one data point to harmonics current source table in the working case.\n\nhar_cursrc_name\n\n add or change harmonics current source table name in the working case.\n\nhar_cursrc_onept\n\n modify or add new one data point to harmonics current source table in the workin"
  },
  {
    "id": "chunk_160",
    "text": "nt to harmonics current source table in the working case.\n\nhar_cursrc_purg\n\n purge specified harmonics current source table data from the working case.\n\nhar_cursrc_purg_onept\n\n purge specified data point in harmonics current source table.\n\nhar_facts\n\n modify or add new harmonics FACTS device data to the working case.\n\nhar_facts_chng\n\n modify harmonics FACTS device data in the working case.\n\nhar_facts_purg\n\n purge specified harmonics FACTS device data from the working case.\n\nhar_impchar\n\n modify "
  },
  {
    "id": "chunk_161",
    "text": "data from the working case.\n\nhar_impchar\n\n modify or add new harmonics impedance characteristics table data to the working case.\n\nhar_impchar_chng\n\n change harmonics impedance characteristics table data in the working case.\n\nhar_impchar_chng_name\n\n change harmonics impedance characteristics table name in the working case.\n\nhar_impchar_chng_onept\n\n modify one data point to harmonics impedance characteristics table in the working case.\n\nhar_impchar_name\n\n add or change harmonics impedance characte"
  },
  {
    "id": "chunk_162",
    "text": "_name\n\n add or change harmonics impedance characteristics table name in the working case.\n\nhar_impchar_onept\n\n modify or add new one data point to harmonics impedance characteristics table in the working case.\n\nhar_impchar_purg\n\n purge specified harmonics impedance characteristics table data from the working case.\n\nhar_impchar_purg_onept\n\n purge specified data point in harmonics impedance characteristics table.\n\nhar_indmc\n\n modify or add new harmonics induction machine data to the working case.\n"
  },
  {
    "id": "chunk_163",
    "text": "onics induction machine data to the working case.\n\nhar_indmc_chng\n\n modify harmonics induction machine data to the working case.\n\nhar_indmc_purg\n\n purge specified harmonics induction machine data from the working case.\n\nhar_load\n\n modify or add new harmonics load data to the working case.\n\nhar_load_chng\n\n modify harmonics load data to the working case.\n\nhar_load_purg\n\n purge specified harmonics load data from the working case.\n\nhar_mach\n\n modify or add new harmonics machine data to the working c"
  },
  {
    "id": "chunk_164",
    "text": "or add new harmonics machine data to the working case.\n\nhar_mach_chng\n\n modify harmonics machine data to the working case.\n\nhar_mach_purg\n\n purge specified harmonics machine data from the working case.\n\nhar_mtdc\n\n modify or add new harmonics Multi Terminal DC data to the working case.\n\nhar_mtdc_chng\n\n modify harmonics Multi Terminal DC data in the working case.\n\nhar_mtdc_purg\n\n purge specified harmonics Multi Terminal DC data from the working case.\n\nhar_passive_filter\n\n modify or add new harmoni"
  },
  {
    "id": "chunk_165",
    "text": "e.\n\nhar_passive_filter\n\n modify or add new harmonics passive filter data to the working case.\n\nhar_passive_filter_chng\n\n modify harmonics passive filter data in the working case.\n\nhar_passive_filter_purg\n\n purge specified harmonics passive filter data from the working case.\n\nhar_set_par_lodmdl_cigre_measurement\n\n set parameters for harmonics load data user model CIGRE_MEASUREMENT.\n\nhar_set_par_lodmdl_cigre_motive\n\n set parameters for harmonics load data user model CIGRE_MOTIVE.\n\nhar_set_par_lodm"
  },
  {
    "id": "chunk_166",
    "text": "ad data user model CIGRE_MOTIVE.\n\nhar_set_par_lodmdl_cigre_passive\n\n set parameters for harmonics load data user model CIGRE_PASSIVE.\n\nhar_set_par_lodmdl_ieee_2rl_parallel\n\n set parameters for harmonics load data user model IEEE_2RL_PARALLEL.\n\nhar_set_par_lodmdl_ieee_im\n\n set parameters for harmonics load data user model IEEE_IM.\n\nhar_set_par_lodmdl_ieee_measurement\n\n set parameters for harmonics load data user model IEEE_MEASUREMENT.\n\nhar_set_par_lodmdl_ieee_skin\n\n set parameters for harmonics "
  },
  {
    "id": "chunk_167",
    "text": "r_lodmdl_ieee_skin\n\n set parameters for harmonics load data user model IEEE_SKIN.\n\nhar_set_par_lodmdl_large_async_motor\n\n set parameters for harmonics load data user model LARGE_ASYNC_MOTOR.\n\nhar_trn\n\n modify or add new harmonics transformer data to the working case.\n\nhar_trn_chng\n\n modify harmonics transformer data to the working case.\n\nhar_trn_purg\n\n purge specified harmonics transformer data from the working case.\n\nhar_vltsrc\n\n modify or add new harmonics voltage source table data to the work"
  },
  {
    "id": "chunk_168",
    "text": "ew harmonics voltage source table data to the working case.\n\nhar_vltsrc_chng\n\n change harmonics voltage source table data in the working case.\n\nhar_vltsrc_chng_name\n\n change harmonics voltage source table name in the working case.\n\nhar_vltsrc_chng_onept\n\n modify one data point to harmonics voltage source table in the working case.\n\nhar_vltsrc_name\n\n add or change harmonics voltage source table name in the working case.\n\nhar_vltsrc_onept\n\n modify or add new one data point to harmonics voltage sou"
  },
  {
    "id": "chunk_169",
    "text": "or add new one data point to harmonics voltage source table in the working case.\n\nhar_vltsrc_purg\n\n purge specified harmonics voltage source table data from the working case.\n\nhar_vltsrc_purg_onept\n\n purge specified data point in harmonics voltage source table.\n\nhar_vscdc\n\n modify or add new harmonics VSCDC data to the working case.\n\nhar_vscdc_chng\n\n modify harmonics VSCDC data in the working case.\n\nhar_vscdc_purg\n\n purge specified harmonics VSCDC data from the working case.\n\n--- Harmonics Opera"
  },
  {
    "id": "chunk_170",
    "text": "C data from the working case.\n\n--- Harmonics Operation \u2014 .txt ---\n\nHarmonics Operation \u2014 \n\nHarmonics Operation\u00b6\n\n\n\n\n\nhar_analysis\n\n\n\nhar_analysis_2\n\n run harmonics analysis.\n\nhar_create_pfcase\n\n save working case updated for harmonic frequency and passive filters added as fixed shunts.\n\nhar_exists_dstn_results\n\nCheck if Harmonics Distortion Calculation results available in PSSE working memory from previously run harmonic analysis activity.\n\nhar_exists_fscan_results\n\nCheck if Harmonics Frequency "
  },
  {
    "id": "chunk_171",
    "text": "xists_fscan_results\n\nCheck if Harmonics Frequency Scan results available in PSSE working memory from previously run harmonic analysis activity.\n\nhar_export_dstn\n\n export harmonics distortion calculation results to comma separated (.csv) file.\n\nhar_export_fscan\n\n export harmonics frequency scan results to comma separated (.csv) file.\n\nhar_new\n\n initialize all data records required for Harmonics analysis.\n\nhar_purg\n\n purge all harmonics data from the working case.\n\nhar_set_resn_thresholds\n\n set pa"
  },
  {
    "id": "chunk_172",
    "text": "he working case.\n\nhar_set_resn_thresholds\n\n set parameters to filter resonances from harmonic analysis frequency scan response.\n\nhar_set_resn_thresholds_default\n\n set default parameters to filter resonances from harmonic analysis frequency scan response.\n\n--- Induction Machine Bus Data \u2014 .txt ---\n\nInduction Machine Bus Data \u2014 \n\nInduction Machine Bus Data\u00b6\n\n\n\n\n\naindmacbuschar\n\nUse this API routine to return an array of character values for subsystem buses.\n\naindmacbuscount\n\nUse this API routine t"
  },
  {
    "id": "chunk_173",
    "text": "em buses.\n\naindmacbuscount\n\nUse this API routine to obtain the number of array entries required to accommodate the data to be returned by the remaining members of the induction machine bus data family.\n\naindmacbuscplx\n\nUse this API routine to return an array of complex values for subsystem buses.\n\naindmacbusint\n\nUse this API routine to return an array of integer values for subsystem buses.\n\naindmacbusreal\n\nUse this API routine to return an array of real values for subsystem buses.\n\naindmacbustyp"
  },
  {
    "id": "chunk_174",
    "text": "of real values for subsystem buses.\n\naindmacbustypes\n\nUse this API routine to return an array of character values indicating the data types corresponding to a set of specified STRING values that are valid input values to any of the data retrieval routines of the induction machine bus data family (aIndMacBusInt, aIndMacBusReal, aIndMacBusCplx and aIndMacBusChar).\n\n--- Induction Machine Data \u2014 .txt ---\n\nInduction Machine Data \u2014 \n\nInduction Machine Data\u00b6\n\n\n\n\n\naindmacchar\n\nUse this API routine to re"
  },
  {
    "id": "chunk_175",
    "text": "Data\u00b6\n\n\n\n\n\naindmacchar\n\nUse this API routine to return an array of character values for subsystem induction machines.\n\naindmaccount\n\nUse this API routine to obtain the number of array entries required to accommodate the data to be returned by the remaining members of the induction machine data family.\n\naindmaccplx\n\nUse this API routine to return an array of complex values for subsystem induction machines.\n\naindmacint\n\nUse this API routine to return an array of integer values for subsystem induct"
  },
  {
    "id": "chunk_176",
    "text": "rn an array of integer values for subsystem induction machines.\n\naindmacreal\n\nUse this API routine to return an array of real values for subsystem induction machines.\n\naindmactypes\n\nUse this API routine to return an array of character values indicating the data types corresponding to a set of specified STRING values that are valid input values to any of the data retrieval routines of the induction machine data family (aIndMacInt, aIndMacReal, aIndMacCplx and aIndMacChar).\n\n--- Induction Machine "
  },
  {
    "id": "chunk_177",
    "text": "dMacCplx and aIndMacChar).\n\n--- Induction Machine Models \u2014 .txt ---\n\nInduction Machine Models \u2014 \n\nInduction Machine Models\u00b6\n\n\n\n\n\nadd_indmac_model\n\n add an induction machine model to a specified machine.\n\nchange_immod_chricn\n\n change the value of a character ICON (i.e., an element of the CHRICN array) of an induction machine model at a specified machine.\n\nchange_immod_con\n\n change the value of a CON of a designated induction machine model at a specified machine.\n\nchange_immod_icon\n\n change the va"
  },
  {
    "id": "chunk_178",
    "text": "cified machine.\n\nchange_immod_icon\n\n change the value of an integer ICON of a designated induction machine model at a specified machine.\n\nchange_immod_var\n\n change the value of a VAR of a designated induction machine model at a specified machine.\n\nimmod_pack\n\n remove entries that are marked as unused from the induction machine model contables.\n\nimmod_remove\n\n remove an induction machine model of a designated type from a specified machine.\n\nimmod_status\n\n change the status of an induction machine"
  },
  {
    "id": "chunk_179",
    "text": "status\n\n change the status of an induction machine model at a specified machine.\n\nimmod_unconnected\n\n list or remove from dynamics working memory those induction machine models that are assigned to machines that are not present in the current power flow working case (unconnected).\n\nimmod_user\n\n list user-written induction machine model definitions or to remove user-written induction machine model definitions that are not assigned to any machines (unused) from the user model definition tables.\n\n-"
  },
  {
    "id": "chunk_180",
    "text": "(unused) from the user model definition tables.\n\n--- Line Relay Models \u2014 .txt ---\n\nLine Relay Models \u2014 \n\nLine Relay Models\u00b6\n\n\n\n\n\nadd_relay_model\n\n add a line relay model in the designated relay slot of the from bus end of a specified branch.\n\nchange_rlmod_chricn\n\n change the value of a character ICON (i.e., an element of the CHRICN array) of the line relay model in the designated relay slot of the from bus end of a specified branch.\n\nchange_rlmod_con\n\n change the value of a CON of the line relay"
  },
  {
    "id": "chunk_181",
    "text": "_con\n\n change the value of a CON of the line relay model in the designated relay slot of the from bus end of a specified branch.\n\nchange_rlmod_data\n\n\n\nchange_rlmod_icon\n\n change the value of an integer ICON of the line relay model in the designated relay slot of the from bus end of a specified branch.\n\nchange_rlmod_var\n\n change the value of a VAR of the line relay model in the designated relay slot of the from bus end of a specified branch.\n\nrlmod_pack\n\n remove entries that are marked as unused "
  },
  {
    "id": "chunk_182",
    "text": "d_pack\n\n remove entries that are marked as unused from the line relay model connection tables and the line relay model array allocation tables.\n\nrlmod_remove\n\n remove the line relay model in the designated relay slot of the from bus end of a specified branch.\n\nrlmod_status\n\n change the status of the line relay model in the designated relay slot of the from bus end of a specified branch.\n\nrlmod_unconnected\n\n list or remove from dynamics working memory those line relay models that are assigned to "
  },
  {
    "id": "chunk_183",
    "text": "mory those line relay models that are assigned to branches that are not present in the current power flow working case (unconnected).\n\nrlmod_user\n\n list user-written line relay model definitions or to remove user-written line relay model definitions that are not assigned to any branches (unused) from the user model definition tables.\n\n--- Load Bus Data \u2014 .txt ---\n\nLoad Bus Data \u2014 \n\nLoad Bus Data\u00b6\n\n\n\n\n\nalodbuschar\n\n return an array of character values for subsystem buses.\n\nalodbuscount\n\n return t"
  },
  {
    "id": "chunk_184",
    "text": "lues for subsystem buses.\n\nalodbuscount\n\n return the number of array entries required to accommodate the data to be returned by the remaining members of the load bus data family.\n\nalodbuscplx\n\n return an array of complex values for subsystem buses.\n\nalodbusint\n\n return an array of integer values for subsystem buses.\n\nalodbusreal\n\n return an array of real values for subsystem buses.\n\nalodbustypes\n\n return an array of character values indicating the data types corresponding to a set of specified S"
  },
  {
    "id": "chunk_185",
    "text": "e data types corresponding to a set of specified STRING values that are valid input values to any of the data retrieval routines of the load bus data family (aLodBusInt, aLodBusReal, aLodBusCplx and aLodBusChar).\n\n--- Load Component Models \u2014 .txt ---\n\nLoad Component Models \u2014 \n\nLoad Component Models\u00b6\n\n\n\n\n\nadd_loadc_model\n\n add a load component model of a designated type to a specified load or subsystem.\n\nchange_ldmodc_cdesc\n\n change the value of a Model Description of a load component model at a "
  },
  {
    "id": "chunk_186",
    "text": " Model Description of a load component model at a specified load or subsystem).\n\nchange_ldmodc_chricn\n\n change the value of a CHRICN of a load component model at a specified load or subsystem).\n\nchange_ldmodc_con\n\n change the value of a CON of a load component model at a specified load or subsystem.\n\nchange_ldmodc_icon\n\n change the value of a ICON of a load component model at a specified load or subsystem.\n\nchange_ldmodc_var\n\n change the value of a VAR of a load component model at a specified lo"
  },
  {
    "id": "chunk_187",
    "text": " a VAR of a load component model at a specified load or subsystem.\n\n--- Load Data \u2014 .txt ---\n\nLoad Data \u2014 \n\nLoad Data\u00b6\n\n\n\n\n\naloadchar\n\n return an array of character values for subsystem loads.\n\naloadcount\n\n return the number of array entries required to accommodate the data to be returned by the remaining members of the load data family.\n\naloadcplx\n\n return an array of complex values for subsystem loads.\n\naloadint\n\n return an array of integer values for subsystem loads.\n\naloadreal\n\n return an ar"
  },
  {
    "id": "chunk_188",
    "text": "ues for subsystem loads.\n\naloadreal\n\n return an array of real values for subsystem loads.\n\naloadtypes\n\n return an array of character values indicating the data types corresponding to a set of specified STRING values that are valid input values to any of the data retrieval routines of the load data family (aLoadInt, aLoadReal, aLoadCplx and aLoadChar).\n\n--- Load Related Models \u2014 .txt ---\n\nLoad Related Models \u2014 \n\nLoad Related Models\u00b6\n\n\n\n\n\nadd_load_model\n\n add a load related model of a designated t"
  },
  {
    "id": "chunk_189",
    "text": "model\n\n add a load related model of a designated type to a specified load or subsystem.\n\nchange_ldmod_chricn\n\n change the value of a character ICON (i.e., an element of the CHRICN array) of a load related model at a specified load or subsystem.\n\nchange_ldmod_con\n\n change the value of a CON of a load related model at a specified load or subsystem.\n\nchange_ldmod_data\n\n\n\nchange_ldmod_icon\n\n change the value of an integer ICON of a load related model at a specified load or subsystem.\n\nchange_ldmod_v"
  },
  {
    "id": "chunk_190",
    "text": " at a specified load or subsystem.\n\nchange_ldmod_var\n\n change the value of a VAR of a load related model at a specified load or subsystem.\n\nldmod_pack\n\n remove entries that are marked as unused from the load model connection tables and the load model array allocation tables.\n\nldmod_remove\n\n remove a load related model of a designated type from a specified load or subsystem.\n\nldmod_status\n\n change the status of a load related model of a designated type for all subsystem loads at which it is appli"
  },
  {
    "id": "chunk_191",
    "text": " type for all subsystem loads at which it is applied.\n\nldmod_status2\n\n change the status of a load related model of a designated type at a specified load.\n\nldmod_unconnected\n\n list or remove from dynamics working memory those load related models that are assigned to loads that are not present in the current power flow working case (unconnected).\n\nldmod_user\n\n list user-written load model definitions or to remove user-written load model definitions that are not assigned to any loads (unused) from"
  },
  {
    "id": "chunk_192",
    "text": "s that are not assigned to any loads (unused) from the user model definition tables.\n\nldmodc_pack\n\n remove entries that are marked as unused from the load component model connection tables.\n\nldmodc_remove\n\n remove a load component related model of a designated type from a specified load or subsystem.\n\nldmodc_status\n\n change the status of a load related model of a designated type for all subsystem loads at which it is applied.\n\nldmodc_unconnected\n\n list or remove from dynamics working memory thos"
  },
  {
    "id": "chunk_193",
    "text": "\n list or remove from dynamics working memory those load Component models that are assigned to loads that are not present in the current power flow working case (unconnected).\n\nldmodc_user\n\n list user-written load component model definitions or to remove user-written load model definitions that are not assigned to any loads (unused) from the user model definition tables.\n\n--- Machine Data \u2014 .txt ---\n\nMachine Data \u2014 \n\nMachine Data\u00b6\n\n\n\n\n\namachchar\n\n return an array of character values for subsyste"
  },
  {
    "id": "chunk_194",
    "text": "\n return an array of character values for subsystem machines.\n\namachcount\n\n return the number of array entries required to accommodate the data to be returned by the remaining members of the machine data family.\n\namachcplx\n\n return an array of complex values for subsystem machines.\n\namachint\n\n return an array of integer values for subsystem machines.\n\namachreal\n\n return an array of real values for subsystem machines.\n\namachtypes\n\n return an array of character values indicating the data types cor"
  },
  {
    "id": "chunk_195",
    "text": " of character values indicating the data types corresponding to a set of specified STRING values that are valid input values to any of the data retrieval routines of the machine data family (aMachInt, aMachReal, aMachCplx and aMachChar).\n\n--- Multi-Terminal Dc Line Converter Data \u2014 .txt ---\n\nMulti-Terminal Dc Line Converter Data \u2014 \n\nMulti-Terminal Dc Line Converter Data\u00b6\n\n\n\n\n\namultitrmdcconvchar\n\n return an array of character values for subsystem multi-terminal dc line converters.\n\namultitrmdcco"
  },
  {
    "id": "chunk_196",
    "text": " multi-terminal dc line converters.\n\namultitrmdcconvcount\n\n return the number of array entries required to accommodate the data to be returned by the remaining members of the multi-terminal dc line converter data family.\n\namultitrmdcconvcplx\n\n return an array of complex values for subsystem multi-terminal dc line converters.\n\namultitrmdcconvint\n\n return an array of integer values for subsystem multi-terminal dc line converters.\n\namultitrmdcconvreal\n\n return an array of real values for subsystem "
  },
  {
    "id": "chunk_197",
    "text": "al\n\n return an array of real values for subsystem multi-terminal dc line converters.\n\namultitrmdcconvtypes\n\n return an array of character values indicating the data types corresponding to a set of specified STRING values that are valid input values to any of the data retrieval routines of the two-terminal dc line converter data family (aMultiTrmDcConvInt, aMultiTrmDcConvReal, aMultiTrmDcConvCplx and aMultiTrmDcConvChar).\n\n--- Multi-Terminal Dc Line Data \u2014 .txt ---\n\nMulti-Terminal Dc Line Data \u2014 "
  },
  {
    "id": "chunk_198",
    "text": "ne Data \u2014 .txt ---\n\nMulti-Terminal Dc Line Data \u2014 \n\nMulti-Terminal Dc Line Data\u00b6\n\n\n\n\n\namultitrmdcchar\n\n return an array of character values for subsystem multi-terminal dc lines.\n\namultitrmdccount\n\n return the number of array entries required to accommodate the data to be returned by the remaining members of the multi-terminal dc line data family.\n\namultitrmdccplx\n\n return an array of complex values for subsystem multi-terminal dc lines.\n\namultitrmdcint\n\n return an array of integer values for su"
  },
  {
    "id": "chunk_199",
    "text": "rmdcint\n\n return an array of integer values for subsystem multi-terminal dc lines.\n\namultitrmdcreal\n\n return an array of real values for subsystem multi-terminal dc lines.\n\namultitrmdctypes\n\n return an array of character values indicating the data types corresponding to a set of specified STRING values that are valid input values to any of the data retrieval routines of the multi-terminal dc line data family (aMultiTrmDcInt, aMultiTrmDcReal, aMultiTrmDcCplx and aMultiTrmDcChar).\n\n--- Multiple El"
  },
  {
    "id": "chunk_200",
    "text": "tiTrmDcCplx and aMultiTrmDcChar).\n\n--- Multiple Element Data \u2014 .txt ---\n\nMultiple Element Data \u2014 \n\nMultiple Element Data\u00b6\n\n\n\n\n\navoltagedroopchar\n\n return an array of character values for the voltage droop controls.\n\navoltagedroopcount\n\n return the number of voltage droop controls.\n\navoltagedroopint\n\n return an array of real values for the voltage droop controls.\n\navoltagedroopreal\n\n return an array of real values for the voltage droop controls.\n\ngetmodellibraries\n\nReturn the list of libraries th"
  },
  {
    "id": "chunk_201",
    "text": "getmodellibraries\n\nReturn the list of libraries that are searched for dynamically (i.e.\n\ngetmodelprograms\n\nReturn the list dynamically (i.e.\n\ngettspfprofilebyelement\n\n return an array of character values for the Time Series Power Flow profiles by element name.\n\ngettspfprofilecountbyelement\n\n return the number of Time Series Power Flow profile by element name.\n\ngettspfprofiledata\n\n return an array of real values for Time Series Power Flow profile data.\n\ngettspfprofiledatabyset\n\n return an array o"
  },
  {
    "id": "chunk_202",
    "text": "data.\n\ngettspfprofiledatabyset\n\n return an array of real values for Time Series Power Flow profile data for given curve set id.\n\ngettspfprofiledatacolumncount\n\n return the number of Time Series Power Flow profile data column count for a curve set.\n\ngettspfprofiledatacount\n\n return the number of Time Series Power Flow profile data count.\n\nlast_pf\n\nReturn last attempted network solution data.\n\nrxpath\n\n return buses from starting bus to ending bus with shortest electricity distance in terms of one "
  },
  {
    "id": "chunk_203",
    "text": "ith shortest electricity distance in terms of one of two options, impedance and number of buses.\n\ntreedat\n\n return Swing Bus and Island Data of Working Case Network.\n\n--- Node Breaker Data \u2014 .txt ---\n\nNode Breaker Data \u2014 \n\nNode Breaker Data\u00b6\n\n\n\n\n\nfetch_adjvar_term_node\n\n obtain the terminal node to which an OPF adjustable bus shunt is connected to.\n\nfetch_indmachine_term_node\n\n obtain the terminal node to which a machine is connected to.\n\nfetch_load_term_node\n\n obtain the terminal node to which "
  },
  {
    "id": "chunk_204",
    "text": "oad_term_node\n\n obtain the terminal node to which a load is connected to.\n\nfetch_machine_term_node\n\n obtain the terminal node to which a machine is connected to.\n\nfetch_shunt_term_node\n\n obtain the terminal node to which a shunt is connected to.\n\nfetch_sws_shunt_term_node\n\n\n\nfetch_sws_shunt_term_node_2\n\n obtain the terminal node to which a switched shunt is connected to.\n\nplant_bus_section_chng\n\n\n\nstation_2dc_bus_term_chng\n\n change the station two-term dc rectifier or inverter node terminal conn"
  },
  {
    "id": "chunk_205",
    "text": "o-term dc rectifier or inverter node terminal connection in the working case.\n\nstation_2dc_conv_term_chng\n\nThis API changes both node terminal connections of an existing two-term dc rectifier and inverter terminal data in the working case.\n\nstation_adjvar_term_chng\n\n change a substation OPF adjustable bus shunt node terminal connection in the working case.\n\nstation_branch_term_chng\n\n access existing station branch terminal data in the working case.\n\nstation_branch_term_move\n\n move one terminal n"
  },
  {
    "id": "chunk_206",
    "text": "e.\n\nstation_branch_term_move\n\n move one terminal node connection of a branch in the working case.\n\nstation_bus_purg\n\nThis API routine was first introduced in release 34.2.\n\nstation_chng\n\n modify the data of an existing substation data in the working case.\n\nstation_data\n\n modify the data of an existing substation data in the working case, or to add a new substation to the working case.\n\nstation_facts_bus_term_chng\n\n change the station FACTS device node terminal data connection in the working case"
  },
  {
    "id": "chunk_207",
    "text": " node terminal data connection in the working case.\n\nstation_facts_term_chng\n\nThis API changes the FACTS device sending and terminal end node terminal connections.\n\nstation_indmachine_term_chng\n\n change a substation induction machine node terminal connection in the working case.\n\nstation_load_term_chng\n\n access existing station load terminal data in the working case.\n\nstation_machine_term_chng\n\n change a substation machine terminal connection in the working case.\n\nstation_mtdc_bus_term_chng\n\n ch"
  },
  {
    "id": "chunk_208",
    "text": "the working case.\n\nstation_mtdc_bus_term_chng\n\n change the station multi-terminal converter node terminal connection in the working case.\n\nstation_mtdc_term_chng\n\nThis API changes both node terminal connections of an existing multi-terminal converter in the working case.\n\nstation_node_chng\n\n modify the data of an existing substation node in the working case.\n\nstation_node_data\n\n modify the data of an existing substation node in the working case, or to add a new substation node to the working cas"
  },
  {
    "id": "chunk_209",
    "text": "or to add a new substation node to the working case.\n\nstation_node_number\n\n change a node number in an existing substation.\n\nstation_node_purg\n\n delete a node in an existing substation.\n\nstation_number\n\n change a substation number for an existing substation.\n\nstation_purg\n\n delete a substation and all node-breaker components within that substation from the working case.\n\nstation_shunt_term_chng\n\n change a substation fixed shunt terminal connection in the working case.\n\nstation_swd_chng\n\n modify "
  },
  {
    "id": "chunk_210",
    "text": "n in the working case.\n\nstation_swd_chng\n\n modify the data of an existing station switching device in the working case.\n\nstation_swd_data\n\n modify the data of an existing substation switching device in the working case, or to add a new substation switching device to the working case.\n\nstation_swd_mbid\n\n modify the circuit identifier of an existing station switching device in the working case.\n\nstation_swd_move\n\n move the \u201cto\u201d node of an existing substation switching device in the working case.\n\n"
  },
  {
    "id": "chunk_211",
    "text": "substation switching device in the working case.\n\nstation_swd_purg\n\n delete an existing substation switching device in the working case.\n\nstation_sws_shunt_term_chng\n\n\n\nstation_sws_shunt_term_chng_2\n\n change a substation switched shunt node terminal connection in the working case.\n\nstation_three_wnd_term_chng\n\n access existing substation three-winding transformer terminal data in the working case.\n\nstation_three_wnd_term_move\n\n move one terminal node connection of a three-winding transformer in "
  },
  {
    "id": "chunk_212",
    "text": "node connection of a three-winding transformer in the working case.\n\nstation_vscdc_bus_term_chng\n\n change the vsc dc converter node terminal connection in the working case.\n\nstation_vscdc_conv_term_chng\n\nThis API changes both node terminal connections of an existing vsc dc converter in the working case.\n\nsystem_swd_chng\n\n modify the data of an existing system switching device in the working case, or to add a new system switching device to the working case.\n\nsystem_swd_data\n\n add or modify the da"
  },
  {
    "id": "chunk_213",
    "text": "king case.\n\nsystem_swd_data\n\n add or modify the data of an existing system switching device in the working case, or to add a new system switching device to the working case.\n\n--- Node Breaker Operation \u2014 .txt ---\n\nNode Breaker Operation \u2014 \n\nNode Breaker Operation\u00b6\n\n\n\n\n\nconvert_section_to_bus\n\nUse this API routine to convert a bus section, one that had been automatically created within a substation due to open substation switching devices, into a main network bus.\n\nisolate2dclinebybreaker\n\n isola"
  },
  {
    "id": "chunk_214",
    "text": "main network bus.\n\nisolate2dclinebybreaker\n\n isolate a two-terminal DC line using system or substation breakers.\n\nisolate3wtbybreaker\n\n isolate a three-winding transformer using system or substation breakers.\n\nisolatebusbybreaker\n\n isolate a bus using system or substation breakers.\n\nisolatefactsbybreaker\n\n isolate a FACTS device using system or substation breakers.\n\nisolateindmachinebybreaker\n\n isolate an induction machine using system or substation breakers.\n\nisolatelinebybreaker\n\n isolate a tw"
  },
  {
    "id": "chunk_215",
    "text": "ion breakers.\n\nisolatelinebybreaker\n\n isolate a two-winding transformer or non-transformer line using system or substation breakers.\n\nisolateloadbybreaker\n\n isolate a load using system or substation breakers.\n\nisolatemachinebybreaker\n\n isolate a machine using system or substation breakers.\n\nisolatemslinebybreaker\n\n isolate a multi-section line using system or substation breakers.\n\nisolatemtdclinebybreaker\n\n isolate a multi-terminal dc line using system or substation breakers.\n\nisolatenodebybreak"
  },
  {
    "id": "chunk_216",
    "text": "system or substation breakers.\n\nisolatenodebybreaker\n\n isolate a substation node using system or substation breakers.\n\nisolateshuntbybreaker\n\n isolate a fixed shunt using system or substation breakers.\n\nisolateswdbybreaker\n\n isolate a substation switching device using system or substation breakers.\n\nisolateswshuntbybreaker\n\n\n\nisolateswshuntbybreaker_2\n\n isolate a switched shunt using system or substation breakers.\n\nisolatevscdclinebybreaker\n\n isolate a VSC DC line using system or substation brea"
  },
  {
    "id": "chunk_217",
    "text": "late a VSC DC line using system or substation breakers.\n\nrestorestatesfromisolate\n\n restore the network working case back to its original state; the state prior to all \u201cIsolate By Breaker\u201d actions that have been taken.\n\nstation_ampout\n\n print current within a substation.\n\nstation_build_config\n\n automatically build a general layout configuration for a bus being built within a substation.\n\nstation_list\n\n list components in a substation.\n\nstation_pout\n\n\n\nstation_pout_2\n\n print power flows within a "
  },
  {
    "id": "chunk_218",
    "text": "ut\n\n\n\nstation_pout_2\n\n print power flows within a substation.\n\nstation_tree\n\nUse this API routine to check the node breaker model and the consistency between node breaker and bus branch models.\n\n--- Non-Engineering \u2014 .txt ---\n\nNon-Engineering \u2014 \n\nNon-Engineering\u00b6\n\n\n\n\n\nalert\n\n send output to the alert device.\n\nappendrecording\n\nStart recording program operation at end of specified file.\n\nbeginreport\n\n create a new report tab in the GUI.\n\nclearalertoutput\n\nClear the Alerts/Warnings tab of the outpu"
  },
  {
    "id": "chunk_219",
    "text": "output\n\nClear the Alerts/Warnings tab of the output bar in the GUI\n\nclearprogressoutput\n\nClear the Progress tab of the output bar in the GUI\n\nfilein\n\nGet input from file (Fortran unit number).\n\ngetbatdefaults\n\nRetrieve \u201cno input\u201d value for integers and reals.\n\ngetdefaultchar\n\nRetrieve \u201cno input\u201d value for characters (i.e., strings) other than filenames.\n\ngetdefaultint\n\nRetrieve \u201cno input\u201d value for integers.\n\ngetdefaultreal\n\nRetrieve \u201cno input\u201d value for reals (floats).\n\ngetloadedmodules\n\nget li"
  },
  {
    "id": "chunk_220",
    "text": "alue for reals (floats).\n\ngetloadedmodules\n\nget list of all modules currently loaded\n\ngetmodfunclist\n\nGet list if external callable methods given a module name.\n\nioflush\n\nForce all files in PSSE to flush buffers to disk, if possible.\n\nlaunch_program\n\nThis API routine was first introduced in release 34.1.\n\npagereport\n\n place a report separator on the active report tab of the GUI.\n\npauserecording\n\nPause or resume recording program operation.\n\nprogress\n\nSend output to progress device.\n\nprompt\n\nSend"
  },
  {
    "id": "chunk_221",
    "text": "ess\n\nSend output to progress device.\n\nprompt\n\nSend output to prompt device.\n\npsseinit\n\nInitialize PSSE.\n\npsseversion\n\nGet PSSE version information.\n\nrefreshgui\n\nRefresh the graphical user interface.\n\nreport\n\nSend output to report device.\n\nruniplanfile\n\nExecute an IPLAN program.\n\nrunrspnsfile\n\nRun a response file.\n\nshowloadedlibraries\n\n\n\nshowloadedmodules\n\n\n\nstartrecording\n\nStart recording program operation.\n\nstoprecording\n\nStop recording program operation.\n\nt_alert_output\n\n specify a \u201cT\u201c\u2018d alert"
  },
  {
    "id": "chunk_222",
    "text": "operation.\n\nt_alert_output\n\n specify a \u201cT\u201c\u2018d alert device, i.e. a destination for a copy of everything sent to the alert device.\n\nt_progress_output\n\n specify a \u201cT\u201c\u2018d progress device, i.e. a destination for a copy of everything sent to the progress device.\n\nt_prompt_output\n\n specify a \u201cT\u201c\u2018d prompt device, i.e. a destination for a copy of everything sent to the prompt device.\n\nt_report_output\n\n specify a \u201cT\u201c\u2018d report device, i.e. a destination for a copy of everything sent to the report device.\n\nu"
  },
  {
    "id": "chunk_223",
    "text": "a copy of everything sent to the report device.\n\nuserin\n\nGet input from interactive device.\n\n--- Optimal Power Flow Data \u2014 .txt ---\n\nOptimal Power Flow Data \u2014 \n\nOptimal Power Flow Data\u00b6\n\n\n\n\n\nnewopf\n\n initialize the working case with default OPF data for all bus oriented data records.\n\nopf_adjbrx_indv\n\n add an individual adjustable branch reactance data record to the working case.\n\nopf_adjbrx_subsys\n\n add or modify all OPF branch reactance data records in a specified subsystem of the working case"
  },
  {
    "id": "chunk_224",
    "text": "cords in a specified subsystem of the working case.\n\nopf_adjload_tbl\n\n add an individual adjustable bus load table record to the working case.\n\nopf_adjvar_indv\n\n\n\nopf_adjvar_indv_2\n\n add an individual OPF adjustable bus shunt data record to the working case.\n\nopf_adjvar_subsys\n\n add or modify all OPF adjustable bus shunt records in a specified subsystem of the working case.\n\nopf_apdsp_tbl\n\n add an individual active power dispatch table record to the working case.\n\nopf_brflw_3wt_indv\n\n add a flow"
  },
  {
    "id": "chunk_225",
    "text": "the working case.\n\nopf_brflw_3wt_indv\n\n add a flow constraint record for an individual winding of a three-winding transformer in the working case.\n\nopf_brflw_brn_indv\n\n add an individual branch or two-winding transformer flow constraint record to the working case.\n\nopf_brflw_subsys\n\n add or modify all branch flow data records in a specified subsystem of the working case.\n\nopf_bus_indv\n\n\n\nopf_bus_indv_2\n\n add OPF bus voltage magnitude data to the working case.\n\nopf_bus_subsys\n\n add OPF bus attrib"
  },
  {
    "id": "chunk_226",
    "text": "working case.\n\nopf_bus_subsys\n\n add OPF bus attribute data for all records in a specified subsystem of the working case.\n\nopf_change_3wt_flow_id\n\n change the identifier of a flow constraint record for an individual winding of a three-winding transformer in the working case.\n\nopf_change_adjvar_id\n\n\n\nopf_change_brn_flow_id\n\n change the identifier of a branch or two-winding transformer OPF flow constraint record in the working case.\n\nopf_csttbl_lin\n\n add a linear cost curve table record to the work"
  },
  {
    "id": "chunk_227",
    "text": "\n add a linear cost curve table record to the working case.\n\nopf_csttbl_poly\n\n add a polynomial and exponential cost curve table record to the working case.\n\nopf_csttbl_quad\n\n add a quadratic cost curve table record to the working case.\n\nopf_gen_rcap_indv\n\n add an individual generation reactive capability data record to the working case.\n\nopf_gen_rcap_subsys\n\n add or modify all OPF generator reactive capability records in a specified subsystem of the working case.\n\nopf_gendsp_indv\n\n add generato"
  },
  {
    "id": "chunk_228",
    "text": " the working case.\n\nopf_gendsp_indv\n\n add generator dispatch data to an individual record in the working case.\n\nopf_gendsp_subsys\n\n add OPF generator dispatch data to all records in a specified subsystem of the working case.\n\nopf_genrsv_indv\n\n add an individual generator reserve data record to the working case.\n\nopf_genrsv_subsys\n\n add or modify all OPF generator reserve records in a specified subsystem of the working case.\n\nopf_intflw_3wt\n\n add a participating three-winding transformer winding "
  },
  {
    "id": "chunk_229",
    "text": "a participating three-winding transformer winding to a specified interface flow constraint in the working case.\n\nopf_intflw_brn\n\n add a participating branch to a specified interface flow constraint in the working case.\n\nopf_intflw_main\n\n add an interface flow constraint record to the working case.\n\nopf_intflw_reset\n\n remove all interface branches associated with a particular interface flow constraint in the working case.\n\nopf_lnceqn_adjload\n\n add a participating adjustable bus load variable to a"
  },
  {
    "id": "chunk_230",
    "text": " a participating adjustable bus load variable to a specified linear constraint dependency equation in the working case.\n\nopf_lnceqn_adjvar\n\n add a participating adjustable bus shunt variable to a specified linear constraint dependency equation in the working case.\n\nopf_lnceqn_brflow\n\n add a participating branch flow variable to a specified linear constraint dependency equation in the working case.\n\nopf_lnceqn_intflow\n\n add a participating interface flow constraint variable to a specified linear "
  },
  {
    "id": "chunk_231",
    "text": "ce flow constraint variable to a specified linear constraint dependency equation in the working case.\n\nopf_lnceqn_main\n\n add a linear constraint dependency record to the working case.\n\nopf_lnceqn_pgen\n\n add a participating active power dispatch variable to a specified linear constraint dependency equation in the working case.\n\nopf_lnceqn_qgen\n\n add a participating reactive power dispatch variable of a specified linear constraint dependency equation in the working case.\n\nopf_lnceqn_reset\n\n remove"
  },
  {
    "id": "chunk_232",
    "text": "on in the working case.\n\nopf_lnceqn_reset\n\n remove all participating variables from a particular OPF linear constraint dependency equation in the working case.\n\nopf_lnceqn_swshunt\n\n\n\nopf_lnceqn_swshunt_2\n\n add a participating switched shunt variable to a specified linear constraint dependency equation in the working case.\n\nopf_lnceqn_tran\n\n add a participating transformer control variable to a specified linear constraint dependency equation in the working case.\n\nopf_lnceqn_vang\n\n\n\nopf_lnceqn_van"
  },
  {
    "id": "chunk_233",
    "text": "e working case.\n\nopf_lnceqn_vang\n\n\n\nopf_lnceqn_vang_2\n\n add a participating bus voltage angle variable to a specified linear constraint dependency equation in the working case.\n\nopf_lnceqn_vmag\n\n\n\nopf_lnceqn_vmag_2\n\n add a participating bus voltage magnitude variable to a specified linear constraint dependency equation in the working case.\n\nopf_load_indv\n\n add an individual OPF bus load data record to the working case.\n\nopf_load_subsys\n\n add or modify all OPF bus load data records in a specified"
  },
  {
    "id": "chunk_234",
    "text": "odify all OPF bus load data records in a specified subsystem of the working case.\n\nopf_perrsv_gen\n\n add a participating generation reserve unit to a previously defined period reserve constraint in the working case.\n\nopf_perrsv_main\n\n add a period reserve constraint record to the working case.\n\nopf_perrsv_reset\n\n remove all generation reserve units associated with a particular period reserve constraint in the working case.\n\npurge_all_opf_data\n\n purge and re-initialize all OPF data records in the "
  },
  {
    "id": "chunk_235",
    "text": "rge and re-initialize all OPF data records in the working case.\n\npurge_opf_adjbrx_indv\n\n purge an individual adjustable branch reactance data record from the working case.\n\npurge_opf_adjbrx_subsys\n\n purge all OPF branch reactance data records from a specified subsystem of the working case.\n\npurge_opf_adjload_tbl\n\n purge an individual adjustable bus load table from the working case.\n\npurge_opf_adjvar_indv\n\n\n\npurge_opf_adjvar_indv_3\n\n purge an individual OPF adjustable bus shunt data record from t"
  },
  {
    "id": "chunk_236",
    "text": "vidual OPF adjustable bus shunt data record from the working case.\n\npurge_opf_adjvar_subsys\n\n purge all OPF adjustable bus shunt records from a specified subsystem of the working case.\n\npurge_opf_apdsp_tbl\n\n purge an individual active power dispatch table record from the working case.\n\npurge_opf_brflw_3wt\n\n purge an individual flow constraint record of a three-winding transformer from the working case.\n\npurge_opf_brflw_brn\n\n purge an individual branch or two-winding transformer flow constraint r"
  },
  {
    "id": "chunk_237",
    "text": "ranch or two-winding transformer flow constraint record from the working case.\n\npurge_opf_brflw_subsys\n\n purge all branch flow data records in a specified subsystem in the working case.\n\npurge_opf_bus_indv\n\n\n\npurge_opf_bus_indv_3\n\n purge (re-initialize) OPF bus voltage magnitude data for an individual bus or bus section record in the working case.\n\npurge_opf_bus_subsys\n\n purge (re-initialize) OPF bus attribute data for all records in a specified subsystem of the working case.\n\npurge_opf_csttbl_l"
  },
  {
    "id": "chunk_238",
    "text": "subsystem of the working case.\n\npurge_opf_csttbl_lin\n\n purge an optimal power flow linear cost curve record from the working case.\n\npurge_opf_csttbl_poly\n\n purge an optimal power flow polynomial and exponential cost curve record from the working case.\n\npurge_opf_csttbl_quad\n\n purge an optimal power flow quadratic cost curve record from the working case.\n\npurge_opf_gen_rcap_indv\n\n purge an individual OPF generation reactive capability data record from the working case.\n\npurge_opf_gen_rcap_subsys\n"
  },
  {
    "id": "chunk_239",
    "text": "from the working case.\n\npurge_opf_gen_rcap_subsys\n\n purge all OPF generator reactive capability records in a specified subsystem from the working case.\n\npurge_opf_gendsp_indv\n\n purge generator dispatch data for an individual record from the working case.\n\npurge_opf_gendsp_subsys\n\n purge generator dispatch data for all records from a specified subsystem of the working case.\n\npurge_opf_genrsv_indv\n\n purge an individual optimal power flow generator reserve data record from the working case.\n\npurge_"
  },
  {
    "id": "chunk_240",
    "text": "reserve data record from the working case.\n\npurge_opf_genrsv_subsys\n\n purge all OPF generator reserve records in a specified subsystem from the working case.\n\npurge_opf_intflw\n\n purge an OPF interface flow constraint record, including all of its participating branches, from the working case.\n\npurge_opf_intflw_3wt\n\n remove a participating three-winding transformer winding from a specified OPF interface flow constraint in the working case.\n\npurge_opf_intflw_brn\n\n remove a participating branch from"
  },
  {
    "id": "chunk_241",
    "text": "pf_intflw_brn\n\n remove a participating branch from a specified OPF interface flow constraint in the working case.\n\npurge_opf_lnceqn\n\n purge an OPF linear constraint dependency record, including all of its participating variables, from the working case.\n\npurge_opf_lnceqn_adjload\n\n remove a participating adjustable bus load variable from a specified OPF linear constraint dependency equation in the working case.\n\npurge_opf_lnceqn_adjvar\n\n remove a participating adjustable bus shunt variable from a "
  },
  {
    "id": "chunk_242",
    "text": "articipating adjustable bus shunt variable from a specified OPF linear constraint dependency equation in the working case.\n\npurge_opf_lnceqn_brflow\n\n remove a participating branch flow variable from a specified OPF linear constraint dependency equation in the working case.\n\npurge_opf_lnceqn_intflow\n\n remove a participating interface flow constraint variable from a specified OPF linear constraint dependency equation in the working case.\n\npurge_opf_lnceqn_pgen\n\n remove a participating active power"
  },
  {
    "id": "chunk_243",
    "text": "_lnceqn_pgen\n\n remove a participating active power dispatch variable from a specified OPF linear constraint dependency equation in the working case.\n\npurge_opf_lnceqn_qgen\n\n remove a participating reactive power dispatch variable from a specified OPF linear constraint dependency equation in the working case.\n\npurge_opf_lnceqn_swshunt\n\n\n\npurge_opf_lnceqn_swshunt_2\n\n remove a participating switched shunt variable from a specified OPF linear constraint dependency equation in the working case.\n\npurg"
  },
  {
    "id": "chunk_244",
    "text": "int dependency equation in the working case.\n\npurge_opf_lnceqn_tran\n\n remove a participating transformer control variable from a specified OPF linear constraint dependency equation in the working case.\n\npurge_opf_lnceqn_vang\n\n\n\npurge_opf_lnceqn_vang_2\n\n remove a participating bus voltage angle variable from a specified OPF linear constraint dependency equation in the working case.\n\npurge_opf_lnceqn_vmag\n\n\n\npurge_opf_lnceqn_vmag_2\n\n remove a participating bus voltage magnitude variable from a spe"
  },
  {
    "id": "chunk_245",
    "text": "cipating bus voltage magnitude variable from a specified OPF linear constraint dependency equation in the working case.\n\npurge_opf_load_indv\n\n purge (re-initialize) an individual OPF bus load data record from the working case.\n\npurge_opf_load_subsys\n\n purge (re-initialize) all OPF bus load data records in a specified subsystem of the working case.\n\npurge_opf_perrsv\n\n purge an OPF period reserve constraint record and its association with participating reserve units from the working case.\n\npurge_o"
  },
  {
    "id": "chunk_246",
    "text": "ting reserve units from the working case.\n\npurge_opf_perrsv_gen\n\n remove a participating period reserve unit from a specified OPF period reserve constraint.\n\n--- Optimal Power Flow Operation \u2014 .txt ---\n\nOptimal Power Flow Operation \u2014 \n\nOptimal Power Flow Operation\u00b6\n\n\n\n\n\nadd_details_to_opf_log\n\n specify or return the value of the OPF solution option to add details of the sensitivity values and Lagrange multipliers to the OPF Output Log file.\n\napply_alternate_step_size\n\n specify or return the valu"
  },
  {
    "id": "chunk_247",
    "text": "y_alternate_step_size\n\n specify or return the value of the OPF solution option for applying an alternate lambda mismatch step size.\n\napply_automatic_scaling\n\n specify or return the value of the OPF solution option to apply automatic scaling of the objective coefficients and derivatives to improve convergence of the OPF solution.\n\nbad_iter_coarse_limit\n\n specify or return the number of bad iterations allowed when the barrier coefficient is greater than 011 (mu greater then -2) before the solution"
  },
  {
    "id": "chunk_248",
    "text": " than 011 (mu greater then -2) before the solution progress is terminated as being infeasible.\n\nbad_iter_fine_limit\n\n specify or return the the bad iteration limit when the barrier coefficient is less than, or equal to 011 (mu less than or equal to -2) before the solution progress is terminated as being infeasible.\n\nclamp_nonoptimized_gens\n\n specify or return the value of the OPF solution option to apply the clamp equation to non-optimized generators.\n\nconstrain_interface_flows\n\n specify or retu"
  },
  {
    "id": "chunk_249",
    "text": "tors.\n\nconstrain_interface_flows\n\n specify or return the value of the OPF option to constrain interface flows.\n\nfinal_opf_barrier_coeff\n\n specify or return the value of the final coefficient value that the barrier function is attempting to attain.\n\nimport_ecdi\n\n import data from an Economics Dispatch Data File, as prepared for use in activity ECDI, into the OPF working data.\n\ninitial_opf_barrier_coeff\n\n specify or return the value of the initial OPF barrier coefficient.\n\ninterface_flow_cost_coef"
  },
  {
    "id": "chunk_250",
    "text": "OPF barrier coefficient.\n\ninterface_flow_cost_coeff\n\n specify or return the value of the coefficient for the interface flow objective.\n\nlsto\n\n list OPF working case data in a form suitable for data documentation.\n\nminimize_adj_bus_shunts\n\n specify or return the value of the OPF minimize adjustable bus shunts (var compensation) objective function option.\n\nminimize_fuel_cost\n\n specify or return the value of the OPF minimize fuel cost objective option.\n\nminimize_interface_flows\n\n specify or return "
  },
  {
    "id": "chunk_251",
    "text": "on.\n\nminimize_interface_flows\n\n specify or return the value of the OPF minimize interface flows objective option.\n\nminimize_load_adjustments\n\n specify or return the value of the OPF minimize adjustable bus load objective option.\n\nminimize_p_losses\n\n specify or return the value of the OPF minimize active power loss objective option.\n\nminimize_p_slack\n\n specify or return the value of the OPF minimize active power slack objective option.\n\nminimize_q_losses\n\n specify or return the value of the OPF m"
  },
  {
    "id": "chunk_252",
    "text": "_losses\n\n specify or return the value of the OPF minimize reactive power loss objective option.\n\nminimize_q_slack\n\n specify or return the value of the OPF minimize reactive power slack objective option.\n\nminimize_reactive_reserve\n\n specify or return the value of the OPF minimize reactive reserve objective option.\n\nminimize_series_comp\n\n specify or return the value of the OPF minimize series compensation (adjustable branch reactance) objective option.\n\nnopf\n\n run the Optimal Power Flow solution.\n"
  },
  {
    "id": "chunk_253",
    "text": "ion.\n\nnopf\n\n run the Optimal Power Flow solution.\n\nopen_bus_voltage_limits\n\n specify or return the value of the OPF solution option to automatically adjust bus voltage limits, making them more open for initial feasibility.\n\nopf_barrier_step_length\n\n specify or return the value of the barrier function step length setting.\n\nopf_clamp_decay_factor\n\n specify or return the value of the clamp equation decay factor.\n\nopf_final_clamp_tol\n\n specify or return the value of the final clamp tolerance.\n\nopf_f"
  },
  {
    "id": "chunk_254",
    "text": "urn the value of the final clamp tolerance.\n\nopf_fix_all_generators\n\n specify or return the value of the OPF option to treat all generators as nonoptimized (fixed).\n\nopf_fix_phase_shifters\n\n specify or return the value of the OPF option to fix transformer phase shift angle settings.\n\nopf_fix_switched_shunts\n\n specify or return the value of the OPF option to fix switched shunt settings.\n\nopf_fix_tap_ratios\n\n specify or return the value of the OPF option to fix transformer tap ratio settings.\n\nopf"
  },
  {
    "id": "chunk_255",
    "text": "option to fix transformer tap ratio settings.\n\nopf_fixed_voltage_penalty\n\n specify or return the value of the penalty for fixed voltage excursions.\n\nopf_initial_clamp_tol\n\n specify or return the value of the initial clamp tolerance.\n\nopf_interior_shift_factor\n\n specify or return the value of the interior shift factor multiplier.\n\nopf_lambda_tolerance\n\n specify or return the value of the Lagrange multiplier blow-up tolerance during an optimal power flow solution.\n\nopf_lf_control_penalty\n\n specify"
  },
  {
    "id": "chunk_256",
    "text": "r flow solution.\n\nopf_lf_control_penalty\n\n specify or return the value of the quadratic penalty for loadflow controls.\n\nopf_max_tap_ratio_step\n\n specify or return the value of the maximum transformer tap ratio step.\n\nopf_min_tap_ratio_step\n\n set or return the value of the minimum transformer tap ratio step.\n\nopf_regulate_area_int\n\n set or return the value of the OPF option to regulate area interchange.\n\nopf_round_switched_shunts\n\n set or return the value of the OPF solution option to discretize "
  },
  {
    "id": "chunk_257",
    "text": "he value of the OPF solution option to discretize switched shunts.\n\nopf_round_tap_ratios\n\n set or return the value of the OPF solution option to round transformer tap ratio settings.\n\nopf_scale_qgen_limits\n\n set or return the value of the OPF option to scale reactive generation limits in the clamped constraint equation.\n\nopf_step_length_tolerance\n\n set or return the value of the OPF minimum barrier step length tolerance.\n\nopf_use_generator_vsched\n\n set or return the value of the OPF option to em"
  },
  {
    "id": "chunk_258",
    "text": "\n\n set or return the value of the OPF option to employ the generator scheduled voltage.\n\nopto\n\nPlease use the individual OPF option setting API\u2019s described in this section.\n\np_losses_cost_coeff\n\n set or return the value of the coefficient for the active power loss objective (OPF Solution Options).\n\nproduce_opf_log_file\n\n set or return the value of the OPF solution option to produce an OPF solution log file, and if so, the name of the log file.\n\nq_losses_cost_coeff\n\n set or return the value of th"
  },
  {
    "id": "chunk_259",
    "text": "_losses_cost_coeff\n\n set or return the value of the coefficient for the reactive power loss objective.\n\nreactive_resv_cost_coeff\n\n set or return the value of the coefficient for the reactive reserve objective.\n\nropf\n\n read an Optimal Power Flow Raw Data File.\n\nrwop\n\n replicate the OPF data contained in the working case in the form of an Optimal Power Flow Data File.\n\nset_opf_report_subsystem\n\n define the subsystem to be used when producing the opf output report.\n\nuse_dual_criteria\n\n set or retur"
  },
  {
    "id": "chunk_260",
    "text": "f output report.\n\nuse_dual_criteria\n\n set or return the value of the OPF solution option to apply the power flow mismatch tolerance to the dual variable problem.\n\nuse_emergency_flow_limits\n\n set or return the value of the OPF solution option to impose the emergency flow limits instead of the normal flow limits.\n\nuse_emergency_volt_limits\n\n set or return the value of the OPF solution option to impose the emergency bus voltage limits instead of the normal bus voltage limits.\n\nwrite_opf_options_fil"
  },
  {
    "id": "chunk_261",
    "text": " normal bus voltage limits.\n\nwrite_opf_options_file\n\n save the PSSE OPF solution option settings to the PSSOPF.OPT file.\n\n--- Owner Data \u2014 .txt ---\n\nOwner Data \u2014 \n\nOwner Data\u00b6\n\n\n\n\n\naownerchar\n\n return an array of character values for subsystem owners.\n\naownercount\n\n return the number of array entries required to accommodate the data to be returned by the remaining members of the owner data family.\n\naownercplx\n\n return an array of complex values for subsystem owners.\n\naownerint\n\n return an array "
  },
  {
    "id": "chunk_262",
    "text": "or subsystem owners.\n\naownerint\n\n return an array of integer values for subsystem owners.\n\naownerreal\n\n return an array of real values for subsystem owners.\n\naownertypes\n\n return an array of character values indicating the data types corresponding to a set of specified STRING values that are valid input values to any of the data retrieval routines of the owner data family (aOwnerInt, aOwnerReal, aOwnerCplx and aOwnerChar).\n\n--- Owner Subsystems \u2014 .txt ---\n\nOwner Subsystems \u2014 \n\nOwner Subsystems\u00b6\n"
  },
  {
    "id": "chunk_263",
    "text": " .txt ---\n\nOwner Subsystems \u2014 \n\nOwner Subsystems\u00b6\n\n\n\n\n\nosys\n\n define an owner subsystem.\n\nosysdef\n\n set the definition of an owner subsystem.\n\nosysinit\n\n initialize or re-initialize an owner subsystem.\n\n--- Plant Bus Data \u2014 .txt ---\n\nPlant Bus Data \u2014 \n\nPlant Bus Data\u00b6\n\n\n\n\n\nagenbuschar\n\n return an array of character values for subsystem buses.\n\nagenbuscount\n\n return the number of array entries required to accommodate the data to be returned by the remaining members of the plant bus data family.\n\n"
  },
  {
    "id": "chunk_264",
    "text": " remaining members of the plant bus data family.\n\nagenbuscplx\n\n return an array of complex values for subsystem buses.\n\nagenbusint\n\n return an array of integer values for subsystem buses.\n\nagenbusreal\n\n return an array of real values for subsystem buses.\n\nagenbustypes\n\n return an array of character values indicating the data types corresponding to a set of specified STRING values that are valid input values to any of the data retrieval routines of the plant bus data family (aGenBusInt, aGenBusRe"
  },
  {
    "id": "chunk_265",
    "text": "f the plant bus data family (aGenBusInt, aGenBusReal, aGenBusCplx and aGenBusChar).\n\n--- Plant Related Models \u2014 .txt ---\n\nPlant Related Models \u2014 \n\nPlant Related Models\u00b6\n\n\n\n\n\nadd_plant_model\n\n add a plant related model of a designated type to a specified machine.\n\nchange_plmod_chricn\n\n change the value of a character ICON (i.e., an element of the CHRICN array) of a designated plant related model at a specified machine.\n\nchange_plmod_con\n\n change the value of a CON of a designated plant related mo"
  },
  {
    "id": "chunk_266",
    "text": "he value of a CON of a designated plant related model at a specified machine.\n\nchange_plmod_data\n\n\n\nchange_plmod_icon\n\n change the value of an integer ICON of a designated plant related model at a specified machine.\n\nchange_plmod_var\n\n change the value of a VAR of a designated plant related model at a specified machine.\n\ngmb_add_plant_model\n\n add a plant related GMB model to a specified machine.\n\nplmod_consistency\n\n check consistency among the plant related models referenced at each machine.\n\npl"
  },
  {
    "id": "chunk_267",
    "text": "ant related models referenced at each machine.\n\nplmod_pack\n\n remove entries that are marked as unused from the plant model connection tables and the plant model array allocation tables.\n\nplmod_remove\n\n remove a plant related model of a designated type from a specified machine.\n\nplmod_status\n\n change the status of a plant related model of a designated type at a specified machine.\n\nplmod_unconnected\n\n list or remove from dynamics working memory those plant related models that are assigned to machi"
  },
  {
    "id": "chunk_268",
    "text": "se plant related models that are assigned to machines that are not present in the current power flow working case (unconnected).\n\nplmod_user\n\n list user-written plant model definitions or to remove user-written plant model definitions that are not assigned to any machines (unused) from the user model definition tables.\n\n--- Power Flow Data \u2014 .txt ---\n\nPower Flow Data \u2014 \n\nPower Flow Data\u00b6\n\n\n\n\n\narea_data\n\n modify area data in the working case (see PSSE Program Operation Manual, Areas, Zones and Ow"
  },
  {
    "id": "chunk_269",
    "text": "PSSE Program Operation Manual, Areas, Zones and Owners).\n\nbranch_chng\n\n\n\nbranch_chng_3\n\nUse this API routine to modify the data of an existing non-transformer branch in the working case (see PSSE Program Operation Manual, Non-Transformer Branch Data).\n\nbranch_data\n\n\n\nbranch_data_3\n\n modify the data of an existing non-transformer branch in the working case or to add a new non-transformer branch to the working case (see PSSE Program Operation Manual, Non- Transformer Branch Data).\n\nbus_chng_3\n\nUse"
  },
  {
    "id": "chunk_270",
    "text": "l, Non- Transformer Branch Data).\n\nbus_chng_3\n\nUse this API routine to modify the data of an existing bus in the working case (see PSSE Program Operation Manual, Bus Data).\n\nbus_chng_4\n\nUse this API routine to modify the data of an existing bus in the working case (see PSSE Program Operation Manual, Bus Data).\n\nbus_data\n\n\n\nbus_data_2\n\n\n\nbus_data_3\n\n\n\nbus_data_4\n\nUse this API routine to modify the data of an existing bus in the working case, or to add a new bus to the working case (see PSSE Progr"
  },
  {
    "id": "chunk_271",
    "text": " add a new bus to the working case (see PSSE Program Operation Manual, Bus Data).\n\nbus_number\n\n change the bus number of an existing bus in the working case.\n\ncase_title_data\n\n change the two line case title in the working case (see PSSE Program Operation Manual, Case Identification Data).\n\ncasolution_parameters\n\n modify the contingency analysis solution parameters.\n\ncasolution_parameters_2\n\n modify the contingency analysis solution parameters.\n\ncasolution_parameters_3\n\n modify the contingency a"
  },
  {
    "id": "chunk_272",
    "text": "casolution_parameters_3\n\n modify the contingency analysis solution parameters.\n\nextr\n\n purge specified buses and all branches connected to them from the working case (activity EXTR).\n\nfacts_chng_2\n\n\n\nfacts_chng_3\n\nUse this API routine to modify the data of an existing FACTS device in the working case (see PSSE Program Operation Manual, FACTS Device Data).\n\nfacts_data\n\n\n\nfacts_data_2\n\n\n\nfacts_data_3\n\n modify the data of an existing FACTS device in the working case, or to add a new FACTS device to"
  },
  {
    "id": "chunk_273",
    "text": " the working case, or to add a new FACTS device to the working case (see PSSE Program Operation Manual, FACTS Device Data).\n\ngne_chng\n\nUse this API routine to modify the data of an existing GNE device in the working case (see PSSE Program Operation Manual, GNE Device Data).\n\ngne_data\n\nUse this API routine to run the GNE device data specification function.\n\nimpedance_correction_data\n\n\n\nimpedance_correction_data_3\n\n modify the data of an existing transformer impedance correction table in the worki"
  },
  {
    "id": "chunk_274",
    "text": "ransformer impedance correction table in the working case or to add a new transformer impedance correction table to the working case (see PSSE Program Operation Manual, Transformer Impedance Correction Table Data).\n\ninduction_machine_chng\n\nUse this API routine to modify the data of an existing induction machine in the working case (see PSSE Program Operation Manual, Induction Machine Data).\n\ninduction_machine_data\n\nUse this API routine to modify the data of an existing induction machine in the w"
  },
  {
    "id": "chunk_275",
    "text": "the data of an existing induction machine in the working case, or to add a new induction machine to the working case (see PSSE Program Operation Manual, Induction Machine Data).\n\nload_chng_4\n\n\n\nload_chng_5\n\n\n\nload_chng_6\n\nUse this API routine to modify the data of an existing load in the working case (see PSSE Program Operation Manual, Load Data).\n\nload_data\n\n\n\nload_data_3\n\n\n\nload_data_4\n\n\n\nload_data_5\n\n\n\nload_data_6\n\nUse this API routine to modify the data of an existing load in the working cas"
  },
  {
    "id": "chunk_276",
    "text": "fy the data of an existing load in the working case, or to add a new load to the working case (see PSSE Program Operation Manual, Load Data).\n\nlong_title_data\n\n change the sixteen line long title in the working case (see PSSE Program Operation Manual, activity CHTI).\n\nmachine_cap_curve_chng\n\nUse this API routine to modify the capability curve data of an existing machine in the working case.\n\nmachine_cap_curve_data\n\nUse this API routine to specify or modify the capability curve data of an existin"
  },
  {
    "id": "chunk_277",
    "text": " or modify the capability curve data of an existing machine in the working case.\n\nmachine_chng_2\n\n\n\nmachine_chng_3\n\nUse this API routine to modify the data of an existing machine in the working case (see PSSE Program Operation Manual, Plant Data).\n\nmachine_chng_4\n\nUse this API routine to modify the data of an existing machine in the working case (see PSSE Program Operation Manual, Plant Data).\n\nmachine_data\n\n\n\nmachine_data_2\n\n\n\nmachine_data_3\n\n modify the data of an existing machine in the worki"
  },
  {
    "id": "chunk_278",
    "text": "odify the data of an existing machine in the working case, or to add a new machine to a plant bus in the working case (see PSSE Program Operation Manual, Plant Data).\n\nmachine_data_4\n\n modify the data of an existing machine in the working case, or to add a new machine to a plant bus in the working case (see PSSE Program Operation Manual, Plant Data).\n\nmbid2dc\n\n change the name of the specified two-terminal dc line.\n\nmbid3wnd\n\n change the identifier of the specified three-winding transformer.\n\nmb"
  },
  {
    "id": "chunk_279",
    "text": "er of the specified three-winding transformer.\n\nmbidatrn\n\n change the identifier of the specified inter-area transfer.\n\nmbidbrn\n\n change the identifier of the specified non-transformer branch or two-winding transformer.\n\nmbidfacts\n\n change the name of the specified FACTS device.\n\nmbidgne\n\nUse this API routine to change the GNE device name of the specified GNE device.\n\nmbidindmac\n\nUse this API routine to change the identifier of the specified induction machine.\n\nmbidload\n\n change the identifier o"
  },
  {
    "id": "chunk_280",
    "text": "ction machine.\n\nmbidload\n\n change the identifier of the specified load.\n\nmbidmac\n\n change the identifier of the specified machine.\n\nmbidmdc\n\n change the name of the specified multi-terminal dc line.\n\nmbidmsl\n\n change the identifier of the specified multi-section line.\n\nmbidshunt\n\n change the identifier of the specified fixed bus shunt.\n\nmbidswshunt\n\n change the identifier of the specified switched bus shunt.\n\nmbidvd\n\n change the voltage droop control name of the specified voltage droop control i"
  },
  {
    "id": "chunk_281",
    "text": "trol name of the specified voltage droop control in the working case.\n\nmbidvsc\n\n change the VSC dc line name of the specified VSC dc line.\n\nmulti_section_line_data\n\n modify the definition of an existing multi-section line grouping in the working case or to add a new multi-section line grouping to the working case (see PSSE Program Operation Manual, Multi-Section Line Grouping Data).\n\nmulti_section_line_edit\n\n modify the status and/or metered end designation of an existing multi-section line grou"
  },
  {
    "id": "chunk_282",
    "text": "designation of an existing multi-section line grouping in the working case (see PSSE Program Operation Manual, Multi-Section Line Grouping Data).\n\nmulti_term_dc_bus_data\n\n modify the data of a dc bus of an existing multi-terminal dc line in the working case or to add a new dc bus to a multi-terminal dc line in the working case (see PSSE Program Operation Manual, Multi-Terminal DC Transmission Line Data).\n\nmulti_term_dc_convr_data\n\n modify the data of a dc converter of an existing multi-terminal "
  },
  {
    "id": "chunk_283",
    "text": "a of a dc converter of an existing multi-terminal dc line in the working case or to add a new converter to a multi-terminal dc line in the working case (see PSSE Program Operation Manual, Multi-Terminal DC Transmission Line Data).\n\nmulti_term_dc_line_chng\n\nUse this API routine to modify the control mode and mode switch voltage of an existing multi- terminal dc line in the working case (see PSSE Program Operation Manual, Multi-Terminal DC Transmission Line Data).\n\nmulti_term_dc_line_data\n\n modify"
  },
  {
    "id": "chunk_284",
    "text": "sion Line Data).\n\nmulti_term_dc_line_data\n\n modify the control mode and mode switch voltage of an existing multi-terminal dc line in the working case or to add a new multi-terminal dc line to the working case (see PSSE Program Operation Manual, Multi-Terminal DC Transmission Line Data).\n\nmulti_term_dc_link_data\n\n modify the data of a dc link of an existing multi-terminal dc line in the working case or to add a new dc link to a multi-terminal dc line in the working case (see PSSE Program Operatio"
  },
  {
    "id": "chunk_285",
    "text": "ine in the working case (see PSSE Program Operation Manual, Multi-Terminal DC Transmission Line Data).\n\nowner_data\n\n modify owner data in the working case (see PSSE Program Operation Manual, Interarea Transfer Data).\n\npbus_add_mod\n\n add or modify transaction event participating bus data.\n\npbus_delete\n\n remove a bus from the set of buses that are participating in a transaction event.\n\nplant_chng\n\n\n\nplant_chng_3\n\n\n\nplant_chng_4\n\nUse this API routine to modify the data of an existing plant that is "
  },
  {
    "id": "chunk_286",
    "text": "e to modify the data of an existing plant that is part of a substation in the working case.\n\nplant_data\n\n\n\nplant_data_3\n\n\n\nplant_data_4\n\n modify the data of an existing plant in the working case, or to add a new plant to the working case (see PSSE Program Operation Manual, Fixed Bus Shunt Data).\n\npurg\n\nUse this API routine to delete specified outaged equipment items from the working case.\n\npurg2dc\n\n delete the specified two-terminal dc line from the working case.\n\npurg3wnd\n\n delete the specified"
  },
  {
    "id": "chunk_287",
    "text": "the working case.\n\npurg3wnd\n\n delete the specified three-winding transformer from the working case.\n\npurg_voltage_droop\n\n delete an existing voltage droop control from the working case.\n\npurgarea\n\n delete areas with no equipment assigned to them from the working case.\n\npurgatrn\n\n delete the specified inter-area transfer from the working case.\n\npurgbrn\n\n delete the specified non-transformer branch or two-winding transformer from the working case.\n\npurgcapcurve\n\n delete the specified machine\u2019s cap"
  },
  {
    "id": "chunk_288",
    "text": "\npurgcapcurve\n\n delete the specified machine\u2019s capability curve from the working case.\n\npurge_multi_term_dc_bus\n\n delete the specified dc bus from the specified multi-terminal dc line in the working case.\n\npurge_multi_term_dc_convr\n\n delete the specified converter from the specified multi-terminal dc line in the working case.\n\npurge_multi_term_dc_link\n\n delete the specified dc link from the specified multi-terminal dc line in the working case.\n\npurgfacts\n\n delete the specified FACTS device from "
  },
  {
    "id": "chunk_289",
    "text": "urgfacts\n\n delete the specified FACTS device from the working case.\n\npurggne\n\nUse this API routine to delete the specified GNE device from the working case.\n\npurgindmac\n\nUse this API routine to delete the specified induction machine from the working case.\n\npurgindmacs\n\nUse this API routine to delete all induction machines from the specified bus in the working case.\n\npurgload\n\n delete the specified load from the working case.\n\npurgloads\n\n delete all loads from the specified bus in the working cas"
  },
  {
    "id": "chunk_290",
    "text": "ll loads from the specified bus in the working case.\n\npurgmac\n\n delete the specified machine from the working case.\n\npurgmdc\n\n delete the specified multi-terminal dc line from the working case.\n\npurgmsl\n\n delete the specified multi-section line grouping from the working case.\n\npurgmut\n\n delete the specified zero sequence mutual coupling from the working case.\n\npurgowner\n\n delete owners with no equipment assigned to them from the working case.\n\npurgplnt\n\n delete the plant and machine data at the "
  },
  {
    "id": "chunk_291",
    "text": "rgplnt\n\n delete the plant and machine data at the specified bus from the working case.\n\npurgshunt\n\n delete the specified fixed bus shunt from the working case.\n\npurgshunts\n\n delete all fixed shunts from the specified bus in the working case.\n\npurgsws\n\n delete all switched shunts from the specified bus in the working case.\n\npurgswshunt\n\n delete the specified switched bus shunt from the working case.\n\npurgvsc\n\n delete the specified VSC dc line from the working case.\n\npurgzone\n\n delete zones with n"
  },
  {
    "id": "chunk_292",
    "text": " the working case.\n\npurgzone\n\n delete zones with no equipment assigned to them from the working case.\n\nratingsettextdata\n\n change the column and descriptions for a particular rating set used in reporting.\n\nshunt_chng\n\nUse this API routine to modify the data of an existing fixed bus shunt in the working case (see PSSE Program Operation Manual, Fixed Bus Shunt Data).\n\nshunt_data\n\n modify the data of an existing fixed bus shunt in the working case or to add a new fixed bus shunt to the working case"
  },
  {
    "id": "chunk_293",
    "text": "r to add a new fixed bus shunt to the working case (see PSSE Program Operation Manual, Fixed Bus Shunt Data).\n\nsolution_parameters\n\n\n\nsolution_parameters_2\n\n\n\nsolution_parameters_3\n\n\n\nsolution_parameters_4\n\n\n\nsolution_parameters_5\n\n modify the power flow solution parameters in the working case (see PSSE Program Operation Manual, Sections 6.3.13, 6.3.18, 6.5.1 and 11.7).\n\nswitched_shunt_chng_3\n\n\n\nswitched_shunt_chng_4\n\n\n\nswitched_shunt_chng_5\n\nUse this API routine to modify the data of an existin"
  },
  {
    "id": "chunk_294",
    "text": " this API routine to modify the data of an existing switched shunt in the working case (see PSSE Program Operation Manual, Switched Shunt Data).\n\nswitched_shunt_data\n\n\n\nswitched_shunt_data_3\n\n\n\nswitched_shunt_data_4\n\n\n\nswitched_shunt_data_5\n\n modify the data of an existing switched shunt in the working case or to add a new switched shunt to the working case (see PSSE Program Operation Manual, Switched Shunt Data).\n\nthree_winding_data\n\n\n\nthree_wnd_imped_chng_3\n\n\n\nthree_wnd_imped_chng_4\n\nUse this "
  },
  {
    "id": "chunk_295",
    "text": "_imped_chng_3\n\n\n\nthree_wnd_imped_chng_4\n\nUse this API routine to modify the impedance data of an existing three-winding transformer in the working case (see PSSE Program Operation Manual, Non-Transformer Branch Data).\n\nthree_wnd_imped_data_3\n\n\n\nthree_wnd_imped_data_4\n\nUse this API routine to modify the impedance data of an existing three-winding transformer in the working case, or to add a new three-winding transformer to the working case (see PSSE Program Operation Manual, Non-Transformer Branc"
  },
  {
    "id": "chunk_296",
    "text": "SE Program Operation Manual, Non-Transformer Branch Data).\n\nthree_wnd_impedance_data\n\n\n\nthree_wnd_winding_data\n\n\n\nthree_wnd_winding_data_3\n\n\n\nthree_wnd_winding_data_4\n\n\n\nthree_wnd_winding_data_5\n\n modify the data of one winding of an existing three-winding transformer in the working case (see PSSE Program Operation Manual, Non-Transformer Branch Data).\n\ntransaction_add_mod\n\n add or modify transaction event data in PSSE working memory.\n\ntransaction_delete\n\n delete a transaction event from PSSE wo"
  },
  {
    "id": "chunk_297",
    "text": "n_delete\n\n delete a transaction event from PSSE working memory.\n\ntransfer_chng\n\nUse this API routine to modify the data of an inter-area transfer in the working case (see PSSE Program Operation Manual, Zone Data).\n\ntransfer_data\n\nUse this API routine to modify the data of an inter-area transfer in the working case, or to add a new inter-area transfer to the working case (see PSSE Program Operation Manual, Zone Data).\n\ntwo_term_dc_converter_data_3\n\n modify the data of a dc converter of an existin"
  },
  {
    "id": "chunk_298",
    "text": "\n\n modify the data of a dc converter of an existing two-terminal dc line in the working case (see PSSE Program Operation Manual, Area Interchange Data).\n\ntwo_term_dc_convr_data\n\n\n\ntwo_terminal_dc_line_chng\n\nUse this API routine to modify the link data of an existing two-terminal dc line in the working case (see PSSE Program Operation Manual, Area Interchange Data).\n\ntwo_terminal_dc_line_data\n\nUse this API routine to modify the link data of an existing two-terminal dc line in the working case, or"
  },
  {
    "id": "chunk_299",
    "text": "sting two-terminal dc line in the working case, or to add a new two-terminal dc line and its link data to the working case (see PSSE Program Operation Manual, Area Interchange Data).\n\ntwo_winding_chng_4\n\n\n\ntwo_winding_chng_5\n\n\n\ntwo_winding_chng_6\n\nUse this API routine to modify the data of an existing two-winding transformer in the working case (see PSSE Program Operation Manual, Owner Data).\n\ntwo_winding_data\n\n\n\ntwo_winding_data_3\n\n\n\ntwo_winding_data_4\n\n\n\ntwo_winding_data_5\n\n\n\ntwo_winding_data_"
  },
  {
    "id": "chunk_300",
    "text": "_data_4\n\n\n\ntwo_winding_data_5\n\n\n\ntwo_winding_data_6\n\n modify the data of an existing two-winding transformer in the working case, or to add a new two-winding transformer to the working case (see PSSE Program Operation Manual, Owner Data).\n\nvoltage_droop_chng\n\nUse this API routine to modify the voltage droop control in the working case(see PSSE Program Operation Manual.\n\nvoltage_droop_data\n\nUse this API routine to modify the voltage droop control in the working case, or to add a new voltage droop"
  },
  {
    "id": "chunk_301",
    "text": "in the working case, or to add a new voltage droop control to the working case (see PSSE Program Operation Manual.\n\nvsc_dc_converter_data\n\n\n\nvsc_dc_converter_data_3\n\n modify the data of a dc converter of an existing VSC dc line in the working case (see PSSE Program Operation Manual, Voltage Source Converter (VSC) DC Transmission Line Data).\n\nvsc_dc_line_chng\n\nUse this API routine to modify the link data of an existing VSC dc line in the working case (see PSSE Program Operation Manual, Voltage So"
  },
  {
    "id": "chunk_302",
    "text": "ase (see PSSE Program Operation Manual, Voltage Source Converter (VSC) DC Transmission Line Data).\n\nvsc_dc_line_data\n\nUse this API routine to modify the link data of an existing VSC dc line in the working case, or to add a new VSC dc line to the working case (see PSSE Program Operation Manual, Voltage Source Converter (VSC) DC Transmission Line Data).\n\nzone_data\n\n modify zone data in the working case (see PSSE Program Operation Manual, Zone Data).\n\n--- Power Flow Operation \u2014 .txt ---\n\nPower Flow"
  },
  {
    "id": "chunk_303",
    "text": ".\n\n--- Power Flow Operation \u2014 .txt ---\n\nPower Flow Operation \u2014 \n\nPower Flow Operation\u00b6\n\n\n\n\n\naccc\n\n\n\naccc_2\n\n\n\naccc_multiple_merge\n\n merge a number of AC contingency solution files (acc files) into one acc file.\n\naccc_multiple_run_report\n\n\n\naccc_multiple_run_report_2\n\n report the results of up to twenty two executions of the AC Contingency Calculation function.\n\naccc_parallel\n\n\n\naccc_parallel_2\n\nUse this API routine to run the second release of the parallel implementation of the AC contingency ca"
  },
  {
    "id": "chunk_304",
    "text": "e parallel implementation of the AC contingency calculation function (use ACCC_WITH_DSP_3 to run AC contingency calculation function serially).\n\naccc_single_run_report\n\n\n\naccc_single_run_report_2\n\n\n\naccc_single_run_report_3\n\n\n\naccc_single_run_report_4\n\n\n\naccc_single_run_report_5\n\n\n\naccc_single_run_report_6\n\nThis API is the sixth release of the AC Contingency Report function.\n\naccc_trip_cor\n\n\n\naccc_trip_cor_2\n\n\n\naccc_trip_cor_3\n\nThis API is the third release of the function to run AC contingency "
  },
  {
    "id": "chunk_305",
    "text": "ird release of the function to run AC contingency analysis with tripping simulation and corrective actions.\n\naccc_with_cor\n\n\n\naccc_with_cor_2\n\n\n\naccc_with_cor_3\n\nThis API is the third release of function to run AC contingency analysis with corrective actions.\n\naccc_with_dsp\n\n\n\naccc_with_dsp_2\n\n\n\naccc_with_dsp_3\n\n run the second release of AC contingency calculation function (ACCC, ACCC_WITH_DSP).\n\naccc_with_trip\n\n\n\naccc_with_trip_2\n\n run the second version of AC contingency calculation function "
  },
  {
    "id": "chunk_306",
    "text": "nd version of AC contingency calculation function with a post- contingency tripping function.\n\naccc_with_trip_parallel\n\n run the parallel version of AC contingency calculation function with a post- contingency tripping function (use ACCC_WITH_TRIP_2 to run the function sequentially).\n\naccor\n\n\n\naccor_2\n\n\n\naccor_3\n\nThis API is the third release of corrective action function.\n\nalert_output\n\n specify the alert device.\n\nallow_pssuserpf\n\n specify or return the option to allow or disallow the loading o"
  },
  {
    "id": "chunk_307",
    "text": "turn the option to allow or disallow the loading or use of the Powerflow Customization Interface (PCI) implementation module (pssuserpf).\n\nalph\n\n print an alphabetically sorted table of all buses in a specified subsystem of the working case (activity ALPH).\n\nappend_accc\n\n replicate system conditions of a contingency case solution, as contained in a designated Saved Case File, in the form of a Contingency Solution Output File.\n\napply_var_limits\n\n specify or return the option for the default VAR l"
  },
  {
    "id": "chunk_308",
    "text": "specify or return the option for the default VAR limits setting; either apply automatically, apply immediately, ignore, or apply on a specific iteration\n\narea\n\n\n\narea_2\n\n tabulate area totals by area, as well as the desired area net interchange (activity AREA).\n\narea_zone\n\n tabulate area totals by area, along with subtotals by zone.\n\narnm\n\n\n\narnm_2\n\nThis API routine is the second release of the area renumbering function.\n\nbase_frequency\n\n specify or return the value of the base frequency option "
  },
  {
    "id": "chunk_309",
    "text": " or return the value of the base frequency option setting.\n\nbgen\n\n convert the mismatch at boundary buses to equivalent load and/or generation (activity BGEN).\n\nbrch\n\n\n\nbrch_2\n\n tabulate those branches where impedances or other characteristics are such that they may be detrimental to the rate of convergence of one or more of the power flow solution activities.\n\nbsnm\n\n change the bus numbers of specified network buses in the working case and retain a tabulation, in file form, of bus number change"
  },
  {
    "id": "chunk_310",
    "text": "n a tabulation, in file form, of bus number changes made (activity BSNM).\n\nbus_input\n\n specify or return the bus input option setting, for either numbers or names.\n\nbus_output\n\n specify or return the bus output option setting, for either numbers or names.\n\nbus_size_level\n\n specify or return the value of the PSSE size level option setting to a multiple of 1,000 between 1,000 and 200,000.\n\nbusn\n\n tabulate unused bus numbers within a specified bus number range (activity BUSN).\n\nca_iterations\n\n spec"
  },
  {
    "id": "chunk_311",
    "text": "umber range (activity BUSN).\n\nca_iterations\n\n specify or return the contingency iterations limit setting.\n\ncase\n\n open a PSSE Saved Case file and transfers its data into the PSSE working case.\n\ncheck_powerflow_data\n\nUse this API routine to perform data checks on the selected categories of powerflow data for all buses in the working case or for all buses in a specified subsystem.\n\ncheckvoltagelimits\n\n tabulate those buses where voltage magnitude is beyond their normal or emergency voltage limits."
  },
  {
    "id": "chunk_312",
    "text": "s beyond their normal or emergency voltage limits.\n\nchkcntduplicon\n\nCheck duplicate labels in Contingengy (CON) file.\n\nchkcntduplidfx\n\nCheck duplicate labels in DFAX file.\n\nclose_powerflow\n\nRemoves the current powerflow working case from PSSE\u2019s working memory.\n\nclose_report\n\nSets the report output device to the standard output and sets the command line to request device selection for individual reporting activities (Activity CLOS).\n\ncmpr\n\n tabulate certain case totals, as contained in the workin"
  },
  {
    "id": "chunk_313",
    "text": "te certain case totals, as contained in the working case, with those of a designated Saved Case (activity CMPR).\n\ncntb\n\n tabulate the voltage setpoints and desired voltage bands of voltage-controlling equipment in the working case (activity CNTB).\n\ncong\n\n convert generators from their power flow representation in preparation for switching studies and dynamic simulations (activity CONG).\n\nconl\n\n convert the constant MVA load for a specified grouping of network loads to a specified mixture of the "
  },
  {
    "id": "chunk_314",
    "text": "ng of network loads to a specified mixture of the constant MVA, constant current, and constant admittance load characteristics (activity CONL).\n\nconnectivity_check\n\n specify or return the option to enable or disable the solution connectivity checking option setting.\n\ncontrol_area_interchange\n\n to specify or return the area interchange control option setting to disabled, or enabled with tie lines only, or enabled with tie lines and loads.\n\ncsv_to_rawx\n\n import a rawx (extended raw data) data tabl"
  },
  {
    "id": "chunk_315",
    "text": "rawx\n\n import a rawx (extended raw data) data table from a CSV (comma-separated values) file.\n\ncsv_to_rawx_with_metamodel\n\n import a rawx (extended raw data) data table from a CSV (comma-separated values) file with metamodel.\n\ndc_tap_adjustment\n\n specify or return the option to enable or disable the dc tap adjustment option setting.\n\ndccc\n\n\n\ndccc_2\n\n run contingency case solutions using a linear network (dc) model (activity DCCC).\n\ndccor\n\n apply corrective actions to the base case using linear p"
  },
  {
    "id": "chunk_316",
    "text": "corrective actions to the base case using linear programming methods.\n\ndccor_2\n\n apply corrective actions to the base case using linear programming methods.\n\ndclf\n\n\n\ndclf_2\n\nUse this API routine to apply the dc analogy network solution algorithm to the network modeled in the working case (activity DCLF).\n\ndcpscopf\n\nThis API is the DC based Preventive Security Constrained Optimal Power Flow solution (DCPSCOPF).\n\ndeltmpfiles\n\nDelete closed temporary files.\n\ndfax\n\n\n\ndfax_2\n\n construct a Distributio"
  },
  {
    "id": "chunk_317",
    "text": "y files.\n\ndfax\n\n\n\ndfax_2\n\n construct a Distribution Factor Data File (activity DFAX).\n\ndfax_contingency\n\n combine one contingency in the first Distribution Factor file with one contingency in the second Distribution Factor file and so on, till specified contingency level is reached, to create multiple event contingencies and then export resulting contingencies to user defined report device.\n\ndfti\n\n compare tie lines, as contained in the working case, with those of a designated Saved Case (activi"
  },
  {
    "id": "chunk_318",
    "text": "ase, with those of a designated Saved Case (activity DFTI).\n\ndiff\n\n compare specified power flow data and solution results, as contained in the working case, with those of a designated Saved Case (activity DIFF).\n\ndscn\n\n electrically disconnect a bus (activity DSCN).\n\nduplicate_cntlabel_check\n\n specify or return the option to enable or disable the duplicated contingency labels check     when Distribution Factor Data File (.dfx) or Contingency Description Data File (.con) files are used.\n\necdi\n\n "
  },
  {
    "id": "chunk_319",
    "text": "cription Data File (.con) files are used.\n\necdi\n\n place machines in a specified subsystem on- or off-line to satisfy a given subsystem minimum capacity; the in-service machines in the subsystem are then dispatched on the basis of incremental cost to meet a specified total subsystem generation (activity ECDI).\n\necho\n\n enable or disable response echoing (activity ECHO).\n\neeqv\n\n construct an electrical equivalent of a specified subsystem of the working case (activity EEQV).\n\neqrd\n\n build an electri"
  },
  {
    "id": "chunk_320",
    "text": "ing case (activity EEQV).\n\neqrd\n\n build an electrical equivalent of radial and, optionally, two-point Type 1 buses in a specified subsystem of the working case (activity EQRD).\n\nexam\n\n tabulate all power flow data pertaining to a specified bus (activity EXAM).\n\nfact\n\n factorize the network admittance matrix in preparation for switching studies and dynamic simulations (activity FACT).\n\nfdns\n\n apply the fixed slope decoupled Newton-Raphson power flow calculation (activity FDNS).\n\nfile_overwrite\n\n "
  },
  {
    "id": "chunk_321",
    "text": "ow calculation (activity FDNS).\n\nfile_overwrite\n\n specify or return the option to set the file overwrite option setting to either ask first or overwrite.\n\nfind\n\n tabulate a list of buses matching a partial extended bus name (activity FIND).\n\nflat_start\n\n specify or return the option to enable or disable the voltage flat start option setting.\n\nfnsl\n\n apply the Newton-Raphson power flow calculation (activity FNSL).\n\ngcap\n\n\n\ngcap_2\n\n print a report of machine loading and reactive power limit data ("
  },
  {
    "id": "chunk_322",
    "text": "of machine loading and reactive power limit data (activity GCAP).\n\ngdif\n\n calculate differences between the working case and a designated Saved Case (activity GDIF).\n\ngendsp\n\n impose a contingency specified in the Distribution Factor Data file and apply the generation dispatch algorithm used in contingency analysis on the working case.\n\ngendsp_2\n\n impose a contingency specified in the Distribution Factor Data file and apply the generation dispatch algorithm used in contingency analysis on the wo"
  },
  {
    "id": "chunk_323",
    "text": "h algorithm used in contingency analysis on the working case.\n\ngens\n\n tabulate the loading and voltage conditions at plant buses (activity GENS).\n\ngeol\n\n tabulate the loading and voltage conditions at the generator terminals for online machines at Type 2 and 3 buses in the working case (activity GEOL).\n\ngetcontingencysavedcase\n\nUse this API routine to place the working case in the form of a specified system condition as calculated during a previous run of one of the members of the the AC conting"
  },
  {
    "id": "chunk_324",
    "text": "us run of one of the members of the the AC contingency calculation family.\n\ngic_pf\n\nAdd activity GIC calculated Mvar Qloss in scaled manner to the working case to arrive at the converged power flow solution.\n\ngnestatus\n\n specify or return the status of a GNE device.\n\ngnet\n\n change in-service generation to negative MVA load at all Type 2 and 3 buses in the subsystem specified by the user.\n\nimnet\n\nUse this API routine to change the status of induction machines that are in-service to out-of- servic"
  },
  {
    "id": "chunk_325",
    "text": "ion machines that are in-service to out-of- service, and to replace the power flowing from the network into the machine with constant power load.\n\nimoutage\n\nUse this API routine to change the status of induction machines that are in-service, but that have been set to the \u201cstalled\u201d (for motors) or \u201ctripped\u201d (for generators) state by the power flow solution, to out-of-service.\n\nimpc\n\n calculate the impact of transaction events on MW flows using a linear network (dc) model.\n\nimplement_transfer\n\n\n\ni"
  },
  {
    "id": "chunk_326",
    "text": "inear network (dc) model.\n\nimplement_transfer\n\n\n\nimplement_transfer_2\n\nUse this API routine to apply a specified transfer using the same transfer dispatch methods that are available in the PV analysis calculation engine.\n\ninlf\n\n\n\ninlf_2\n\nUse this API routine to run the second release of the inertial and governor response power flow calculation.\n\ninta\n\n summarize tie flows between an interchange area and all other areas in the working case.\n\nintz\n\n summarize tie flows between each zone and all ot"
  },
  {
    "id": "chunk_327",
    "text": "\n summarize tie flows between each zone and all other zones in the working case.\n\nisolate_levels\n\n specify or return the maximum number of levels to go outward when isolating an element by breaker.\n\njoin\n\nThe API combines two buses into a single bus.\n\nlamp\n\n print power flow solution output, including loadings in amps, in a traditional power flow report format.\n\nline_shunt_reporting\n\n specify or return the option to enable or disable the line shunt reporting.\n\nlines_per_page\n\n specify or return "
  },
  {
    "id": "chunk_328",
    "text": "nt reporting.\n\nlines_per_page\n\n specify or return the page length limits for the four output devices; also retrieve device names.\n\nlines_per_page_one_device\n\n specify or return the page length limit and device name for one of the four output devices.\n\nlist\n\nUse this API routine to tabulate the power flow working case in a form suitable for problem data documentation.\n\nlistcontingencysavedcases\n\nUse this API routine to obtain a report listing some or all of the system conditions preserved in a ZI"
  },
  {
    "id": "chunk_329",
    "text": " or all of the system conditions preserved in a ZIP Archive Output File that was created during a previous run of one of the members of the the AC contingency calculation family.\n\nllrf\n\n apply the line loading relief calculation using a linear network (dc) model.\n\nload_reduction\n\n tabulate the amount of load reduction in a specified subsystem due to the voltage at the bus to which the load is connected being below PQBRAK (for constant MVA load) or 0.5 (for constant current load.\n\nlout\n\n print th"
  },
  {
    "id": "chunk_330",
    "text": "r 0.5 (for constant current load.\n\nlout\n\n print the power flow solution results in a traditional power flow report format.\n\nltap\n\n insert a bus at a designated location along a line.\n\nmaccc\n\n\n\nmaccc_2\n\n run the second release of multiple level contingency analysis.\n\nmaccc_3\n\n run the third release of multiple level contingency analysis.\n\nmaccc_parallel\n\n run the multiple level contingency analysis in parallel when the number of contingency processors in Program Settings is greater than 1.\n\nmaccc"
  },
  {
    "id": "chunk_331",
    "text": "sors in Program Settings is greater than 1.\n\nmaccc_parallel_2\n\n run the multiple level contingency analysis in parallel when the number of contingency processors in Program Settings is greater than 1.\n\nmaccc_trip_cor\n\n\n\nmaccc_trip_cor_2\n\n\n\nmaccc_trip_cor_3\n\nThis API is the third release of function to run multiple AC contingency analysis with tripping simulations and corrective actions.\n\nmaccc_trip_cor_4\n\nThis API is the third release of function to run multiple AC contingency analysis with trip"
  },
  {
    "id": "chunk_332",
    "text": " to run multiple AC contingency analysis with tripping simulations and corrective actions.\n\nmaccc_with_cor\n\n\n\nmaccc_with_cor_2\n\n\n\nmaccc_with_cor_3\n\nThis API is the third release of function to run multiple AC contingency analysis with corrective actions.\n\nmaccc_with_cor_4\n\nThis API is the third release of function to run multiple AC contingency analysis with corrective actions.\n\nmaccc_with_trip\n\n\n\nmaccc_with_trip_2\n\n run the second version of multiple level contingency analysis with tripping sim"
  },
  {
    "id": "chunk_333",
    "text": "tiple level contingency analysis with tripping simulation.\n\nmaccc_with_trip_3\n\n run the second version of multiple level contingency analysis with tripping simulation.\n\nmaccc_with_trip_parallel\n\n run the multiple level contingency analysis with tripping simulation in parallel when the number of contingency processors in Program Settings is greater than 1.\n\nmaccc_with_trip_parallel_2\n\n run the multiple level contingency analysis with tripping simulation in parallel when the number of contingency "
  },
  {
    "id": "chunk_334",
    "text": "lation in parallel when the number of contingency processors in Program Settings is greater than 1.\n\nmatrix_growth_factor\n\n specify or return the value of the matrix growth factor option setting.\n\nmcre\n\n read a Machine Impedance Data File and add the data specified in it to the working case.\n\nmodr\n\n uniformly increase or decrease the line resistances of in-service nontransformer branches.\n\nmov_alpha\n\n specify or return the value of the MOV iteration ALPHA option setting.\n\nmov_iterations\n\n specif"
  },
  {
    "id": "chunk_335",
    "text": "ion ALPHA option setting.\n\nmov_iterations\n\n specify or return the value of the maximum MOV iterations option setting.\n\nmov_tolerance\n\n specify or return the value of the MOV iteration tolerance option setting.\n\nmove3wnd\n\n disconnect the third bus of a specified three-winding transformer from the bus to which it is currently connected, and reconnect it to a designated bus.\n\nmovebrn\n\n disconnect the to bus of a specified non-transformer branch or two-winding transformer from the bus to which it is"
  },
  {
    "id": "chunk_336",
    "text": "wo-winding transformer from the bus to which it is currently connected, and reconnect it to a designated bus.\n\nmoveindmac\n\nUse this API routine to disconnect the specified induction machine from the bus to which it is currently connected, and reconnect it to a designated bus.\n\nmoveindmacs\n\nUse this API routine to disconnect all of the induction machines at the specified bus, and reconnect them to a designated bus.\n\nmoveload\n\n disconnect the specified load from the bus to which it is currently co"
  },
  {
    "id": "chunk_337",
    "text": "fied load from the bus to which it is currently connected, and reconnect it to a designated bus.\n\nmoveloads\n\n disconnect all of the load from the specified bus, and reconnect it to a designated bus.\n\nmovemac\n\n disconnect the specified machine from the bus to which it is currently connected, and reconnect it to a designated bus.\n\nmoveplnt\n\n disconnect all of the machines from the specified bus, and reconnect it to a designated bus.\n\nmoveshunt\n\n disconnect the specified fixed shunt from the bus to"
  },
  {
    "id": "chunk_338",
    "text": "sconnect the specified fixed shunt from the bus to which it is currently connected, and reconnect it to a designated bus.\n\nmoveshunts\n\n disconnect all of the fixed shunts from the specified bus and reconnect them to a designated bus.\n\nmovesws\n\n\n\nmoveswshunt\n\n disconnect the specified switched shunt from the bus to which it is currently connected, and reconnect it to a designated bus.\n\nmoveswshunts\n\n disconnect all of the switched shunts from the specified bus and reconnect them to a designated b"
  },
  {
    "id": "chunk_339",
    "text": "specified bus and reconnect them to a designated bus.\n\nmslv\n\n apply the modified Gauss-Seidel power flow calculation.\n\nmsum\n\n print a summary of mileage by owner.\n\nmtdc\n\n produce a report of bus voltages and flows for each in-service multi-terminal dc line.\n\nmultisection_reporting\n\n specify or return the option to enable or disable multi-section line reporting.\n\nmwmi\n\n apply the MAPP MW-mile calculation .\n\nmwomwmsf\n\n tabulate generation (MW) on MW-mile shift factors for a specified transaction e"
  },
  {
    "id": "chunk_340",
    "text": "W-mile shift factors for a specified transaction event.\n\nmwomwosf\n\n tabulate generation (MW) on MW-ohm shift factors for a specified transaction event.\n\nn11_accc\n\n\n\nn11_accc_2\n\nThis API is the second release of N-1-1 contingency analysis solution.\n\nn11_accc_3\n\nThis API is the second release of N-1-1 contingency analysis solution.\n\nn11_accc_parallel\n\n run the N-1-1 contingency analysis in parallel when the number of contingency processors in Program Settings is greater than 1.\n\nn11_accc_parallel_"
  },
  {
    "id": "chunk_341",
    "text": "am Settings is greater than 1.\n\nn11_accc_parallel_2\n\n run the N-1-1 contingency analysis in parallel when the number of contingency processors in Program Settings is greater than 1.\n\nn11_accc_pscopf\n\n\n\nn11_accc_pscopf_2\n\nThe API is the second release of N-1-1 contingency analysis solution in either corrective mode or security constrained optimal power flow mode (SCOPF).\n\nn11_accc_pscopf_3\n\nThe API is the second release of N-1-1 contingency analysis solution in either corrective mode or security "
  },
  {
    "id": "chunk_342",
    "text": "is solution in either corrective mode or security constrained optimal power flow mode (SCOPF).\n\nnetg\n\n change the in-service generation to negative MVA load at all Type 2 and 3 buses except those in the subsystem specified by the user.\n\nnew_dimension\n\n reset PSSE to an increased bus size level.\n\nnewcas\n\n\n\nnewcase_2\n\nThis API is the second release of the function used to initialize a new power flow case.\n\nnewton_tolerance\n\n specify or return the value of the default Newton-Raphson convergence tol"
  },
  {
    "id": "chunk_343",
    "text": "alue of the default Newton-Raphson convergence tolerance.\n\nnon_divergent\n\n specify or return the option to specify or return the option to enable or disable the non-divergent Newton power flow solution.\n\nnon_trans_percent_units\n\n set the non-transformer branch percent units option setting to either MVA or current expressed as MVA.\n\nnsol\n\n apply the decoupled Newton-Raphson power flow calculation.\n\nnumber_threads\n\n specify or return the number of processors available for parallel operations.\n\nord"
  },
  {
    "id": "chunk_344",
    "text": "processors available for parallel operations.\n\nordr\n\n calculate a sparsity preserving ordering of buses in preparation for the processing of network matrices.\n\notdf\n\n tabulate vectors of distribution factors using a linear network (dc) model.\n\noutput_y_matrix\n\n display the network admittance matrix for a subsystem of the working case in the form of a list of matrix terms.\n\nouts\n\n tabulate those components in the working case that are removed from service.\n\nownm\n\n\n\nownm_2\n\n\n\nownm_3\n\nThis API rout"
  },
  {
    "id": "chunk_345",
    "text": " service.\n\nownm\n\n\n\nownm_2\n\n\n\nownm_3\n\nThis API routine is the third release of the owner renumbering function.\n\nownr\n\n tabulate owner totals by owner.\n\npath\n\n specify a directory pathname.\n\nphase_shift_adjustment\n\n specify or return the option to enable or disable the phase shift adjustment.\n\npoly\n\n calculate interchange limits of a study system against two opposing systems using a linear network (dc) model.\n\npout\n\n print the power flow solution results with boundary condition and flow informatio"
  },
  {
    "id": "chunk_346",
    "text": "esults with boundary condition and flow information on the left side of the report and other information on the right side.\n\npower_output\n\n specify or return the option to display power output in either MVA or kVA.\n\npp_accc\n\n report the results of the AC contingency calculation function.\n\npp_accc_multi_case\n\n\n\nprint_outaged_branches\n\n specify or return the option to enable or disable whether to print out-of- service branches.\n\nprint_winding_buses\n\n specify or return the option to enable or disab"
  },
  {
    "id": "chunk_347",
    "text": "\n\n specify or return the option to enable or disable whether to print winding \u201cto\u201d buses of three-winding transformers.\n\nprogress_output\n\n specify the progress output device.\n\nprompt_output\n\n specify the prompt output device.\n\nprti\n\n print the 16 line long title.\n\npscopf\n\n\n\npscopf_2\n\nThis API is the second release of Preventive Security Constrained Optimal Power Flow solution (PSCOPF).\n\npseb\n\n convert a PSEB command file into a PSSE response file.\n\npssehalt\n\n\n\npssehalt_2\n\n end the operation of P"
  },
  {
    "id": "chunk_348",
    "text": ".\n\npssehalt\n\n\n\npssehalt_2\n\n end the operation of PSSE, closes all associated files and returns to the calling application.\n\npv_engine\n\n\n\npv_engine_1a\n\n\n\npv_engine_2\n\n\n\npv_engine_3\n\n\n\npv_engine_4\n\n\n\npv_engine_5\n\n\n\npv_engine_6\n\nUse this API routine to run the PV analysis calculation engine.\n\nqv_engine\n\n\n\nqv_engine_2\n\n\n\nqv_engine_3\n\n\n\nqv_engine_4\n\nUse this API routine to run the QV analysis calculation engine.\n\nrank\n\n estimate the severity of designated single branch outage contingencies and builds"
  },
  {
    "id": "chunk_349",
    "text": "ated single branch outage contingencies and builds a contingency solution output file with contingencies specified in decreasing order of their estimated severities.\n\nrank_brn_and_mac\n\n estimate the severity of designated single element outage contingencies and builds a contingency description data file with contingencies specified in decreasing order of their estimated severities.\n\nrate\n\n\n\nrate_2\n\n check branch loadings.\n\nrating_set\n\n specify or return the current rating set, from 1 to 12.\n\nraw"
  },
  {
    "id": "chunk_350",
    "text": " return the current rating set, from 1 to 12.\n\nrawd\n\n\n\nrawd_2\n\n replicate the working case in the form of a power flow raw data file.\n\nrawdx\n\n\n\nrawx_to_csv\n\n export rawx (extended raw data) table to a CSV (comma-separated values) file.\n\nrdch\n\n read power flow change data into the working case.\n\nrdchrawversion\n\n read a Power Flow Change Raw Data File into the working case.\n\nrdeq\n\n build an electrical equivalent of radial and, optionally, two-point Type 1 buses outside of a specified subsystem of "
  },
  {
    "id": "chunk_351",
    "text": " Type 1 buses outside of a specified subsystem of the working case.\n\nread\n\n read a power flow raw data file and add all the data specified in it to the working case.\n\nreadcapcurves\n\n read data contained in a Machine Capability Curve Data File into the working case.\n\nreadrawversion\n\n read a power flow raw data file and add all the data specified in it to the working case.\n\nreadrawx\n\n read an extended raw data file and add all the data specified to the working case.\n\nreadsub\n\n read a power flow ra"
  },
  {
    "id": "chunk_352",
    "text": " the working case.\n\nreadsub\n\n read a power flow raw data file and add subsystem data specified in it to the working case.\n\nreadsubrawversion\n\n read a power flow raw data file and add subsystem data specified in it to the working case.\n\nreadx\n\n\n\nrecn\n\n electrically reconnect a bus.\n\nregb\n\n tabulate those buses where voltages are controlled by generation, switched shunts, and/or other voltage controlling equipment.\n\nrelind\n\n\n\nrelind_2\n\n run probabilistic reliability assessment for transmission sys"
  },
  {
    "id": "chunk_353",
    "text": "listic reliability assessment for transmission systems.\n\nremm\n\n read transaction event data from a transactions raw data file and add it to PSSE working memory.\n\nreport_output\n\n specify the report output device.\n\nresq\n\n read sequence data from a sequence data file and add it to the working case.\n\nresqversion\n\n read a network sequence data file and add all the data specified in it to the working case.\n\nresult_table_output\n\n get and set the default tabular output.\n\nreti\n\n read the long title from "
  },
  {
    "id": "chunk_354",
    "text": " tabular output.\n\nreti\n\n read the long title from an input file into the working case.\n\nretry_pssuserpf\n\n allow the loading or use of the Powerflow Customization Interface (PCI) implementation module (pssuserpf) after a failure.\n\nrev29_names\n\n set the extended bus name input format to either the PSSE-29 or PSSE-30 format.\n\nrnfi\n\n reproduce the results of a working case bus renumbering operation in auxiliary data input files.\n\nrsol\n\n perform a robust power flow solution (activity RSOL).\n\nrunlasts"
  },
  {
    "id": "chunk_355",
    "text": "ust power flow solution (activity RSOL).\n\nrunlastsolution\n\n run the last known power flow solution.\n\nrwcm\n\n replicate the working case in IEEE common tape format.\n\nrwma\n\n replicate machine parametric data from the working case in the form of a machine impedance data file.\n\nrwmm\n\n replicate transaction event data in the form of a transactions data file.\n\nrwsq\n\n\n\nrwsq_2\n\n replicate the sequence data contained in the working case in the form of a sequence data file.\n\nsave\n\n save the PSSE working ca"
  },
  {
    "id": "chunk_356",
    "text": "quence data file.\n\nsave\n\n save the PSSE working case in a saved case file.\n\nscal\n\n\n\nscal_2\n\n\n\nscal_3\n\n\n\nscal_4\n\nUse this API routine to uniformly increase or decrease any or all specified bus quantities for a specified group of buses.\n\nsensitivity_flow\n\nThis API is used to calculate sensitivity factors of a branch flow to MW power at buses, MW power at generator buses, MW at load buses, phase angle of phase shifters, tap postion of tap changing transformers as well as admittance of switched shun"
  },
  {
    "id": "chunk_357",
    "text": "ransformers as well as admittance of switched shunts:\n\nsensitivity_flows\n\nThis API is used to calculate sensitivity factors of flows on the branches in a subsystem to MW power at buses, MW power at generator buses, MW power at load buses, phase angle of phase shifters, tap postion of tap changing transformers as well as admittance of switched shunts.\n\nsensitivity_interface\n\nThis API is used to calculate sensitivity factors of  an interface flow to MW power at buses, MW power at generator buses, "
  },
  {
    "id": "chunk_358",
    "text": "o MW power at buses, MW power at generator buses, MW power at load buses, phase angle of phase shifters, tap position of tap changing transformers as well as admittance of switched shunts.\n\nsensitivity_voltage\n\nThis API is used to calculate sensitivity factors of a bus voltage to MW and MVar power at buses, MW power at generator buses, MW and MVar at load buses, phase angle of phase shifters, tap postion of tap changing transformers as well as admittance of switched shunts.\n\nsensitivity_voltages"
  },
  {
    "id": "chunk_359",
    "text": "mittance of switched shunts.\n\nsensitivity_voltages\n\nThis API is used to calculate sensitivity factors of  bus voltages in a subsystem to MW and MVar power at buses, MW power at generator buses, MW and MVar at load buses, phase angle of phase shifters, tap postion of tap changing transformers as well as admittance of switched shunts.\n\nset_input_dev\n\n set the terminal input device to a file.\n\nset_progress_verbose\n\n to set the option progress message verbose value.\n\nshnt\n\n tabulate fixed and/or swi"
  },
  {
    "id": "chunk_360",
    "text": "e verbose value.\n\nshnt\n\n tabulate fixed and/or switched bus shunts contained in the working case.\n\nshort_circuit_coordinates\n\n specify or return the option to set the fault analysis voltage and current output coordinates to either rectangular or polar coordinates.\n\nshort_circuit_modeling\n\n specify or return the option for the fault analysis modeling setting; either normal three-phase or center tapped two-phase.\n\nshort_circuit_units\n\n specify or return the option to set the fault analysis voltage"
  },
  {
    "id": "chunk_361",
    "text": "eturn the option to set the fault analysis voltage and current output units to either per unit or physical units.\n\nshort_circuit_warning\n\n specify or return the option to enable or disable the fault analysis warning option setting.\n\nshort_circuit_z_coordinates\n\n specify or return the option to set the fault analysis output impedance coordinates to either rectangular or polar coordinates.\n\nshort_circuit_z_units\n\n specify or return the option to set the fault analysis output impedance units to eit"
  },
  {
    "id": "chunk_362",
    "text": "t the fault analysis output impedance units to either per unit or ohms.\n\nshow\n\n tabulate summaries of Saved Case and/or Snapshot Files.\n\nshowtable\n\nDirects a report table to output console.\n\nshowtablebyindex\n\nThis API routine was first introduced in release 35.\n\nsize\n\n obtain a summary of the number of components in the working case (activity SIZE).\n\nsolv\n\n apply the Gauss-Seidel power flow calculation.\n\nspcb\n\n calculate positive sequence equivalents of branch unbalances.\n\nspil\n\n calculate trans"
  },
  {
    "id": "chunk_363",
    "text": "ents of branch unbalances.\n\nspil\n\n calculate transmission interchange limits using a linear network (dc) model.\n\nsplt\n\n add a bus to the working case and place a zero impedance line between bus BUS and the new bus.\n\nsqli\n\n tabulate the sequence data in a form suitable for problem data documentation.\n\nsraind\n\n run the substation reliability analysis.\n\nstop\n\n\n\nstop_2\n\n end the operation of PSSE.\n\nsubs\n\n summarize conditions in the working case by tabulating the conditions at each swing system bus,"
  },
  {
    "id": "chunk_364",
    "text": "abulating the conditions at each swing system bus, conditions at each area slack area bus, number of components, generation/ load/shunt totals, and loss/line shunt/charging totals by voltage levels.\n\nswitched_shunt_adjustment\n\n specify or return the option to enable or disable switched shunt adjustment.\n\ntap_adjustment\n\n specify or return the option for the default tap adjustment setting; either disabled, stepping or direct.\n\ntext\n\nThis API does nothing.\n\ntflg\n\n set or reset the adjustment contr"
  },
  {
    "id": "chunk_365",
    "text": "nothing.\n\ntflg\n\n set or reset the adjustment control mode flags for all automatically adjustable transformers contained in the specified subsystem.\n\nties\n\n tabulate the flows on all area tie lines, with tie flows grouped by area.\n\ntiez\n\n tabulate the flows on all zone tie lines, with tie flows grouped by zone.\n\ntime\n\n tabulate timing statistics.\n\ntlst\n\n tabulate those transformers in the working case where off-nominal turns ratio or phase shift angle may be adjusted by the power flow solution ac"
  },
  {
    "id": "chunk_366",
    "text": "ngle may be adjusted by the power flow solution activities.\n\ntltg\n\n calculate transmission interchange limits using a linear network (dc) model.\n\ntpch\n\n check the adjustment data associated with voltage or flow controlling transformers.\n\ntransformer_percent_units\n\n specify or return the option to set the transformer percent units to either MVA or current expressed as MVA.\n\ntransmission_line_units\n\n to specify or return the option set the transmission line units to either per unit or ohms.\n\ntree\n"
  },
  {
    "id": "chunk_367",
    "text": "sion line units to either per unit or ohms.\n\ntree\n\n check for the existence of in-service ac islands that do not contain a Type 3 (swing) bus.\n\ntspfprofilecurvevalue\n\n return real parameters of Time Series Power Flow profile data.\n\ntysl\n\n run switching study network solutions.\n\nuser\n\n run the user-written activity, subroutine USERAC.\n\nvamm\n\n tabulate the vector absolute MW-mile report.\n\nvamo\n\n tabulate the vector absolute MW-ohm report.\n\nvchk\n\n tabulate those buses where voltage magnitude is out"
  },
  {
    "id": "chunk_368",
    "text": "abulate those buses where voltage magnitude is outside a specified range.\n\nvoltage_input\n\n specify or return the voltage input option setting; either per unit or kV.\n\nvoltage_output\n\n specify or return the voltage output option setting; either per unit or kV.\n\nvsmo\n\n tabulate the vector MW-ohm report.\n\nwrite_options_file\n\n save the present values of the PSSE-25 program option settings to the file psse.opt.\n\nwritecapcurves\n\n write the capability curve data in the working case in the form of a Cap"
  },
  {
    "id": "chunk_369",
    "text": "urve data in the working case in the form of a Capability Curve Raw Data File.\n\nwriterawversion\n\n replicate the working case in the form of power flow raw data file compatible with PSSE 15 or later.\n\nwriterawx\n\n write an extended raw data file from data in the current working case.\n\nwriterawxsubsys\n\n write an extended raw data file from data in the current working case, specifying a subsystem.\n\nwriteseqversion\n\n\n\nwriteseqversion_2\n\n replicate the working case in the form of a network sequence da"
  },
  {
    "id": "chunk_370",
    "text": " working case in the form of a network sequence data file compatible with PSSE 27 or later.\n\nxeqv\n\n build an electrical equivalent of the portion of the working case outside of a specified subsystem of the working case.\n\nzone\n\n\n\nzone_2\n\n tabulate zone totals by zone.\n\nzone_area\n\n tabulate zone totals by zone, along with subtotals by area.\n\nzonm\n\n\n\nzonm_2\n\nUse this API routine to reassign the buses, loads and/or induction machines in a specified subsystem of the working case from their original z"
  },
  {
    "id": "chunk_371",
    "text": "ubsystem of the working case from their original zone to a designated zone.\n\n--- Scenarios \u2014 .txt ---\n\nScenarios \u2014 \n\nScenarios\u00b6\n\n\n\n\n\nclosescenariofile\n\n\n\nnewscenariofile\n\n\n\nopenscenariofile\n\n\n\nsavescenariofile\n\n\n\nscenarioclose\n\n close the currently open Scenario.\n\nscenariocopyfile\n\n copy a file from one group to another group.\n\nscenariofileadd\n\n add a file to the specified group.\n\nscenariofilecount\n\n retrieve the number of files in a specified group in the Scenario.\n\nscenariofilegetattrs\n\n retri"
  },
  {
    "id": "chunk_372",
    "text": "oup in the Scenario.\n\nscenariofilegetattrs\n\n retrieve the attributes of the specified file.\n\nscenariofilegetcomments\n\n retrieve the comments for the specified file.\n\nscenariofilelengthcomments\n\n determine the buffer size needed to hold the comments for the specified file.\n\nscenariofilelist\n\n retrieve the list of files in the specified group.\n\nscenariofileremove\n\n remove a file from the specified group.\n\nscenariofilerename\n\n rename one of the files in the Scenario.\n\nscenariofilesetattrs\n\n modify "
  },
  {
    "id": "chunk_373",
    "text": "s in the Scenario.\n\nscenariofilesetattrs\n\n modify the attributes of the specified file.\n\nscenariofilesetcomments\n\n define or modify the comments for the specified file.\n\nscenariogetattrs\n\n retrieve the attributes of the Scenario.\n\nscenariogetcomments\n\n retrieve the Scenario comments.\n\nscenariogetopt\n\n retrieve the Scenario options.\n\nscenariogroupadd\n\n add a group to the Scenario.\n\nscenariogroupcount\n\n retrieve the number of groups in the Scenario.\n\nscenariogroupgetcomments\n\n retrieve the comment"
  },
  {
    "id": "chunk_374",
    "text": ".\n\nscenariogroupgetcomments\n\n retrieve the comments for the specified group.\n\nscenariogrouplengthcomments\n\n determine the buffer size needed to hold the comments for the specified group.\n\nscenariogrouplist\n\n retrieve the list of groups in the Scenario.\n\nscenariogroupopen\n\n add a group to the Scenario.\n\nscenariogroupremove\n\n remove a group from the Scenario.\n\nscenariogrouprename\n\n rename one of the groups in the Scenario.\n\nscenariogroupsetcomments\n\n define or modify the comments for the specified"
  },
  {
    "id": "chunk_375",
    "text": "\n\n define or modify the comments for the specified group.\n\nscenarioisdirty\n\n determine if there are any unsaved changes in the current Scenario.\n\nscenarioisvalid\n\n determine if there is a valid Scenario in memory.\n\nscenariolengthcomments\n\n determine the buffer size needed to hold the current Scenario comments.\n\nscenariomodelgroup\n\n create a new group that is identical to another group.\n\nscenariomovefile\n\n move a file from one group to another group.\n\nscenarionew\n\n create a new Scenario.\n\nscenari"
  },
  {
    "id": "chunk_376",
    "text": "up.\n\nscenarionew\n\n create a new Scenario.\n\nscenarioopen\n\n open a previously created Scenario.\n\nscenariosave\n\n save the currently open Scenario.\n\nscenariosetattrs\n\n modify the root path and startup group attributes of the Scenario.\n\nscenariosetcomments\n\n define or modify the Scenario comments.\n\nscenariosetopt\n\n modify the Scenario options.\n\nscenariotrackfileadd\n\n add the files currently being tracked.\n\nscenariotrackfilelist\n\n retrieve the list of files being tracked.\n\nscenariotrackfilenum\n\n retri"
  },
  {
    "id": "chunk_377",
    "text": "files being tracked.\n\nscenariotrackfilenum\n\n retrieve the current number of files being tracked.\n\nscenariounzip\n\n unzip a zipped Scenario.\n\nscenariounzipproblems\n\n retrieve the problems that occurred during the last unzip attempt.\n\nscenariounzipsolutions\n\n submit potential solutions to the problems that occurred during the last unzip attempt.\n\nscenariozip\n\n zip up the current Scenario.\n\nscenariozipactive\n\n determine if the Scenario is currently in Zip Mode.\n\nscenariozipopen\n\n open a zipped Scena"
  },
  {
    "id": "chunk_378",
    "text": "n Zip Mode.\n\nscenariozipopen\n\n open a zipped Scenario.\n\nscenariozipsave\n\nThis API routine was first introduced in release 33.2.\n\n--- Set Disturbance Definition \u2014 .txt ---\n\nSet Disturbance Definition \u2014 \n\nSet Disturbance Definition\u00b6\n\n\n\n\n\ndist_def_3phase_bus_fault\n\n define a three phase fault at a bus in dynamic simulations.\n\ndist_def_3wind_fault\n\n define a fault at the IBUS end of a three-winding transformer in dynamic simulations.\n\ndist_def_branch_fault\n\n define a fault at the IBUS end of a non-t"
  },
  {
    "id": "chunk_379",
    "text": "_fault\n\n define a fault at the IBUS end of a non-transformer branch or a two-winding transformer in dynamic simulations.\n\ndist_def_scmu_fault_3\n\n define an unbalanced fault at a bus in dynamic simulations.\n\ndist_def_spcb_fault_2\n\nUse this API routine to define a branch unbalance in dynamic simulations.\n\n--- Set Disturbance \u2014 .txt ---\n\nSet Disturbance \u2014 \n\nSet Disturbance\u00b6\n\n\n\n\n\ndist_3phase_bus_fault\n\n apply a three phase fault at a bus during dynamic simulations.\n\ndist_3wind_close\n\n set a three-wi"
  },
  {
    "id": "chunk_380",
    "text": "ic simulations.\n\ndist_3wind_close\n\n set a three-winding transformer to in-service during dynamic simulations.\n\ndist_3wind_fault\n\n apply a fault at the IBUS end of a three-winding transformer during dynamic simulations.\n\ndist_3wind_trip\n\n set a three-winding transformer to out-of-service during dynamic simulations.\n\ndist_branch_close\n\n set a non-transformer branch or a two-winding transformer to in-service during dynamic simulations.\n\ndist_branch_fault\n\n apply a fault at the IBUS end of a non-tra"
  },
  {
    "id": "chunk_381",
    "text": "fault\n\n apply a fault at the IBUS end of a non-transformer branch or a two-winding transformer during dynamic simulations.\n\ndist_branch_trip\n\n set a non-transformer branch or a two-winding transformer to out-of-service during dynamic simulations.\n\ndist_bus_fault\n\n\n\ndist_bus_fault_2\n\n\n\ndist_bus_fault_3\n\n apply an unbalanced fault at a bus during dynamic simulations.\n\ndist_bus_trip\n\n disconnect a bus during dynamic simulations.\n\ndist_clear_fault\n\n clear a fault during dynamic simulations.\n\ndist_ma"
  },
  {
    "id": "chunk_382",
    "text": "clear a fault during dynamic simulations.\n\ndist_machine_trip\n\n set a machine to out-of-service during dynamic simulations.\n\ndist_scmu_fault\n\n\n\ndist_scmu_fault_2\n\n\n\ndist_scmu_fault_3\n\n calculate an unbalanced fault and apply the equivalent positive sequence fault admittance at a bus during dynamic simulations.\n\ndist_spcb_fault\n\n\n\ndist_spcb_fault_2\n\nUse this API routine to run the second release of the dynamics branch unbalance function.\n\n--- Single Element Data \u2014 .txt ---\n\nSingle Element Data \u2014 \n"
  },
  {
    "id": "chunk_383",
    "text": "e Element Data \u2014 .txt ---\n\nSingle Element Data \u2014 \n\nSingle Element Data\u00b6\n\n\n\n\n\napierrstr\n\n return the message string associated with a specific error code returned from a recordable PSSE API routine.\n\nardat\n\n return area totals.\n\naredat\n\n return real area data items.\n\nareint\n\n return integer area data items.\n\narenam\n\n return the area name.\n\narenum\n\n return the area number.\n\nareuse\n\n indicate if an area is in use.\n\naritoj\n\n return the interchange between two areas.\n\nbrncur\n\n\n\nbrndat\n\n return real b"
  },
  {
    "id": "chunk_384",
    "text": "tween two areas.\n\nbrncur\n\n\n\nbrndat\n\n return real branch parameters.\n\nbrndt2\n\n return complex positive and zero sequence parameters for non-transformer branches, and complex positive sequence parameters for transformer branches.\n\nbrnflo\n\n return the complex branch flow (P+jQ) as calculated at IBUS.\n\nbrnint\n\n return integer branch parameters.\n\nbrnmsc\n\n return real branch flow values.\n\nbrnmva\n\n\n\nbrnnam\n\n return the name of an AC branch.\n\nbrnstt\n\n\n\nbsysisdef\n\n check whether a bus subsystem has been "
  },
  {
    "id": "chunk_385",
    "text": "sysisdef\n\n check whether a bus subsystem has been defined for a given subsystem ID.\n\nbusdat\n\n return real bus values.\n\nbusdt1\n\n return complex bus parameters as MVA.\n\nbusdt2\n\n return complex bus parameters.\n\nbusexs\n\n check for the existence of a specified bus.\n\nbusint\n\n return integer bus parameters.\n\nbusmsm\n\n return complex bus mismatch.\n\nbusordpos\n\n return the ordinal position of the specified bus or bus section in the numerically ordered list of non-star point buses (i.e., star point buses ar"
  },
  {
    "id": "chunk_386",
    "text": "of non-star point buses (i.e., star point buses are excluded).\n\nbussectdat\n\nUse this API routine to return real bus section values.\n\nbussectdt1\n\nUse this API routine to return complex bus section parameters as MVA.\n\nbussectdt2\n\nUse this API routine to return complex bus section parameters.\n\nbussectexs\n\nUse this API routine to check for the existence of a specified bus section.\n\nbussectint\n\nUse this API routine to return real bus section values.\n\ncctmdlnam_2dco\n\n return model name of CCT 2-termin"
  },
  {
    "id": "chunk_387",
    "text": "cctmdlnam_2dco\n\n return model name of CCT 2-terminal dc line other models.\n\ncctmdlnam_2wtd\n\n return model name of the CCT 2-winding transformer device model.\n\ncctmdlnam_3wtd\n\n return model name of the CCT 3-winding transformer device model.\n\ncctmdlnam_brnd\n\n return model name of the CCT branch device model.\n\ncctmdlnam_brno\n\n return model name of the CCT branch other model.\n\ncctmdlnam_buso\n\n return model name of CCT Bus other models.\n\ncctmdlnam_mcno\n\n return model name of the CCT machine other mo"
  },
  {
    "id": "chunk_388",
    "text": "no\n\n return model name of the CCT machine other models.\n\ncctmdlnam_mcnp\n\n return model name of the CCT machine protection models.\n\ncctmdlnam_msco\n\n return model name of the CCT Miscellaneous other model.\n\ncctmdlnam_swso_2\n\n return model name of the CCT switched shunt other type models.\n\ncctmind_2dco\n\n return starting array indices and status of CCT 2-terminal dc line other models.\n\ncctmind_2wtd\n\n return starting array indices and status of CCT 2-winding transformer device models.\n\ncctmind_3wtd\n\n"
  },
  {
    "id": "chunk_389",
    "text": "winding transformer device models.\n\ncctmind_3wtd\n\n return starting array indices and status of CCT 3-winding transformer device models.\n\ncctmind_brnd\n\n return starting array indices and status of CCT branch device models.\n\ncctmind_brno\n\n return starting array indices and status of CCT branch other models.\n\ncctmind_buso\n\n return starting array indices and status of CCT Bus other models.\n\ncctmind_mcno\n\n return starting array indices and status of CCT machine other models.\n\ncctmind_mcnp\n\n return st"
  },
  {
    "id": "chunk_390",
    "text": "CT machine other models.\n\ncctmind_mcnp\n\n return starting array indices and status of CCT machine protection models.\n\ncctmind_msco\n\n return starting array indices and status of CCT Miscellaneous other models.\n\ncctmind_swso\n\n\n\ncctmind_swso_2\n\n return starting array indices and status of CCT Switched Shunt other models.\n\nchktre\n\n check for Type 4 (or greater) buses with in-service branches connected to them.\n\nchnval\n\n return the present value of the simulation variable assigned to a specified outpu"
  },
  {
    "id": "chunk_391",
    "text": " simulation variable assigned to a specified output channel.\n\ndc2auxmind\n\n return the starting array indices and status of auxiliary signal model associated with 2-terminal dc line for the specified signal index.\n\ndc2auxmnam\n\n return the auxiliary signal model name associated with a 2-terminal dc line for the specified auxiliary signal index.\n\ndc2dat\n\n\n\ndc2dat_2\n\nThis API is the second release of the API that returns real two-terminal dc line quantities.\n\ndc2int\n\n\n\ndc2int_2\n\nThis API is the seco"
  },
  {
    "id": "chunk_392",
    "text": "ntities.\n\ndc2int\n\n\n\ndc2int_2\n\nThis API is the second release of the API that returns integer two-terminal dc line quantities.\n\ndc2mind\n\n return 2-terminal dc line model starting array indices and status.\n\ndc2mnam\n\n return 2-terminal dc line model name.\n\ndcnauxmind\n\n return the starting array indices and status of auxiliary signal model associated with N-terminal dc line for the specified signal index.\n\ndcnauxmnam\n\n return the auxiliary signal model name associated with a N-terminal dc line for t"
  },
  {
    "id": "chunk_393",
    "text": "el name associated with a N-terminal dc line for the specified auxiliary signal index.\n\ndcncin\n\n\n\ndcncin_2\n\nThis API is the second release of the API that returns integer multi-terminal dc line converter quantities.\n\ndcndat\n\n\n\ndcndat_2\n\nThis API is the second release of the API that returns real multi-terminal dc line quantities.\n\ndcnint\n\n\n\ndcnint_2\n\nThis API is the second release of the API that returns integer multi-terminal dc line quantities.\n\ndcnmind\n\n return N-terminal dc line model starti"
  },
  {
    "id": "chunk_394",
    "text": "\n\ndcnmind\n\n return N-terminal dc line model starting array indices and status.\n\ndcnmnam\n\n return N-terminal dc line model name.\n\ndscval\n\n return dynamics character array values.\n\ndsival\n\n return dynamics integer array values.\n\ndsrval\n\n return dynamics real values.\n\nfcdauxmind\n\n return the starting array indices and status of auxiliary signal model associated with FACTS device for the specified signal index.\n\nfcdauxmnam\n\n return the auxiliary signal model name associated with a FACTS device for t"
  },
  {
    "id": "chunk_395",
    "text": "al model name associated with a FACTS device for the specified auxiliary signal index.\n\nfcddat\n\n\n\nfcddat_2\n\nThis API is the second release of the API that returns FACTS device real quantities.\n\nfcdint\n\n\n\nfcdint_2\n\nThis API is the second release of the API that returns FACTS device integer quantities.\n\nfcdmind\n\n return FACTS device model starting array indices and status.\n\nfcdmnam\n\n return FACTS device model name.\n\nfxsdt1\n\n return the magnitude of a specified fixed bus shunt.\n\nfxsdt2\n\n return com"
  },
  {
    "id": "chunk_396",
    "text": " a specified fixed bus shunt.\n\nfxsdt2\n\n return complex fixed bus shunt.\n\nfxsint\n\n return integer quantities of the specified fixed bus shunt.\n\ngencnv\n\n return a flag indicating whether generators are converted.\n\ngendat\n\n return plant total power output.\n\ngendt1\n\nReturns total plant power output in MVA.\n\ngensectdat\n\nUse this API routine to return a bus section\u2019s plant total power output.\n\ngensectdt1\n\nUse this API routine to return a bus section\u2019s total plant power output in MVA.\n\nget_mstate\n\n ret"
  },
  {
    "id": "chunk_397",
    "text": "total plant power output in MVA.\n\nget_mstate\n\n return the MSTATE value.\n\ngethomepath\n\n retrieve a user\u2019s HOMEPATH directory.\n\ngnechr\n\nUse this API routine to return character quantities of a specified GNE device.\n\ngnedat\n\nUse this API routine to return real quantities of a specified GNE device.\n\ngneint\n\nUse this API routine to return integer quantities of a specified GNE device.\n\ninddt1\n\nUse this API routine to return real induction machine quantities.\n\ninddt2\n\nUse this API routine to return com"
  },
  {
    "id": "chunk_398",
    "text": "ities.\n\ninddt2\n\nUse this API routine to return complex induction machine quantities.\n\nindint\n\nUse this API routine to return integer induction machine quantities.\n\nini2dc\n\nInitializes the two-terminal dc line fetching routine \u2018NXT2DC\u2019 for retrieving two-terminal dc lines in dc line name alphabetical order.\n\ninibrn\n\nInitializes the branch fetching routine \u2018NXTBRN\u2019 or \u2018NXTBRN3\u2019 for returning branches connected to IBUS.\n\ninibrn_2\n\nInitializes the branch fetching routine \u2018NXTBRN_2\u2019 or \u2018NXTBRN3_2\u2019 fo"
  },
  {
    "id": "chunk_399",
    "text": "anch fetching routine \u2018NXTBRN_2\u2019 or \u2018NXTBRN3_2\u2019 for returning branches connected to bus sections described by IBUS and INODE.\n\ninibrx\n\nInitializes the branch fetching routine, \u2018NXTBRN\u2019 or \u2018NXTBRN3\u2019 for returning branches connected to IBUS.\n\ninibrx_2\n\nInitializes the branch fetching routine, \u2018NXTBRN_2\u2019 or \u2018NXTBRN3_2\u2019 for returning branches connected to IBUS.\n\ninibus\n\nInitializes the bus fetching routine \u2018NXTBUS\u2019 for retrieving buses in ascending numerical order.\n\ninibus_2\n\nInitializes the bus fet"
  },
  {
    "id": "chunk_400",
    "text": "umerical order.\n\ninibus_2\n\nInitializes the bus fetching routine \u2018NXTBUS_2\u2019 for retrieving buses in ascending numerical order.\n\ninibux\n\nInitializes the bus fetching routine \u2018NXTBUS\u2019 for retrieving buses in ascending numerical order.\n\ninifax\n\nInitializes the FACTS device fetching routine \u2018NXTFAX\u2019 for retrieving FACTS devices in FACTS device name alphabetical order.\n\ninifxs\n\nInitializes the fixed bus shunt fetching routine \u2018NXTFXS\u2019 for returning fixed shunts attached to bus IBUS.\n\niniind\n\nInitializ"
  },
  {
    "id": "chunk_401",
    "text": "ed shunts attached to bus IBUS.\n\niniind\n\nInitializes induction machine fetching routine \u2018NXTIND\u2019 for returning induction machines attached to IBUS.\n\ninilod\n\nInitializes load fetching routine \u2018NXTLOD\u2019 for returning loads attached to IBUS.\n\ninimac\n\nInitializes machine fetching routine \u2018NXTMAC\u2019 for returning machines attached to IBUS.\n\ninimdc\n\nInitializes the multi-terminal dc line fetching routine \u2018NXTMDC\u2019 for retrieving multi-terminal dc lines in dc line name alphabetical order.\n\ninimsl\n\nInitiali"
  },
  {
    "id": "chunk_402",
    "text": "dc line name alphabetical order.\n\ninimsl\n\nInitializes the multi-section line member fetching routine \u2018NXTMSL\u2019 for retrieving lines that are sections of the specified multi-section line from IBUS to JBUS.\n\nininam\n\nInitializes the bus fetching routine \u2018NXTBUS\u2019 for retrieving buses in ascending alphabetical order.\n\nininam_2\n\nInitializes the bus fetching routine \u2018NXTBUS_2\u2019 for retrieving buses in ascending alphabetical order.\n\nininax\n\nInitializes the bus fetching routine \u2018NXTBUS\u2019 for retrieving buse"
  },
  {
    "id": "chunk_403",
    "text": " bus fetching routine \u2018NXTBUS\u2019 for retrieving buses in ascending alphabetical order.\n\ninistabussect\n\nUse this API routine to initialize the bus section fetching routine \u2018NXTSTABUSSECT\u2019 for retrieving the bus sections in a substation.\n\ninistanode\n\nUse this API routine to initialize the node fetching routine \u2018NXTSTANODE\u2019 for retrieving the nodes in a sub-station.\n\ninistaswdev\n\nUse this API routine to initialize the switching device fetching routine \u2018NXTSTASWDEV\u2019 for retrieving the switching device"
  },
  {
    "id": "chunk_404",
    "text": " \u2018NXTSTASWDEV\u2019 for retrieving the switching devices in a substation.\n\ninisws\n\nInitializes the switched shunt fetching routine \u2018NXTSWS\u2019 for returning switched shunts attached to bus IBUS.\n\ninitie\n\nInitializes the tie branch fetching routine \u2018NXTTIE\u2019 or \u2018NXTTIE3\u2019 for returning tie branches from area IAR.\n\ninitix\n\nInitializes the tie branch fetching routine \u2018NXTTIE\u2019 or \u2018NXTTIE3\u2019 for returning tie branches from area IAR.\n\ninivsc\n\nInitializes the VSC dc line fetching routine \u2018NXTVSC\u2019 for retrieving V"
  },
  {
    "id": "chunk_405",
    "text": "dc line fetching routine \u2018NXTVSC\u2019 for retrieving VSC dc lines in dc line name alphabetical order.\n\nisland\n\nTrips in-service branches connected to Type 4 (or greater) buses, and disconnects islands not containing a swing bus.\n\niterat\n\n return the number of iterations used in the last solution attempt.\n\nlmodind\n\nReturns load-related model starting array indices and status.\n\nlmodnam\n\nReturns load-related model name.\n\nlodcnv\n\nThis obsolete API always returns a 0.\n\nloddt1\n\nReturns load quantities in "
  },
  {
    "id": "chunk_406",
    "text": " returns a 0.\n\nloddt1\n\nReturns load quantities in MVA.\n\nloddt2\n\n return complex load quantities.\n\nlodind\n\n return the load array index.\n\nlodint\n\n return integer load quantities.\n\nlodtype\n\n return the load type character string.\n\nmacchr\n\n return character machine quantities.\n\nmacdat\n\n return real machine quantities.\n\nmacdt2\n\n return complex machine quantities.\n\nmacind\n\n return the machine array index.\n\nmacint\n\n return integer machine quantities.\n\nmacstt\n\n return the machine status value.\n\nmaxmsm\n"
  },
  {
    "id": "chunk_407",
    "text": "macstt\n\n return the machine status value.\n\nmaxmsm\n\n return the complex bus mismatch at the bus with the largest MVA mismatch.\n\nmdlind\n\n return plant-related model starting array indices and status.\n\nmdllibcnt\n\n return the number of libraries in the list to be searched for dynamics library models.\n\nmdlnam\n\n return plant-related model name.\n\nmdlpgmcnt\n\n returns the number of model programs loaded from dynamics model libraries.\n\nnatono\n\n return the bus number for a specified 18-character extended b"
  },
  {
    "id": "chunk_408",
    "text": "bus number for a specified 18-character extended bus name.\n\nnotona\n\n return the bus 18-character extended bus name for a specified bus number.\n\nnotonasect\n\n return the bus 18-character extended bus name for a specified bus section.\n\nnxt2dc\n\nReturns the next two-terminal dc line in dc line name alphabetical order.\n\nnxtbrn\n\nReturns the next branch connected to a bus, excluding three-winding transformers.\n\nnxtbrn3\n\nReturns the next branch connected to a bus, including three-winding transformers.\n\nn"
  },
  {
    "id": "chunk_409",
    "text": "to a bus, including three-winding transformers.\n\nnxtbrn3_2\n\nReturns the next branch connected to a bus section, including three-winding transformers.\n\nnxtbrn_2\n\nReturns the next branch connected to a bus, excluding three-winding transformers.\n\nnxtbus\n\nReturns the next bus in ordered sequence.\n\nnxtbus_2\n\nReturns the next bus in ordered sequence.\n\nnxtfax\n\nReturns the next FACTS device in FACTS device name alphabetical order.\n\nnxtfxs\n\n return the identifier of the next fixed shunt connected to a bu"
  },
  {
    "id": "chunk_410",
    "text": "entifier of the next fixed shunt connected to a bus.\n\nnxtind\n\nUse this API routine to return the identifier of the next induction machine connected to a bus.\n\nnxtlod\n\n return the identifier of the next load connected to a bus.\n\nnxtmac\n\n return the identifier of the next machine connected to a bus.\n\nnxtmdc\n\nReturns the next multi-terminal dc line in dc line name alphabetical order.\n\nnxtmsl\n\n return the next multi-section line member branch.\n\nnxtstabussect\n\nUse this API routine to retrieve the nex"
  },
  {
    "id": "chunk_411",
    "text": "abussect\n\nUse this API routine to retrieve the next bus section in the specified substation.\n\nnxtstanode\n\nUse this API routine to retrieve the next node in the specified substation.\n\nnxtstaswdev\n\nUse this API routine to retrieve the next switching device in the specified substation.\n\nnxtsws\n\n return the identifier of the next switched shunt connected to a bus.\n\nnxttie\n\n return the next tie branch from an area, excluding three-winding transformers.\n\nnxttie3\n\n return the next tie branch from an ar"
  },
  {
    "id": "chunk_412",
    "text": ".\n\nnxttie3\n\n return the next tie branch from an area, including three-winding transformers.\n\nnxtvsc\n\nReturns the next VSC dc line in dc line name alphabetical order.\n\nokstrt\n\nRoutine which may be called after activity STRT or MSTR to indicate the presence of INITIAL CONDITIONS SUSPECT errors (for activity STRT) or at least one MODEL NOT AVAILABLE IN MSTR/MRUN message (for MSTR).\n\nopenun\n\nConnects an IPLAN unit number to the Fortran unit used by activity OPEN and returns that IPLAN unit number.\n\n"
  },
  {
    "id": "chunk_413",
    "text": "ctivity OPEN and returns that IPLAN unit number.\n\nordbus\n\nThis API routine returns the bus number corresponding to the specified position in the ordered list (numeric or alphabetic) of non-hidden buses (i.e., star point buses and topological buses are excluded).\n\nordbussect\n\nThis API routine returns the bus number and section number corresponding to the specified position in the ordered list (numeric or alphabetic) of non-star point buses (i.e., star point buses are excluded).\n\nowndat\n\nReturns t"
  },
  {
    "id": "chunk_414",
    "text": "star point buses are excluded).\n\nowndat\n\nReturns the data associated with an owner (\u2018LOAD\u2019 gets loads at buses of owner \u2018IAR\u2019, \u2018LOADLD\u2019 gets loads assigned to owner \u2018IAR\u2019).\n\nownnam\n\nReturns the owner name for a specified owner number.\n\nownnum\n\nReturns the owner number for a specified owner name.\n\nownuse\n\n indicate whether an owner is in use.\n\nprmdat\n\nUse this API routine to return real-valued solution parameters.\n\nprmint\n\nUse this API routine to return integer-valued solution parameters.\n\nratchr"
  },
  {
    "id": "chunk_415",
    "text": "return integer-valued solution parameters.\n\nratchr\n\n get rating set parameters.\n\nrmodind\n\nReturns the branch relay model starting array indices and status.\n\nrmodnam\n\nReturns the branch relay model name.\n\nsbsgtbkv\n\n get previously defined bus subsystem voltage limits.\n\nsc3wnd\n\nReturns the three-winding transformer short circuit currents arriving at IBUS following activity SCMU.\n\nscbrn2\n\nReturns the branch short circuit currents arriving at IBUS following activity SCMU.\n\nscbus2\n\nReturns complex bu"
  },
  {
    "id": "chunk_416",
    "text": "llowing activity SCMU.\n\nscbus2\n\nReturns complex bus voltages and currents following activity SCMU.\n\nscdone\n\n restore the working case after \u2018SCINIT\u2019.\n\nscinit\n\n initialize the short-circuit data retrieval APIs.\n\nscmac2\n\n return the machine short circuit currents following activity SCMU.\n\nselctr\n\n return the activity selector indicator.\n\nsethomepath\n\n set a user\u2019s HOMEPATH directory.\n\nsfiles\n\n return the current Saved Case and Snapshot filenames.\n\nslmodind\n\n return the subsystem load-related model"
  },
  {
    "id": "chunk_417",
    "text": "slmodind\n\n return the subsystem load-related model starting array indices and status.\n\nslmodnam\n\n return the subsystem load-related model name.\n\nsolstr\n\n return a string indicating the result of the last solution attempt.\n\nsolved\n\n check whether the last solution attempt reached tolerance.\n\nsolved_ca\n\n check whether the last corrective action solution attempt reached tolerance.\n\nstadat\n\nUse this API routine to return real substation values.\n\nstaint\n\nUse this API routine to return integer substat"
  },
  {
    "id": "chunk_418",
    "text": "nt\n\nUse this API routine to return integer substation values.\n\nstaname\n\nUse this API routine to return a substation\u2019s name.\n\nstanodeint\n\nUse this API routine to return integer substation values.\n\nstanodename\n\nUse this API routine to return the name of a substation node.\n\nstarea\n\n restrict \u2018NXTBUS\u2019 to a single area.\n\nstaswdevdat\n\nUse this API routine to return real substation switching device values.\n\nstaswdevint\n\nUse this API routine to return integer substation switching device values.\n\nstaswde"
  },
  {
    "id": "chunk_419",
    "text": "teger substation switching device values.\n\nstaswdevname\n\nUse this API routine to return the name of a substation switching device.\n\nstbskv\n\n restrict \u2018NXTBUS\u2019 to a single base voltage level.\n\nstzone\n\n restrict \u2018NXTBUS\u2019 to a single zone.\n\nswsblk\n\n\n\nswsblk_2\n\n return data for a specified block of a specified switched shunt.\n\nswsblz\n\n\n\nswsblz2\n\n\n\nswsdat\n\n\n\nswsdat_2\n\n return switched shunt real data.\n\nswsdt1\n\n\n\nswsint\n\n\n\nswsint_2\n\n return switched shunt integer parameters.\n\nswsmind\n\n\n\nswsmind_2\n\n re"
  },
  {
    "id": "chunk_420",
    "text": "unt integer parameters.\n\nswsmind\n\n\n\nswsmind_2\n\n return switched shunt model starting array indices and status.\n\nswsmnam\n\n\n\nswsmnam_2\n\n return switched shunt model name.\n\nsysmsm\n\n return the total system MVA mismatch.\n\nsysmva\n\n return the system base MVA.\n\nsystot\n\n return complex system-wide values.\n\ntitldt\n\n return the two line case title.\n\ntotbus\n\n return the total number of buses in the working case.\n\ntr3dat\n\n return three-winding transformer real values.\n\ntr3dt2\n\n return three-winding transfo"
  },
  {
    "id": "chunk_421",
    "text": "eal values.\n\ntr3dt2\n\n return three-winding transformer complex values.\n\ntr3int\n\n return three-winding transformer integer values.\n\ntr3nam\n\n return three-winding transformer name.\n\ntrndat\n\n\n\ntrxdat\n\n return the inter-area transfer MW.\n\ntspfprofilechr\n\n return string parameters of Time Series Power Flow profile.\n\ntspfprofilecurvechr\n\n return string parameters of Time Series Power Flow profile curve.\n\ntspfprofilecurveint\n\n return integer parameters of Time Series Power Flow profile curve.\n\ntspfprof"
  },
  {
    "id": "chunk_422",
    "text": "of Time Series Power Flow profile curve.\n\ntspfprofilecurvereal\n\n return real parameters of Time Series Power Flow profile curve.\n\ntspfprofileint\n\n return integer parameters of Time Series Power Flow profile.\n\ntspfprofilereal\n\n return real parameters of Time Series Power Flow profile.\n\nvoltagedroopdata\n\n return voltage droop control real parameters.\n\nvoltagedroopint\n\n return voltage droop control integer parameters.\n\nvscauxmind\n\n return the starting array indices and status of auxiliary signal mo"
  },
  {
    "id": "chunk_423",
    "text": "ng array indices and status of auxiliary signal model associated with VSC dc line for the specified signal index.\n\nvscauxmnam\n\n return the auxiliary signal model name associated with a VSC dc line for the specified auxiliary signal index.\n\nvsccdt\n\n return VSC dc line real parameters.\n\nvsccin\n\n return VSC dc line converter integer parameters.\n\nvscint\n\n return VSC dc line integer parameters.\n\nvscmind\n\n return VSC dc line model starting array indices and status.\n\nvscmnam\n\n return VSC dc line model "
  },
  {
    "id": "chunk_424",
    "text": "s and status.\n\nvscmnam\n\n return VSC dc line model name.\n\nwindmind\n\n return wind model starting array indices and status.\n\nwindmnam\n\n return wind model name.\n\nwnddat\n\n return three-winding transformer real values for winding connected to bus IBUS.\n\nwnddt2\n\n return three-winding transformer complex values for winding connected to bus IBUS.\n\nwndint\n\n return three-winding transformer integer values for winding connected to bus IBUS.\n\nxfrdat\n\n return two-winding transformer real parameters.\n\nxfrint\n\n"
  },
  {
    "id": "chunk_425",
    "text": "two-winding transformer real parameters.\n\nxfrint\n\n return two-winding transformer integer parameters.\n\nxfrnam\n\n return two-winding transformer name.\n\nzndat\n\n return zone totals.\n\nznitoj\n\n return the interchange between two zones.\n\nzonnam\n\n return the zone name.\n\nzonnum\n\n return the zone number.\n\nzonuse\n\n indicate whether a zone is in use.\n\n--- Substation Data \u2014 .txt ---\n\nSubstation Data \u2014 \n\nSubstation Data\u00b6\n\n\n\n\n\nastationchar\n\n return an array of character values for subsystem substations.\n\nastat"
  },
  {
    "id": "chunk_426",
    "text": "character values for subsystem substations.\n\nastationcount\n\n return the number of array entries required to accommodate the data to be returned by the remaining members of the substation data family.\n\nastationint\n\n return an array of integer values for subsystem substations.\n\nastationreal\n\n return an array of real values for subsystem substations.\n\nastationtypes\n\n return an array of character values indicating the data types corresponding to a set of specified STRING values that are valid input "
  },
  {
    "id": "chunk_427",
    "text": "t of specified STRING values that are valid input values to any of the data retrieval routines of the substation data family (aStationInt, aStationReal and aStationChar).\n\n--- Substation Node Data \u2014 .txt ---\n\nSubstation Node Data \u2014 \n\nSubstation Node Data\u00b6\n\n\n\n\n\nanodechar\n\n return an array of character values for subsystem substation nodes.\n\nanodecount\n\n return the number of array entries required to accommodate the data to be returned by the remaining members of the substation node data family.\n\n"
  },
  {
    "id": "chunk_428",
    "text": "ning members of the substation node data family.\n\nanodeint\n\n return an array of integer values for subsystem substation nodes.\n\nanodereal\n\n return an array of real values for subsystem substation nodes.\n\nanodetypes\n\n return an array of character values indicating the data types corresponding to a set of specified STRING values that are valid input values to any of the data retrieval routines of the substation node data family (aNodeInt and aNodeChar).\n\n--- Substation Switching Device Data \u2014 .txt"
  },
  {
    "id": "chunk_429",
    "text": "har).\n\n--- Substation Switching Device Data \u2014 .txt ---\n\nSubstation Switching Device Data \u2014 \n\nSubstation Switching Device Data\u00b6\n\n\n\n\n\nastaswdevchar\n\n return an array of character values for subsystem substation switching devices.\n\nastaswdevcount\n\n return the number of array entries required to accommodate the data to be returned by the remaining members of the substation switching device data family.\n\nastaswdevcplx\n\n return an array of complex values for subsystem substation switching devices.\n\nas"
  },
  {
    "id": "chunk_430",
    "text": "es for subsystem substation switching devices.\n\nastaswdevint\n\n return an array of integer values for subsystem substation switching devices.\n\nastaswdevreal\n\n return an array of real values for subsystem substation switching devices.\n\nastaswdevtypes\n\n return an array of character values indicating the data types corresponding to a set of specified STRING values that are valid input values to any of the data retrieval routines of the substation switching device data family (aStaSwDevInt, aStaSwDev"
  },
  {
    "id": "chunk_431",
    "text": "tching device data family (aStaSwDevInt, aStaSwDevReal, aStaSwDevCplx and aStaSwDevChar).\n\n--- Substation Terminal Data \u2014 .txt ---\n\nSubstation Terminal Data \u2014 \n\nSubstation Terminal Data\u00b6\n\n\n\n\n\naterminalchar\n\n return an array of integer values for subsystem substation terminals.\n\naterminalcount\n\n return the number of array entries required to accommodate the data to be returned by the remaining members of the substation terminal data family.\n\naterminalint\n\n return an array of integer values for su"
  },
  {
    "id": "chunk_432",
    "text": "inalint\n\n return an array of integer values for subsystem substation terminals.\n\naterminaltypes\n\n return an array of character values indicating the data types corresponding to a set of specified STRING values that are valid input values to any of the data retrieval routines of the substation terminal data family (aTerminalInt and aTerminalChar).\n\n--- Switched Shunt Bus Data \u2014 .txt ---\n\nSwitched Shunt Bus Data \u2014 \n\nSwitched Shunt Bus Data\u00b6\n\n\n\n\n\naswshuntbuschar\n\n return an array of character value"
  },
  {
    "id": "chunk_433",
    "text": "wshuntbuschar\n\n return an array of character values for subsystem buses.\n\naswshuntbuscount\n\n return the number of array entries required to accommodate the data to be returned by the remaining members of the switched shunt bus data family.\n\naswshuntbuscplx\n\n return an array of complex values for subsystem buses.\n\naswshuntbusint\n\n return an array of integer values for subsystem buses.\n\naswshuntbusreal\n\n return an array of real values for subsystem buses.\n\naswshuntbustypes\n\n return an array of cha"
  },
  {
    "id": "chunk_434",
    "text": " buses.\n\naswshuntbustypes\n\n return an array of character values indicating the data types corresponding to a set of specified STRING values that are valid input values to any of the data retrieval routines of the switched shunt bus data family (aSwShntBusInt, aSwShntBusReal, aSwShntBusCplx and aSwShntBusChar).\n\n--- Switched Shunt Data \u2014 .txt ---\n\nSwitched Shunt Data \u2014 \n\nSwitched Shunt Data\u00b6\n\n\n\n\n\naswshchar\n\n return an array of character values for subsystem switched shunts.\n\naswshcount\n\n return t"
  },
  {
    "id": "chunk_435",
    "text": " subsystem switched shunts.\n\naswshcount\n\n return the number of array entries required to accommodate the data to be returned by the remaining members of the switched shunt data family.\n\naswshcplx\n\n return an array of complex values for subsystem switched shunts.\n\naswshint\n\n return an array of integer values for subsystem switched shunts.\n\naswshreal\n\n return an array of real values for subsystem switched shunts.\n\naswshtypes\n\n return an array of character values indicating the data types correspon"
  },
  {
    "id": "chunk_436",
    "text": "aracter values indicating the data types corresponding to a set of specified STRING values that are valid input values to any of the data retrieval routines of the switched shunt data family (aSwshInt, aSwshReal, aSwshCplx and aSwshChar).\n\n--- Switched Shunt Models \u2014 .txt ---\n\nSwitched Shunt Models \u2014 \n\nSwitched Shunt Models\u00b6\n\n\n\n\n\nadd_swshunt_model\n\n\n\nadd_swshunt_model_2\n\n add a switched shunt model to the specified switched shunt device.\n\nchange_swsmod_chricn\n\n\n\nchange_swsmod_chricn_2\n\n change t"
  },
  {
    "id": "chunk_437",
    "text": "swsmod_chricn\n\n\n\nchange_swsmod_chricn_2\n\n change the value of a character ICON (i.e., an element of the CHRICN array) of the switched shunt model of a specified switched shunt device.\n\nchange_swsmod_con\n\n\n\nchange_swsmod_con_2\n\n change the value of a CON of the switched shunt model of a specified switched shunt device.\n\nchange_swsmod_icon\n\n\n\nchange_swsmod_icon_2\n\n change the value of an integer ICON (i.e., an element of the ICON array) of the switched shunt model of a specified switched shunt dev"
  },
  {
    "id": "chunk_438",
    "text": "ched shunt model of a specified switched shunt device.\n\nchange_swsmod_var\n\n\n\nchange_swsmod_var_2\n\n change the value of a VAR of the switched shunt model of a specified switched shunt device.\n\ngmb_add_swshunt_model\n\n\n\ngmb_add_swshunt_model_2\n\n add a GMB switched shunt model to the specified switched shunt device.\n\nswsmod_pack\n\n remove entries that are marked as unused from the switched shunt model connection tables and the switched shunt model array allocation tables.\n\nswsmod_remove\n\n\n\nswsmod_rem"
  },
  {
    "id": "chunk_439",
    "text": "ay allocation tables.\n\nswsmod_remove\n\n\n\nswsmod_remove_2\n\n remove the switched shunt model from a specified switched shunt.\n\nswsmod_status\n\n\n\nswsmod_status_2\n\n change the status of the switched shunt model at a specified switched shunt device.\n\nswsmod_unconnected\n\n list or remove from dynamics working memory those switched shunt models that are assigned to switched shunt that are not present in the current power flow working case (unconnected).\n\nswsmod_user\n\n list user-written switched shunt mode"
  },
  {
    "id": "chunk_440",
    "text": "wsmod_user\n\n list user-written switched shunt model definitions or to remove user-written switched shunt model definitions that are not assigned to any switched shunt devices (unused) from the user model definition tables.\n\n--- Three-Winding Transformer Data \u2014 .txt ---\n\nThree-Winding Transformer Data \u2014 \n\nThree-Winding Transformer Data\u00b6\n\n\n\n\n\natr3char\n\n return an array of character values for subsystem three-winding transformers.\n\natr3count\n\n return the number of array entries required to accommod"
  },
  {
    "id": "chunk_441",
    "text": "n the number of array entries required to accommodate the data to be returned by the remaining members of the three-winding transformer data family.\n\natr3cplx\n\n return an array of complex values for subsystem three-winding transformers.\n\natr3int\n\n return an array of integer values for subsystem three-winding transformers.\n\natr3real\n\n return an array of real values for subsystem three-winding transformers.\n\natr3types\n\n return an array of character values indicating the data types corresponding to"
  },
  {
    "id": "chunk_442",
    "text": " values indicating the data types corresponding to a set of specified STRING values that are valid input values to any of the data retrieval routines of the three-winding transformer data family (aTr3Int, aTr3Real, aTr3Cplx and aTr3Char).\n\n--- Three-Winding Transformer Winding Data \u2014 .txt ---\n\nThree-Winding Transformer Winding Data \u2014 \n\nThree-Winding Transformer Winding Data\u00b6\n\n\n\n\n\nawndchar\n\n return an array of character values for subsystem three-winding transformer windings.\n\nawndcount\n\n return "
  },
  {
    "id": "chunk_443",
    "text": "winding transformer windings.\n\nawndcount\n\n return the number of array entries required to accommodate the data to be returned by the remaining members of the three-winding transformer winding data family.\n\nawndcplx\n\n return an array of complex values for subsystem three-winding transformer windings.\n\nawndint\n\n return an array of integer values for subsystem three-winding transformer windings.\n\nawndreal\n\n return an array of real values for subsystem three-winding transformer windings.\n\nawndtypes\n"
  },
  {
    "id": "chunk_444",
    "text": "em three-winding transformer windings.\n\nawndtypes\n\n return an array of character values indicating the data types corresponding to a set of specified STRING values that are valid input values to any of the data retrieval routines of the three-winding transformer winding data family (aWndInt, aWndReal, aWndCplx and aWndChar).\n\n--- Time Series Power Flow Data \u2014 .txt ---\n\nTime Series Power Flow Data \u2014 \n\nTime Series Power Flow Data\u00b6\n\n\n\n\n\npurge_tspf_channel\n\n delete all Time Series Power Flow profile"
  },
  {
    "id": "chunk_445",
    "text": "hannel\n\n delete all Time Series Power Flow profiles for an element.\n\npurge_tspf_channel_all\n\n remover all time series power flow channels for a selected element.\n\npurge_tspf_profile\n\n delete Time Series Power Flow profile by profile name.\n\npurge_tspf_profilecurve\n\n delete Time Series Power Flow profile curve by curvesetid and curvecol and index.\n\npurge_tspf_profilecurveset\n\n delete Time Series Power Flow profile curve set by profile curvesetid.\n\npurge_tspf_profiledata\n\n delete Time Series Power "
  },
  {
    "id": "chunk_446",
    "text": "purge_tspf_profiledata\n\n delete Time Series Power Flow profile data by curvesetid and curvecol and index.\n\ntspf_channel_chng\n\n select time series power flow Cchannels.\n\ntspf_channel_data\n\n select time series power flow Cchannels.\n\ntspf_profile_chng\n\nUse this API routine to modify the data of an existing Time Series Power Flow profile.\n\ntspf_profile_data\n\nUse this API routine to modify the data of an existing Time Series Power Flow profile, or to add a new Time Series Power Flow profile.\n\ntspf_pr"
  },
  {
    "id": "chunk_447",
    "text": "add a new Time Series Power Flow profile.\n\ntspf_profilecurveset_chng\n\nUse this API routine to modify the data of an existing Time Series Power Flow profile curve set.\n\ntspf_profilecurveset_data\n\nUse this API routine to modify the data of an existing Time Series Power Flow profile curve set, or to add a new Time Series Power Flow profile curve set.\n\ntspf_profiledata_chng\n\nUse this API routine to modify the data of an existing Time Series Power Flow profile curve value.\n\ntspf_profiledata_data\n\nUse"
  },
  {
    "id": "chunk_448",
    "text": "w profile curve value.\n\ntspf_profiledata_data\n\nUse this API routine to modify the data of an existing Time Series Power Flow profile curve value, or to add a new Time Series Power Flow profile curve value.\n\n--- Time Series Power Flow Operation \u2014 .txt ---\n\nTime Series Power Flow Operation \u2014 \n\nTime Series Power Flow Operation\u00b6\n\n\n\n\n\nimposeprofile\n\n impose generation/load at the given time point on profile curves.\n\ntspf\n\n run the time series power flow solution.\n\ntspf_output_pmatrix\n\n output the pro"
  },
  {
    "id": "chunk_449",
    "text": "ow solution.\n\ntspf_output_pmatrix\n\n output the profile curves within one profile set in the matrix format.\n\ntspf_output_pmatrix_2\n\n output the profile curves within one profile set in the matrix format.\n\n--- Two-Terminal Dc Line Converter Data \u2014 .txt ---\n\nTwo-Terminal Dc Line Converter Data \u2014 \n\nTwo-Terminal Dc Line Converter Data\u00b6\n\n\n\n\n\na2trmdcconvchar\n\n return an array of character values for subsystem two-terminal dc line converters.\n\na2trmdcconvcount\n\n return the number of array entries requir"
  },
  {
    "id": "chunk_450",
    "text": "vcount\n\n return the number of array entries required to accommodate the data to be returned by the remaining members of the two-terminal dc line converter data family.\n\na2trmdcconvcplx\n\n return an array of complex values for subsystem two-terminal dc line converters.\n\na2trmdcconvint\n\n return an array of integer values for subsystem two-terminal dc line converters.\n\na2trmdcconvreal\n\n return an array of real values for subsystem two-terminal dc line converters.\n\na2trmdcconvtypes\n\n return an array "
  },
  {
    "id": "chunk_451",
    "text": "e converters.\n\na2trmdcconvtypes\n\n return an array of character values indicating the data types corresponding to a set of specified STRING values that are valid input values to any of the data retrieval routines of the two-terminal dc line converter data family (a2TrmDcConvInt, a2TrmDcConvReal, a2TrmDcConvCplx and a2TrmDcConvChar).\n\n--- Two-Terminal Dc Line Data \u2014 .txt ---\n\nTwo-Terminal Dc Line Data \u2014 \n\nTwo-Terminal Dc Line Data\u00b6\n\n\n\n\n\na2trmdcchar\n\n return an array of character values for subsyst"
  },
  {
    "id": "chunk_452",
    "text": "\n\n return an array of character values for subsystem two-terminal dc lines.\n\na2trmdccount\n\n return the number of array entries required to accommodate the data to be returned by the remaining members of the two-terminal dc line data family.\n\na2trmdccplx\n\n return an array of complex values for subsystem two-terminal dc lines.\n\na2trmdcint\n\n return an array of integer values for subsystem two-terminal dc lines.\n\na2trmdcreal\n\n return an array of real values for subsystem two-terminal dc lines.\n\na2tr"
  },
  {
    "id": "chunk_453",
    "text": " values for subsystem two-terminal dc lines.\n\na2trmdctypes\n\n return an array of character values indicating the data types corresponding to a set of specified STRING values that are valid input values to any of the data retrieval routines of the two-terminal dc line data family (a2TrmDcInt, a2TrmDcReal, a2TrmDcCplx and a2TrmDcChar).\n\n--- Two-Winding Transformer Data \u2014 .txt ---\n\nTwo-Winding Transformer Data \u2014 \n\nTwo-Winding Transformer Data\u00b6\n\n\n\n\n\natrnchar\n\n return an array of character values for "
  },
  {
    "id": "chunk_454",
    "text": "trnchar\n\n return an array of character values for subsystem two-winding transformers.\n\natrncount\n\n return the number of array entries required to accommodate the data to be returned by the remaining members of the two-winding transformer data family.\n\natrncplx\n\n return an array of complex values for subsystem two-winding transformers.\n\natrnint\n\n return an array of integer values for subsystem two-winding transformers.\n\natrnreal\n\n return an array of real values for subsystem two-winding transform"
  },
  {
    "id": "chunk_455",
    "text": "of real values for subsystem two-winding transformers.\n\natrntypes\n\n return an array of character values indicating the data types corresponding to a set of specified STRING values that are valid input values to any of the data retrieval routines of the two-winding transformer data family (aTrnInt, aTrnReal, aTrnCplx and aTrnChar).\n\n--- Using The Vendor Neutral Contingency And Ras Auxiliary File \u2014 .txt ---\n\nUsing The Vendor Neutral Contingency And Ras Auxiliary File \u2014 \n\nUsing The Vendor Neutral C"
  },
  {
    "id": "chunk_456",
    "text": " Ras Auxiliary File \u2014 \n\nUsing The Vendor Neutral Contingency And Ras Auxiliary File\u00b6\n\n\n\n\n\naccc_ras\n\n\n\naccc_ras_2\n\n run AC contingency calculation function with RAS model.\n\nadd2windingconditionelement\n\nAdd 2WindingConditionElement to RAS memory model\n\nadd2windingcontingencyelement\n\nAdd 2WindingContingencyElement to RAS memory model\n\nadd2windingremedialactionelement\n\nAdd 2WindingRemedialActionElement to RAS memory model\n\nadd3windingconditionelement\n\nAdd 3WindingConditionElement to RAS memory model"
  },
  {
    "id": "chunk_457",
    "text": "\n\nAdd 3WindingConditionElement to RAS memory model\n\nadd3windingcontingencyelement\n\nAdd 3WindingContingencyElement to RAS memory model\n\nadd3windingremedialactionelement\n\nAdd 3WindingRemedialActionElement to RAS memory model\n\naddaclineconditionelement\n\nAdd AclineConditionElement to RAS memory model\n\naddaclinecontingencyelement\n\nAdd AclineContingencyElement to RAS memory model\n\naddaclineremedialactionelement\n\nAdd AclineRemedialActionElement to RAS memory model\n\naddbusconditionelement\n\nAdd BusCondit"
  },
  {
    "id": "chunk_458",
    "text": "emory model\n\naddbusconditionelement\n\nAdd BusConditionElement to RAS memory model\n\naddbuscontingencyelement\n\nAdd BusContingencyElement to RAS memory model\n\naddbusremedialactionelement\n\nAdd BusRemedialActionElement to RAS memory model\n\naddcondition\n\nAdd Condition to RAS memory model\n\naddconditionelement\n\nAdd ConditionElement to RAS memory model\n\naddcontingency\n\nAdd Contingency to RAS memory model\n\naddcontingencyelement\n\nAdd ContingencyElement to RAS memory model\n\nadddcconvconditionelement\n\nAdd Dcc"
  },
  {
    "id": "chunk_459",
    "text": "S memory model\n\nadddcconvconditionelement\n\nAdd DcconvConditionElement to RAS memory model\n\nadddcconvcontingencyelement\n\nAdd DcconvContingencyElement to RAS memory model\n\nadddcconvremedialactionelement\n\nAdd DcconvRemedialActionElement to RAS memory model\n\nadddclineconditionelement\n\nAdd DclineConditionElement to RAS memory model\n\nadddclinecontingencyelement\n\nAdd DclineContingencyElement to RAS memory model\n\nadddclineremedialactionelement\n\nAdd DclineRemedialActionElement to RAS memory model\n\naddfix"
  },
  {
    "id": "chunk_460",
    "text": "eRemedialActionElement to RAS memory model\n\naddfixshuntconditionelement\n\nAdd FixshuntConditionElement to RAS memory model\n\naddfixshuntcontingencyelement\n\nAdd FixshuntContingencyElement to RAS memory model\n\naddfixshuntremedialactionelement\n\nAdd FixshuntRemedialActionElement to RAS memory model\n\naddgenconditionelement\n\nAdd GenConditionElement to RAS memory model\n\naddgencontingencyelement\n\nAdd GenContingencyElement to RAS memory model\n\naddgenremedialactionelement\n\nAdd GenRemedialActionElement to RA"
  },
  {
    "id": "chunk_461",
    "text": "lactionelement\n\nAdd GenRemedialActionElement to RAS memory model\n\naddloadconditionelement\n\nAdd LoadConditionElement to RAS memory model\n\naddloadcontingencyelement\n\nAdd LoadContingencyElement to RAS memory model\n\naddloadremedialactionelement\n\nAdd LoadRemedialActionElement to RAS memory model\n\naddnestedcondition\n\nAdd NestedCondition to RAS memory model\n\naddpythonconditionelement\n\nAdd PythonConditionElement to RAS memory model\n\naddpythoncontingencyelement\n\nAdd PythonContingencyElement to RAS memory"
  },
  {
    "id": "chunk_462",
    "text": "lement\n\nAdd PythonContingencyElement to RAS memory model\n\naddpythonremedialactionelement\n\nAdd PythonRemedialActionElement to RAS memory model\n\naddremedialaction\n\nAdd RemedialAction to RAS memory model\n\naddremedialactionelement\n\nAdd RemedialActionElement to RAS memory model\n\naddsubconditionelement\n\nAdd SubConditionElement to RAS memory model\n\naddsubcontingencyelement\n\nAdd SubContingencyElement to RAS memory model\n\naddsubremedialactionelement\n\nAdd SubRemedialActionElement to RAS memory model\n\naddv"
  },
  {
    "id": "chunk_463",
    "text": "SubRemedialActionElement to RAS memory model\n\naddvscdcconditionelement\n\nAdd VscdcConditionElement to RAS memory model\n\naddvscdccontingencyelement\n\nAdd VscdcContingencyElement to RAS memory model\n\naddvscdcremedialactionelement\n\nAdd VscdcRemedialActionElement to RAS memory model\n\nappend_ras\n\n read a Contingency Definition and Remedial Actions auxiliary file, adding to definitions in memory, if present.\n\nread_ras\n\n read a Contingency Definition and Remedial Actions auxiliary file into memory.\n\nvali"
  },
  {
    "id": "chunk_464",
    "text": "Remedial Actions auxiliary file into memory.\n\nvalidate_ras\n\n validate Contingency and Remedial Actions definitions in memory.\n\nwrite_ras\n\n write a Contingency Definition and Remedial Actions auxiliary file from memory.\n\n--- Vsc Dc Line Converter Data \u2014 .txt ---\n\nVsc Dc Line Converter Data \u2014 \n\nVsc Dc Line Converter Data\u00b6\n\n\n\n\n\navscdcconvchar\n\n return an array of character values for subsystem VSC dc line converters.\n\navscdcconvcount\n\n return the number of array entries required to accommodate the "
  },
  {
    "id": "chunk_465",
    "text": "mber of array entries required to accommodate the data to be returned by the remaining members of the VSC dc line converter data family.\n\navscdcconvcplx\n\n return an array of complex values for subsystem VSC dc line converters.\n\navscdcconvint\n\n return an array of integer values for subsystem VSC dc line converters.\n\navscdcconvreal\n\n return an array of real values for subsystem VSC dc line converters.\n\navscdcconvtypes\n\n return an array of character values indicating the data types corresponding to"
  },
  {
    "id": "chunk_466",
    "text": " values indicating the data types corresponding to a set of specified STRING values that are valid input values to any of the data retrieval routines of the VSC dc line converter data family (aVscDcConvInt, aVscDcConvReal, aVscDcConvCplx and aVscDcConvChar).\n\n--- Vsc Dc Line Data \u2014 .txt ---\n\nVsc Dc Line Data \u2014 \n\nVsc Dc Line Data\u00b6\n\n\n\n\n\navscdcchar\n\n return an array of character values for subsystem VSC dc lines.\n\navscdccount\n\n return the number of array entries required to accommodate the data to "
  },
  {
    "id": "chunk_467",
    "text": "array entries required to accommodate the data to be returned by the remaining members of the VSC dc line data family.\n\navscdccplx\n\n return an array of complex values for subsystem VSC dc lines.\n\navscdcint\n\n return an array of integer values for subsystem VSC dc lines.\n\navscdcreal\n\n return an array of real values for subsystem VSC dc lines.\n\navscdctypes\n\n return an array of character values indicating the data types corresponding to a set of specified STRING values that are valid input values to"
  },
  {
    "id": "chunk_468",
    "text": "ified STRING values that are valid input values to any of the data retrieval routines of the VSC dc line data family (aVscDcInt, aVscDcReal, aVscDcCplx and aVscDcChar).\n\n--- Wind Related Models \u2014 .txt ---\n\nWind Related Models \u2014 \n\nWind Related Models\u00b6\n\n\n\n\n\nadd_wind_model\n\n add a renewable related model of a designated type to a specified renewable machine.\n\nchange_wnmod_chricn\n\n change the value of a character ICON (i.e., an element of the CHRICN array) of a designated renewable related model at "
  },
  {
    "id": "chunk_469",
    "text": "array) of a designated renewable related model at a specified renewable machine.\n\nchange_wnmod_con\n\n change the value of a CON of a designated renewable machine related model at a specified renewable machine.\n\nchange_wnmod_icon\n\n change the value of an integer ICON of a designated renewable machine related model at a specified renewable machine.\n\nchange_wnmod_var\n\n change the value of a VAR of a designated renewable machine related model at a specified renewable machine.\n\nwnmod_consistency\n\n che"
  },
  {
    "id": "chunk_470",
    "text": "cified renewable machine.\n\nwnmod_consistency\n\n check consistency among the renewable machine related models referenced at each machine.\n\nwnmod_pack\n\n remove entries that are marked as unused from the wind model connection tables and the renewable machine model array allocation tables.\n\nwnmod_remove\n\n remove a renewable machine related model of a designated type from a specified renewable machine.\n\nwnmod_status\n\n change the status of a renewable machine related model of a designated type at a spe"
  },
  {
    "id": "chunk_471",
    "text": "achine related model of a designated type at a specified renewable machine.\n\nwnmod_unconnected\n\n list or remove from dynamics working memory those renewable machine related models that are assigned to renewable machines that are not present in the current power flow working case (unconnected).\n\nwnmod_user\n\n list user-written renewable machine model definitions or to remove user-written renewable machine model definitions that are not assigned to any renewable machines (unused) from the user mode"
  },
  {
    "id": "chunk_472",
    "text": "any renewable machines (unused) from the user model definition tables.\n\n--- Zero Sequence Mutuals Data \u2014 .txt ---\n\nZero Sequence Mutuals Data \u2014 \n\nZero Sequence Mutuals Data\u00b6\n\n\n\n\n\nazmutchar\n\n return an array of character values for subsystem zero sequence mutual branches.\n\nazmutcount\n\n return the number of array entries required to accommodate the data to be returned by the remaining members of the branch zero sequence mutual data family.\n\nazmutcplx\n\n return an array of complex values for subsyst"
  },
  {
    "id": "chunk_473",
    "text": "lx\n\n return an array of complex values for subsystem zero sequence mutual branches.\n\nazmutint\n\n return an array of integer values for subsystem zero sequence mutual branches.\n\nazmutreal\n\n return an array of real values for subsystem zero sequence mutual branches.\n\nazmuttypes\n\n return an array of character values indicating the data types corresponding to a set of specified STRING values that are valid input values to any of the data retrieval routines of the branch zero sequence mutual data fami"
  },
  {
    "id": "chunk_474",
    "text": "tines of the branch zero sequence mutual data family (aZmutInt, aZmutReal, aZmutCplx and aZmutChar).\n\n--- Zone Data \u2014 .txt ---\n\nZone Data \u2014 \n\nZone Data\u00b6\n\n\n\n\n\nazonechar\n\n return an array of character values for subsystem zones.\n\nazonecount\n\n return the number of array entries required to accommodate the data to be returned by the remaining members of the zone data family.\n\nazonecplx\n\n return an array of complex values for subsystem zones.\n\nazoneint\n\n return an array of integer values for subsyste"
  },
  {
    "id": "chunk_475",
    "text": "t\n\n return an array of integer values for subsystem zones.\n\nazonereal\n\n return an array of real values for subsystem zones.\n\nazonetypes\n\n return an array of character values indicating the data types corresponding to a set of specified STRING values that are valid input values to any of the data retrieval routines of the zone data family (aZoneInt, aZoneReal, aZoneCplx and aZoneChar).\n\n--- Zone Subsystems \u2014 .txt ---\n\nZone Subsystems \u2014 \n\nZone Subsystems\u00b6\n\n\n\n\n\nzsys\n\n define a zone subsystem.\n\nzsys"
  },
  {
    "id": "chunk_476",
    "text": "ystems\u00b6\n\n\n\n\n\nzsys\n\n define a zone subsystem.\n\nzsysdef\n\n set the definition of an zone subsystem.\n\nzsysinit\n\n initialize or re-initialize a zone subsystem.\n#[accc_reports.py]  GET ACCC SOLUTION IN ARRAYS and CREATE CUSTOM REPORTS\n# ====================================================================================================\n'''\nThis is an example file showing how to use ACCC Solution Array fetch APIs\nfrom Python to generate custom accc solution reports.\n\nFollowing ACCC solutions can be ret"
  },
  {
    "id": "chunk_477",
    "text": "tion reports.\n\nFollowing ACCC solutions can be retrieved:\n    - post-contingency solution,\n    - post-tripping solution, or\n    - post-corrective action solution\n\nThese ACCC solutions can be obtained in Python lists for:\n    - single contingency,\n    - multiple contingencies, or\n    - all contingencies\n\nThe APIs used in this program are part of python \"arrbox.accc_pp\" module.\n    accobj = arrbox.accc_pp.CONTINGENCY_PP(accfile)\n    Following methods are defined for accobj.\n    - accobj.summary an"
  },
  {
    "id": "chunk_478",
    "text": "ds are defined for accobj.\n    - accobj.summary and accobj.solution methods return ACCC solution\n      in python object, which can be used to create custom reports, or\n    - accobj.summary_report, accobj.solution_report or accobj.violations_report\n      methods can be used to get pre-defined reports.\n\nGet more info on as:\n    help(arrbox.accc_pp.CONTINGENCY_PP)\n\n---------------------------------------------------------------------------------\nHow to use this file?\n\nAs showed in __main__ (end of "
  },
  {
    "id": "chunk_479",
    "text": " to use this file?\n\nAs showed in __main__ (end of this file)\n- Enable PSSE version specific environment, as an example:\n    import psse35\n\n- call funtion\n    run_accc_reports()\n    You may want to change input arguments when you call this function.\n    run_accc_reports(accfile, rptfile)\n    \n---------------------------------------------------------------------------------\nAlternatively, use either of the following menu items to export ACCC file output to Excel.\n- from Windows Start>Programs>PSSE"
  },
  {
    "id": "chunk_480",
    "text": "utput to Excel.\n- from Windows Start>Programs>PSSExx>Export Results to Excel OR\n- from PSSE GUI, Power Flow>Reports>Export Results to Excel\n'''\n# ----------------------------------------------------------------------------------------------------\n\nimport sys, os, random, time\n\n# ----------------------------------------------------------------------------------------------------\n\ndef create_accc_reports(accfile, rptfile):\n\n    import psspy, arrbox.accc_pp\n\n    if not os.path.exists(accfile):\n    "
  },
  {
    "id": "chunk_481",
    "text": ".accc_pp\n\n    if not os.path.exists(accfile):\n        prgmsg = \" Error: Input accfile '{0}' does not exist\".format(accfile)\n        print(prgmsg)\n        return\n\n    if rptfile:\n        p, nx = os.path.split(rptfile)\n        n, x = os.path.splitext(nx)\n        if not x:\n            x = '.txt'\n            nx = n + x\n        if p:\n            rptfile = os.path.join(p, nx)\n        else:\n            rptfile = os.path.join(os.getcwd(), nx)\n\n        rptfpath, rptext = os.path.splitext(rptfile)\n\n    # "
  },
  {
    "id": "chunk_482",
    "text": "tfpath, rptext = os.path.splitext(rptfile)\n\n    # ----------------------------------------------------------------------------------------------------\n    # common variables values (assumed)\n    busmsm    = 0.5\n    sysmsm    = 5.0\n    rating    = 'a'\n    flowlimit = 80.0\n    stype_cnt = 'contingency'\n    stype_trp = 'tripping'\n    stype_cact= 'caction'\n\n    # ----------------------------------------------------------------------------------------------------\n    # (1) Create object\n    accobj = "
  },
  {
    "id": "chunk_483",
    "text": "------------\n    # (1) Create object\n    accobj = arrbox.accc_pp.CONTINGENCY_PP(accfile)\n    if accobj.ierr:\n        prgmsg = \" Error {0:d} creating 'accobj'.\".format(accobj.ierr)\n        print(prgmsg)\n        return\n\n    # ----------------------------------------------------------------------------------------------------\n    # (2) ACCC summary report\n    sumfile = None\n    if rptfile:  sumfile = rptfpath + '_summary' + rptext\n    accobj.summary_report(rptfile=sumfile)\n\n    # ------------------"
  },
  {
    "id": "chunk_484",
    "text": "_report(rptfile=sumfile)\n\n    # ----------------------------------------------------------------------------------------------------\n    # (3) ACCC post contingency solution report\n    accobj.solution_options(stype=stype_cnt,busmsm=busmsm,sysmsm=sysmsm,rating=rating,flowlimit=flowlimit)\n    cntsolnfile = None\n    if rptfile:  cntsolnfile = rptfpath + '_solution_cnt' + rptext\n    accobj.solution_report(colabels=None,rptfile=cntsolnfile)\n\n    # -----------------------------------------------------"
  },
  {
    "id": "chunk_485",
    "text": "-------------------------------------------------------------------------------------------------\n    # (4) ACCC post tripping solution report\n    trpsolnfile = None\n    if rptfile:  trpsolnfile = rptfpath + '_solution_trp' + rptext\n    accobj.solution_options(stype=stype_trp)    # changed only solution type, other options remain same\n    accobj.solution_report(colabels=None,rptfile=trpsolnfile)\n\n    # ----------------------------------------------------------------------------------------------"
  },
  {
    "id": "chunk_486",
    "text": "--------------------------------------------------------\n    # (5) ACCC post corrective action solution report\n    cactsolnfile = None\n    if rptfile:  cactsolnfile = rptfpath + '_solution_cact' + rptext\n    accobj.solution_options(stype=stype_cact)    # changed only solution type, other options remain same\n    accobj.solution_report(colabels=None,rptfile=cactsolnfile)\n\n    # ----------------------------------------------------------------------------------------------------\n    # (6) ACCC post "
  },
  {
    "id": "chunk_487",
    "text": "-----------------------------\n    # (6) ACCC post contingency violations report\n    cntviofile = None\n    if rptfile:  cntviofile = rptfpath + '_violations_cnt' + rptext\n    accobj.solution_options(stype=stype_cnt)\n    accobj.violations_report(rptfile=cntviofile)\n\n    # ----------------------------------------------------------------------------------------------------\n    # (7) ACCC post tripping violations report\n    trpviofile = None\n    if rptfile:  trpviofile = rptfpath + '_violations_trp' "
  },
  {
    "id": "chunk_488",
    "text": "tfile:  trpviofile = rptfpath + '_violations_trp' + rptext\n    accobj.solution_options(stype=stype_trp)\n    accobj.violations_report(rptfile=trpviofile)\n\n    # ----------------------------------------------------------------------------------------------------\n    # (8) ACCC post corrective action violations report\n    cactviofile = None\n    if rptfile:  cactviofile = rptfpath + '_violations_cact' + rptext\n    accobj.solution_options(stype=stype_cact)\n    accobj.violations_report(rptfile=cactvio"
  },
  {
    "id": "chunk_489",
    "text": "cact)\n    accobj.violations_report(rptfile=cactviofile)\n\n    # ----------------------------------------------------------------------------------------------------\n    # (9) Getting summary arrays and printing contingency lables in PSS(R)E progress window\n    smryobj = accobj.summary()\n        # note: returned \"smryobj\" is used in the following (10) to (16) examples of this program.\n    psspy.progress('\\n Contingency Labels:\\n')\n    for each in smryobj.colabel:\n        psspy.progress('    '+each"
  },
  {
    "id": "chunk_490",
    "text": "mryobj.colabel:\n        psspy.progress('    '+each+'\\n')\n\n    # ----------------------------------------------------------------------------------------------------\n    # (10) Getting solution arrays for one contingency and printing monitored element MVA and AMP flows\n    #      in PSS(R)E progress window\n    idx   = random.sample(list(range(len(smryobj.colabel))),1)   # select one contingency randomly\n    colbl = smryobj.colabel[idx[0]]\n    accobj.solution_options(stype=stype_cnt)\n    solnobj  "
  },
  {
    "id": "chunk_491",
    "text": "bj.solution_options(stype=stype_cnt)\n    solnobj  = accobj.solution(colabel=colbl)\n    if solnobj!=None:        # contingency solution found/error, proceed\n        rating = rating.strip().lower()\n        try:\n            rate = smryobj.rating.rating\n        except:\n            rate = smryobj.rating.a\n\n        psspy.progress(\"\\n Monitored Element Flows for contingency '%12s':\\n\" % colbl)\n        psspy.progress(\"<-----------------MONITORED ELEMENT------------------> <RATING> <MVAFLOW> \\\n    <AMPFL"
  },
  {
    "id": "chunk_492",
    "text": "-----------------> <RATING> <MVAFLOW> \\\n    <AMPFLOW> <PCTFLOW>\\n\")\n        for i in range(len(solnobj.mvaflow)):\n            elmt    = \"%54s\" % smryobj.melement[i]\n            mvaflow = \"%9.2f\" % solnobj.mvaflow[i]\n            if i < smryobj.acccsize.nmline:\n                ampflow = \"%9.2f\" % solnobj.ampflow[i] # AMP flow exists for nmlines only.\n                pctflow = abs(solnobj.ampflow[i])\n            else:\n                ampflow = 9*' '                 # for interfaces, no AMP flow\n   "
  },
  {
    "id": "chunk_493",
    "text": "                 # for interfaces, no AMP flow\n                pctflow = abs(solnobj.mvaflow[i])  # for interfaces, MVA rating to be considered\n\n            if rate[i]:\n                elmt_rate = \"%8.2f\" % rate[i]\n                pctflow   = \"%9.2f\" % (pctflow*100.0/rate[i])\n            else:   # if rating is not provided, don't calculate %flow\n                elmt_rate = 8*' '\n                pctflow   = 9*' '\n\n            txtstr = \"%(elmt)s %(elmt_rate)s %(mvaflow)s %(ampflow)s %(pctflow)s \\n"
  },
  {
    "id": "chunk_494",
    "text": "elmt_rate)s %(mvaflow)s %(ampflow)s %(pctflow)s \\n\" %vars()\n            psspy.progress(txtstr)\n\n    # ----------------------------------------------------------------------------------------------------\n    # (11) Getting solution arrays for three contingency and printing monitored element MVA and AMP flows\n    #      in PSS(R)E progress window for converged contingencies\n\n    # select upto maximum of 3 contingencies randomly\n    idx    = random.sample(list(range(len(smryobj.colabel))),min(len(s"
  },
  {
    "id": "chunk_495",
    "text": "sample(list(range(len(smryobj.colabel))),min(len(smryobj.colabel),3))\n    colbls = [smryobj.colabel[x] for x in idx]\n\n    rating = rating.strip().lower()\n    try:\n        rate = smryobj.rating.rating\n    except:\n        rate = smryobj.rating.a\n\n    for lbl in colbls:\n        solnobj  = accobj.solution(colabel=lbl)\n        if solnobj==None: continue          # contingency solution not found, move to next\n        if not solnobj.cnvflag: continue    # contingency solution not converged, move to nex"
  },
  {
    "id": "chunk_496",
    "text": " # contingency solution not converged, move to next\n        psspy.progress(\"\\n Monitored Element Flows for contingency '%12s':\\n\" % lbl)\n        psspy.progress(\"<-----------------MONITORED ELEMENT------------------> <RATING> <MVAFLOW> \\\n<AMPFLOW> <PCTFLOW>\\n\")\n        for i in range(len(solnobj.mvaflow)):\n            elmt    = \"%54s\" % smryobj.melement[i]\n            mvaflow = \"%9.2f\" % solnobj.mvaflow[i]\n\n            if i < smryobj.acccsize.nmline:\n                ampflow = \"%9.2f\" % solnobj.am"
  },
  {
    "id": "chunk_497",
    "text": "ne:\n                ampflow = \"%9.2f\" % solnobj.ampflow[i] # AMP flow exists for nmlines only.\n                pctflow = abs(solnobj.ampflow[i])\n            else:\n                ampflow = 9*' '                 # for interfaces, no AMP flow\n                pctflow = abs(solnobj.mvaflow[i])  # for interfaces, MVA rating to be considered\n\n            if rate[i]:\n                elmt_rate = \"%8.2f\" % rate[i]\n                pctflow   = \"%9.2f\" % (pctflow*100.0/rate[i])\n            else:   # if rati"
  },
  {
    "id": "chunk_498",
    "text": "tflow*100.0/rate[i])\n            else:   # if rating is not provided, don't calculate %flow\n                elmt_rate = 8*' '\n                pctflow   = 9*' '\n\n            txtstr = \"%(elmt)s %(elmt_rate)s %(mvaflow)s %(ampflow)s %(pctflow)s \\n\" %vars()\n            psspy.progress(txtstr)\n        psspy.progress('\\n')\n\n    # ----------------------------------------------------------------------------------------------------\n    # (12) Creating Overload report (similar to PSS(R)E ACCC Spreadsheet O"
  },
  {
    "id": "chunk_499",
    "text": "load report (similar to PSS(R)E ACCC Spreadsheet Overload Report) in\n    #      PSS(R)E progress window\n\n    rating = rating.strip().lower()\n    try:\n        rate = smryobj.rating.rating\n    except:\n        rate = smryobj.rating.a\n\n    psspy.progress(\"\\n OVERLOAD Report\\n\")\n    for lbl in smryobj.colabel:\n        solnobj  = accobj.solution(colabel=lbl)\n        if solnobj==None: continue         # contingency solution not found, move to next\n        if not solnobj.cnvflag: continue   # contingenc"
  },
  {
    "id": "chunk_500",
    "text": "   if not solnobj.cnvflag: continue   # contingency solution not converged, move to next\n        psspy.progress(\" Monitored Element Flows above %g%% for contingency '%12s':\\n\" % (flowlimit,lbl))\n        psspy.progress(\"<-----------------MONITORED ELEMENT------------------> <RATING> <MVAFLOW> \\\n<AMPFLOW> <PCTFLOW>\\n\")\n        for i in range(len(solnobj.mvaflow)):\n            elmt    = \"%54s\" % smryobj.melement[i]\n            mvaflow = \"%9.2f\" % solnobj.mvaflow[i]\n\n            if i < smryobj.acccs"
  },
  {
    "id": "chunk_501",
    "text": "lnobj.mvaflow[i]\n\n            if i < smryobj.acccsize.nmline:\n                ampflow = \"%9.2f\" % solnobj.ampflow[i] # AMP flow exists for nmlines only.\n                pctflow = abs(solnobj.ampflow[i])\n            else:\n                ampflow = 9*' '                 # for interfaces, no AMP flow\n                pctflow = abs(solnobj.mvaflow[i])  # for interfaces, MVA rating to be considered\n\n            if rate[i]:\n                elmt_rate = \"%8.2f\" % rate[i]\n                pctflow_v = pctfl"
  },
  {
    "id": "chunk_502",
    "text": "%8.2f\" % rate[i]\n                pctflow_v = pctflow*100.0/rate[i]\n                pctflow   = \"%9.2f\" % (pctflow*100.0/rate[i])\n            else:   # if rating is not provided, don't calculate %flow\n                elmt_rate = 8*' '\n                pctflow   = 9*' '\n                pctflow_v = 0\n\n            if pctflow_v >= flowlimit:\n                psspy.progress(\"%(elmt)s %(elmt_rate)s %(mvaflow)s %(ampflow)s %(pctflow)s \\n\" %vars())\n        psspy.progress('\\n')\n\n    # ----------------------"
  },
  {
    "id": "chunk_503",
    "text": "psspy.progress('\\n')\n\n    # ----------------------------------------------------------------------------------------------------\n    # (13) Creating Voltage Violations report in Text file, if provided\n\n    if rptfile:  sumfile = rptfpath + '_summary' + rptext\n    if rptfile:\n        vviofpath, vviofext = os.path.splitext(rptfile)\n        if not vviofext: vviofext = '.txt'\n        vviofile   = vviofpath + '_vvio' + vviofext\n        vviofile_h = open(vviofile,'w')\n        report     = vviofile_h.w"
  },
  {
    "id": "chunk_504",
    "text": "en(vviofile,'w')\n        report     = vviofile_h.write\n    else:\n        psspy.beginreport()\n        report = psspy.report\n\n    report(\"\\n Post Contingency VOLTAGE VIOLATIONS Report\\n\")\n\n    # get base case solution\n    solnobj_basecase = accobj.solution(colabel=\"BASE CASE\")\n\n    if solnobj_basecase==None or not solnobj_basecase.cnvflag:\n        report(\"    BASE CASE not converged\\n\")\n    else:\n        # remaining contingencies\n        for lbl in smryobj.colabel[1:]:   # skipped \"BASE CASE\"\n    "
  },
  {
    "id": "chunk_505",
    "text": " smryobj.colabel[1:]:   # skipped \"BASE CASE\"\n            solnobj  = accobj.solution(colabel=lbl)\n            if solnobj==None: continue          # contingency solution not found, move to next\n            if not solnobj.cnvflag: continue    # contingency solution not converged, move to next\n            vvio_exists = False\n            for r in range(len(solnobj.volts)):\n                if solnobj.volts[r] == 0.0: continue # disconnected bus, move to next\n                if smryobj.mvrectype[r]=='"
  },
  {
    "id": "chunk_506",
    "text": "to next\n                if smryobj.mvrectype[r]=='RANGE':\n                    if smryobj.mvrecmin[r] and solnobj.volts[r] < smryobj.mvrecmin[r]:\n                        vvio = solnobj.volts[r] - smryobj.mvrecmin[r]\n                    elif smryobj.mvrecmax[r] and solnobj.volts[r] > smryobj.mvrecmax[r]:\n                        vvio = solnobj.volts[r] - smryobj.mvrecmax[r]\n                    else:\n                        vvio = 0\n                else: # DEVIATION\n                    delta = solno"
  },
  {
    "id": "chunk_507",
    "text": "lse: # DEVIATION\n                    delta = solnobj.volts[r] - solnobj_basecase.volts[r]\n                    if delta < 0:\n                        if smryobj.mvrecmin[r] and abs(delta) > smryobj.mvrecmin[r]:\n                            vvio =  delta + smryobj.mvrecmin[r]\n                        else:\n                            vvio = 0\n                    else:\n                        if smryobj.mvrecmax[r] and delta > smryobj.mvrecmax[r]:\n                            vvio = delta - smryobj.mvr"
  },
  {
    "id": "chunk_508",
    "text": "                        vvio = delta - smryobj.mvrecmax[r]\n                        else:\n                            vvio = 0\n                if vvio:\n                    if not vvio_exists:\n                        report(\" Voltage Violations for contingency '%12s':\\n\" % (lbl))\n                        report(\"<-----MONITORED BUS-----> <--MONITOR LABEL---> <--TYPE-> <-VMIN-> <-VMAX-> <-VINIT-> \\\n<-VOLT--> <-VVIO-->\\n\")\n                        vvio_exists = True\n                    mvbuslabel     "
  },
  {
    "id": "chunk_509",
    "text": "_exists = True\n                    mvbuslabel     = smryobj.mvbuslabel[r]\n                    mvreclabel     = smryobj.mvreclabel[r]\n                    mvrectype      = smryobj.mvrectype[r]\n                    if smryobj.mvrecmin[r]:\n                        mvrecmin   = \"%8.5f\" % smryobj.mvrecmin[r]\n                    else:\n                        mvrecmin   = '   --   '\n                    if smryobj.mvrecmax[r]:\n                        mvrecmax   = \"%8.5f\" % smryobj.mvrecmax[r]\n             "
  },
  {
    "id": "chunk_510",
    "text": "ax   = \"%8.5f\" % smryobj.mvrecmax[r]\n                    else:\n                        mvrecmax   = '   --   '\n                    mvrecvolts_init= solnobj_basecase.volts[r]\n                    mvrecvolts     = solnobj.volts[r]\n                    report(\"%(mvbuslabel)25s %(mvreclabel)20s %(mvrectype)9s %(mvrecmin)s \\\n%(mvrecmax)s %(mvrecvolts_init)9.5f %(mvrecvolts)9.5f %(vvio)9.5f \\n\" %  vars())\n\n            if vvio_exists: report('\\n')\n\n    if rptfile:\n        vviofile_h.close()\n        print"
  },
  {
    "id": "chunk_511",
    "text": " rptfile:\n        vviofile_h.close()\n        print('\\n Voltage Violations Report saved to file %s' % vviofile)\n    else:\n        print('\\n Voltage Violations Report created in Report window.')\n\n    # ----------------------------------------------------------------------------------------------------\n    # (14) Creating Post-Contingency Solution Load Shedding report in progress\n\n    report = psspy.progress\n    load_curtailment_exists = False\n    report('\\n Post-Contingency LOAD CURTAILMENTS Repor"
  },
  {
    "id": "chunk_512",
    "text": "eport('\\n Post-Contingency LOAD CURTAILMENTS Report\\n')\n    stype = stype_cnt\n    for lbl in smryobj.colabel:\n        solnobj  = accobj.solution(colabel=lbl)\n        if solnobj==None: continue              # contingency solution not found, move to next\n        if not solnobj.cnvflag: continue        # contingency solution not converged, move to next\n        if not len(solnobj.lshedbus): continue  # no load shedding, move to next\n        report(\"\\n Load Curtailments for contingency '%12s':\\n\" % ("
  },
  {
    "id": "chunk_513",
    "text": "n Load Curtailments for contingency '%12s':\\n\" % (lbl))\n        if not load_curtailment_exists:\n            if stype=='contingency' or stype=='tripping':\n                report(\"<----------BUS----------> <LDSHED(MW)> <CONTINGENCY>\\n\")\n            else:\n                report(\"<----------BUS----------> <INITLD(MW)>  <LDSHED(MW)> <CONTINGENCY>\\n\")\n            load_curtailment_exists = True\n\n        for c in range(len(solnobj.lshedbus)):\n            if stype=='contingency' or stype=='tripping':\n   "
  },
  {
    "id": "chunk_514",
    "text": " if stype=='contingency' or stype=='tripping':\n                report(\"%25s %12.2f %-12s\\n\" % (solnobj.lshedbus[c],solnobj.loadshed[c],lbl))\n            else:\n                report(\"%25s %12.2f %12.2f %-12s\\n\" % (solnobj.lshedbus[c],solnobj.loadshed[0][c],\n                                                       solnobj.loadshed[1][c],lbl))\n    if not load_curtailment_exists:\n        report('    None\\n')\n\n    # --------------------------------------------------------------------------------------"
  },
  {
    "id": "chunk_515",
    "text": "----------------------------------------------------------------\n    # (15) Creating Corrective Action Solution Generation Dispatch report in progress\n\n    accobj.solution_options(stype=stype_cact)\n\n    report = psspy.progress\n    gen_disp_exists = False\n    report('\\n Corrective Action GENERATION DISPATCH  Report\\n')\n\n    for lbl in smryobj.colabel:\n        solnobj  = accobj.solution(colabel=lbl)\n        if solnobj==None: continue              # contingency solution not found, move to next\n    "
  },
  {
    "id": "chunk_516",
    "text": " contingency solution not found, move to next\n        if not solnobj.cnvflag: continue        # contingency solution not converged, move to next\n        if not len(solnobj.gdispbus): continue  # no generation dispatch, move to next\n        if not gen_disp_exists:\n            report(\"<----------BUS----------> <INITGEN(MW)>  <GENDISP(MW)> <CONTINGENCY>\\n\")\n            gen_disp_exists = True\n        for c in range(len(solnobj.gdispbus)):\n            report(\"%25s %9.2f %s %9.2f %s %-12s\\n\" % (solnob"
  },
  {
    "id": "chunk_517",
    "text": " report(\"%25s %9.2f %s %9.2f %s %-12s\\n\" % (solnobj.gdispbus[c],solnobj.gendisp[0][c],4*' ',\n                                                      solnobj.gendisp[1][c],3*' ',lbl))\n\n    if not gen_disp_exists:\n        report('    None\\n')\n\n    # ----------------------------------------------------------------------------------------------------\n    # (16) Creating Corrective Action Solution Phase Shifter Angle report in progress\n\n    accobj.solution_options(stype=stype_cact)\n\n    report = psspy."
  },
  {
    "id": "chunk_518",
    "text": "ion_options(stype=stype_cact)\n\n    report = psspy.progress\n    phsftr_exists = False\n    report('\\n Corrective Action PHASE SHIFTER ANGLE Report\\n')\n\n    for lbl in smryobj.colabel:\n        solnobj  = accobj.solution(colabel=lbl)\n        if solnobj==None: continue              # contingency solution not found, move to next\n        if not solnobj.cnvflag: continue        # contingency solution not converged, move to next\n        if not len(solnobj.phsftr): continue    # no generation dispatch, mo"
  },
  {
    "id": "chunk_519",
    "text": ".phsftr): continue    # no generation dispatch, move to next\n        if not phsftr_exists:\n            report(\"<-------FROM BUS------------------TO BUS-----------ID> <INITANG(deg)> <NEWANG(deg)> \\\n<CONTINGENCY>\\n\")\n            phsftr_exists = True\n        for c in range(len(solnobj.phsftr)):\n            report(\"%54s %9.2f %s %9.2f %s %-12s\\n\" % (solnobj.phsftr[c],solnobj.phsftrang[0][c],5*' ',\n                                                       solnobj.phsftrang[1][c],3*' ',lbl))\n    if not p"
  },
  {
    "id": "chunk_520",
    "text": "  solnobj.phsftrang[1][c],3*' ',lbl))\n    if not phsftr_exists:\n        report('    None\\n')\n\n# =====================================================================================================\n\ndef check_psse_example_folder(rptfile):\n    # if called from PSSE's Example Folder, create report in subfolder 'Output_Pyscript'\n    rptpath, rptfnam = os.path.split(rptfile)\n    if not rptpath:\n        rptpath = os.getcwd()\n        cwd = rptpath.lower()\n        i = cwd.find('pti')\n        j = cwd.fi"
  },
  {
    "id": "chunk_521",
    "text": "r()\n        i = cwd.find('pti')\n        j = cwd.find('psse')\n        k = cwd.find('example')\n        if i>0 and j>i and k>j:     # called from Example folder\n            outdir = os.path.join(os.getcwd(), 'Output_Pyscript')\n            if not os.path.exists(outdir): os.mkdir(outdir)\n        else:\n            outdir = os.getcwd()\n        rptfile  = os.path.join(outdir, rptfnam)\n\n    return rptfile\n\n# ================================================================================================="
  },
  {
    "id": "chunk_522",
    "text": "======================================================\n\ndef run_accc_reports(accfile='savnw.acc', rptfile='accc_reports_savnw.txt'):\n\n    rptfile  = check_psse_example_folder(rptfile)\n    \n    create_accc_reports(accfile, rptfile)\n\n# ====================================================================================================\n# ====================================================================================================\n\nif __name__ == '__main__':\n    import psse35\n    run_accc_rep"
  },
  {
    "id": "chunk_523",
    "text": " == '__main__':\n    import psse35\n    run_accc_reports()\n\n# ====================================================================================================\n#[ascc_demo.py]   Fault Calculations using ASCC\n# =====================================================================================================\n'''There are three different ways to calculate faults using ASCC.\n1) Using activity ASCC (psspy.ascc_3)\n   Runs all types of faults, creates text reports, but no access to results from Py"
  },
  {
    "id": "chunk_524",
    "text": "tes text reports, but no access to results from Python script.\n\n2) Using Python module arrbox.ascc.ascc_currents\n   Runs all types of faults, creates text reports and returns results in python object that can be\n   accessed from Python script.\n   The returned python object\n       a) contain both phase and sequence fault currents.\n       b) contain faults currents for bus faults only.\n       c) does not contain faults currents for linout and linend faults.\n\n3) Using Python module arrbox.fault.FAU"
  },
  {
    "id": "chunk_525",
    "text": "d faults.\n\n3) Using Python module arrbox.fault.FAULT_SUMMARY\n   Runs all types of faults, creates text reports and returns results in python object that can be\n   accessed from Python script.\n   The returned python object\n       a) contain only total fault currents for faults calculated.\n       b) contain faults currents for bus, linout and linend faults.\n\nThis is an example file showing how to run ASCC fault calculations using either of these methods.\n\n------------------------------------------"
  },
  {
    "id": "chunk_526",
    "text": "thods.\n\n---------------------------------------------------------------------------------\nHow to use this file?\n\nA) As showed in __main__ (end of this file), enable PSSE version specific environment, as an example:\n    import psse35\n\nB) This file contain following functions that uses savnw.sav file run ASCC calculations.\n    run_ascc_3_savnw(..)\n    run_ascc_currents_savnw_txtrpt(..)\n    run_ascc_currents_savnw_xls(..)\n    run_fault_summary_ascc_savnw(..)\n\n    Run either of these functions under"
  },
  {
    "id": "chunk_527",
    "text": "savnw(..)\n\n    Run either of these functions under  __main__ to see how they work.\n\nC) Create similar functions for the network case and faults you want to run.\n\n'''\n# ========================================================================================\n#\n\"\"\"\nUse any of these keywords to run psspy.ascc or arrbox.ascc.ascc_currents or arrbox.fault.FAULT_SUMMARY.\nKeyword   Default      Description\n                       # STATUS array\nfltlg     = 0          # 1  0=>omit, 1=>include\nlinout    = "
  },
  {
    "id": "chunk_528",
    "text": "= 0          # 1  0=>omit, 1=>include\nlinout    = 0          # 2  0=>omit, 1=>include\nlinend    = 0          # 3  0=>omit, 1=>include\nvoltop    = 0          # 4  0=>from PF, 1=>at specified for all buses, 2=>at specified faulted bus\ngenxop    = 0          # 5  0=>X'' 1=>X', 2=>Xs\nrptop     = -1         # 6  -1=>no report, 0=>summary, 1=>total, 2=>contributions 3=>total+contributions\nrptlvl    = 0          # 7  number of contribution levels\ntpunty    = 0          # 8  0=>N and phi unchanged, 1=>N"
  },
  {
    "id": "chunk_529",
    "text": "    = 0          # 8  0=>N and phi unchanged, 1=>N=1 and phi=0, 2=>N=1 and phi unchanged, 3=>N unchanged and phi=0\ndcload    = 1          # 9  0=>blocked, 1=>represent as load (dc line and FACTS option)\nzcorec    = 1          # 10 0=>ignore, 1=>apply  (zero sequence transformer impedance correction option)\nflt3ph    = 0          # 11 0=>omit, 1=>include\nfltllg    = 0          # 12 0=>omit, 1=>include\nfltll     = 0          # 13 0=>omit, 1=>include\nlnchrg    = 0          # 14 0=>unchanged, 1=>0.0"
  },
  {
    "id": "chunk_530",
    "text": "e\nlnchrg    = 0          # 14 0=>unchanged, 1=>0.0 in +/- sequences, 2=>0.0 in all sequences (line charging)\nshntop    = 0          # 15 0=>unchanged, 1=>0.0 in +/- sequences, 2=>0.0 in all sequences (line, fixed, swicthed shunts, xmer magnetization)\nloadop    = 0          # 16 0=>unchanged, 1=>0.0 in +/- sequences, 2=>0.0 in all sequences (load)\nmachpq    = 0          # 17 0=>from PF, 1=>0.0 (generator/motor PQ output)\n                       # VALUES array\nvolts     = 1.0        # 1  specified "
  },
  {
    "id": "chunk_531",
    "text": "ALUES array\nvolts     = 1.0        # 1  specified bus voltage, used when voltop=1 or 2\n                       # File args\nrelfile   = ''\nfcdfile   = ''\nscfile    = 'nooutput'\n\"\"\"\n# ========================================================================================\n\nimport sys, os, time, math\n\nbsys_kwds = {'usekv':0, 'basekv':[0.0, 999.0], 'areas':[], 'buses':[],\n             'owners':[], 'zones':[]}\n\ndef fault_bsys(sid, **kwds):\n    import psspy\n\n    if sid==0: return\n\n    actv_kwds = {}  #"
  },
  {
    "id": "chunk_532",
    "text": "sspy\n\n    if sid==0: return\n\n    actv_kwds = {}  # activity keywords\n    for k, v in bsys_kwds.items():\n        if k in kwds:\n            actv_kwds[k] = kwds[k]\n        else:\n            actv_kwds[k] = v\n\n    actv_kwds['sid']      = sid\n    actv_kwds['numarea']  = len(actv_kwds['areas'])\n    actv_kwds['numbus']   = len(actv_kwds['buses'])\n    actv_kwds['numowner'] = len(actv_kwds['owners'])\n    actv_kwds['numzone']  = len(actv_kwds['zones'])\n\n    ierr = psspy.bsys(**actv_kwds)\n\n    return ierr\n\n"
  },
  {
    "id": "chunk_533",
    "text": " ierr = psspy.bsys(**actv_kwds)\n\n    return ierr\n\n# ========================================================================================\n\ndef set_prg_rpt(prgfile='', rptfile=''):\n    import psspy\n    psspy.lines_per_page_one_device(1,10000000)\n    if prgfile: psspy.progress_output(2,prgfile,[0,0])\n    if rptfile: psspy.report_output(2,rptfile,[0,0])\n\n# ========================================================================================\n\ndef reset_prg_rpt():\n    import psspy\n    psspy.lin"
  },
  {
    "id": "chunk_534",
    "text": "ef reset_prg_rpt():\n    import psspy\n    psspy.lines_per_page_one_device(2,10000000)\n    psspy.progress_output(1,'',[0,0])\n    psspy.report_output(1,'',[0,0])\n\n# ========================================================================================\n\nclass ASCC_DEMO:\n    \"\"\" Run PSSE ASCC Calculations\"\"\"\n\n    def __init__(self):\n        import psspy\n        self.ierr = psspy.psseinit(buses=150000)\n\n    # ------------------------------------------------------------------------------------\n    de"
  },
  {
    "id": "chunk_535",
    "text": "-------------------------------------------\n    def _frmted_z(self, cnum):\n        r=cnum.real\n        x=cnum.imag\n        csign='+j'\n        if x<0:\n            csign='-j'\n            x=abs(x)\n\n        if r==0:\n            rstr=''\n        else:\n            rstr=\"%9.6f\" % r\n\n        if x==0:\n            xstr=''\n            csign=''\n        else:\n            xstr=\"%9.6f\" % x\n\n        zstr = \"%(rstr)s%(csign)s%(xstr)s\" % vars()\n\n        return zstr\n\n    # ------------------------------------------"
  },
  {
    "id": "chunk_536",
    "text": "\n\n    # ------------------------------------------------------------------------------------\n    def _frmted_z_xbyr(self, cnum):\n\n        zstr = self._frmted_z(cnum)\n\n        r=cnum.real\n        x=abs(cnum.imag)\n        if r==0:\n            xbyr=''\n        else:\n            xbyr=\"%9.6f\" % (x/r)\n\n        cstr=\"%(zstr)s, %(xbyr)s\" % vars()\n\n        return cstr\n\n    # ------------------------------------------------------------------------------------\n\n    def _crnt_mag(self, fmt, cval):\n        if"
  },
  {
    "id": "chunk_537",
    "text": "--\n\n    def _crnt_mag(self, fmt, cval):\n        if fmt=='rectangular':\n            return abs(cval)\n        else:\n            return cval.real\n\n    # ------------------------------------------------------------------------------------\n\n    def _crnt_mva_mag(self, scfmt, scunit, cval, basekv, sbase):\n        if scfmt=='rectangular':\n            if scunit=='pu':\n                baseamp = (1000.0*sbase)/(math.sqrt(3.0)*basekv)\n                crnt = cval*baseamp\n            else:\n                cr"
  },
  {
    "id": "chunk_538",
    "text": " cval*baseamp\n            else:\n                crnt = cval\n            crnt = abs(crnt)\n        else:\n            cval = cval.real\n            if scunit=='pu':\n                baseamp = (1000.0*sbase)/(math.sqrt(3.0)*basekv)\n                crnt = cval*baseamp\n            else:\n                crnt = cval\n\n        mva  = math.sqrt(3.0)*basekv*crnt/1000.0\n\n        return crnt, mva\n\n    # ------------------------------------------------------------------------------------\n    def run_ascc_api(sel"
  },
  {
    "id": "chunk_539",
    "text": "-------------------------\n    def run_ascc_api(self, sid, allbus, **kwds):\n        import psspy\n        ierr = psspy.ascc_3(sid, allbus, **kwds)\n\n    # ------------------------------------------------------------------------------------\n    def run_ascc_currents(self, sid, allbus, **kwds):\n        import psspy, arrbox.ascc\n\n        rlst = arrbox.ascc.ascc_currents(sid, allbus, **kwds)\n\n        if rlst.ierr!=0:\n            raise Exception(\"arrbox.ascc.ascc_currents error= {}\\n\".format(rlst.ierr))"
  },
  {
    "id": "chunk_540",
    "text": "ascc.ascc_currents error= {}\\n\".format(rlst.ierr))\n\n        return rlst\n\n    # ------------------------------------------------------------------------------------\n    def run_fault_summary(self, sid, allbus, **kwds):\n        import psspy, arrbox.fault\n\n        fltobj = arrbox.fault.FAULT_SUMMARY('ASCC', sid, allbus, **kwds)\n\n        if fltobj.ierr!=0:\n            raise Exception(\"arrbox.fault.FAULT_SUMMARY error= {}\\n\".format(fltobj.ierr))\n\n        return fltobj\n\n    # -------------------------"
  },
  {
    "id": "chunk_541",
    "text": "    return fltobj\n\n    # ------------------------------------------------------------------------------------\n    def report_ascc_currents(self, rlst, rptfile=''):\n        import psspy\n\n        if rlst.ierr: return\n\n        if rptfile:\n            p, nx = os.path.split(rptfile)\n            n, x = os.path.splitext(nx)\n            if not x:\n                x = '.txt'\n                nx = n + x\n            if p:\n                rptfile = os.path.join(p, nx)\n            else:\n                rptfile"
  },
  {
    "id": "chunk_542",
    "text": "n(p, nx)\n            else:\n                rptfile = os.path.join(os.getcwd(), nx)\n            rptfile_h = open(rptfile,'w')\n            report    = rptfile_h.write\n        else:\n            psspy.beginreport()\n            report = psspy.report\n\n        flt3ph = rlst.flt3ph\n        fltlg  = rlst.fltlg\n        fltllg = rlst.fltllg\n        fltll  = rlst.fltll\n\n        nfbus=len(rlst.fltbus)\n\n        txtlst = []\n        if not rptfile: txtlst.append('')\n\n        ttlstr=\"PSS(R)E ASCC SHORT CIRCUIT C"
  },
  {
    "id": "chunk_543",
    "text": "('')\n\n        ttlstr=\"PSS(R)E ASCC SHORT CIRCUIT CURRENTS\" + 10*' ' + time.ctime()\n        ln1str,ln2str=psspy.titldt()\n        maxlen=max(len(ttlstr),len(ln1str),len(ln2str))\n        txtlst.append(ttlstr.center(maxlen))\n        txtlst.append(ln1str.center(maxlen))\n        txtlst.append(ln2str.center(maxlen))\n        txtlst.append('')\n        txtall = \"\\n\".join(txtlst)\n        report(txtall)\n\n        scunit = rlst.scunit\n        scfmt  = rlst.scfmt\n\n        scunit_z = rlst.scunit_z\n        scfmt"
  },
  {
    "id": "chunk_544",
    "text": "mt\n\n        scunit_z = rlst.scunit_z\n        scfmt_z  = rlst.scfmt_z\n\n        if scunit == 'pu':\n            units = 'PU'\n        else:\n            units = 'AMP'\n        unitstr   = units.center(10)\n        clnhdr    = \"   BUS     \" + 6*unitstr\n\n        for i in range(nfbus):\n            txtlst = []\n            txtlst.append('')\n            txtlst.append(\"           <--ia1--> <--ia2--> <--ia0--> <--ia---> <--ib---> <--ic--->\")\n            txtlst.append(clnhdr)\n            fbus   = rlst.fltbus[i]"
  },
  {
    "id": "chunk_545",
    "text": "append(clnhdr)\n            fbus   = rlst.fltbus[i]\n            if flt3ph:\n                ttxt   = \"%6d\" % fbus\n                spc    = '3PH'\n                ia1    = self._crnt_mag(scfmt,rlst.flt3ph[i].ia1)\n                ia2    = self._crnt_mag(scfmt,rlst.flt3ph[i].ia2)\n                ia0    = self._crnt_mag(scfmt,rlst.flt3ph[i].ia0)\n                ia     = self._crnt_mag(scfmt,rlst.flt3ph[i].ia)\n                ib     = self._crnt_mag(scfmt,rlst.flt3ph[i].ib)\n                ic     = self"
  },
  {
    "id": "chunk_546",
    "text": "t,rlst.flt3ph[i].ib)\n                ic     = self._crnt_mag(scfmt,rlst.flt3ph[i].ic)\n                tmptxt = \"%(ttxt)s %(spc)s %(ia1)9.2f %(ia2)9.2f %(ia0)9.2f %(ia)9.2f %(ib)9.2f %(ic)9.2f\" % vars()\n                txtlst.append(tmptxt)\n\n            if fltlg:\n                if flt3ph:\n                    ttxt = 6*' '\n                else:\n                    ttxt = \"%6d\" % fbus\n                spc    = ' LG'\n                ia1    = self._crnt_mag(scfmt,rlst.fltlg[i].ia1)\n                ia2"
  },
  {
    "id": "chunk_547",
    "text": "t_mag(scfmt,rlst.fltlg[i].ia1)\n                ia2    = self._crnt_mag(scfmt,rlst.fltlg[i].ia2)\n                ia0    = self._crnt_mag(scfmt,rlst.fltlg[i].ia0)\n                ia     = self._crnt_mag(scfmt,rlst.fltlg[i].ia)\n                ib     = self._crnt_mag(scfmt,rlst.fltlg[i].ib)\n                ic     = self._crnt_mag(scfmt,rlst.fltlg[i].ic)\n                tmptxt = \"%(ttxt)s %(spc)s %(ia1)9.2f %(ia2)9.2f %(ia0)9.2f %(ia)9.2f %(ib)9.2f %(ic)9.2f\" % vars()\n                txtlst.append(t"
  },
  {
    "id": "chunk_548",
    "text": "(ic)9.2f\" % vars()\n                txtlst.append(tmptxt)\n\n            if fltllg:\n                if flt3ph or fltlg:\n                    ttxt = 6*' '\n                else:\n                    ttxt = \"%6d\" % fbus\n                spc    = 'LLG'\n                ia1    = self._crnt_mag(scfmt,rlst.fltllg[i].ia1)\n                ia2    = self._crnt_mag(scfmt,rlst.fltllg[i].ia2)\n                ia0    = self._crnt_mag(scfmt,rlst.fltllg[i].ia0)\n                ia     = self._crnt_mag(scfmt,rlst.fltllg[i"
  },
  {
    "id": "chunk_549",
    "text": "       ia     = self._crnt_mag(scfmt,rlst.fltllg[i].ia)\n                ib     = self._crnt_mag(scfmt,rlst.fltllg[i].ib)\n                ic     = self._crnt_mag(scfmt,rlst.fltllg[i].ic)\n                tmptxt = \"%(ttxt)s %(spc)s %(ia1)9.2f %(ia2)9.2f %(ia0)9.2f %(ia)9.2f %(ib)9.2f %(ic)9.2f\" % vars()\n                txtlst.append(tmptxt)\n\n            if fltll:\n                if flt3ph or fltlg or fltllg:\n                    ttxt = 6*' '\n                else:\n                    ttxt = \"%6d\" % f"
  },
  {
    "id": "chunk_550",
    "text": "        else:\n                    ttxt = \"%6d\" % fbus\n                spc     = ' LL'\n                ia1    = self._crnt_mag(scfmt,rlst.fltll[i].ia1)\n                ia2    = self._crnt_mag(scfmt,rlst.fltll[i].ia2)\n                ia0    = self._crnt_mag(scfmt,rlst.fltll[i].ia0)\n                ia     = self._crnt_mag(scfmt,rlst.fltll[i].ia)\n                ib     = self._crnt_mag(scfmt,rlst.fltll[i].ib)\n                ic     = self._crnt_mag(scfmt,rlst.fltll[i].ic)\n                tmptxt = \"%"
  },
  {
    "id": "chunk_551",
    "text": "cfmt,rlst.fltll[i].ic)\n                tmptxt = \"%(ttxt)s %(spc)s %(ia1)9.2f %(ia2)9.2f %(ia0)9.2f %(ia)9.2f %(ib)9.2f %(ic)9.2f\" % vars()\n                txtlst.append(tmptxt)\n\n            txtlst.append(\"\\nTHEVENIN IMPEDANCE (pu), X/R\")\n\n            z1str = self._frmted_z_xbyr(rlst.thevzpu[i].z1)\n            z1str =\"Z1: \" + z1str\n            if fltlg or fltllg or fltll:\n                z2str = self._frmted_z_xbyr(rlst.thevzpu[i].z2)\n                z2str =\"Z2: \" + z2str\n                z0str = "
  },
  {
    "id": "chunk_552",
    "text": "    z2str =\"Z2: \" + z2str\n                z0str = self._frmted_z_xbyr(rlst.thevzpu[i].z0)\n                z0str =\"Z0: \" + z0str\n                tmptxt=\"%(z1str)s    %(z2str)s    %(z0str)s\" % vars()\n            else:\n                tmptxt=\"%(z1str)s\" % vars()\n            txtlst.append(tmptxt)\n\n            if scunit_z!='pu':\n                txtlst.append(\"\\nTHEVENIN IMPEDANCE (ohms), X/R\")\n                z1str = self._frmted_z_xbyr(rlst.thevz[i].z1)\n                z1str =\"Z1: \" + z1str\n        "
  },
  {
    "id": "chunk_553",
    "text": "z1)\n                z1str =\"Z1: \" + z1str\n                if fltlg or fltllg or fltll:\n                    z2str = self._frmted_z_xbyr(rlst.thevz[i].z2)\n                    z2str =\"Z2: \" + z2str\n                    z0str = self._frmted_z_xbyr(rlst.thevz[i].z0)\n                    z0str =\"Z0: \" + z0str\n                    tmptxt=\"%(z1str)s    %(z2str)s    %(z0str)s\" % vars()\n                else:\n                    tmptxt=\"%(z1str)s\" % vars()\n                txtlst.append(tmptxt)\n\n            tm"
  },
  {
    "id": "chunk_554",
    "text": "             txtlst.append(tmptxt)\n\n            tmptxt=110*'-'\n            txtlst.append(tmptxt)\n            txtlst.append('')\n\n            txtall = \"\\n\".join(txtlst)\n            report(txtall)\n\n        # Maximum Fault Currents\n        inam = ['ia1', 'ia2', 'ia0', 'ia', 'ib', 'ic']\n        unitstr   = units.center(11)\n        unitstr = ''\n        for each in ['ia1', 'ia2', 'ia0', ' ia', ' ib', ' ic']:\n            t = each+'('+units+')'\n            t = ' ' + t.center(9) + ' '\n            unitstr "
  },
  {
    "id": "chunk_555",
    "text": "  t = ' ' + t.center(9) + ' '\n            unitstr += t\n\n        txtlst = []\n        txtlst.append('')\n\n        clnhdr    = \"   BUS  \" + unitstr + \"  Description\"\n        txtlst.append(\"BREAKER DUTY CURRENTS\")\n        txtlst.append(clnhdr)\n        txtall = \"\\n\".join(txtlst)\n        report(txtall)\n\n        for i in range(nfbus):\n            fbus   = rlst.fltbus[i]\n            ia1    = self._crnt_mag(scfmt,rlst.maxflt[i].ia1)\n            ia2    = self._crnt_mag(scfmt,rlst.maxflt[i].ia2)\n           "
  },
  {
    "id": "chunk_556",
    "text": "lf._crnt_mag(scfmt,rlst.maxflt[i].ia2)\n            ia0    = self._crnt_mag(scfmt,rlst.maxflt[i].ia0)\n            ia     = self._crnt_mag(scfmt,rlst.maxflt[i].ia)\n            ib     = self._crnt_mag(scfmt,rlst.maxflt[i].ib)\n            ic     = self._crnt_mag(scfmt,rlst.maxflt[i].ic)\n            dsc    = rlst.maxfltdsc[i]\n            if rptfile: report('\\n')\n            tmptxt = \"%(fbus)6d   %(ia1)9.2f  %(ia2)9.2f  %(ia0)9.2f  %(ia)9.2f  %(ib)9.2f  %(ic)9.2f   %(dsc)s\" % vars()\n            report"
  },
  {
    "id": "chunk_557",
    "text": "  %(ic)9.2f   %(dsc)s\" % vars()\n            report(tmptxt)\n\n        # ------------------------------------------------------------------------------------------------\n        if rptfile:\n            rptfile_h.close()\n            print('\\n Done .... ASCC FAULT Report saved to file %s' % rptfile)\n\n    # ------------------------------------------------------------------------------------\n    def excel_ascc_currents(self, rlst, faults_applied, xlsfile=''):\n        import psspy\n        import excelpy"
  },
  {
    "id": "chunk_558",
    "text": "e=''):\n        import psspy\n        import excelpy\n\n        if rlst.ierr: return\n\n        # bus data\n        sid  = -1   # consider subsystem of all buses\n        flag = 1    # consider only in-service buses\n        ierr,(busnums,)   = psspy.abusint(sid,flag,['NUMBER'])\n        ierr,(busbasevs,) = psspy.abusreal(sid,flag,'BASE')\n        ierr,(busvlt,)    = psspy.abuscplx(sid,flag,'VOLTAGE') # pre-fault bus voltages in pu\n        ierr,(busname,)   = psspy.abuschar(sid,flag,'NAME')\n\n        bus_da"
  },
  {
    "id": "chunk_559",
    "text": " = psspy.abuschar(sid,flag,'NAME')\n\n        bus_data = {}\n        for bnum, bbasev, bvlt, bnam in zip(busnums,busbasevs,busvlt,busname):\n            bus_data[bnum] = {'prefltv': bvlt, 'basekv': bbasev, 'name': bnam}\n\n        flt3ph = rlst.flt3ph\n        fltlg  = rlst.fltlg\n        fltllg = rlst.fltllg\n        fltll  = rlst.fltll\n\n        scunit   = rlst.scunit\n        scfmt    = rlst.scfmt\n        scunit_z = rlst.scunit_z\n        scfmt_z  = rlst.scfmt_z\n\n        nfbus=len(rlst.fltbus)\n\n        x"
  },
  {
    "id": "chunk_560",
    "text": "scfmt_z\n\n        nfbus=len(rlst.fltbus)\n\n        xlswbk = excelpy.workbook(xlsfile)\n        xlswbk.show()\n\n        savfile, snpfile = psspy.sfiles()\n        line1, line2 = psspy.titldt()\n\n        ttl      = r\"PSSE Short Circuit Calculations Using ASCC\"\n        ttl      = ttl + 5*' ' + time.ctime()\n        ttl_file = savfile\n        ttl_line1= line1.strip()\n        ttl_line2= line2.strip()\n\n        cln_mrglst = []\n        cln_heads_r1 = ['BUS', '', 'BASE', 'PREFLT']\n        cln_heads_r2 = ['NUMBE"
  },
  {
    "id": "chunk_561",
    "text": ", 'BASE', 'PREFLT']\n        cln_heads_r2 = ['NUMBER', 'NAME', 'kV', 'kV']\n        for fltok, clnnam in zip([flt3ph, fltlg, fltllg, fltll],\n                                 ['3-PH FAULT', 'LG FAULT', 'LLG FAULT', 'LL FAULT']):\n            if fltok:\n                cln_mrglst.append(len(cln_heads_r1)+1)\n                cln_heads_r1.extend([clnnam, ''])\n                cln_heads_r2.extend(['MVA', 'AMP'])\n\n        cln_heads_r1.extend(['THEVENIN IMPEDANCE (PU on 100 MVA and bus base KV)','', ''])\n   "
  },
  {
    "id": "chunk_562",
    "text": "ANCE (PU on 100 MVA and bus base KV)','', ''])\n        cln_heads_r2.extend(['Positive Sequence', 'Negative Sequence', 'Zero Sequence'])\n\n        colheads = [cln_heads_r1, cln_heads_r2]\n\n        row = 7\n        cln = 1\n\n        sbase = psspy.sysmva()\n\n        for i in range(nfbus):\n            rowdata = []\n            fbus    = rlst.fltbus[i]\n            basekv  = bus_data[fbus]['basekv']\n            prefltv = bus_data[fbus]['prefltv']\n\n            rowdata.append(fbus)\n            rowdata.append("
  },
  {
    "id": "chunk_563",
    "text": "  rowdata.append(fbus)\n            rowdata.append(bus_data[fbus]['name'])\n            rowdata.append(basekv)\n            rowdata.append(basekv*abs(prefltv))\n\n            if flt3ph:\n                cval = rlst.flt3ph[i].ia1   # Ifault=Ia1=Ia\n                crnt, mva = self._crnt_mva_mag(scfmt, scunit, cval, basekv, sbase)\n                rowdata.extend([mva, crnt])\n\n            if fltlg:\n                cval = rlst.fltlg[i].ia0    # Ifault=3*Ia0=Ia\n                crnt, mva = self._crnt_mva_mag("
  },
  {
    "id": "chunk_564",
    "text": "Ia\n                crnt, mva = self._crnt_mva_mag(scfmt, scunit, cval, basekv, sbase)\n                rowdata.extend([3*mva, 3*crnt])\n\n            if fltllg:\n                cval = rlst.fltllg[i].ia0   # Ifault=3*Ia0\n                crnt, mva = self._crnt_mva_mag(scfmt, scunit, cval, basekv, sbase)\n                rowdata.extend([3*mva, 3*crnt])\n\n            if fltll:\n                cval = rlst.fltll[i].ib   # Ifault=Ib\n                crnt, mva = self._crnt_mva_mag(scfmt, scunit, cval, basekv,"
  },
  {
    "id": "chunk_565",
    "text": " = self._crnt_mva_mag(scfmt, scunit, cval, basekv, sbase)\n                rowdata.extend([mva, crnt])\n\n            zpos  = rlst.thevzpu[i].z1\n            zneg  = rlst.thevzpu[i].z2\n            zzero = rlst.thevzpu[i].z0\n\n            s_zpos  = self._frmted_z(zpos)\n            s_zneg  = self._frmted_z(zneg)\n            s_zzero = self._frmted_z(zzero)\n\n            rowdata.extend([s_zpos, s_zneg, s_zzero])\n\n            brow,rcln = xlswbk.set_range(row,cln,rowdata)\n            row = brow + 1\n\n       "
  },
  {
    "id": "chunk_566",
    "text": "w,cln,rowdata)\n            row = brow + 1\n\n        xlswbk.font((6,3,brow,8),numberFormat=\"0.00\")\n        xlswbk.autofit_columns((6,9,brow,rcln))\n        xlswbk.align((6,9,brow,rcln),'right')\n\n        # headings and column titles\n        xlswbk.set_cell((1,1),ttl,fontStyle=\"Bold\",fontSize=12, fontColor=\"red\")\n        xlswbk.merge((1,1,1,rcln))\n\n        xlswbk.set_cell((2,1),ttl_file,fontStyle=\"Bold\",fontSize=10, fontColor=\"red\")\n        xlswbk.merge((2,1,2,rcln))\n\n        xlswbk.set_cell((3,1),tt"
  },
  {
    "id": "chunk_567",
    "text": "ge((2,1,2,rcln))\n\n        xlswbk.set_cell((3,1),ttl_line1,fontStyle=\"Bold\",fontSize=10, fontColor=\"red\")\n        xlswbk.merge((3,1,3,rcln))\n\n        xlswbk.set_cell((4,1),ttl_line2,fontStyle=\"Bold\",fontSize=10, fontColor=\"red\")\n        xlswbk.merge((4,1,4,rcln))\n\n        brow,rcln = xlswbk.set_range(5,1,colheads,fontSize=11, fontColor=\"blue\")\n\n        xlswbk.merge((5,1,5,2))\n        for cln in cln_mrglst:\n            xlswbk.merge((5,cln,5,cln+1))\n        xlswbk.merge((5,rcln-2,5,rcln))\n\n        "
  },
  {
    "id": "chunk_568",
    "text": "\n        xlswbk.merge((5,rcln-2,5,rcln))\n\n        xlswbk.align((1,1),'h_center')\n        xlswbk.align_rows((1,1,6,1),'h_center')\n\n        if xlsfile: xlswbk.save(xlsfile)\n\n# ========================================================================================\ndef run_ascc_3_savnw(**kwds):\n    import psspy\n    psspy.psseinit(buses=150000)\n\n    savfile = 'savnw.sav'\n    sid, allbus = 3, 0\n    buses = [153, 154]\n    rptfile = ''\n\n    ierr = psspy.case(savfile)\n    ierr = fault_bsys(sid, buses=bu"
  },
  {
    "id": "chunk_569",
    "text": ".case(savfile)\n    ierr = fault_bsys(sid, buses=buses)\n\n    nam_unt = {0:'pu', 1:'amp'}\n    unt=1\n\n    rptfile = \"z_savnw_ascc_3_{}_rpt{}_report.txt\".format(nam_unt[unt], kwds['rptop'])\n\n    set_prg_rpt(rptfile=rptfile)\n\n    # set short circuit options\n    psspy.short_circuit_units(unt)      # 0=PU, 1=Physical\n    psspy.short_circuit_coordinates(1)  # 0=rectangular, 1=polar\n    psspy.short_circuit_warning(0)      # 0= disable, printing of of RESQ/TRSQ/solution warnings\n\n    asccobj = ASCC_DEMO()"
  },
  {
    "id": "chunk_570",
    "text": "/TRSQ/solution warnings\n\n    asccobj = ASCC_DEMO()\n    asccobj.run_ascc_api(sid, allbus, **kwds)\n\n    reset_prg_rpt()\n\n# ========================================================================================\ndef run_ascc_currents_savnw_txtrpt(**kwds):\n    import psspy\n    psspy.psseinit(buses=150000)\n\n    savfile = 'savnw.sav'\n    sid, allbus = 3, 0\n    buses = [153, 154]\n\n    nam_unt = {0:'pu', 1:'amp'}\n    unt=1\n\n    rptfile = \"z_savnw_ascc_currents_{}.txt\".format(nam_unt[unt])\n\n    ierr = p"
  },
  {
    "id": "chunk_571",
    "text": "urrents_{}.txt\".format(nam_unt[unt])\n\n    ierr = psspy.case(savfile)\n    ierr = fault_bsys(sid, buses=buses)\n\n    # set short circuit options\n    psspy.short_circuit_units(unt)      # 0=PU, 1=Physical\n    psspy.short_circuit_coordinates(1)  # 0=rectangular, 1=polar\n    psspy.short_circuit_warning(0)      # 0= disable, printing of of RESQ/TRSQ/solution warnings\n\n    asccobj = ASCC_DEMO()\n    rlst = asccobj.run_ascc_currents(sid, allbus, **kwds)\n    asccobj.report_ascc_currents(rlst, rptfile)\n\n# ="
  },
  {
    "id": "chunk_572",
    "text": "  asccobj.report_ascc_currents(rlst, rptfile)\n\n# ========================================================================================\ndef run_ascc_currents_savnw_xls(**kwds):\n    import psspy\n    psspy.psseinit(buses=150000)\n\n    savfile = 'savnw.sav'\n    sid, allbus = 3, 0\n    buses = [153, 154]\n\n    nam_unt = {0:'pu', 1:'amp'}\n    unt=1\n\n    xlsfile = \"z_savnw_ascc_currents_{}\".format(nam_unt[unt])\n\n    ierr = psspy.case(savfile)\n    ierr = fault_bsys(sid, buses=buses)\n\n    # set short cir"
  },
  {
    "id": "chunk_573",
    "text": " fault_bsys(sid, buses=buses)\n\n    # set short circuit options\n    psspy.short_circuit_units(unt)      # 0=PU, 1=Physical\n    psspy.short_circuit_coordinates(1)  # 0=rectangular, 1=polar\n    psspy.short_circuit_warning(0)      # 0= disable, printing of of RESQ/TRSQ/solution warnings\n\n    asccobj = ASCC_DEMO()\n    rlst = asccobj.run_ascc_currents(sid, allbus, **kwds)\n    asccobj.excel_ascc_currents(rlst, xlsfile)\n\n# ================================================================================="
  },
  {
    "id": "chunk_574",
    "text": "=========================================================\ndef run_fault_summary_ascc_savnw(**kwds):\n    import psspy\n    psspy.psseinit(buses=150000)\n\n    savfile = 'savnw.sav'\n    sid, allbus = 3, 0\n    buses = [153, 154]\n\n    nam_unt = {0:'pu', 1:'amp'}\n    unt=1\n\n    rptfile = \"z_savnw_ascc_fault_summary_{}.txt\".format(nam_unt[unt])\n\n    ierr = psspy.case(savfile)\n    ierr = fault_bsys(sid, buses=buses)\n\n    # set short circuit options\n    psspy.short_circuit_units(unt)      # 0=PU, 1=Physica"
  },
  {
    "id": "chunk_575",
    "text": "py.short_circuit_units(unt)      # 0=PU, 1=Physical\n    psspy.short_circuit_coordinates(1)  # 0=rectangular, 1=polar\n    psspy.short_circuit_warning(0)      # 0= disable, printing of of RESQ/TRSQ/solution warnings\n\n    asccobj = ASCC_DEMO()\n    fltobj = asccobj.run_fault_summary(sid, allbus, **kwds)\n    fltobj.text_report(rptfile)\n\n# ========================================================================================\ndef _temp():\n    # Run either of these functions under  __main__ to see how"
  },
  {
    "id": "chunk_576",
    "text": "ther of these functions under  __main__ to see how they work.\n    run_ascc_3_savnw(flt3ph=1, fltlg=1, fltllg=1, fltll=1, rptop=1)\n\n    run_ascc_currents_savnw_txtrpt(flt3ph=1, fltlg=1, fltllg=1, fltll=1)\n    run_ascc_currents_savnw_xls(flt3ph=1, fltlg=1, fltllg=1, fltll=1)\n\n    run_fault_summary_ascc_savnw(flt3ph=1, fltlg=1, fltllg=1, fltll=1)\n    run_fault_summary_ascc_savnw(flt3ph=1, fltlg=1, fltllg=0, fltll=1, rptop=0, linout=1, linend=1)\n\n# ==================================================="
  },
  {
    "id": "chunk_577",
    "text": "=======================================================================================\nif __name__=='__main__':\n    pass\n    import psse35\n#[ascc_report.py]    Get ASCC fault currents in arrays and create custom report\n# =====================================================================================================\n'''\nThis is an example file showing how to use \"ascc_currents\" function from pssarrays module.\n\nASCC_CURRENTS function returns ASCC short circuit currents for each faulted bus "
  },
  {
    "id": "chunk_578",
    "text": " ASCC short circuit currents for each faulted bus and\neach type of fault applied. They are:\n    ia1   = Positive Sequence Current\n    ia2   = Negative Sequence Current\n    ia0   = Zero Sequence Current\n    ia    = Phase A current\n    ib    = Phase B current\n    ic    = Phase C current\n\nThe APIs used in this program are part of python \"pssarrays\" module.\n\n---------------------------------------------------------------------------------\nHow to use this file?\n\nAs showed in __main__ (end of this fil"
  },
  {
    "id": "chunk_579",
    "text": "this file?\n\nAs showed in __main__ (end of this file)\n- Enable PSSE version specific environment, as an example:\n    import psse35\n\n- call function\n    run_ascc_report()\n\n    You may want to change inputs specified in this function.\n    run_ascc_report(savfile, fltbuses, rptfile)\n    Defaults:\n        savfile  = 'savnw.sav'\n        fltbuses = [151,154]\n        rptfile  = 'ascc_report_savnw.txt'\n                   When this script is called from PSSE's Example Folder,\n                   report is "
  },
  {
    "id": "chunk_580",
    "text": "SE's Example Folder,\n                   report is created in subfolder 'Output_Pyscript'\n'''\n\n# =====================================================================================================\n\nimport os, time, math\n\n# =====================================================================================================\n\ndef encode_complex_number_xbyr(cnum):\n    r=cnum.real\n    x=cnum.imag\n    csign='+j'\n    if x<0:\n        csign='-j'\n        x=abs(x)\n\n    if r==0:\n        rstr=''\n        xb"
  },
  {
    "id": "chunk_581",
    "text": " x=abs(x)\n\n    if r==0:\n        rstr=''\n        xbyr=''\n    else:\n        rstr=\"%9.6f\" % r\n        xbyr=\"%9.6f\" % (x/r)\n\n    if x==0:\n        xstr=''\n        csign=''\n    else:\n        xstr=\"%9.6f\" % x\n\n    cstr=\"%(rstr)s%(csign)s%(xstr)s, %(xbyr)s\" % vars()\n\n    return cstr\n\n# =====================================================================================================\n\ndef get_cplx_mag(fmt, cmplxvalue):\n    if fmt == 'rectangular':\n        return abs(cmplxvalue)\n    else:\n        retur"
  },
  {
    "id": "chunk_582",
    "text": "    return abs(cmplxvalue)\n    else:\n        return cmplxvalue.real\n\n# =====================================================================================================\n\ndef create_report(fltbuses,flt3ph,fltlg,fltllg,fltll,linout,linend,voltop,genxop,\n                  tpunty,dcload,zcorec,lnchrg,shntop,loadop,machpq,volts,\n                  savfile,relfile,fcdfile,scfile,rptfile,rprtyp,rprlvl):\n\n    import psspy, arrbox.ascc\n\n    # open case\n    if savfile: psspy.case(savfile)\n\n    # Save p"
  },
  {
    "id": "chunk_583",
    "text": "\n    if savfile: psspy.case(savfile)\n\n    # Save pre-fault voltages\n    sid  = -1\n    flag = 2\n    ierr, (buslst,)           = psspy.abusint(sid,  flag, ['NUMBER'])\n    ierr, (busvltlst_preflt,) = psspy.abuscplx(sid, flag, ['VOLTAGE'])\n    ierr, (busvltlst_base,)   = psspy.abusreal(sid, flag, ['BASE'])\n    busdata_dict = {}\n    for n, vpf, vnm in zip(buslst, busvltlst_preflt, busvltlst_base):\n        busdata_dict[n] = {'prefltv': vpf, 'basekv': vnm}\n\n    # set sc units and format\n    psspy.short"
  },
  {
    "id": "chunk_584",
    "text": "nm}\n\n    # set sc units and format\n    psspy.short_circuit_units(1)         # 0=PU, 1=Physical\n    psspy.short_circuit_coordinates(0)   # 0=rectangular, 1=polar\n\n    sid = 3\n    if fltbuses:\n        psspy.bsys(sid,0,[0.0,0.0],0,[],len(fltbuses),fltbuses,0,[],0,[])\n        busall = 0\n    else:\n        busall = 1\n\n    # call pssarrays routine\n    rlst = arrbox.ascc.ascc_currents(sid, busall, flt3ph=flt3ph, fltlg=fltlg, fltllg=fltllg,\n           fltll=fltll, linout=linout, linend=linend, voltop=vol"
  },
  {
    "id": "chunk_585",
    "text": "ll=fltll, linout=linout, linend=linend, voltop=voltop, genxop=genxop, tpunty=tpunty,\n           dcload=dcload, zcorec= zcorec, lnchrg=lnchrg, shntop=shntop, loadop=loadop, machpq=machpq,\n           volts=volts, relfile=relfile, fcdfile=fcdfile, scfile=scfile, rprtyp=rprtyp, rprlvl=rprlvl)\n\n    if rlst.ierr!=0:\n        raise Exception(\"arrbox.ascc.ascc_currents error= %d\\n\" % rlst.ierr)\n\n    if rptfile:\n        p, nx = os.path.split(rptfile)\n        n, x = os.path.splitext(nx)\n        if not x:\n "
  },
  {
    "id": "chunk_586",
    "text": "   n, x = os.path.splitext(nx)\n        if not x:\n            x = '.txt'\n            nx = n + x\n        if p:\n            rptfile = os.path.join(p, nx)\n        else:\n            rptfile = os.path.join(os.getcwd(), nx)\n        rptfile_h = open(rptfile,'w')\n        report    = rptfile_h.write\n    else:\n        psspy.beginreport()\n        report = psspy.report\n\n    nfbus=len(rlst.fltbus)\n\n    ttlstr=\"PSS(R)E ASCC SHORT CIRCUIT CURRENTS\" + 10*' ' + time.ctime()\n    ln1str,ln2str=psspy.titldt()\n    ma"
  },
  {
    "id": "chunk_587",
    "text": "me.ctime()\n    ln1str,ln2str=psspy.titldt()\n    maxlen=max(len(ttlstr),len(ln1str),len(ln2str))\n    report(ttlstr.center(maxlen))\n    report(\"\\n\")\n    report(ln1str.center(maxlen))\n    report(\"\\n\")\n    report(ln2str.center(maxlen))\n    report(\"\\n\\n\")\n\n    sbase  = psspy.sysmva()\n\n    scunit = rlst.scunit\n    scfmt  = rlst.scfmt\n\n    if scunit == 'pu':\n        units = 'PU'\n    else:\n        units = 'AMP'\n    unitstr   = units.center(10)\n    clnhdr    = \"   BUS     \" + 6*unitstr + \"\\n\"\n\n    for i "
  },
  {
    "id": "chunk_588",
    "text": "    = \"   BUS     \" + 6*unitstr + \"\\n\"\n\n    for i in range(nfbus):\n        report(\"           <-SCMVA-> <--ia1--> <--ia2--> <--ia0--> <--ia---> <--ib---> <--ic--->\\n\")\n        report(clnhdr)\n        fbus   = rlst.fltbus[i]\n        basekv = busdata_dict[fbus]['basekv']\n        baseamp = (1000.0 * sbase) / (math.sqrt(3.0) * basekv)\n\n        if flt3ph:\n            ttxt   = \"%6d\" % fbus\n            spc    = '3PH'\n\n            ia1    = get_cplx_mag(scfmt,rlst.flt3ph[i].ia1)\n            ia2    = get_c"
  },
  {
    "id": "chunk_589",
    "text": "fmt,rlst.flt3ph[i].ia1)\n            ia2    = get_cplx_mag(scfmt,rlst.flt3ph[i].ia2)\n            ia0    = get_cplx_mag(scfmt,rlst.flt3ph[i].ia0)\n            ia     = get_cplx_mag(scfmt,rlst.flt3ph[i].ia)\n            ib     = get_cplx_mag(scfmt,rlst.flt3ph[i].ib)\n            ic     = get_cplx_mag(scfmt,rlst.flt3ph[i].ic)\n\n            scmva  = math.sqrt(3.0) * basekv * rlst.flt3ph[i].ia1 / 1000.0\n            if scunit == 'pu': scmva = scmva*baseamp\n            scmva  = get_cplx_mag(scfmt,scmva)\n\n  "
  },
  {
    "id": "chunk_590",
    "text": "            scmva  = get_cplx_mag(scfmt,scmva)\n\n            tmptxt = \"%(ttxt)s %(spc)s %(scmva)9.2f %(ia1)9.2f %(ia2)9.2f %(ia0)9.2f %(ia)9.2f %(ib)9.2f %(ic)9.2f \\n\" % vars()\n            report(tmptxt)\n\n        if fltlg:\n            if flt3ph:\n                ttxt = 6*' '\n            else:\n                ttxt = \"%6d\" % fbus\n            spc    = ' LG'\n            ia1    = get_cplx_mag(scfmt,rlst.fltlg[i].ia1)\n            ia2    = get_cplx_mag(scfmt,rlst.fltlg[i].ia2)\n            ia0    = get_cp"
  },
  {
    "id": "chunk_591",
    "text": "fmt,rlst.fltlg[i].ia2)\n            ia0    = get_cplx_mag(scfmt,3*rlst.fltlg[i].ia0)\n            ia     = get_cplx_mag(scfmt,rlst.fltlg[i].ia)\n            ib     = get_cplx_mag(scfmt,rlst.fltlg[i].ib)\n            ic     = get_cplx_mag(scfmt,rlst.fltlg[i].ic)\n\n            scmva  = math.sqrt(3.0) * basekv * 3 * rlst.fltlg[i].ia0 / 1000.0\n            if scunit == 'pu': scmva = scmva*baseamp\n            scmva  = get_cplx_mag(scfmt,scmva)\n\n            tmptxt = \"%(ttxt)s %(spc)s %(scmva)9.2f %(ia1)9.2f"
  },
  {
    "id": "chunk_592",
    "text": "tmptxt = \"%(ttxt)s %(spc)s %(scmva)9.2f %(ia1)9.2f %(ia2)9.2f %(ia0)9.2f %(ia)9.2f %(ib)9.2f %(ic)9.2f \\n\" % vars()\n            report(tmptxt)\n\n        if fltllg:\n            if flt3ph or fltlg:\n                ttxt = 6*' '\n            else:\n                ttxt = \"%6d\" % fbus\n            spc    = 'LLG'\n            ia1    = get_cplx_mag(scfmt,rlst.fltllg[i].ia1)\n            ia2    = get_cplx_mag(scfmt,rlst.fltllg[i].ia2)\n            ia0    = get_cplx_mag(scfmt,3*rlst.fltllg[i].ia0)\n            i"
  },
  {
    "id": "chunk_593",
    "text": "cplx_mag(scfmt,3*rlst.fltllg[i].ia0)\n            ia     = get_cplx_mag(scfmt,rlst.fltllg[i].ia)\n            ib     = get_cplx_mag(scfmt,rlst.fltllg[i].ib)\n            ic     = get_cplx_mag(scfmt,rlst.fltllg[i].ic)\n\n            scmva  = math.sqrt(3.0) * basekv * 3 * rlst.fltllg[i].ia0 / 1000.0\n            if scunit == 'pu': scmva = scmva*baseamp\n            scmva  = get_cplx_mag(scfmt,scmva)\n\n            tmptxt = \"%(ttxt)s %(spc)s %(scmva)9.2f %(ia1)9.2f %(ia2)9.2f %(ia0)9.2f %(ia)9.2f %(ib)9.2f "
  },
  {
    "id": "chunk_594",
    "text": "a1)9.2f %(ia2)9.2f %(ia0)9.2f %(ia)9.2f %(ib)9.2f %(ic)9.2f \\n\" % vars()\n            report(tmptxt)\n\n        if fltll:\n            if flt3ph or fltlg or fltllg:\n                ttxt = 6*' '\n            else:\n                ttxt = \"%6d\" % fbus\n            spc     = ' LL'\n            ia1    = get_cplx_mag(scfmt,rlst.fltll[i].ia1)\n            ia2    = get_cplx_mag(scfmt,rlst.fltll[i].ia2)\n            ia0    = get_cplx_mag(scfmt,rlst.fltll[i].ia0)\n            ia     = get_cplx_mag(scfmt,rlst.fltll["
  },
  {
    "id": "chunk_595",
    "text": "           ia     = get_cplx_mag(scfmt,rlst.fltll[i].ia)\n            ib     = get_cplx_mag(scfmt,rlst.fltll[i].ib)\n            ic     = get_cplx_mag(scfmt,rlst.fltll[i].ic)\n\n            scmva  = math.sqrt(3.0) * basekv * rlst.fltll[i].ib / 1000.0\n            if scunit == 'pu': scmva = scmva*baseamp\n            scmva  = get_cplx_mag(scfmt,scmva)\n\n            tmptxt = \"%(ttxt)s %(spc)s %(scmva)9.2f %(ia1)9.2f %(ia2)9.2f %(ia0)9.2f %(ia)9.2f %(ib)9.2f %(ic)9.2f \\n\" % vars()\n            report(tmptx"
  },
  {
    "id": "chunk_596",
    "text": "2f %(ic)9.2f \\n\" % vars()\n            report(tmptxt)\n\n        report(\"\\nTHEVENIN IMPEDANCE (pu), X/R\\n\")\n        z1str = encode_complex_number_xbyr(rlst.thevzpu[i].z1)\n        z1str =\"Z1: \" + z1str\n        if fltlg or fltllg or fltll:\n            z2str = encode_complex_number_xbyr(rlst.thevzpu[i].z2)\n            z2str =\"Z2: \" + z2str\n            z0str = encode_complex_number_xbyr(rlst.thevzpu[i].z0)\n            z0str =\"Z0: \" + z0str\n            tmptxt=\"%(z1str)s    %(z2str)s    %(z0str)s\\n\" % va"
  },
  {
    "id": "chunk_597",
    "text": "mptxt=\"%(z1str)s    %(z2str)s    %(z0str)s\\n\" % vars()\n        else:\n            tmptxt=\"%(z1str)s\\n\" % vars()\n        report(tmptxt)\n\n        if scunit != 'pu':\n            report(\"\\nTHEVENIN IMPEDANCE (ohms), X/R\\n\")\n            z1str = encode_complex_number_xbyr(rlst.thevz[i].z1)\n            z1str =\"Z1: \" + z1str\n            if fltlg or fltllg or fltll:\n                z2str = encode_complex_number_xbyr(rlst.thevz[i].z2)\n                z2str =\"Z2: \" + z2str\n                z0str = encode_com"
  },
  {
    "id": "chunk_598",
    "text": "=\"Z2: \" + z2str\n                z0str = encode_complex_number_xbyr(rlst.thevz[i].z0)\n                z0str =\"Z0: \" + z0str\n                tmptxt=\"%(z1str)s    %(z2str)s    %(z0str)s\\n\" % vars()\n            else:\n                tmptxt=\"%(z1str)s\\n\" % vars()\n            report(tmptxt)\n\n        tmptxt=110*'-'\n        report(tmptxt)\n        report(\"\\n\")\n\n    # Maximum Fault Currents\n    inam = ['ia1', 'ia2', 'ia0', 'ia', 'ib', 'ic']\n    unitstr   = units.center(11)\n    unitstr = ''\n    for each in"
  },
  {
    "id": "chunk_599",
    "text": " units.center(11)\n    unitstr = ''\n    for each in ['ia1', 'ia2', 'ia0', ' ia', ' ib', ' ic']:\n        t = each+'('+units+')'\n        t = ' ' + t.center(9) + ' '\n        unitstr += t\n\n    clnhdr    = \"   BUS  \" + unitstr + \"  Description\\n\"\n    report(\"\\nBREAKER DUTY CURRENTS\\n\")\n    report(clnhdr)\n    for i in range(nfbus):\n        fbus   = rlst.fltbus[i]\n        ia1    = get_cplx_mag(scfmt,rlst.maxflt[i].ia1)\n        ia2    = get_cplx_mag(scfmt,rlst.maxflt[i].ia2)\n        ia0    = get_cplx_mag"
  },
  {
    "id": "chunk_600",
    "text": ",rlst.maxflt[i].ia2)\n        ia0    = get_cplx_mag(scfmt,rlst.maxflt[i].ia0)\n        ia     = get_cplx_mag(scfmt,rlst.maxflt[i].ia)\n        ib     = get_cplx_mag(scfmt,rlst.maxflt[i].ib)\n        ic     = get_cplx_mag(scfmt,rlst.maxflt[i].ic)\n        dsc    = rlst.maxfltdsc[i]\n        tmptxt = \"%(fbus)6d   %(ia1)9.2f  %(ia2)9.2f  %(ia0)9.2f  %(ia)9.2f  %(ib)9.2f  %(ic)9.2f   %(dsc)s\\n\" % vars()\n        report(tmptxt)\n\n    # -------------------------------------------------------------------------"
  },
  {
    "id": "chunk_601",
    "text": "-------------------------------------------------------------------------\n    if rptfile:\n        rptfile_h.close()\n        print('\\n Done .... ASCC FAULT Report saved to file %s' % rptfile)\n    else:\n        print('\\n Done .... ASCC FAULT Report created in Report window.')\n\n# =====================================================================================================\n\ndef check_psse_example_folder(rptfile):\n    # if called from PSSE's Example Folder, create report in subfolder 'Output_"
  },
  {
    "id": "chunk_602",
    "text": "xample Folder, create report in subfolder 'Output_Pyscript'\n    rptpath, rptfnam = os.path.split(rptfile)\n    if not rptpath:\n        rptpath = os.getcwd()\n        cwd = rptpath.lower()\n        i = cwd.find('pti')\n        j = cwd.find('psse')\n        k = cwd.find('example')\n        if i>0 and j>i and k>j:     # called from Example folder\n            outdir = os.path.join(os.getcwd(), 'Output_Pyscript')\n            if not os.path.exists(outdir): os.mkdir(outdir)\n        else:\n            outdir ="
  },
  {
    "id": "chunk_603",
    "text": "s.mkdir(outdir)\n        else:\n            outdir = os.getcwd()\n        rptfile  = os.path.join(outdir, rptfnam)\n\n    return rptfile\n\n# =====================================================================================================\n\ndef run_ascc_report(savfile=\"savnw.sav\", fltbuses=[151,154], rptfile='ascc_report_savnw.txt'):\n\n    import psspy\n\n    psspy.psseinit()\n\n    # Inputs, change as required\n\n    flt3ph  = 1       #\n    fltlg   = 1       #\n    fltllg  = 1       #\n    fltll   = 1     "
  },
  {
    "id": "chunk_604",
    "text": "    #\n    fltllg  = 1       #\n    fltll   = 1       #\n    linout  = 0       #\n    linend  = 0       #\n    voltop  = 0       #\n    genxop  = 0       #\n    tpunty  = 0       #\n    dcload  = 1       #\n    zcorec  = 1       #\n    lnchrg  = 0       #\n    shntop  = 0       #\n    loadop  = 0       #\n    machpq  = 0       #\n\n    volts   = 1.0     #\n\n    rptfile = check_psse_example_folder(rptfile)\n\n    relfile = \"\"\n    fcdfile = \"\"\n    scfile  = \"\"\n\n    rprtyp  = -1      # no report\n    rprlvl  = 0     "
  },
  {
    "id": "chunk_605",
    "text": "rprtyp  = -1      # no report\n    rprlvl  = 0       # number of contribution levels\n\n    create_report(fltbuses,flt3ph,fltlg,fltllg,fltll,linout,linend,voltop,genxop,\n                  tpunty,dcload,zcorec,lnchrg,shntop,loadop,machpq,volts,\n                  savfile,relfile,fcdfile,scfile,rptfile,rprtyp,rprlvl)\n\n# ====================================================================================================\nif __name__ == '__main__':\n\n    import psse35\n    run_ascc_report()\n\n# ============"
  },
  {
    "id": "chunk_606",
    "text": "mport psse35\n    run_ascc_report()\n\n# ====================================================================================================\nimport os\nimport string\nfrom math import sqrt\n\n# ----------------------------------------------------------------------------------------------------\ndef isfloat(str):\n    \"\"\"Checks if the string is a floating point number.\"\"\"\n\n    try:\n        float(str)\n        return True\t\t\t#Returns true if the string is a floating point number\n    except (ValueError, Type"
  },
  {
    "id": "chunk_607",
    "text": "floating point number\n    except (ValueError, TypeError) as e:\n        return False\t\t\t#Returns false otherwise\n\n# ----------------------------------------------------------------------------------------------------\ndef isint(str):\n    \"\"\"Checks if the string is an integer.\"\"\"\n\n    try:\n        int(str)\n        return True\t\t\t#Returns true if the string is an integer\n    except (ValueError, TypeError) as e:\n        return False\t\t\t#Returns false otherwise\n\n# ----------------------------------------"
  },
  {
    "id": "chunk_608",
    "text": "erwise\n\n# ----------------------------------------------------------------------------------------------------\ndef OpenFile():\n    \"\"\"Opens the BPA file specified in prompt.\"\"\"\n\n    psspy.prompt(\"Enter the BPA file path, followed by its name:\\n\")\n    ierr, fnamestr = psspy.userin()\t\t#User types in the path name\n\n    if ierr != 0: return\n\n    fpath, fext = os.path.splitext(fnamestr)\n    if not fext: fnamestr = fpath + '.dat'\t#To add the extension if left blank\n\n    if os.path.isfile(fnamestr) == "
  },
  {
    "id": "chunk_609",
    "text": "if left blank\n\n    if os.path.isfile(fnamestr) == False:\n        psspy.alert(\"The specified path or file name is invalid\\n\")\n        return\n\n    bpa_file = open(fnamestr, 'r')\t\t#Opens the file in read mode\n\n    return bpa_file\n\n# ----------------------------------------------------------------------------------------------------\ndef GetMVA(bpa_file, bpa_str):\n    \"\"\"Gets the base MVA in the BPA file.\"\"\"\n\n    pos = string.find(bpa_str, \"MVA_BASE\")\n\n    if pos != -1:\n        bpa_file.seek(pos)\n   "
  },
  {
    "id": "chunk_610",
    "text": "\n\n    if pos != -1:\n        bpa_file.seek(pos)\n        bpa_file.readline()\t\t\t#Just to position on to the next line\n        mva_base_str = bpa_file.readline()\n        mva_base_str = mva_base_str.replace(' ', '')\t#To delete any spaces\n        mva_base_str = mva_base_str.strip()\t#To remove trailing and leading whitespaces\n        mva_base_str = mva_base_str[10:]\t#To remove the \"/MVA_BASE=\" part\n        basemva = float(mva_base_str[:-1])\n\n    else:\n        basemva = 100.0\t\t\t\t#The default base MVA in"
  },
  {
    "id": "chunk_611",
    "text": "       basemva = 100.0\t\t\t\t#The default base MVA in BPA is 100 MVA\n\n    return basemva\n\n# ----------------------------------------------------------------------------------------------------\ndef GetTitles(bpa_file, bpa_str):\n    \"\"\"Gets the titles from the BPA file.\"\"\"\n\n    pos = string.find(bpa_str, \"CASEID\")\t#To find title1\n\n    if pos != -1:\n        bpa_file.seek(pos)\n        title_data = bpa_file.readline()\n        pos1 = string.find(title_data, '=')\n        pos2 = string.find(title_data, ','"
  },
  {
    "id": "chunk_612",
    "text": "a, '=')\n        pos2 = string.find(title_data, ',')\n        case_id = title_data[pos1 + 1 : pos2]\n        case_id = case_id.strip()\t\t#To remove trailing and leading whitespaces\n\n    else:\n        case_id = \"\"\t\t\t\t#Title1 is blank by default\n\n\n    pos = string.find(bpa_str, \"PROJECT\")\t#To find title2\n\n    if pos != -1:\n        bpa_file.seek(pos)\n        title_data = bpa_file.readline()\n        pos1 = string.find(title_data, '=')\n        pos2 = string.find(title_data, ',')\t\n        if pos2 == -1:\t\t"
  },
  {
    "id": "chunk_613",
    "text": "ng.find(title_data, ',')\t\n        if pos2 == -1:\t\t\t\t#If there are no other parameters, the line finishes with ')'\n            pos2 = string.find(title_data, ')')\n\n        project_id = title_data[pos1 + 1 : pos2]\n        project_id = project_id.strip()\t\t#To remove trailing and leading whitespaces\n\n    else:\n        project_id = \"\"\t\t\t\t#Title2 is blank by default\n\n    return case_id, project_id\n\n# ----------------------------------------------------------------------------------------------------\nd"
  },
  {
    "id": "chunk_614",
    "text": "------------------------------------------------\ndef GetPCard(bpa_str_ar):\n    \"\"\"Gets the scale data from the BPA file.\"\"\"\n\n    scale_str = []\n\n    for line in bpa_str_ar:\t\t\t#Loop over every line of the BPA file\n        line = line.lstrip()\n        line = line.rstrip('\\n')\n        if line == \"\": continue\t\t\t#To continue if it is a blank line\n\n        if line[0] == 'P' and line[2] == ' ':\t#If the line is a P card\n            line = line + ' '*(80-len(line))\t#To pad each line with spaces up to 80 "
  },
  {
    "id": "chunk_615",
    "text": "len(line))\t#To pad each line with spaces up to 80 records\n            scale_str.append(line)\n\n    return scale_str\t\t\t\t#Returns an array of P cards\n\n# ----------------------------------------------------------------------------------------------------\ndef GetScaleData(scale_str, owner_name, zone_name, type_code):\n    \"\"\"Gets the scale factors for each load and generator.\"\"\"\n\n    scale_ar = [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\t\t#Default factors are unit factors\n\n    for line in scale_str:\t\t\t\t\t"
  },
  {
    "id": "chunk_616",
    "text": " are unit factors\n\n    for line in scale_str:\t\t\t\t\t#For each P card\n        if line[1] == 'O' and line[3:6].strip() == owner_name:\n            if zone_name == line[34:36].strip() or zone_name == line[37:39].strip() or zone_name == line[40:42].strip() or zone_name == line[43:45].strip()\\\n            or zone_name == line[46:48].strip() or zone_name == line[49:51].strip() or zone_name == line[52:54].strip() or zone_name == line[55:57].strip()\\\n            or zone_name == line[58:60].strip() or zone_"
  },
  {
    "id": "chunk_617",
    "text": "      or zone_name == line[58:60].strip() or zone_name == line[61:63].strip() or zone_name == line[64:66].strip() or zone_name == line[67:69].strip()\\\n            or zone_name == line[70:72].strip() or zone_name == line[73:75].strip() or zone_name == line[76:78].strip() or line[34:80].strip() == \"\":\n\n                if isfloat(line[9:14]): scale_ar[0] = scale_ar[0] * float(line[9:14])\t\t#Load P factor\n                if isfloat(line[15:20]): scale_ar[1] = scale_ar[1] * float(line[15:20])\t\t#Load Q"
  },
  {
    "id": "chunk_618",
    "text": "_ar[1] = scale_ar[1] * float(line[15:20])\t\t#Load Q factor\n                elif isfloat(line[9:14]): scale_ar[1] = scale_ar[1] * float(line[9:14])\t\t#Load Q factor is load P factor\n\n                if isfloat(line[21:26]): scale_ar[6] = scale_ar[6] * float(line[21:26])\t\t#Generation P factor\n                if isfloat(line[27:32]): scale_ar[7] = scale_ar[7] * float(line[27:32])\t\t#Generation Q factor\n                elif isfloat(line[21:26]): scale_ar[7] = scale_ar[7] * float(line[21:26])\t#Generatio"
  },
  {
    "id": "chunk_619",
    "text": "r[7] = scale_ar[7] * float(line[21:26])\t#Generation Q factor is generation P factor\n\n        elif line[1] == 'Z' and line[3:5].strip() == zone_name or line[1] == 'N' and line[3:5].strip() == zone_name and type_code == 'N':\n            if owner_name == line[34:37].strip() or owner_name == line[38:41].strip() or owner_name == line[42:45].strip() or owner_name == line[46:49].strip()\\\n            or owner_name == line[50:53].strip() or owner_name == line[54:57].strip() or owner_name == line[58:61].s"
  },
  {
    "id": "chunk_620",
    "text": "line[54:57].strip() or owner_name == line[58:61].strip() or owner_name == line[62:65].strip()\\\n            or owner_name == line[66:69].strip() or owner_name == line[70:73].strip() or owner_name == line[74:77].strip() or line[34:80].strip() == \"\":\n\n                if isfloat(line[9:14]): scale_ar[0] = scale_ar[0] * float(line[9:14])\t\t#Load P factor\n                if isfloat(line[15:20]): scale_ar[1] = scale_ar[1] * float(line[15:20])\t\t#Load Q factor\n                elif isfloat(line[9:14]): sca"
  },
  {
    "id": "chunk_621",
    "text": "ctor\n                elif isfloat(line[9:14]): scale_ar[1] = scale_ar[1] * float(line[9:14])\t\t#Load Q factor is load P factor\n\n                if isfloat(line[21:26]): scale_ar[6] = scale_ar[6] * float(line[21:26])\t\t#Generation P factor\n                if isfloat(line[27:32]): scale_ar[7] = scale_ar[7] * float(line[27:32])\t\t#Generation Q factor\n                elif isfloat(line[21:26]): scale_ar[7] = scale_ar[7] * float(line[21:26])\t#Generation Q factor is generation P factor\n\n        elif line["
  },
  {
    "id": "chunk_622",
    "text": " factor is generation P factor\n\n        elif line[1] == 'A':\n            if isfloat(line[9:14]): scale_ar[0] = scale_ar[0] * float(line[9:14])\t\t#Load P factor\n            if isfloat(line[15:20]): scale_ar[1] = scale_ar[1] * float(line[15:20])\t\t#Load Q factor\n            elif isfloat(line[9:14]): scale_ar[1] = scale_ar[1] * float(line[9:14])\t\t#Load Q factor is load P factor\n\n            if isfloat(line[21:26]): scale_ar[6] = scale_ar[6] * float(line[21:26])\t\t#Generation P factor\n            if is"
  },
  {
    "id": "chunk_623",
    "text": "ne[21:26])\t\t#Generation P factor\n            if isfloat(line[27:32]): scale_ar[7] = scale_ar[7] * float(line[27:32])\t\t#Generation Q factor\n            elif isfloat(line[21:26]): scale_ar[7] = scale_ar[7] * float(line[21:26])\t\t#Generation Q factor is generation P factor\n\n        elif line[1] == 'B' and type_code == 'X' and line[3:6].strip() == owner_name:\n            if zone_name == line[34:36].strip() or zone_name == line[37:39].strip() or zone_name == line[40:42].strip() or zone_name == line[43"
  },
  {
    "id": "chunk_624",
    "text": "ame == line[40:42].strip() or zone_name == line[43:45].strip()\\\n            or zone_name == line[46:48].strip() or zone_name == line[49:51].strip() or zone_name == line[52:54].strip() or zone_name == line[55:57].strip()\\\n            or zone_name == line[58:60].strip() or zone_name == line[61:63].strip() or zone_name == line[64:66].strip() or zone_name == line[67:69].strip()\\\n            or zone_name == line[70:72].strip() or zone_name == line[73:75].strip() or zone_name == line[76:78].strip() or"
  },
  {
    "id": "chunk_625",
    "text": "75].strip() or zone_name == line[76:78].strip() or line[34:80].strip() == \"\":\n\n                if isfloat(line[9:14]): scale_ar[2] = scale_ar[2] * float(line[9:14])\t\t#Constant current load P factor\n                if isfloat(line[15:20]): scale_ar[3] = scale_ar[3] * float(line[15:20])\t\t#Constant current load Q factor\n                elif isfloat(line[9:14]): scale_ar[3] = scale_ar[3] * float(line[9:14])\t\t#Constant current load Q factor is load P factor\n\n                if isfloat(line[21:26]): s"
  },
  {
    "id": "chunk_626",
    "text": "factor\n\n                if isfloat(line[21:26]): scale_ar[4] = scale_ar[4] * float(line[21:26])\t\t#Constant admittance load P factor\n                if isfloat(line[27:32]): scale_ar[5] = scale_ar[5] * float(line[27:32])\t\t#Constant admittance load Q factor\n                elif isfloat(line[21:26]): scale_ar[5] = scale_ar[5] * float(line[21:26])\t#Constant admittance load Q factor is load P factor\n\n        elif line[1] == 'B' and type_code == 'Y' and line[3:6].strip() == owner_name:\n            if "
  },
  {
    "id": "chunk_627",
    "text": "d line[3:6].strip() == owner_name:\n            if zone_name == line[34:36].strip() or zone_name == line[37:39].strip() or zone_name == line[40:42].strip() or zone_name == line[43:45].strip()\\\n            or zone_name == line[46:48].strip() or zone_name == line[49:51].strip() or zone_name == line[52:54].strip() or zone_name == line[55:57].strip()\\\n            or zone_name == line[58:60].strip() or zone_name == line[61:63].strip() or zone_name == line[64:66].strip() or zone_name == line[67:69].str"
  },
  {
    "id": "chunk_628",
    "text": "ine[64:66].strip() or zone_name == line[67:69].strip()\\\n            or zone_name == line[70:72].strip() or zone_name == line[73:75].strip() or zone_name == line[76:78].strip() or line[34:80].strip() == \"\":\n\n                if isfloat(line[21:26]): scale_ar[4] = scale_ar[4] * float(line[21:26])\t\t#Constant admittance load P factor\n                if isfloat(line[27:32]): scale_ar[5] = scale_ar[5] * float(line[27:32])\t\t#Constant admittance load Q factor\n                elif isfloat(line[21:26]): sc"
  },
  {
    "id": "chunk_629",
    "text": "ctor\n                elif isfloat(line[21:26]): scale_ar[5] = scale_ar[5] * float(line[21:26])\t#Constant admittance load Q factor is load P factor\n\n        elif line[1] == 'C' and type_code == 'X' and line[3:5].strip() == zone_name:\n            if owner_name == line[34:37].strip() or owner_name == line[38:41].strip() or owner_name == line[42:45].strip() or owner_name == line[46:49].strip()\\\n            or owner_name == line[50:53].strip() or owner_name == line[54:57].strip() or owner_name == lin"
  },
  {
    "id": "chunk_630",
    "text": "r_name == line[54:57].strip() or owner_name == line[58:61].strip() or owner_name == line[62:65].strip()\\\n            or owner_name == line[66:69].strip() or owner_name == line[70:73].strip() or owner_name == line[74:77].strip() or line[34:80].strip() == \"\":\n\n                if isfloat(line[9:14]): scale_ar[2] = scale_ar[2] * float(line[9:14])\t\t#Constant current load P factor\n                if isfloat(line[15:20]): scale_ar[3] = scale_ar[3] * float(line[15:20])\t\t#Constant current load Q factor\n "
  },
  {
    "id": "chunk_631",
    "text": "at(line[15:20])\t\t#Constant current load Q factor\n                elif isfloat(line[9:14]): scale_ar[3] = scale_ar[3] * float(line[9:14])\t\t#Constant current load Q factor is load P factor\n\n                if isfloat(line[21:26]): scale_ar[4] = scale_ar[4] * float(line[21:26])\t\t#Constant admittance load P factor\n                if isfloat(line[27:32]): scale_ar[5] = scale_ar[5] * float(line[27:32])\t\t#Constant admittance load Q factor\n                elif isfloat(line[21:26]): scale_ar[5] = scale_a"
  },
  {
    "id": "chunk_632",
    "text": "  elif isfloat(line[21:26]): scale_ar[5] = scale_ar[5] * float(line[21:26])\t#Constant admittance load Q factor is load P factor\n\n        elif line[1] == 'C' and type_code == 'Y' and line[3:5].strip() == zone_name:\n            if owner_name == line[34:37].strip() or owner_name == line[38:41].strip() or owner_name == line[42:45].strip() or owner_name == line[46:49].strip()\\\n            or owner_name == line[50:53].strip() or owner_name == line[54:57].strip() or owner_name == line[58:61].strip() or"
  },
  {
    "id": "chunk_633",
    "text": "7].strip() or owner_name == line[58:61].strip() or owner_name == line[62:65].strip()\\\n            or owner_name == line[66:69].strip() or owner_name == line[70:73].strip() or owner_name == line[74:77].strip() or line[34:80].strip() == \"\":\n\n                if isfloat(line[21:26]): scale_ar[4] = scale_ar[4] * float(line[21:26])\t\t#Constant admittance load P factor\n                if isfloat(line[27:32]): scale_ar[5] = scale_ar[5] * float(line[27:32])\t\t#Constant admittance load Q factor\n            "
  },
  {
    "id": "chunk_634",
    "text": ")\t\t#Constant admittance load Q factor\n                elif isfloat(line[21:26]): scale_ar[5] = scale_ar[5] * float(line[21:26])\t#Constant admittance load Q factor is load P factor\n\n    return scale_ar\t\t#Returns the scale factors\n \n# ----------------------------------------------------------------------------------------------------\ndef CheckICard(bpa_str_ar, area_name):\n    \"\"\"To check if there is an I card with the specified area name.\"\"\"\n\n    for line in bpa_str_ar:\t\t\t#Loop over every line of "
  },
  {
    "id": "chunk_635",
    "text": "or line in bpa_str_ar:\t\t\t#Loop over every line of the BPA file\n        line = line.lstrip()\n        line = line.rstrip('\\n')\n        if line == \"\": continue\t\t\t#To continue if it is a blank line\n        \n        if line[0] == 'I' and line[2] == ' ':\t#If it is an I card\n            line = line + ' '*(34-len(line))\t#To pad each line with spaces up to 34 records\n            if line[3:13].strip() == area_name or line[14:24].strip() == area_name: return True\t\t#Returns true if the area is found in an I"
  },
  {
    "id": "chunk_636",
    "text": "n True\t\t#Returns true if the area is found in an I card\n\n    return False\t\t\t#Returns false if the area has not been found in I cards\n\n# ----------------------------------------------------------------------------------------------------\ndef GetXCard(bpa_str_ar, bus_name, Vmax, Vmin, remote_bus_name, RMPCT, remote_bus_nbr, bus_nbr):\n    \"\"\"Gets the switched shunts attached to the specified bus.\"\"\"\n\n    for line in bpa_str_ar:\t\t#This loop is used to get the corresponding switched shunts\n        li"
  },
  {
    "id": "chunk_637",
    "text": "o get the corresponding switched shunts\n        line = line.lstrip()\n        line = line.rstrip('\\n')\n        if line == \"\": continue\t\t#To continue if it is a blank line\n        \n        #--------------#\n        #Default values#\n        #--------------#\n        intgar = [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n        realar = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n\n        if isfloat(line[28:32]): remote_kv = float(line[28:32])\t#The remote bus base voltage\n        else: remote_kv = "
  },
  {
    "id": "chunk_638",
    "text": "remote bus base voltage\n        else: remote_kv = 0.0\n\n        if line[0] == 'X' and bus_name == (line[6:14].strip() + str(float(line[14:18]))) and remote_bus_name == (line[20:28].strip() + str(remote_kv)):\n            if line[2] == ' ':\t\t\t\t\t#The modification code for a new record\n                line = line + ' '*(80-len(line))\t\t#To pad each line with spaces up to 80 records\n\n                if isint(line[32]): intgar[0] = int(line[32])\t#Number of steps for block 1\n                if isint(line"
  },
  {
    "id": "chunk_639",
    "text": "of steps for block 1\n                if isint(line[38]): intgar[1] = int(line[38])\t#Number of steps for block 2\n                if isint(line[44]): intgar[2] = int(line[44])\t#Number of steps for block 3\n                if isint(line[50]): intgar[3] = int(line[50])\t#Number of steps for block 4\n                if isint(line[56]): intgar[4] = int(line[56])\t#Number of steps for block 5\n                if isint(line[62]): intgar[5] = int(line[62])\t#Number of steps for block 6\n                if isint"
  },
  {
    "id": "chunk_640",
    "text": "mber of steps for block 6\n                if isint(line[68]): intgar[6] = int(line[68])\t#Number of steps for block 7\n                if isint(line[74]): intgar[7] = int(line[74])\t#Number of steps for block 8\n\n                if isfloat(line[33:38]): realar[0] = float(line[33:38])\t#Admittance increment for block 1\n                if isfloat(line[39:44]): realar[1] = float(line[39:44])\t#Admittance increment for block 2\n                if isfloat(line[45:50]): realar[2] = float(line[45:50])\t#Admitt"
  },
  {
    "id": "chunk_641",
    "text": "ne[45:50]): realar[2] = float(line[45:50])\t#Admittance increment for block 3\n                if isfloat(line[51:56]): realar[3] = float(line[51:56])\t#Admittance increment for block 4\n                if isfloat(line[57:62]): realar[4] = float(line[57:62])\t#Admittance increment for block 5\n                if isfloat(line[63:68]): realar[5] = float(line[63:68])\t#Admittance increment for block 6\n                if isfloat(line[69:74]): realar[6] = float(line[69:74])\t#Admittance increment for block 7"
  },
  {
    "id": "chunk_642",
    "text": "oat(line[69:74])\t#Admittance increment for block 7\n                if isfloat(line[75:80]): realar[7] = float(line[75:80])\t#Admittance increment for block 8\n\n                if isfloat(Vmax): realar[8] = float(Vmax)\t#Upper voltage limit\n                if isfloat(Vmin): realar[9] = float(Vmin)\t#Lower voltage limit\n                if isfloat(RMPCT):\n                    realar[11] = float(RMPCT)\t#The RMPCT\n                    if realar[11] > 1.0: realar[11] = realar[11] / 100.0\t#To bring back the "
  },
  {
    "id": "chunk_643",
    "text": "ealar[11] = realar[11] / 100.0\t#To bring back the RMPCT from percent to unit\n\n                intgar[9] = remote_bus_nbr\n\n                count_nbr = -1\n                for nbr in realar[0:8]:\t\t#This loop is used to get the reactors first in the list for PSS/E to work\n                    count_nbr = count_nbr + 1\n                    if nbr < 0.0 and count_nbr != 0:\t#If the admittance is negative (reactor) and it is not already first in the list\n                        realar.insert(0, nbr)\n     "
  },
  {
    "id": "chunk_644",
    "text": "                       realar.insert(0, nbr)\n                        realar.pop(count_nbr + 1)\n                        intgar.insert(0, intgar[count_nbr])\n                        intgar.pop(count_nbr + 1)\n\n                ierr = psspy.switched_shunt_data(bus_nbr, intgar, realar, '')\t#The API used to load switched shunts in PSS/E\n\n# ----------------------------------------------------------------------------------------------------\ndef GetACard(bpa_str_ar, zone_str, bus_str, bus_nbr, area_str, ar"
  },
  {
    "id": "chunk_645",
    "text": "a_str_ar, zone_str, bus_str, bus_nbr, area_str, area_slack_nbr, area_nbr):\n    \"Gets the area data from the BPA file.\"\"\"\n\n    if zone_str != \"\":\t\t\t#Only look for area number if the zone is not blank\n        for line in bpa_str_ar:\t\t#This loop is used to get the corresponding area data\n            line = line.lstrip()\n            line = line.rstrip('\\n')\n            if line == \"\": continue\t#To continue if the line is blank\n            \n            if line[0] == 'A' and line[1] != 'O':\n           "
  },
  {
    "id": "chunk_646",
    "text": " if line[0] == 'A' and line[1] != 'O':\n                if line[2] == ' ':\t\t\t#The modification code for a new record\n                    line = line + ' '*(95-len(line))\t#To pad each line with spaces up to 95 records\n                    if zone_str == line[35:37].strip() or zone_str == line[38:40].strip() or zone_str == line[41:43].strip() or zone_str == line[44:46].strip()\\\n                    or zone_str == line[47:49].strip() or zone_str == line[50:52].strip() or zone_str == line[53:55].strip("
  },
  {
    "id": "chunk_647",
    "text": "e[50:52].strip() or zone_str == line[53:55].strip() or zone_str == line[56:58].strip()\\\n                    or zone_str == line[59:61].strip() or zone_str == line[62:64].strip() or zone_str == line[65:67].strip() or zone_str == line[68:70].strip()\\\n                    or zone_str == line[71:73].strip() or zone_str == line[74:76].strip() or zone_str == line[77:79].strip() or zone_str == line[80:82].strip()\\\n                    or zone_str == line[83:85].strip() or zone_str == line[86:88].strip() "
  },
  {
    "id": "chunk_648",
    "text": "83:85].strip() or zone_str == line[86:88].strip() or zone_str == line[89:91].strip() or zone_str == line[92:94].strip():\n\n                        if line[13:21].strip() + str(float(line[21:25])) not in bus_str:\t#If the bus is not in the list, add it\n                            bus_nbr = bus_nbr + 1\n                            bus_str[line[13:21].strip() + str(float(line[21:25]))] = bus_nbr\t#A new dictionnary entry\n                            bus_flag = True\t\t\t\t\t\t\t#True if the bus number has been"
  },
  {
    "id": "chunk_649",
    "text": "flag = True\t\t\t\t\t\t\t#True if the bus number has been incremented\n                        else:\n                            bus_nbr = bus_str[line[13:21].strip() + str(float(line[21:25]))]\t#Get the bus number\n                            bus_flag = False\t\t\t\t\t\t\t#False if the bus number hasn't been incremented\n\n                        if isfloat(line[26:34]):\t\t\t\t\t#If the value of interchange is specified\n                            if CheckICard(bpa_str_ar, line[3:13].strip()):\t\t#If there is an I card"
  },
  {
    "id": "chunk_650",
    "text": "r_ar, line[3:13].strip()):\t\t#If there is an I card, do not include interchange given\n                                if (line[3:13].strip(), 0.0) not in area_str:\t#If the area is not in the list, add it\n                                    area_nbr = area_nbr + 1\n                                    area_str[(line[3:13].strip(), 0.0)] = area_nbr\n                                    area_slack_nbr.append(bus_nbr)\t\t\t#An array with slack bus numbers for each area\n                                else:\n"
  },
  {
    "id": "chunk_651",
    "text": "r each area\n                                else:\n                                    area_nbr = area_str[(line[3:13].strip(), 0.0)]\t#Get the area number\n                            else:\t\t\t\t\t\t\t#If there is no I card, include the interchange value given\n                                if (line[3:13].strip(),float(line[26:34])) not in area_str:\t#If the area is not in the list, add it\n                                    area_nbr = area_nbr + 1\n                                    area_str[(line[3:1"
  },
  {
    "id": "chunk_652",
    "text": "                                area_str[(line[3:13].strip(), float(line[26:34]))] = area_nbr\n                                    area_slack_nbr.append(bus_nbr)\t\t\t#Add the corresponding slack bus number\n                                else:\n                                    area_nbr = area_str[(line[3:13].strip(),float(line[26:34]))]\t#Get the area number\n\n                        else:\t\t\t\t#If there is no value of interchange specified\n                            if (line[3:13].strip(), 0.0) not"
  },
  {
    "id": "chunk_653",
    "text": "                  if (line[3:13].strip(), 0.0) not in area_str:\t\t#If the area is not in the list, add it\n                                area_nbr = area_nbr + 1\n                                area_str[(line[3:13].strip(), 0.0)] = area_nbr\n                                area_slack_nbr.append(bus_nbr)\t\t\t\t#Add the corresponding slack bus number\n                            else:\n                                area_nbr = area_str[(line[3:13].strip(), 0.0)]\t\t#Get the area number\n\n                  "
  },
  {
    "id": "chunk_654",
    "text": "), 0.0)]\t\t#Get the area number\n\n                        area_flag = True\t\t#True if the zone name has a corresponding area card\n\n                        return area_flag, bus_flag, area_nbr, bus_nbr, bus_str, area_str, area_slack_nbr\n\n\n    area_flag = False\t\t#The zone name has no corresponding area card\n    bus_flag = False\t\t#The bus number hasn't changed\n\n    return area_flag, bus_flag, area_nbr, bus_nbr, bus_str, area_str, area_slack_nbr\n\n# ------------------------------------------------------"
  },
  {
    "id": "chunk_655",
    "text": "------------------------------------------------------------------------------------------------\ndef GetBCard(bpa_str_ar, base_mva, scale_str):\n    \"\"\"Gets the AC bus data from the BPA file.\"\"\"\n\n    bus_data_str = []\t\t\t#The array to contain all AC bus lines\n    bus_str = {}\t\t\t#A dictionnary with bus names and the corresponding bus numbers\n    bus_owner_nbr = [0]\t\t\t#An array with the owner number for each bus\n    bus_zone_str = [\"0\"]\t\t#An array with the zone of each bus\n    load_id_ar = [0]\t\t\t#An"
  },
  {
    "id": "chunk_656",
    "text": "th the zone of each bus\n    load_id_ar = [0]\t\t\t#An array used to determine the load CKT for each bus\n    machine_id_ar = [0]\t\t\t#An array used to determine the machine CKT for each bus\n    owner_str = {'DEFAULT': 1}\t\t#The default owner\n    zone_str = {'DEFAULT': 1}\t\t#The default zone\n    area_str = {(\"DEFAULT\", 0.0): 1}\t#The default area is used for zones without A cards or for data without zones\n    area_slack_nbr = [0]\t\t#An array with the slack bus of each area\n    bus_nbr = 0\t\t\t\t#The bus numbe"
  },
  {
    "id": "chunk_657",
    "text": "bus of each area\n    bus_nbr = 0\t\t\t\t#The bus number\n    owner_nbr = 1\t\t\t#The owner number\n    zone_nbr = 1\t\t\t#The zone number\n    area_nbr = 1\t\t\t#The area number\n\n    for line in bpa_str_ar:\t\t#This loop is used to fill the bus data array with each line of bus data\n        line = line.lstrip()\n        line = line.rstrip('\\n')\n        if line == \"\": continue\t\t#Continue if the line is blank\n        if line[0] == 'B':\t\t#If it is a bus\n            if line[1] != 'D' and line[1] != 'M':\t#But not a DC b"
  },
  {
    "id": "chunk_658",
    "text": "line[1] != 'D' and line[1] != 'M':\t#But not a DC bus\n                bus_data_str.append(line)\t\t#Add the line to the array\n\n    for line in bus_data_str:\n        line = line + ' '*(80-len(line))\t#To pad each line with spaces up to 80 records\n\n        #--------------#\n        #Default values#\n        #--------------#\n        bus_intgar = [1, 0, 1, 0]\n        load_intgar = [1, 1, 1, 1]\n        machine_intgar = [0, 0, 0, 0, 0]\n        bus_realar = [0.0, 0.0, 0.0, 1.0, 0.0]\n        load_realar = [0."
  },
  {
    "id": "chunk_659",
    "text": "0.0, 0.0, 0.0, 1.0, 0.0]\n        load_realar = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n        machine_realar = [0.0, 0.0, 9999.0, -9999.0, 9999.0, -9999.0, base_mva, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]\n        plant_realar = [1.0, 1.0]\n        remote_bus_nbr = 0\n        remote_kv = 0.0\n\n        if line[2] == ' ':\t\t\t#The modification code for a new record\n            if line[1] == ' ' or line[1] == 'T' or line[1] == 'C' or line[1] == 'V' or line[1] == 'F' or line[1] == 'J' or line [1] == 'X':\n  "
  },
  {
    "id": "chunk_660",
    "text": "1] == 'F' or line[1] == 'J' or line [1] == 'X':\n                bus_intgar[0] = 1\t\t#The bus type code for a PQ bus\n            elif line[1] == 'E' or line[1] == 'Q' or line[1] == 'G' or line[1] == 'K' or line[1] == 'L':\n                bus_intgar[0] = 2\t\t#The bus type code for a PV bus\n            elif line[1] == 'S':\n                bus_intgar[0] = 3\t\t#The bus type code for a swing bus\n\n            if line[3:6] != \"   \" and line[3:6].strip() not in owner_str:\t#If the owner is not in the list, a"
  },
  {
    "id": "chunk_661",
    "text": " in owner_str:\t#If the owner is not in the list, add it to the list with a new number\n                owner_nbr = owner_nbr + 1\n                owner_str[line[3:6].strip()] = owner_nbr\n                bus_intgar[3] = owner_nbr\t\t\t#The owner number\n            elif line[3:6] != \"   \" and line[3:6].strip() in owner_str:\n                bus_intgar[3] =  owner_str[line[3:6].strip()]\t#Get the owner number\n            elif line[3:6] == \"   \":\n                bus_intgar[3] = 1\t\t\t\t#The default owner numb"
  },
  {
    "id": "chunk_662",
    "text": "      bus_intgar[3] = 1\t\t\t\t#The default owner number\n\n            bus_namear = line[6:14].strip()\t\t#The bus name\n            bus_realar[2] = float(line[14:18])\t\t#The bus base voltage in kV\n\n            if bus_namear + str(bus_realar[2]) not in bus_str:\t#If the bus is not in the list, add it (the bus could be in the list if assigned as a remote for another bus)\n                bus_nbr = bus_nbr + 1\n                bus_str[bus_namear + str(bus_realar[2])] = bus_nbr\t#A new dictionnary entry\n       "
  },
  {
    "id": "chunk_663",
    "text": "ar[2])] = bus_nbr\t#A new dictionnary entry\n            else:\n                bus_nbr = bus_str[bus_namear + str(bus_realar[2])]\t#Get the bus number\n\n            bus_owner_nbr.insert(bus_nbr + 1, bus_intgar[3])\t\t#Insert the corresponding owner of the bus\n\n            load_id_ar.append(0)\t#To initialize the load CKT number\n            machine_id_ar.append(0)\t#To initialize the machine CKT number\n\n            if line[18:20] != \"  \":\t#If the zone is not blank\n                if line[18:20].strip() n"
  },
  {
    "id": "chunk_664",
    "text": "not blank\n                if line[18:20].strip() not in zone_str:\t#If the zone is not in the list, add it\n                    zone_nbr = zone_nbr + 1\n                    zone_str[line[18:20].strip()] = zone_nbr\n                    bus_intgar[2] = zone_nbr\t\t#The zone number\n                else:\n                    bus_intgar[2] =  zone_str[line[18:20].strip()]\t#Get the zone number\n\n            bus_zone_str.insert(bus_nbr + 1, line[18:20].strip())\t#Insert the corresponding zone of the bus\n\n      "
  },
  {
    "id": "chunk_665",
    "text": "\t#Insert the corresponding zone of the bus\n\n            if isfloat(line[20:25]): load_realar[0] = float(line[20:25])\t#Load P in MW\n            if isfloat(line[25:30]): load_realar[1] = float(line[25:30])\t#Load Q in Mvar\n\n            if isfloat(line[30:34]): bus_realar[0] = float(line[30:34])\t\t#Fixed bus shunt active load\n            if isfloat(line[34:38]): bus_realar[1] = float(line[34:38])\t\t#Fixed bus shunt reactive load\n\n            if isfloat(line[38:42]): machine_realar[4] = float(line[38:4"
  },
  {
    "id": "chunk_666",
    "text": "(line[38:42]): machine_realar[4] = float(line[38:42])\t#Maximum active power generation\n            if isfloat(line[42:47]): machine_realar[0] = float(line[42:47])\t#Actual active power generation\n\n            if line[1] != ' ' and line[1] != 'C' and line[1] != 'T' and line[1] != 'V':\t#If not a PQ bus\n                if isfloat(line[47:52]): machine_realar[2] = float(line[47:52])\t#Machine reactive upper limit\n                if isfloat(line[52:57]): machine_realar[3] = float(line[52:57])\t#Machine "
  },
  {
    "id": "chunk_667",
    "text": ": machine_realar[3] = float(line[52:57])\t#Machine reactive lower limit\n\n            if line[1] == ' ' or line[1] == 'C' or line[1] == 'T' or line[1] == 'V':\t#If it is a PQ bus\n                if isfloat(line[47:52]): \n                    machine_realar[2] = float(line[47:52])\t#Machine reactive upper limit\n                    machine_realar[3] = machine_realar[2]\t#Machine reactive lower limit\n                    machine_realar[1] = machine_realar[2]\t#Machine reactive power output\n\n            eli"
  },
  {
    "id": "chunk_668",
    "text": "2]\t#Machine reactive power output\n\n            elif line[1] == 'E' or line[1] == 'Q' or line[1] == 'G':\t\t#If it is a PV bus\n                if isfloat(line[57:61]): \n                    plant_realar[0] = float(line[57:61])\t\t\t#Scheduled voltage\n                    bus_realar[3] = float(line[57:61])\t\t\t\t#Bus voltage magnitude\n\n            elif line[1] == 'S':\t\t\t\t\t\t#If it is a swing bus\n                if isfloat(line[57:61]):\n                    plant_realar[0] = float(line[57:61])\t\t\t#Scheduled vol"
  },
  {
    "id": "chunk_669",
    "text": "nt_realar[0] = float(line[57:61])\t\t\t#Scheduled voltage\n                    bus_realar[3] = float(line[57:61])\t\t\t\t#Bus voltage magnitude\n                if isfloat(line[61:65]): bus_realar[4] = float(line[61:65])\t#The voltage phase angle\n\n            if line[65:73] != \"        \":\t\t\t\t\t#If there is a remote bus\n                remote_kv = float(line[73:77])\t\t\t\t\t#The remote bus base voltage\n                if line[65:73].strip() + str(remote_kv) not in bus_str:\t#If the remote bus name is not in the "
  },
  {
    "id": "chunk_670",
    "text": "in bus_str:\t#If the remote bus name is not in the list, add it\n                    remote_bus_nbr = bus_nbr + 1\n                    bus_str[line[65:73].strip() + str(remote_kv)] = remote_bus_nbr\n                else:\n                    remote_bus_nbr = bus_str[line[65:73].strip() + str(remote_kv)]\t#Get the remote bus number\n\n            if isfloat(line[77:80]):\n                plant_realar[1] = float(line[77:80])\t#The RMPCT\n                if plant_realar[1] > 1.0: plant_realar[1] = plant_reala"
  },
  {
    "id": "chunk_671",
    "text": "ant_realar[1] > 1.0: plant_realar[1] = plant_realar[1] / 100.0\t#To bring back the RMPCT from percent to unit\n\n            area_flag, bus_flag, area_nbr, swing_bus_nbr, bus_str, area_str, area_slack_nbr = GetACard(bpa_str_ar, line[18:20].strip(), bus_str, bus_nbr, area_str, area_slack_nbr, area_nbr)\n\n            if bus_flag == True: bus_nbr = swing_bus_nbr\t#To change the bus number if it has been incremented\n\n            if area_flag == True:\t\t#To assign the area number to the buses and loads\n   "
  },
  {
    "id": "chunk_672",
    "text": " assign the area number to the buses and loads\n                bus_intgar[1] = area_nbr\n                load_intgar[1] = area_nbr\n            else:\t\t\t\t#The default area number\n                bus_intgar[1] = 1\n                load_intgar[1] = 1\n            \n            ierr = psspy.bus_data(bus_nbr, bus_intgar, bus_realar, bus_namear)\t#Loads the bus data in PSS/E\n\n            if line[1] == 'X': GetXCard(bpa_str_ar, bus_namear + str(bus_realar[2]), line[57:61], line[61:65], line[65:73].strip() + "
  },
  {
    "id": "chunk_673",
    "text": ", line[57:61], line[61:65], line[65:73].strip() + str(remote_kv), line[77:80], remote_bus_nbr, bus_nbr)\n\n            scale_ar = GetScaleData(scale_str, line[3:6].strip(), line[18:20].strip(), 'N')\t#To get the scale factors\n\n            load_realar[0] = load_realar[0] * scale_ar[0]\t\t#To scale the load P\n            load_realar[1] = load_realar[1] * scale_ar[1]\t\t#To scale the load Q\n            machine_realar[0] = machine_realar[0] * scale_ar[6]\t\t#To scale the machine P\n            machine_realar["
  },
  {
    "id": "chunk_674",
    "text": "To scale the machine P\n            machine_realar[1] = machine_realar[1] * scale_ar[7]\t\t#To scale the machine Q\n\n            if load_realar[0] != 0.0 or load_realar[1] != 0.0: \t\t\t#If there is a load\n                load_intgar[2] = bus_intgar[2]\t\t#The zone number\n                load_intgar[3] = bus_intgar[3]\t\t#The owner number\n                load_id_ar[bus_nbr] = 1\t\t\t#The load CKT number is now 1\n                ierr = psspy.load_data(bus_nbr, '1', load_intgar, load_realar)\t#Loads the load dat"
  },
  {
    "id": "chunk_675",
    "text": "'1', load_intgar, load_realar)\t#Loads the load data in PSS/E\n\n            if machine_realar[0] != 0.0:\t\t#If there is a generator\n                machine_intgar[0] = 1\t\t\t#The machine status\n                machine_intgar[1] = bus_intgar[3]\t#The owner number\n                machine_id_ar[bus_nbr] = 1\t\t#The machine CKT number is now 1\n                ierr = psspy.plant_data(bus_nbr, remote_bus_nbr, plant_realar)\t#First load the plant data\n                ierr = psspy.machine_data(bus_nbr, '1', mach"
  },
  {
    "id": "chunk_676",
    "text": "      ierr = psspy.machine_data(bus_nbr, '1', machine_intgar, machine_realar)\t#After add the generator data\n\n            if remote_bus_nbr == bus_nbr + 1: bus_nbr = bus_nbr + 1\t#To change the actual bus number\n\n    return area_str, area_nbr, area_slack_nbr, owner_str, owner_nbr, bus_owner_nbr, bus_str, bus_nbr, zone_str, zone_nbr, load_id_ar, machine_id_ar, bus_zone_str\n\n# ----------------------------------------------------------------------------------------------------\ndef GetRCard(bpa_str_ar"
  },
  {
    "id": "chunk_677",
    "text": "--------------------------\ndef GetRCard(bpa_str_ar, from_bus, to_bus, bus_str):\n    \"\"\"Gets the regulation parameters for the two-winding transformers.\"\"\"\n\n    #--------------#\n    #Default values#\n    #--------------#\n    #Only the returned values are useful\n    intgar = [1, 0, 1, 0, 0, 0, 33, 0, 0, 0, 0, 0, 2, 1, 1]\n    realari = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.1, 0.9, 1.1, 0.9, 0.0, 0.0]\n\n    for line in bpa_str_ar:\n        line = line.l"
  },
  {
    "id": "chunk_678",
    "text": "\n    for line in bpa_str_ar:\n        line = line.lstrip()\n        line = line.rstrip('\\n')\n        if line == \"\": continue\t\t#Continue if the line is blank\n\n        if line[0] == 'R' and line[1] != 'Z':\t#If it is a R card but not RZ\n            if line[2] == ' ' and from_bus == (line[6:14].strip() + str(float(line[14:18]))) and to_bus == (line[19:27].strip() + str(float(line[27:31]))):\n                line = line + ' '*(67-len(line))\t#To pad each line with spaces up to 67 records\n\n               "
  },
  {
    "id": "chunk_679",
    "text": "line with spaces up to 67 records\n\n                if line[33:41] != \"        \": intgar[9] = bus_str[line[33:41].strip() + str(float(line[41:45]))]\t#Controlled bus number\n                if isfloat(line[45:50]): realari[17] = float(line[45:50])\t#Winding one ratio/angle high limit\n                if isfloat(line[50:55]): realari[18] = float(line[50:55])\t#Winding one ratio/angle low limit\n                if isint(line[55:57]): intgar[6] = int(line[55:57])\t\t#Number of tap positions\n\n               "
  },
  {
    "id": "chunk_680",
    "text": "55:57])\t\t#Number of tap positions\n\n                if line[1] == ' ':\t#If it is a R card\n                    intgar[11] = 1\t#Control mode = 1\n                elif line[1] == 'V':\t#If it is a RV card\n                    intgar[11] = 1\t#Control mode = 1\n \n                elif line[1] == 'Q':\t#If it is a RQ card\n                    intgar[11] = 2\t#Control mode = 2\n                elif line[1] == 'N':\t#If it is a RN card\n                    intgar[11] = 2\t#Control mode = 2\n                    if isf"
  },
  {
    "id": "chunk_681",
    "text": "] = 2\t#Control mode = 2\n                    if isfloat(line[57:62]): realari[19] = float(line[57:62])\t#Voltage or flow upper limit\n                    else: realari[19] = 0.0\t\t\t\t\t#Default\n                    if isfloat(line[62:67]): realari[20] = float(line[62:67])\t#Voltage or flow lower limit\n                    else: realari[20] = 0.0\t\t\t\t\t#Default\n\n                elif line[1] == 'P':\t#If it is a RP card\n                    intgar[11] = 3\t#Control mode = 3\n                elif line[1] == 'M':\t"
  },
  {
    "id": "chunk_682",
    "text": "rol mode = 3\n                elif line[1] == 'M':\t#If it is a RM card\n                    intgar[11] = 3\t#Control mode = 3\n                    if isfloat(line[57:62]): realari[19] = float(line[57:62])\t#Voltage or flow upper limit\n                    else: realari[19] = 0.0\t\t\t\t\t#Default\n                    if isfloat(line[62:67]): realari[20] = float(line[62:67])\t#Voltage or flow lower limit\n                    else: realari[19] = 0.0\t\t\t\t\t#Default\n\n                return intgar[11], intgar[9], re"
  },
  {
    "id": "chunk_683",
    "text": "\n\n                return intgar[11], intgar[9], realari[17], realari[18], intgar[6], realari[19], realari[20]\n\n    return intgar[11], intgar[9], realari[17], realari[18], intgar[6], realari[19], realari[20]\n\n# ----------------------------------------------------------------------------------------------------\ndef GetSectionLine(bpa_str_ar, iarg, jarg, section_nbr, dummy_nbr, bus_nbr, bus_str, bus_owner_nbr, owner_nbr, multi_intgar, ckt_nbr, base_mva):\n    \"\"\"To get the multi-section line data fr"
  },
  {
    "id": "chunk_684",
    "text": "mva):\n    \"\"\"To get the multi-section line data from BPA.\n\n    This function is recursive.\n    \"\"\"\n\n    for line in bpa_str_ar:\n        line = line.lstrip()\n        line = line.rstrip('\\n')\n        if line == \"\": continue\t\t#Continue if the line is blank\n\n        #--------------#\n        #Default values#\n        #--------------#\n        bus_intgar = [1, 1, 1, owner_nbr]\n        bus_realar = [0.0, 0.0, 0.0, 1.0, 0.0]\n        line_intgar = [1, 0, 1, 0, 0, 0]\n        line_realar = [0.0, 0.0001, 0.0,"
  },
  {
    "id": "chunk_685",
    "text": " 0, 0, 0]\n        line_realar = [0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]\n        trans_intgar = [1, 0, 1, 0, 0, 0, 33, 0, 0, 0, 0, 0, 2, 1, 1]\n        trans_realari = [0.0, 0.0, base_mva, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.1, 0.9, 1.1, 0.9, 0.0, 0.0]\n\n        if line[0] == 'L' and line[1] == ' ' and line[2] == ' ' or line[0] == 'E' and line[1] == ' ' and line[2] == ' ':\n            if iarg == bus_str[line[6:14].strip() + "
  },
  {
    "id": "chunk_686",
    "text": "          if iarg == bus_str[line[6:14].strip() + str(float(line[14:18]))] and jarg == bus_str[line[19:27].strip() + str(float(line[27:31]))] and line[32] == str(section_nbr) and ckt_nbr == line[31]:\n                line = line + ' '*(80-len(line))\t\t#To pad each line with spaces up to 80 records\n                section_nbr = section_nbr + 1\t\t\t#To increment the section number\n                dummy_nbr = dummy_nbr + 1\t\t\t#To increment the dummy bus number\n                bus_nbr = bus_nbr + 1\t\t\t\t#T"
  },
  {
    "id": "chunk_687",
    "text": "number\n                bus_nbr = bus_nbr + 1\t\t\t\t#To increment the bus number\n                bus_namear = \"DUMMY #\" + str(dummy_nbr)\t\t#The name of the new dummy bus\n                bus_str[bus_namear] = bus_nbr\t\t\t#Add the bus to the dictionnary\n                bus_owner_nbr.insert(bus_nbr + 1, owner_nbr)\t#Insert the owner number of that bus\n                if isfloat(line[14:18]): bus_realar[2] = float(line[14:18])\t#The bus base voltage\n                multi_intgar[section_nbr - 2] = bus_nbr\t\t#T"
  },
  {
    "id": "chunk_688",
    "text": "       multi_intgar[section_nbr - 2] = bus_nbr\t\t#The bus number of the dummy bus\n                from_bus = bus_nbr\t\t\t\t#To remember the value of the from bus before recalling this function\n\n                ierr = psspy.bus_data(bus_nbr, bus_intgar, bus_realar, bus_namear)\t\t#Loads the bus data in PSS/E\n\n                to_bus, dummy_nbr, bus_nbr, bus_str, bus_owner_nbr, owner_nbr, multi_intgar = GetSectionLine(bpa_str_ar, iarg, jarg, section_nbr, dummy_nbr, bus_nbr, bus_str, bus_owner_nbr, owner_"
  },
  {
    "id": "chunk_689",
    "text": "dummy_nbr, bus_nbr, bus_str, bus_owner_nbr, owner_nbr, multi_intgar, ckt_nbr, base_mva)\t#Recursive function\n\n                if line[3:6] != \"   \" and line[3:6].strip() not in owner_str:\t\t#If the owner is not in the list, add it to the list with a new number\n                    owner_nbr = owner_nbr + 1\n                    owner_str[line[3:6].strip()] = owner_nbr\t\t#A new dictionnary entry\n                    line_intgar[2] = owner_nbr\t\t\t\t#The new owner number\n                elif line[3:6] != \" "
  },
  {
    "id": "chunk_690",
    "text": " owner number\n                elif line[3:6] != \"   \" and line[3:6].strip() in owner_str:\n                    line_intgar[2] =  owner_str[line[3:6].strip()]\t#Get the owner number\n                elif line[3:6] == \"   \":\n                    line_intgar[2] = 1\t\t\t#The default owner\n\n                line_intgar[1] = from_bus\t\t#Every section of the line is set as metered from (default)\n\n                if isfloat(line[33:37]) and isfloat(line[14:18]): line_realar[3] = sqrt(3)*float(line[33:37])*float"
  },
  {
    "id": "chunk_691",
    "text": " line_realar[3] = sqrt(3)*float(line[33:37])*float(line[14:18])/1000.0\t#The Rate A in MVA\n\n                if line[31] != ' ': ckt = line[31]\t\t#The circuit identifier\n                else: ckt = '1'\t\t\t#If none is mentionned, the default is 1\n\n                if isfloat(line[38:44]): line_realar[0] = float(line[38:44])\t\t\t#Nominal branch resistance\n                if isfloat(line[44:50]) and float(line[44:50]) != 0.0: line_realar[1] = float(line[44:50])\t#Nominal branch reactance\n\n                i"
  },
  {
    "id": "chunk_692",
    "text": ":50])\t#Nominal branch reactance\n\n                if line[0] == 'L':\t\t#If it is an L card\n                    if isfloat(line[50:56]):\n                        line_realar[6] = float(line[50:56])/2.0\t\t\t\t\t#Real line shunt at bus IARG end\n                        line_realar[8] = line_realar[6]\t\t\t\t\t\t#Real line shunt at bus JARG end\n                    if isfloat(line[56:62]): line_realar[2] = float(line[56:62])*2.0\t\t#Total line charging\n                    if isfloat(line[62:66]): line_realar[10] = f"
  },
  {
    "id": "chunk_693",
    "text": "      if isfloat(line[62:66]): line_realar[10] = float(line[62:66])\t\t#Line's length in miles\n\n                else:\t\t\t\t#If it is an E card\n                    if isfloat(line[50:56]): line_realar[6] = float(line[50:56])\t\t#Real line shunt at bus IARG end\n                    if isfloat(line[56:62]): line_realar[7] = float(line[56:62])\t\t#Reactive line shunt at bus IARG end\n                    if isfloat(line[62:68]): line_realar[8] = float(line[62:68])\t\t#Real line shunt at bus JARG end\n            "
  },
  {
    "id": "chunk_694",
    "text": "8])\t\t#Real line shunt at bus JARG end\n                    if isfloat(line[68:74]): line_realar[9] = float(line[68:74])\t\t#Reactive line shunt at bus JARG end\n\n                #It seems the format for the date in the file 2006eh-tmp-1.dat is not the same as in the user manual\n                #if line[77:80] != \"   \": line_intgar[0] = 0\t\t#If there is an out of service date, the status is offline\n\n                ierr = psspy.branch_data(from_bus, to_bus, ckt, line_intgar, line_realar)\t#The API to l"
  },
  {
    "id": "chunk_695",
    "text": "_bus, ckt, line_intgar, line_realar)\t#The API to load branch data in PSS/E\n\n                return from_bus, dummy_nbr, bus_nbr, bus_str, bus_owner_nbr, owner_nbr, multi_intgar\n\n        if line[0] == 'T' and line[2] == ' ' and line[6:14].strip() + str(float(line[14:18])) in bus_str and line[19:27].strip() + str(float(line[27:31])) in bus_str:\n            if iarg == bus_str[line[6:14].strip() + str(float(line[14:18]))] and jarg == bus_str[line[19:27].strip() + str(float(line[27:31]))] and line[32"
  },
  {
    "id": "chunk_696",
    "text": "27].strip() + str(float(line[27:31]))] and line[32] == str(section_nbr) and ckt_nbr == line[31]:\n                line = line + ' '*(80-len(line))\t\t#To pad each line with spaces up to 80 records\n                section_nbr = section_nbr + 1\t\t\t#To increment the section number\n                dummy_nbr = dummy_nbr + 1\t\t\t#To increment the dummy bus number\n                bus_nbr = bus_nbr + 1\t\t\t\t#To increment the bus number\n                bus_namear = \"DUMMY #\" + str(dummy_nbr)\t\t#The name of the du"
  },
  {
    "id": "chunk_697",
    "text": " = \"DUMMY #\" + str(dummy_nbr)\t\t#The name of the dummy bus\n                bus_str[bus_namear] = bus_nbr\t\t\t#A new dictionnary entry\n                bus_owner_nbr.insert(bus_nbr + 1, owner_nbr)\t#Insert the owner of this bus\n                if isfloat(line[14:18]): bus_realar[2] = float(line[14:18])\t#The bus base voltage\n                multi_intgar[section_nbr - 2] = bus_nbr\t\t#The bus number of the dummy bus\n                from_bus = bus_nbr\n\n                ierr = psspy.bus_data(bus_nbr, bus_int"
  },
  {
    "id": "chunk_698",
    "text": "            ierr = psspy.bus_data(bus_nbr, bus_intgar, bus_realar, bus_namear)\t#Loads the bus data in PSS/E\n\n                to_bus, dummy_nbr, bus_nbr, bus_str, bus_owner_nbr, owner_nbr, multi_intgar = GetSectionLine(bpa_str_ar, iarg, jarg, section_nbr, dummy_nbr, bus_nbr, bus_str, bus_owner_nbr, owner_nbr, multi_intgar, ckt_nbr, base_mva)\t#Recursive function\n\n                if line[3:6] != \"   \" and line[3:6].strip() not in owner_str:\t#If the owner is not in the list, add it to the list with "
  },
  {
    "id": "chunk_699",
    "text": "owner is not in the list, add it to the list with a new number\n                    owner_nbr = owner_nbr + 1\n                    owner_str[line[3:6].strip()] = owner_nbr\t#A new dictionnary entry\n                    trans_intgar[2] = owner_nbr\t\t\t#The new owner number\n                elif line[3:6] != \"   \" and line[3:6].strip() in owner_str:\n                    trans_intgar[2] =  owner_str[line[3:6].strip()]\t#Get the owner number\n                elif line[3:6] == \"   \":\n                    trans_"
  },
  {
    "id": "chunk_700",
    "text": "lif line[3:6] == \"   \":\n                    trans_intgar[2] = 1\t\t\t#The default owner\n\n                trans_intgar[1] = from_bus\t\t#Every section of the line is set as metered from (default)\n\n                trans_intgar[8] = from_bus\t\t#The winding one side\n\n                if isfloat(line[14:18]): trans_realari[4] = float(line[14:18])\t\t#Winding one nominal voltage\n\n                if isfloat(line[27:31]): trans_realari[7] = float(line[27:31])\t\t#Winding two nominal voltage\n\n                if isf"
  },
  {
    "id": "chunk_701",
    "text": "inding two nominal voltage\n\n                if isfloat(line[33:37]): trans_realari[8] = float(line[33:37])\t\t#The Rate A in MVA\n\n                if line[31] != ' ': ckt = line[31]\t#The circuit identifier\n                else: ckt = '1'\t\t\t\t#If none is mentionned, the default is 1\n\n                if isfloat(line[38:44]): trans_realari[0] = float(line[38:44])\t#Nominal transformer resistance\n                if isfloat(line[44:50]) and float(line[44:50]) != 0.0: trans_realari[1] = float(line[44:50])\t"
  },
  {
    "id": "chunk_702",
    "text": "0]) != 0.0: trans_realari[1] = float(line[44:50])\t#Nominal transformer reactance\n\n                if isfloat(line[50:56]): trans_realari[15] = float(line[50:56])\t\t#The magnetizing conductance\n\n                if isfloat(line[56:62]): trans_realari[16] = float(line[56:62])\t\t#The magnetization susceptance\n\n                if line[1] == ' ':\n                    if isfloat(line[62:67]): trans_realari[3] = float(line[62:67])\t\t#The winding one ratio/voltage\n                    if isfloat(line[67:72]):"
  },
  {
    "id": "chunk_703",
    "text": "ltage\n                    if isfloat(line[67:72]): trans_realari[6] = float(line[67:72])\t\t#The winding one ratio/voltage\n\n                else:\t\t#For the phase shifting transformer\n                    if isfloat(line[62:67]): trans_realari[5] = float(line[62:67])\t\t#The winding one phase shift angle\n                    trans_realari[3] = trans_realari[4]\n                    trans_realari[6] = trans_realari[7]\n\n                #It seems the format for the date in the file 2006eh-tmp-1 is not the s"
  },
  {
    "id": "chunk_704",
    "text": "for the date in the file 2006eh-tmp-1 is not the same as in the user manual\n                #if line[77:80] != \"   \": trans_intgar[0] = 0\t\t#If there is an out of service date, the status is offline\n\n                trans_intgar[11], trans_intgar[9], trans_realari[17], trans_realari[18], trans_intgar[6], trans_realari[19], trans_realari[20] = GetRCard(bpa_str_ar, line[6:14].strip() + str(float(line[14:18])), line[19:27].strip() + str(float(line[27:31])), bus_str)\n\n                ierr, realaro  ="
  },
  {
    "id": "chunk_705",
    "text": ":31])), bus_str)\n\n                ierr, realaro  = psspy.two_winding_data(from_bus, to_bus, ckt, trans_intgar, trans_realari, \"\")\t#The API to load transformer data in PSS/E\n\n                return from_bus, dummy_nbr, bus_nbr, bus_str, bus_owner_nbr, owner_nbr, multi_intgar\n\n    return jarg, dummy_nbr, bus_nbr, bus_str, bus_owner_nbr, owner_nbr, multi_intgar\n\n# ----------------------------------------------------------------------------------------------------\ndef GetLCard(bpa_str_ar, owner_str,"
  },
  {
    "id": "chunk_706",
    "text": "--------------\ndef GetLCard(bpa_str_ar, owner_str, owner_nbr, bus_str, bus_nbr, bus_owner_nbr, base_mva):\n    \"\"\"Gets the symmetrical and asymmetrical lines from BPA.\"\"\"\n\n    line_str = []\t#An array to contain all AC line data\n    dummy_nbr = 0\t#The dummy bus number for multi-section lines\n\n    for line in bpa_str_ar:\t\t#This loop is used to fill the branch data array with each line of branch data\n        line = line.lstrip()\n        line = line.rstrip('\\n')\n        if line == \"\": continue\t\t#Cont"
  },
  {
    "id": "chunk_707",
    "text": "strip('\\n')\n        if line == \"\": continue\t\t#Continue if the line is blank\n        if line[0] == 'L' and line[1] == ' ' or line[0] == 'E' and line[1] == ' ': line_str.append(line)\n\n    for line in line_str:\n        line = line + ' '*(80-len(line))\t#To pad each line with spaces up to 80 records\n\n        #--------------#\n        #Default values#\n        #--------------#\n        intgar = [1, 0, 1, 0, 0, 0]\n        realar = [0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1"
  },
  {
    "id": "chunk_708",
    "text": ".0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]\n\n        if line[2] == ' ':\t\t\t#The modification code for a new record\n\n            if line[3:6] != \"   \" and line[3:6].strip() not in owner_str:\t\t#If the owner is not in the list, add it to the list with a new number\n                owner_nbr = owner_nbr + 1\n                owner_str[line[3:6].strip()] = owner_nbr\t#A new dictionnary entry\n                intgar[2] = owner_nbr\t\t\t\t#The new owner number\n            elif line[3:6] != \"   \" and li"
  },
  {
    "id": "chunk_709",
    "text": " number\n            elif line[3:6] != \"   \" and line[3:6].strip() in owner_str:\n                intgar[2] =  owner_str[line[3:6].strip()]\t#Get the owner number\n            elif line[3:6] == \"   \":\n                intgar[2] = 1\t\t\t\t\t#The default owner\n\n            iarg = bus_str[line[6:14].strip() + str(float(line[14:18]))]\t\t#From bus\n            jarg = bus_str[line[19:27].strip() + str(float(line[27:31]))]\t\t#To bus\n\n            if line[18] == '1': intgar[1] = iarg\t#The metered end is IARG\n       "
  },
  {
    "id": "chunk_710",
    "text": " intgar[1] = iarg\t#The metered end is IARG\n            elif line[18] == '2': intgar[1] = jarg\t#The metered end is JARG\n            elif line[18] == ' ':\t\t\t#If the metered end is left blank, BPA chooses\n                if bus_owner_nbr[iarg] == bus_owner_nbr[jarg]: intgar[1] = iarg\t\t#If both ends have the same owner, IARG is the metered end\n                elif bus_owner_nbr[iarg] == intgar[2]: intgar[1] = jarg\t\t\t#Else the end that has a different owner from the line is the metered end\n          "
  },
  {
    "id": "chunk_711",
    "text": " owner from the line is the metered end\n                elif bus_owner_nbr[jarg] == intgar[2]: intgar[1] = iarg\n\n            if isfloat(line[33:37]) and intgar[1] == iarg and isfloat(line[14:18]): realar[3] = sqrt(3)*float(line[33:37])*float(line[14:18])/1000.0\t#The Rate A in MVA\n            elif isfloat(line[33:37]) and intgar[1] == jarg and isfloat(line[27:31]): realar[3] = sqrt(3)*float(line[33:37])*float(line[27:31])/1000.0\t#The Rate A in MVA\n\n            if line[31] != ' ': ckt = line[31]\t\t"
  },
  {
    "id": "chunk_712",
    "text": "\n\n            if line[31] != ' ': ckt = line[31]\t\t#The circuit identifier\n            else: ckt = '1'\t\t\t\t#If none is mentionned, the default is 1\n\n            if isfloat(line[38:44]): realar[0] = float(line[38:44])\t\t\t#Nominal branch resistance\n            if isfloat(line[44:50]) and float(line[44:50]) != 0.0: realar[1] = float(line[44:50])\t#Nominal branch reactance\n\n            if line[0] == 'L':\t\t#If it is an L card\n                if isfloat(line[50:56]):\n                    realar[6] = float("
  },
  {
    "id": "chunk_713",
    "text": "ne[50:56]):\n                    realar[6] = float(line[50:56])/2.0\t\t\t\t\t#Real line shunt at bus IARG end\n                    realar[8] = realar[6]\t\t\t\t\t\t#Real line shunt at bus JARG end\n                if isfloat(line[56:62]): realar[2] = float(line[56:62])*2.0\t\t#Total line charging\n                if isfloat(line[62:66]): realar[10] = float(line[62:66])\t\t#Line's length in miles\n\n            else:\t\t\t#If it is an E card\n                if isfloat(line[50:56]): realar[6] = float(line[50:56])\t\t#Real "
  },
  {
    "id": "chunk_714",
    "text": "ne[50:56]): realar[6] = float(line[50:56])\t\t#Real line shunt at bus IARG end\n                if isfloat(line[56:62]): realar[7] = float(line[56:62])\t\t#Reactive line shunt at bus IARG end\n                if isfloat(line[62:68]): realar[8] = float(line[62:68])\t\t#Real line shunt at bus JARG end\n                if isfloat(line[68:74]): realar[9] = float(line[68:74])\t\t#Reactive line shunt at bus JARG end\n\n            #It seems the format for the date in the file 2006eh-tmp-1.dat is not the same as in"
  },
  {
    "id": "chunk_715",
    "text": "in the file 2006eh-tmp-1.dat is not the same as in the user manual\n            #if line[77:80] != \"   \": intgar[0] = 0\t\t#If there is an out of service date, the status is offline\n\n            if line[32] == ' ': ierr = psspy.branch_data(iarg, jarg, ckt, intgar, realar)\t#The API to load branch data in PSS/E\n\n            elif line[32] == '1':\t#If the branch is the section number 1\n                multi_intgar = [intgar[1], 0, 0, 0, 0, 0, 0, 0, 0, 0]\n                section_nbr = 2\t\t#To search for "
  },
  {
    "id": "chunk_716",
    "text": "]\n                section_nbr = 2\t\t#To search for a section number 2\n                to_bus, dummy_nbr, bus_nbr, bus_str, bus_owner_nbr, owner_nbr, multi_intgar = GetSectionLine(bpa_str_ar, iarg, jarg, section_nbr, dummy_nbr, bus_nbr, bus_str, bus_owner_nbr, owner_nbr, multi_intgar, line[31], base_mva)\n\n                intgar[1] = iarg\t#The metered end is IARG\n                ierr = psspy.branch_data(iarg, to_bus, ckt, intgar, realar)\t#The API to load branch data in PSS/E\n                if mult"
  },
  {
    "id": "chunk_717",
    "text": " load branch data in PSS/E\n                if multi_intgar[1] != 0: ierr = psspy.multi_section_line_data(iarg, jarg, \"&\" + ckt, multi_intgar)\t#The API to load the multi-section line data in PSS/E\t\n\n    return owner_str, owner_nbr, dummy_nbr, bus_nbr, bus_str, bus_owner_nbr\n\n# ----------------------------------------------------------------------------------------------------\ndef GetTCard(bpa_str_ar, owner_str, owner_nbr, bus_str, bus_nbr, bus_owner_nbr, dummy_nbr, base_mva):\n    \"\"\"Gets the two-"
  },
  {
    "id": "chunk_718",
    "text": "er_nbr, dummy_nbr, base_mva):\n    \"\"\"Gets the two-winding transformer data from BPA.\"\"\"\n\n    transformer_str = []\t#An array to contain all lines with two-winding transformers connecting AC buses\n\n    for line in bpa_str_ar:\t\t#This loop is used to fill the transformer data array with each line of transformer data\n        line = line.lstrip()\n        line = line.rstrip('\\n')\n        if line == \"\": continue\t\t#Continue if the line is blank\n        if line[0] == 'T' and line[1] == ' ' or line[0] == '"
  },
  {
    "id": "chunk_719",
    "text": " line[0] == 'T' and line[1] == ' ' or line[0] == 'T' and line[1] == 'P': transformer_str.append(line)\n\n    for line in transformer_str:\n        line = line + ' '*(80-len(line))\t#To pad each line with spaces up to 80 records\n\n        #--------------#\n        #Default values#\n        #--------------#\n        intgar = [1, 0, 1, 0, 0, 0, 33, 0, 0, 0, 0, 0, 2, 1, 1]\n        realari = [0.0, 0.0, basemva, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.1, 0.9, 1.1, 0.9, 0.0, 0.0"
  },
  {
    "id": "chunk_720",
    "text": ", 1.0, 1.0, 0.0, 0.0, 1.1, 0.9, 1.1, 0.9, 0.0, 0.0]\n\n        if line[2] == ' ' and line[6:14].strip() + str(float(line[14:18])) in bus_str and line[19:27].strip() + str(float(line[27:31])) in bus_str:\n\n            if line[3:6] != \"   \" and line[3:6].strip() not in owner_str:\t\t#If the owner is not in the list, add it to the list with a new number\n                owner_nbr = owner_nbr + 1\n                owner_str[line[3:6].strip()] = owner_nbr\t#A new dictionnary entry\n                intgar[2] = "
  },
  {
    "id": "chunk_721",
    "text": "new dictionnary entry\n                intgar[2] = owner_nbr\t\t\t\t#The new owner number\n            elif line[3:6] != \"   \" and line[3:6].strip() in owner_str:\n                intgar[2] =  owner_str[line[3:6].strip()]\t#Get the owner number\n            elif line[3:6] == \"   \":\n                intgar[2] = 1\t\t\t\t\t#The default owner\n\n            iarg = bus_str[line[6:14].strip() + str(float(line[14:18]))]\t\t#From bus\n            jarg = bus_str[line[19:27].strip() + str(float(line[27:31]))]\t\t#To bus\n\n    "
  },
  {
    "id": "chunk_722",
    "text": ".strip() + str(float(line[27:31]))]\t\t#To bus\n\n            intgar[8] = iarg\t\t\t\t\t\t#The winding one side\n\n            if isfloat(line[14:18]): realari[4] = float(line[14:18])\t#Winding one nominal voltage\n\n            if line[18] == '1': intgar[1] = iarg\t#The metered end is IARG\n            elif line[18] == '2': intgar[1] = jarg\t#The metered end is JARG\n            elif line[18] == ' ':\t\t\t#If the metered end is left blank, BPA chooses\n                if bus_owner_nbr[iarg] == bus_owner_nbr[jarg]: in"
  },
  {
    "id": "chunk_723",
    "text": " if bus_owner_nbr[iarg] == bus_owner_nbr[jarg]: intgar[1] = iarg\t\t#If both ends have the same owner, IARG is the metered end\n                elif bus_owner_nbr[iarg] == intgar[2]: intgar[1] = jarg\t\t\t#Else the end that has a different owner from the line is the metered end\n                elif bus_owner_nbr[jarg] == intgar[2]: intgar[1] = iarg\n\n            if isfloat(line[27:31]): realari[7] = float(line[27:31])\t#Winding two nominal voltage\n\n            if isfloat(line[33:37]): realari[8] = float"
  },
  {
    "id": "chunk_724",
    "text": "       if isfloat(line[33:37]): realari[8] = float(line[33:37])\t#The Rate A in MVA\n\n            if line[31] != ' ': ckt = line[31]\t\t#The circuit identifier\n            else: ckt = '1'\t\t\t\t#If none is mentionned, the default is 1\n\n            if isfloat(line[38:44]): realari[0] = float(line[38:44])\t\t\t#Nominal transformer resistance\n            if isfloat(line[44:50]) and float(line[44:50]) != 0.0: realari[1] = float(line[44:50])\t#Nominal transformer reactance\n\n            if isfloat(line[50:56]): "
  },
  {
    "id": "chunk_725",
    "text": "r reactance\n\n            if isfloat(line[50:56]): realari[15] = float(line[50:56])\t\t#The magnetizing conductance\n\n            if isfloat(line[56:62]): realari[16] = float(line[56:62])\t\t#The magnetizing susceptance\n\n            if line[1] == ' ':\n                if isfloat(line[62:67]): realari[3] = float(line[62:67])\t#The winding one ratio/voltage\n                if isfloat(line[67:72]): realari[6] = float(line[67:72])\t#The winding two ratio/voltage\n\n            else:\n                if isfloat("
  },
  {
    "id": "chunk_726",
    "text": "age\n\n            else:\n                if isfloat(line[62:67]): realari[5] = float(line[62:67])\t#The winding one phase shift angle\n                realari[3] = realari[4]\t\t\t\t\t\t#The winding one ratio/voltage\n                realari[6] = realari[7]\t\t\t\t\t\t#The winding two ratio/voltage\n\n            #It seems the format for the date in the file 2006eh-tmp-1 is not the same as in the user manual\n            #if line[77:80] != \"   \": intgar[0] = 0\t\t#If there is an out of service date, the status is off"
  },
  {
    "id": "chunk_727",
    "text": "there is an out of service date, the status is offline\n\n            intgar[11], intgar[9], realari[17], realari[18], intgar[6], realari[19], realari[20] = GetRCard(bpa_str_ar, line[6:14].strip() + str(float(line[14:18])), line[19:27].strip() + str(float(line[27:31])), bus_str)\n\n            if line[32] == ' ': ierr, realaro  = psspy.two_winding_data(iarg, jarg, ckt, intgar, realari, \"\")\t#The API to load transformer data in PSS/E\n\n            elif line[32] == '1':\t#If the transformer is section nu"
  },
  {
    "id": "chunk_728",
    "text": "line[32] == '1':\t#If the transformer is section number 1\n                multi_intgar = [intgar[1], 0, 0, 0, 0, 0, 0, 0, 0, 0]\n                section_nbr = 2\t\t#To search for section number 2\n                to_bus, dummy_nbr, bus_nbr, bus_str, bus_owner_nbr, owner_nbr, multi_intgar = GetSectionLine(bpa_str_ar, iarg, jarg, section_nbr, dummy_nbr, bus_nbr, bus_str, bus_owner_nbr, owner_nbr, multi_intgar, line[31], base_mva)\n\n                intgar[1] = iarg\t#The metered end is IARG\n              "
  },
  {
    "id": "chunk_729",
    "text": "[1] = iarg\t#The metered end is IARG\n                ierr, realaro  = psspy.two_winding_data(iarg, to_bus, ckt, intgar, realari, \"\")\t\t#The API used to load two-winding data in PSS/E\n                if multi_intgar[1] != 0: ierr = psspy.multi_section_line_data(iarg, jarg, \"&\" + ckt, multi_intgar)\t#The API used to load multi-section line in PSS/E\n\n    return owner_str, owner_nbr, bus_nbr, bus_str, bus_owner_nbr\n\n# -------------------------------------------------------------------------------------"
  },
  {
    "id": "chunk_730",
    "text": "-----------------------------------------------------------------\ndef GetPlusCard(bpa_str_ar, load_id_ar, machine_id_ar, bus_str, owner_str, owner_nbr, base_mva, scale_str, bus_zone_str):\n    \"\"\"Gets the bus supplement data from BPA.\"\"\"\n\n    for line in bpa_str_ar:\n        line = line.lstrip()\n        line = line.rstrip('\\n')\n        if line == \"\": continue\t\t#Continue if the line is blank\n\n        #--------------#\n        #Default values#\n        #--------------#\n        load_intgar = [1, 1, 1, "
  },
  {
    "id": "chunk_731",
    "text": " #--------------#\n        load_intgar = [1, 1, 1, 1]\n        machine_intgar = [0, 0, 0, 0, 0]\n        load_realar = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n        machine_realar = [0.0, 0.0, 9999.0, -9999.0, 9999.0, -9999.0, base_mva, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]\n        plant_realar = [1.0, 1.0]\n\n        if line[0] == '+' and line[2] == ' ':\t#If it is a + card\n            line = line + ' '*(77-len(line))\t#To pad each line with spaces up to 77 records\n\n            if line[3:6] != \"   \" a"
  },
  {
    "id": "chunk_732",
    "text": "to 77 records\n\n            if line[3:6] != \"   \" and line[3:6].strip() not in owner_str:\t#If the owner is not in the list, add it to the list with a new number\n                owner_nbr = owner_nbr + 1\n                owner_str[line[3:6].strip()] = owner_nbr\t#A new dictionnary entry\n                load_intgar[3] = owner_nbr\t\t\t#The new owner number\n            elif line[3:6] != \"   \" and line[3:6].strip() in owner_str:\n                load_intgar[3] =  owner_str[line[3:6].strip()]\t#Get the owner"
  },
  {
    "id": "chunk_733",
    "text": "[3] =  owner_str[line[3:6].strip()]\t#Get the owner number\n            elif line[3:6] == \"   \":\n                load_intgar[3] = 1\t\t\t\t#The default owner\n\n            iarg = bus_str[line[6:14].strip() + str(float(line[14:18]))]\t#The from bus number\n\n            if line[18:20] == \"*I\" or line[18:20] == \"01\":\t\t\t#If it is a constant current load\n                if isfloat(line[20:25]): load_realar[2] = float(line[20:25])\t#Constant current load P\n                if isfloat(line[25:30]): load_realar[3]"
  },
  {
    "id": "chunk_734",
    "text": "           if isfloat(line[25:30]): load_realar[3] = float(line[25:30])\t#Constant current load Q\n            elif line[18:20] == \"*P\" or line[18:20] == \"02\":\t\t\t#If it is a constant power load\n                if isfloat(line[20:25]): load_realar[0] = float(line[20:25])\t#Constant power load P\n                if isfloat(line[25:30]): load_realar[1] = float(line[25:30])\t#Constant power load Q\n\n            if isfloat(line[30:34]): load_realar[4] = float(line[30:34])\t#Constant impedance load P\n       "
  },
  {
    "id": "chunk_735",
    "text": "at(line[30:34])\t#Constant impedance load P\n            if isfloat(line[34:38]): load_realar[5] = float(line[34:38])\t#Constant impedance load Q\n\n            if isfloat(line[42:47]): machine_realar[0] = float(line[42:47])\t#Generation P\n            if isfloat(line[47:52]): machine_realar[1] = float(line[47:52])\t#Generation Q\n\n            if line[1] != 'A' and line[1] != 'F' and line[1] != 'I' and line[1] != 'P': type_code = 'N'\t#Non-industrial load or generation\n            elif line[1] == 'F' or l"
  },
  {
    "id": "chunk_736",
    "text": "or generation\n            elif line[1] == 'F' or line[1] == 'I' or line[1] == 'P': type_code = 'I'\t\t\t#Industrial load\n            elif line[1] == 'A' and line[18:20] == \"*I\" or line[18:20] == \"01\": type_code = 'X'\t\t#If it is a +A card with constant current load\n            elif line[1] == 'A' and line[18:20] == \"*P\" or line[18:20] == \"02\": type_code = 'Y'\t\t#If is is a +A card with constant power load\n\n            scale_ar = GetScaleData(scale_str, line[3:6].strip(), bus_zone_str[iarg], type_code"
  },
  {
    "id": "chunk_737",
    "text": ", line[3:6].strip(), bus_zone_str[iarg], type_code)\t#To get the scale factors\n\n            load_realar[0] = load_realar[0] * scale_ar[0]\t\t#To scale the constant power load P\n            load_realar[1] = load_realar[1] * scale_ar[1]\t\t#To scale the constant power load Q\n            load_realar[2] = load_realar[2] * scale_ar[2]\t\t#To scale the constant current load P\n            load_realar[3] = load_realar[3] * scale_ar[3]\t\t#To scale the constant current load Q\n            load_realar[4] = load_rea"
  },
  {
    "id": "chunk_738",
    "text": "rrent load Q\n            load_realar[4] = load_realar[4] * scale_ar[4]\t\t#To scale the constant impedance load P\n            load_realar[5] = load_realar[5] * scale_ar[5]\t\t#To scale the constant impedance load Q\n            machine_realar[0] = machine_realar[0] * scale_ar[6]\t\t#To scale the generation P\n            machine_realar[1] = machine_realar[1] * scale_ar[7]\t\t#To scale the generation Q\n\n            if load_realar[0] != 0.0 or load_realar[1] != 0.0 or load_realar[2] != 0.0 or load_realar[3]"
  },
  {
    "id": "chunk_739",
    "text": " != 0.0 or load_realar[2] != 0.0 or load_realar[3] != 0.0 or load_realar[4] != 0.0 or load_realar[5] != 0.0:\n                load_id_ar[iarg] = load_id_ar[iarg] + 1\t\t#To increment the load CKT\n                ierr = psspy.load_data(iarg, str(load_id_ar[iarg]), load_intgar, load_realar)\t#Loads the load data in PSS/E\n\n            if machine_realar[0] != 0.0 or machine_realar[1] != 0.0:\t#If there is a generator\n                machine_id_ar[iarg] = machine_id_ar[iarg] + 1\t\t#To increment the machine"
  },
  {
    "id": "chunk_740",
    "text": "machine_id_ar[iarg] + 1\t\t#To increment the machine CKT\n                machine_intgar[0] = 1\t\t\t\t\t#The machine status\n                machine_intgar[1] = owner_nbr\t\t\t\t#The owner number\n                if machine_id_ar[iarg] == 1:\t\t\t\t#If it is the first generator on this bus\n                    ierr = psspy.plant_data(iarg, 0, plant_realar)\t#First load the plant data\n                ierr = psspy.machine_data(iarg, str(machine_id_ar[iarg]), machine_intgar, machine_realar)\t#After add the generator d"
  },
  {
    "id": "chunk_741",
    "text": "intgar, machine_realar)\t#After add the generator data\n\n    return owner_str, owner_nbr\n\n# ----------------------------------------------------------------------------------------------------\ndef GetICard(bpa_str_ar, area_str, area_slack_nbr):\n    \"\"\"Gets the inter-area transfer data from BPA.\"\"\"\n\n    inter_nbr = 48\t\t\t#In order to start to the character '1' in the transfer ID\n\n    for line in bpa_str_ar:\t\t#This loop is used to get the inter-area transfer data\n        line = line.lstrip()\n        "
  },
  {
    "id": "chunk_742",
    "text": "ransfer data\n        line = line.lstrip()\n        line = line.rstrip('\\n')\n        if line == \"\": continue\t\t#Continue if it is a blank line\n\n        #--------------#\n        #Default values#\n        #--------------#\n        ia = 1\t\t\t\t#Default area number\n        ja = 1\t\t\t\t#Default area number\n        realar = [0.0]\t\t\t#Default transfer\n\n        if line[0] == 'I' and line[2] == ' ':\t\t#If it is an I card\n            line = line + ' '*(34-len(line))\t\t#To pad each line with spaces up to 34 records\n  "
  },
  {
    "id": "chunk_743",
    "text": "\t#To pad each line with spaces up to 34 records\n            for (x,y), z in area_str.items():\n                if x == line[3:13].strip(): ia = z\t#The 'from' area number\n                if x == line[14:24].strip(): ja = z\t#The 'to' area number\n\n            if isfloat(line[26:34]): realar[0] = float(line[26:34])\t#The amount of MW in the transfer\n\n            inter_nbr = inter_nbr + 1\t#To increment the transfer ID\n\n            if inter_nbr == 123:\t#After the 'Z' character, PSS/E do not accept the o"
  },
  {
    "id": "chunk_744",
    "text": "After the 'Z' character, PSS/E do not accept the other ASCII characters\n                psspy.alert(\" WARNING: MAXIMUM NUMBER OF INTER-AREA TRANSFERS REACHED\\n\")\n                return\n\n            ierr = psspy.transfer_data(1, ia, ja, chr(inter_nbr), realar[0])\t#The transfer data API\n\n# ----------------------------------------------------------------------------------------------------\ndef GetRZCard(bpa_str_ar):\n    \"\"\"Gets the line series compensation from BPA.\"\"\"\n\n    for line in bpa_str_ar:\n"
  },
  {
    "id": "chunk_745",
    "text": "nsation from BPA.\"\"\"\n\n    for line in bpa_str_ar:\n        line = line.lstrip()\n        line = line.rstrip('\\n')\n        if line == \"\": continue\t\t#Continue if the line is blank\n\n        if line[0] == 'R' and line[1] == 'Z':\t#If it is an RZ card\n            line = line + ' '*(60-len(line))\t#To pad each line with spaces up to 60 records\n\n            #Found no equivalent way to model this series compensation device in PSS/E\n            psspy.alert(\" WARNING: THE RZ CARD GOING FROM BUS [\" + line[6:18"
  },
  {
    "id": "chunk_746",
    "text": "WARNING: THE RZ CARD GOING FROM BUS [\" + line[6:18] + \"] TO BUS [\" + line[19:31] + \"] CANNOT BE IMPORTED\\n\")\n\n# ----------------------------------------------------------------------------------------------------\ndef GetZCard(bpa_str_ar, zone_str):\n    \"\"\"Gets the renamed zone names from BPA.\"\"\"\n\n    zone_str_temp = {}\t\t#A dictionnary containing the modified zone names\n\n    for line in bpa_str_ar:\n        line = line.lstrip()\n        line = line.rstrip('\\n')\n        if line == \"\": continue\n\n    "
  },
  {
    "id": "chunk_747",
    "text": "rstrip('\\n')\n        if line == \"\": continue\n\n        if line[0] == 'Z':\n            line = line + ' '*(77-len(line))\t#To pad each line with spaces up to 77 records\n\n            for x, y in zone_str.items():\n                if x == line[3:5].strip(): zone_str_temp[line[5:7].strip()] = y\n                elif x == line[8:10].strip(): zone_str_temp[line[10:12].strip()] = y\n                elif x == line[13:15].strip(): zone_str_temp[line[15:17].strip()] = y\n                elif x == line[18:20].str"
  },
  {
    "id": "chunk_748",
    "text": "p()] = y\n                elif x == line[18:20].strip(): zone_str_temp[line[20:22].strip()] = y\n                elif x == line[23:25].strip(): zone_str_temp[line[25:27].strip()] = y\n                elif x == line[28:30].strip(): zone_str_temp[line[30:32].strip()] = y\n                elif x == line[33:35].strip(): zone_str_temp[line[35:37].strip()] = y\n                elif x == line[38:40].strip(): zone_str_temp[line[40:42].strip()] = y\n                elif x == line[43:45].strip(): zone_str_temp["
  },
  {
    "id": "chunk_749",
    "text": "     elif x == line[43:45].strip(): zone_str_temp[line[45:47].strip()] = y\n                elif x == line[48:50].strip(): zone_str_temp[line[50:52].strip()] = y\n                elif x == line[53:55].strip(): zone_str_temp[line[55:57].strip()] = y\n                elif x == line[58:60].strip(): zone_str_temp[line[60:62].strip()] = y\n                elif x == line[63:65].strip(): zone_str_temp[line[65:67].strip()] = y\n                elif x == line[68:70].strip(): zone_str_temp[line[70:72].strip()]"
  },
  {
    "id": "chunk_750",
    "text": "68:70].strip(): zone_str_temp[line[70:72].strip()] = y\n                elif x == line[73:75].strip(): zone_str_temp[line[75:77].strip()] = y\n                else: zone_str_temp[x] = y\n\n            zone_str.clear()\t\t\t#To clear the dictionnary\n            zone_str.update(zone_str_temp)\t#To copy the contents of the temporary dictionnary\n\n    return zone_str\n\n# ----------------------------------------------------------------------------------------------------\ndef GetDZCard(bpa_str_ar, zone_str):\n  "
  },
  {
    "id": "chunk_751",
    "text": "----------\ndef GetDZCard(bpa_str_ar, zone_str):\n    \"\"\"Gets the deleted zone names from BPA and remove connected buses and equipment.\"\"\"\n\n    for line in bpa_str_ar:\n        line = line.lstrip()\n        line = line.rstrip('\\n')\n        if line == \"\": continue\t\t#Continue if the line is blank\n\n        if line[0] == 'D' and line[1] == 'Z':\t#If it is a DZ card\n            line = line + ' '*(5-len(line))\t#To pad each line with spaces up to 5 records\n            if line[3:5].strip() in zone_str:\n     "
  },
  {
    "id": "chunk_752",
    "text": "           if line[3:5].strip() in zone_str:\n                ierr = psspy.bsys(0, 0, [0.0,0.0], 0, [], 0, [], 0, [], 1, [zone_str[line[3:5].strip()]])\t#A bus subsystem of this zone\n                ierr = psspy.extr(0, 0, [1, 0])\t\t\t\t\t\t#To delete this subsystem\n                ierr = psspy.bsys(0, 1, [0.0, 9999.], 0, [], 0, [], 0, [], 0, [])\t#To bring back the original unfiltered view\n                del zone_str[line[3:5].strip()]\t\t\t\t\t\t#To delete the zone\n\n            else: psspy.alert(\" WARNING:"
  },
  {
    "id": "chunk_753",
    "text": "the zone\n\n            else: psspy.alert(\" WARNING: THE ZONE [\" +  line[3:5].strip() + \"] SPECIFIED IN THE DZ CARD CANNOT BE FOUND\\n\")\t#If the zone is not found\n\n    return zone_str\n\n# ----------------------------------------------------------------------------------------------------\ndef GetDCOwners(bpa_str_ar, from_bus, to_bus):\n    \"\"\"Gets the owners of the DC buses for the two-terminal DC lines in BPA.\"\"\"\n\n    owner_1 = \"\"\t#The owner of bus 'converter 1'\n    owner_2 = \"\"\t#The owner of bus 'co"
  },
  {
    "id": "chunk_754",
    "text": "onverter 1'\n    owner_2 = \"\"\t#The owner of bus 'converter 2'\n\n    for line in bpa_str_ar:\n        line = line.lstrip()\n        line = line.rstrip('\\n')\n        if line == \"\": continue\t\t#Continue if the line is blank\n\n        if line[0] == 'B' and line[1] == 'D' and line[2] == ' ':\t#If it is a BD card\n            if from_bus == (line[6:14].strip() + str(float(line[14:18]))): owner_1 = line[3:6].strip()\n            elif to_bus == (line[6:14].strip() + str(float(line[14:18]))): owner_2 = line[3:6]."
  },
  {
    "id": "chunk_755",
    "text": ") + str(float(line[14:18]))): owner_2 = line[3:6].strip()\n\n    return owner_1, owner_2\n\n# ----------------------------------------------------------------------------------------------------\ndef GetTwoTermConv(bpa_str_ar, from_bus, to_bus, dc_line_nbr, flow_flag, bus_str):\n    \"\"\"Gets the converter data for two-terminal lines in BPA.\"\"\"\n\n    #--------------#\n    #Default values#\n    #--------------#\n    intgar_1 = [0, 0, 0, 0, 0]\n    realari_1 = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,"
  },
  {
    "id": "chunk_756",
    "text": "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n    intgar_2 = [0, 0, 0, 0, 0]\n    realari_2 = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n\n    for line in bpa_str_ar:\n        line = line.lstrip()\n        line = line.rstrip('\\n')\n        if line == \"\": continue\t\t\t#Continue if the line is blank\n\n        if line[0] == 'B' and line[1] == 'D' and line[2] == ' ':\t#If it is a BD card\n            line = line + ' '*(62-len(line))\t#To pad each line with spaces up to 62 records\n\n      "
  },
  {
    "id": "chunk_757",
    "text": "pad each line with spaces up to 62 records\n\n            if from_bus == line[6:14].strip() + str(float(line[14:18])):\t#If the bus is converter 1\n                if flow_flag: cnvflg_1 = 1\t#If the flow is positive, the converter 1 is a rectifier\n                else: cnvflg_1 = 2\t\t#If the flow is negative, the converter 1 is an inverter\n\n                if line[50:58].strip() + str(float(line[58:62])) in bus_str: intgar_1[0] = bus_str[line[50:58].strip() + str(float(line[58:62]))]\t#Converter 1 bus"
  },
  {
    "id": "chunk_758",
    "text": "trip() + str(float(line[58:62]))]\t#Converter 1 bus number\n\n                if isint(line[23:25]): intgar_1[1] = int(line[23:25])\t\t#Number of bridges in series\n                if isfloat(line[30:35]): realari_1[0] = float(line[30:35])\t#Minimum firing angle\n                if isfloat(line[35:40]): realari_1[1] = float(line[35:40])\t#Maximum firing angle\n\n            elif to_bus == line[6:14].strip() + str(float(line[14:18])):\t#If the bus is converter 2\n                if flow_flag: cnvflg_2 = 2\t#If"
  },
  {
    "id": "chunk_759",
    "text": "r 2\n                if flow_flag: cnvflg_2 = 2\t#If the flow is positive, the converter 2 is an inverter\n                else: cnvflg_2 = 1\t\t#If the flow is negative, the converter 2 is a rectifier\n\n                if line[50:58].strip() + str(float(line[58:62])) in bus_str: intgar_2[0] = bus_str[line[50:58].strip() + str(float(line[58:62]))]\t#Converter 2 bus number\n\n                if isint(line[23:25]): intgar_2[1] = int(line[23:25])\t\t#Number of bridges in series\n                if isfloat(line"
  },
  {
    "id": "chunk_760",
    "text": " bridges in series\n                if isfloat(line[30:35]): realari_2[0] = float(line[30:35])\t#Minimum firing angle\n                if isfloat(line[35:40]): realari_2[1] = float(line[35:40])\t#Maximum firing angle\n\n        if line[0] == 'T' and line[1] == ' ' and line[2] == ' ':\t\t#If it is a T card\n            line = line + ' '*(80-len(line))\t#To pad each line with spaces up to 80 records\n\n            if from_bus == line[6:14].strip() + str(float(line[14:18])) or from_bus == line[19:27].strip() +"
  },
  {
    "id": "chunk_761",
    "text": "line[14:18])) or from_bus == line[19:27].strip() + str(float(line[27:31])):\n                if isfloat(line[38:44]): realari_1[2] = float(line[38:44])\t#Commutating resistance\n                if isfloat(line[44:50]): realari_1[3] = float(line[44:50])\t#Commutating reactance\n\n                realari_1[4] = float(line[14:18])\t\t\t\t#Primary base voltage\n\n                if isfloat(line[67:72]): realari_1[5] = float(line[67:72])\t#Transformer ratio\n                if isfloat(line[62:67]): realari_1[6] = "
  },
  {
    "id": "chunk_762",
    "text": "          if isfloat(line[62:67]): realari_1[6] = float(line[62:67])\t#Tap setting\n\n            elif to_bus == line[6:14].strip() + str(float(line[14:18])) or to_bus == line[19:27].strip() + str(float(line[27:31])):\n                if isfloat(line[38:44]): realari_2[2] = float(line[38:44])\t#Commutating resistance\n                if isfloat(line[44:50]): realari_2[3] = float(line[44:50])\t#Commutating reactance\n\n                realari_2[4] = float(line[14:18])\t\t\t\t#Primary base voltage\n\n           "
  },
  {
    "id": "chunk_763",
    "text": "line[14:18])\t\t\t\t#Primary base voltage\n\n                if isfloat(line[67:72]): realari_2[5] = float(line[67:72])\t#Transformer ratio\n                if isfloat(line[62:67]): realari_2[6] = float(line[62:67])\t#Tap setting\n\n        if line[0] == 'R' and line[1] == ' ' and line[2] == ' ':\t\t#If it is a R card\n            line = line + ' '*(67-len(line))\t#To pad each line with spaces up to 67 records\n\n            if from_bus == line[6:14].strip() + str(float(line[14:18])) or from_bus == line[19:27].s"
  },
  {
    "id": "chunk_764",
    "text": "r(float(line[14:18])) or from_bus == line[19:27].strip() + str(float(line[27:31])):\n                if isfloat(line[45:50]): realari_1[7] = float(line[45:50])\t#Maximum tap setting\n                if isfloat(line[50:55]): realari_1[8] = float(line[50:55])\t#Minimum tap setting\n                if isint(line[55:57]) and int(line[55:57]) != 0: realari_1[9] = (realari_1[7] - realari_1[8])/int(line[55:57])\t#Tap step\n\n            elif to_bus == line[6:14].strip() + str(float(line[14:18])) or to_bus == l"
  },
  {
    "id": "chunk_765",
    "text": "].strip() + str(float(line[14:18])) or to_bus == line[19:27].strip() + str(float(line[27:31])):\n                if isfloat(line[45:50]): realari_2[7] = float(line[45:50])\t#Maximum tap setting\n                if isfloat(line[50:55]): realari_2[8] = float(line[50:55])\t#Minimum tap setting\n                if isint(line[55:57]) and int(line[55:57]) != 0: realari_2[9] = (realari_2[7] - realari_2[8])/int(line[55:57])\t#Tap step\n\n    ierr,realaro = psspy.two_term_dc_convr_data(cnvflg_1, dc_line_nbr, int"
  },
  {
    "id": "chunk_766",
    "text": ".two_term_dc_convr_data(cnvflg_1, dc_line_nbr, intgar_1, realari_1, \"\")\t#To load the converter 1 in PSS/E\n    ierr,realaro = psspy.two_term_dc_convr_data(cnvflg_2, dc_line_nbr, intgar_2, realari_2, \"\")\t#To load the converter 2 in PSS/E\n\n# ----------------------------------------------------------------------------------------------------\ndef GetTwoTermLine(bpa_str_ar, bus_str):\n    \"\"\"Gets the two-terminal DC line data from BPA.\"\"\"\n\n    dc_line_nbr = 0\t#The two-terminal DC line number\n\n    for l"
  },
  {
    "id": "chunk_767",
    "text": "br = 0\t#The two-terminal DC line number\n\n    for line in bpa_str_ar:\n        line = line.lstrip()\n        line = line.rstrip('\\n')\n        if line == \"\": continue\t\t#Continue if the line is blank\n\n        if line[0] == 'L' and line[1] == 'D' and line[2] == ' ':\t#If it is a LD card\n            line = line + ' '*(78-len(line))\t#To pad each line with spaces up to 78 records\n\n            #--------------#\n            #Default values#\n            #--------------#\n            intgar = [1, 0]\n           "
  },
  {
    "id": "chunk_768",
    "text": "---------#\n            intgar = [1, 0]\n            realari = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n\n            dc_line_nbr = dc_line_nbr + 1\t#To increment the DC line number\n\n            if isfloat(line[56:61]): realari[0] = float(line[56:61])\t#Scheduled power demand\n            if isfloat(line[61:66]): realari[1] = float(line[61:66])\t#Scheduled DC voltage\n            if isfloat(line[37:43]): realari[4] = float(line[37:43])\t#DC line resistance\n\n            if line[55] == 'I': realari[5] = 0\t"
  },
  {
    "id": "chunk_769",
    "text": "e\n\n            if line[55] == 'I': realari[5] = 0\t\t\t#Compounding resistance = 0 if Vdc is controlled at the inverter\n            elif line[55] == 'R': realari[5] = realari[4]\t#Compounding resistance = Rdc if Vdc is controlled at the rectifier\n\n            if line[18] == '1':\t\t\t\t#If the metered side is converter 1\n                if realari[0] >= 0.0: metrar = 'R'\t#The metered side is the rectifier if the flow is positive\n                else: metrar = 'I'\t\t\t#The metered side is the inverter if t"
  },
  {
    "id": "chunk_770",
    "text": "rar = 'I'\t\t\t#The metered side is the inverter if the flow is negative\n\n            elif line[18] == '2':\t\t\t#If the metered side is converter 2\n                if realari[0] >= 0.0: metrar = 'I'\t#The metered side is the inverter if the flow is positive\n                else: metrar = 'R'\t\t\t#The metered side is the rectifier if the flow is negative\n\n            elif line[18] == ' ':\t\t\t#If the metered side is left blank, BPA chooses\n                owner_1, owner_2 = GetDCOwners(bpa_str_ar, line[6:1"
  },
  {
    "id": "chunk_771",
    "text": "wner_1, owner_2 = GetDCOwners(bpa_str_ar, line[6:14].strip() + str(float(line[14:18])), line[19:27].strip() + str(float(line[27:31])))\n                if owner_1 == owner_2:\t\t#If both DC buses have the same owner\n                    if realari[0] >= 0.0: metrar = 'R'\t#The metered side is the rectifier if the flow is positive\n                    else: metrar = 'I'\t\t\t#The metered side is the inverter if the flow is negative\n                elif owner_1 == line[3:6].strip():  #If the owner of conve"
  },
  {
    "id": "chunk_772",
    "text": "er_1 == line[3:6].strip():  #If the owner of converter 1 is the same as the line\n                    if realari[0] >= 0.0: metrar = 'I'\t#The metered side is the inverter if the flow is positive\n                    else: metrar = 'R'\t\t\t#The metered side is the rectifier if the flow is negative\n                elif owner_2 == line[3:6].strip():  #If the owner of converter 2 is the same as the line\n                    if realari[0] >= 0.0: metrar = 'R'\t#The metered side is the rectifier if the flow"
  },
  {
    "id": "chunk_773",
    "text": "'R'\t#The metered side is the rectifier if the flow is positive\n                    else: metrar = 'I'\t\t\t#The metered side is the inverter if the flow is negative\n\n            ierr, realaro = psspy.two_terminal_dc_line_data(dc_line_nbr, intgar, realari, metrar)\t#The API to load two-terminal DC line in PSS/E\n\n            GetTwoTermConv(bpa_str_ar, line[6:14].strip() + str(float(line[14:18])), line[19:27].strip() + str(float(line[27:31])), dc_line_nbr, realari[0] >= 0.0, bus_str)\t#To get the 2 conv"
  },
  {
    "id": "chunk_774",
    "text": "br, realari[0] >= 0.0, bus_str)\t#To get the 2 converters data\n\n# ----------------------------------------------------------------------------------------------------\ndef GetConvTrans(bpa_str_ar, conv_intgar, conv_realari, bus_name):\n    \"\"\"Gets the T and R card corresponding to the converter bus specified.\"\"\"\n\n    for line in bpa_str_ar:\n        line = line.lstrip()\n        line = line.rstrip('\\n')\n        if line == \"\": continue\t\t#Continue if the line is blank\n\n        if line[0] == 'T' and lin"
  },
  {
    "id": "chunk_775",
    "text": "e line is blank\n\n        if line[0] == 'T' and line[1] == ' ' and line[2] == ' ':\t#If it is a T card\n            line = line + ' '*(80-len(line))\t#To pad each line with spaces up to 80 records\n\n            if bus_name == line[6:14].strip() + str(float(line[14:18])) or bus_name == line[19:27].strip() + str(float(line[27:31])):\n                if isfloat(line[67:72]): conv_realari[3] = float(line[67:72])\t#Transformer ratio\n                if isfloat(line[38:44]): conv_realari[4] = float(line[38:44"
  },
  {
    "id": "chunk_776",
    "text": "t(line[38:44]): conv_realari[4] = float(line[38:44])\t#Commutating resistance\n                if isfloat(line[44:50]): conv_realari[5] = float(line[44:50])\t#Commutating reactance\n\n                conv_realari[6] = float(line[14:18])\t\t\t\t#Winding one base voltage\n\n                if isfloat(line[62:67]): conv_realari[7] = float(line[62:67])\t#Tap setting\n\n        if line[0] == 'R' and line[1] == ' ' and line[2] == ' ':\t\t#If it is a R card\n            line = line + ' '*(67-len(line))\t#To pad each lin"
  },
  {
    "id": "chunk_777",
    "text": " line = line + ' '*(67-len(line))\t#To pad each line with spaces up to 67 records\n\n            if bus_name == line[6:14].strip() + str(float(line[14:18])) or bus_name == line[19:27].strip() + str(float(line[27:31])):\n                if isfloat(line[45:50]): conv_realari[8] = float(line[45:50])\t#Maximum tap setting\n                if isfloat(line[50:55]): conv_realari[9] = float(line[50:55])\t#Minimum tap setting\n                if isint(line[55:57]) and int(line[55:57]) != 0: conv_realari[10] = (c"
  },
  {
    "id": "chunk_778",
    "text": ") and int(line[55:57]) != 0: conv_realari[10] = (conv_realari[8] - conv_realari[9])/int(line[55:57])\t#Tap step\n\n    return conv_intgar, conv_realari\n\n# ----------------------------------------------------------------------------------------------------\ndef GetMultiTermConv(bpa_str_ar, bus_str, zone_str, zone_nbr, owner_str, owner_nbr, bus_nbr, area_str, area_slack_nbr, area_nbr):\n    \"\"\"Gets the converter data for multi-terminal lines and creates DC buses.\"\"\"\n\n    dc_bus_nbr = 0\t\t#The DC bus num"
  },
  {
    "id": "chunk_779",
    "text": " DC buses.\"\"\"\n\n    dc_bus_nbr = 0\t\t#The DC bus number for multi-terminal lines\n    dc_bus_str = {}\t\t#The dictionnary to contain DC bus names and numbers\n    dc_bus_owner = [\"DEFAULT\"]\t#An array of the owners of each DC bus\n\n    for line in bpa_str_ar:\n        line = line.lstrip()\n        line = line.rstrip('\\n')\n        if line == \"\": continue\t\t#Continue if the line is blank\n\n        if line[0] == 'B' and line[1] == 'M' and line[2] == ' ':\t#If it is a BM card\n            line = line + ' '*(80-le"
  },
  {
    "id": "chunk_780",
    "text": " is a BM card\n            line = line + ' '*(80-len(line))\t#To pad each line with spaces up to 80 records\n            \n            #--------------#\n            #Default values#\n            #--------------#\n            conv_intgar = [0, 0, 0, 0]\n            conv_realari = [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.5, 0.51, 0.00625, 0.0, 1.0]\n            bus_intgar = [0, 0, 0, 0, 0]\n            bus_realari = 0.0\n\n            if line[6:14].strip() + str(float(line[14:18])) not in dc_bus_str:\t\t#If t"
  },
  {
    "id": "chunk_781",
    "text": " str(float(line[14:18])) not in dc_bus_str:\t\t#If the bus is not in the list, add it\n                dc_bus_nbr = dc_bus_nbr + 1\n                dc_bus_str[line[6:14].strip() + str(float(line[14:18]))] = dc_bus_nbr\t\t#A new dictionnary entry\n            else:\n                dc_bus_nbr = dc_bus_str[line[6:14].strip() + str(float(line[14:18]))]\t\t#Get the bus number\n\n            if line[3:6] != \"   \" and line[3:6].strip() not in owner_str:\t#If the owner is not in the list, add it to the list with a "
  },
  {
    "id": "chunk_782",
    "text": "ner is not in the list, add it to the list with a new number\n                owner_nbr = owner_nbr + 1\n                owner_str[line[3:6].strip()] = owner_nbr\t\t#A new dictionnary entry\n                bus_intgar[3] = owner_nbr\t\t\t\t#The new owner number\n            elif line[3:6] != \"   \" and line[3:6].strip() in owner_str:\n                bus_intgar[3] =  owner_str[line[3:6].strip()]\t\t#Get the owner number\n            elif line[3:6] == \"   \":\n                bus_intgar[3] = 1\t\t\t\t\t#The default ow"
  },
  {
    "id": "chunk_783",
    "text": "             bus_intgar[3] = 1\t\t\t\t\t#The default owner\n\n            dc_bus_owner.insert(dc_bus_nbr + 1, line[3:6].strip())\t#Insert the owner number of this bus\n\n            if line[18:20] != \"  \":\n                if line[18:20].strip() not in zone_str:\t\t#If the zone is not in the list, add it\n                    zone_nbr = zone_nbr + 1\n                    zone_str[line[18:20].strip()] = zone_nbr\t\t#A new dictionnary entry\n                    bus_intgar[2] = zone_nbr\t\t\t\t#The new zone number\n       "
  },
  {
    "id": "chunk_784",
    "text": "tgar[2] = zone_nbr\t\t\t\t#The new zone number\n                else:\n                    bus_intgar[2] =  zone_str[line[18:20].strip()]\t#Get the zone number\n\n            area_flag, bus_flag, area_nbr, swing_bus_nbr, bus_str, area_str, area_slack_nbr = GetACard(bpa_str_ar, line[18:20].strip(), bus_str, bus_nbr, area_str, area_slack_nbr, area_nbr)\n\n            if area_flag == True:\t\t#To assign the area number to the DC buses\n                bus_intgar[1] = area_nbr\n            else:\t\t\t\t#The default ar"
  },
  {
    "id": "chunk_785",
    "text": "1] = area_nbr\n            else:\t\t\t\t#The default area number\n                bus_intgar[1] = 1\n\n            if line[62] != ' ':\t\t\t#If it is not a passive DC bus\n                conv_intgar[0] = bus_str[line[50:58].strip() + str(float(line[58:62]))]\t#Converter bus number\n                bus_intgar[0] = conv_intgar[0]\t\t\t\t\t\t#Converter bus number\n\n                if isint(line[23:25]): conv_intgar[1] = int(line[23:25])\t\t#Number of bridges in series\n                if isfloat(line[69:75]):\n           "
  },
  {
    "id": "chunk_786",
    "text": "              if isfloat(line[69:75]):\n                    if float(line[69:75]) != 0.0: conv_realari[0] = float(line[69:75])\t#Scheduled power\n                    elif isfloat(line[75:80]): conv_realari[0] = float(line[75:80])\t#Scheduled voltage\n\n                if line[62] == 'R' and isfloat(line[30:35]): conv_realari[1] = float(line[30:35])\t#Minimum firing angle\n\n                elif line[62] == 'I' and isfloat(line[66:69]) or line[62] == 'M' and isfloat(line[66:69]):\n                    conv_"
  },
  {
    "id": "chunk_787",
    "text": "nd isfloat(line[66:69]):\n                    conv_realari[1] = float(line[66:69])\t\t\t#Minimum extinction angle\n\n                if isfloat(line[35:40]): conv_realari[2] = float(line[35:40])\t#Maximum firing angle\n\n                conv_intgar, conv_realari = GetConvTrans(bpa_str_ar, conv_intgar, conv_realari, line[6:14].strip() + str(float(line[14:18])))\t#To get the corresponding T and R parameters\n\n                ierr,realaro = psspy.multi_term_dc_convr_data(1, conv_intgar, conv_realari)\t#The API"
  },
  {
    "id": "chunk_788",
    "text": "_convr_data(1, conv_intgar, conv_realari)\t#The API to load multi-terminal DC line converter data in PSS/E\n\n            ierr,realaro = psspy.multi_term_dc_bus_data(1, dc_bus_nbr, bus_intgar, bus_realari, line[6:14].strip())\t#The API to load multi-terminal DC line bus data in PSS/E\n\n    return dc_bus_str, dc_bus_owner, owner_str, owner_nbr, zone_str, zone_nbr, area_str, area_slack_nbr, area_nbr\n\n# ----------------------------------------------------------------------------------------------------\n"
  },
  {
    "id": "chunk_789",
    "text": "-------------------------------------------------\ndef GetMultiTermLink(bpa_str_ar, dc_bus_str, dc_bus_owner):\n    \"\"\"Gets the multi-terminal link data from the BPA file.\"\"\"\n\n    for line in bpa_str_ar:\n        line = line.lstrip()\n        line = line.rstrip('\\n')\n        if line == \"\": continue\t\t#Continue if the line is blank\n\n        if line[0] == 'L' and line[1] == 'M' and line[2] == ' ':\t#If it is a LM card\n            line = line + ' '*(80-len(line))\t#To pad each line with spaces up to 80 re"
  },
  {
    "id": "chunk_790",
    "text": "n(line))\t#To pad each line with spaces up to 80 records\n\n            #--------------#\n            #Default values#\n            #--------------#\n            intgar = 0\n            realar = [0.0, 0.0]\n\n            ibus = dc_bus_str[line[6:14].strip() + str(float(line[14:18]))]\t#The from bus\n            jbus = dc_bus_str[line[19:27].strip() + str(float(line[27:31]))]\t#The to bus\n\n            if line[18] == '1': intgar = ibus\t\t#The metered end is IBUS\n            elif line[18] == '2': intgar = jbus\t"
  },
  {
    "id": "chunk_791",
    "text": "S\n            elif line[18] == '2': intgar = jbus\t\t#The metered end is JBUS\n            elif line[18] == ' ':\t\t\t#If the metered end is left blank, BPA chooses\n                if dc_bus_owner[ibus] == dc_bus_owner[jbus]: intgar = ibus\t#If both ends have the same owner, IBUS is the metered end\n                elif dc_bus_owner[ibus] == line[3:6].strip(): intgar = jbus\t#Else the end that has a different owner from the line is the metered end\n                elif dc_bus_owner[jbus] == line[3:6].stri"
  },
  {
    "id": "chunk_792",
    "text": "         elif dc_bus_owner[jbus] == line[3:6].strip(): intgar = ibus\n\n            if isfloat(line[37:43]): realar[0] = float(line[37:43])\t#DC link resistance\n            if isfloat(line[43:49]): realar[1] = float(line[43:49])\t#DC link inductance\n\n            ierr = psspy.multi_term_dc_link_data(1, ibus, jbus, '1', intgar, realar)\t#The API used to load multi-terminal DC line link data in PSS/E\n\n# ----------------------------------------------------------------------------------------------------\n"
  },
  {
    "id": "chunk_793",
    "text": "-------------------------------------------------\ndef GetMultiTermLine(bpa_str_ar, bus_str, zone_str, zone_nbr, owner_str, owner_nbr, area_str, area_slack_nbr, area_nbr):\n    \"\"\"Gets the multi-terminal lines from the BPA file.\"\"\"\n\n    for line in bpa_str_ar:\n        line = line.lstrip()\n        line = line.rstrip('\\n')\n        if line == \"\": continue\t\t#Continue if the line is blank\n\n        if line[0] == 'L' and line[1] == 'M' and line[2] == ' ':\t#If it is a LM card\n            line = line + ' '"
  },
  {
    "id": "chunk_794",
    "text": "\t#If it is a LM card\n            line = line + ' '*(80-len(line))\t#To pad each line with spaces up to 80 records\n\n            #--------------#\n            #Default values#\n            #--------------#\n            intgari = 1\n            realar = 0.0\n\n            ierr, intgaro = psspy.multi_term_dc_line_data(1, intgari, realar)\t#The API used to load multi-terminal DC line data in PSS/E\n\n            #To get the converter, DC bus and DC link data\n            dc_bus_str, dc_bus_owner, owner_str, own"
  },
  {
    "id": "chunk_795",
    "text": "          dc_bus_str, dc_bus_owner, owner_str, owner_nbr, zone_str, zone_nbr, area_str, area_slack_nbr, area_nbr = GetMultiTermConv(bpa_str_ar, bus_str, zone_str, zone_nbr, owner_str, owner_nbr, bus_nbr, area_str, area_slack_nbr, area_nbr)\n            GetMultiTermLink(bpa_str_ar, dc_bus_str, dc_bus_owner)\n\n            return zone_str, zone_nbr, owner_str, owner_nbr, area_str, area_slack_nbr, area_nbr\n\n    return zone_str, zone_nbr, owner_str, owner_nbr, area_str, area_slack_nbr, area_nbr\n\n# ----"
  },
  {
    "id": "chunk_796",
    "text": "er_nbr, area_str, area_slack_nbr, area_nbr\n\n# ----------------------------------------------------------------------------------------------------\nbpa_file = OpenFile()\n\nif bpa_file:\t\t\t\t\t#If the file opened successfully\n\n    psspy.progress(\"\\n\\nFile opened successfully, starting the conversion:\\n\")\n\n    bpa_str = bpa_file.read()\t\t\t#The string containing the text file, to use the find() function\n    bpa_file.seek(- bpa_file.tell(), 1)\t\t#To position back at the beginning\n    bpa_str_ar = bpa_file."
  },
  {
    "id": "chunk_797",
    "text": "n back at the beginning\n    bpa_str_ar = bpa_file.readlines()\t\t#The array that is containing all the lines of the BPA file\n\n    basemva = GetMVA(bpa_file, bpa_str)\t\t#To get the MVA base\n    psspy.progress(\"\\n-Base MVA: \" + str(basemva))\n\n    titl1, titl2 = GetTitles(bpa_file, bpa_str)\t#To get the title data\n    psspy.progress(\"\\n-Title 1: \" + titl1)\n    psspy.progress(\"\\n-Title 2: \" + titl2 + \"\\n\")\n\n    ierr = psspy.newcas(basemva, titl1, titl2)\t#To create the new case\n\n    scale_str = GetPCard("
  },
  {
    "id": "chunk_798",
    "text": "#To create the new case\n\n    scale_str = GetPCard(bpa_str_ar)\t\t#To get the P cards for scaling\n\n    area_str, area_nbr, area_slack_nbr, owner_str, owner_nbr, bus_owner_nbr, bus_str, bus_nbr, zone_str, zone_nbr, load_id_ar, machine_id_ar, bus_zone_str = GetBCard(bpa_str_ar, basemva, scale_str)\n\n    owner_str, owner_nbr, dummy_nbr, bus_nbr, bus_str, bus_owner_nbr = GetLCard(bpa_str_ar, owner_str, owner_nbr, bus_str, bus_nbr, bus_owner_nbr, basemva)\n\n    owner_str, owner_nbr, bus_nbr, bus_str, bus_"
  },
  {
    "id": "chunk_799",
    "text": "\n\n    owner_str, owner_nbr, bus_nbr, bus_str, bus_owner_nbr = GetTCard(bpa_str_ar, owner_str, owner_nbr, bus_str, bus_nbr, bus_owner_nbr, dummy_nbr, basemva)\n\n    owner_str, owner_nbr = GetPlusCard(bpa_str_ar, load_id_ar, machine_id_ar, bus_str, owner_str, owner_nbr, basemva, scale_str, bus_zone_str)\n\n    GetTwoTermLine(bpa_str_ar, bus_str)\n    zone_str, zone_nbr, owner_str, owner_nbr, area_str, area_slack_nbr, area_nbr = GetMultiTermLine(bpa_str_ar, bus_str, zone_str, zone_nbr, owner_str, owner"
  },
  {
    "id": "chunk_800",
    "text": "_ar, bus_str, zone_str, zone_nbr, owner_str, owner_nbr, area_str, area_slack_nbr, area_nbr)\n\n    zone_str = GetZCard(bpa_str_ar, zone_str)\t#To get Z cards\n    zone_str = GetDZCard(bpa_str_ar, zone_str)\t#To get DZ cards\n\n    for x, y in zone_str.items():\n        ierr = psspy.zone_data(y, x)\t#The API used to load zone data in PSS/E\n\n    for (x,y), z in area_str.items():\n        ierr = psspy.area_data(z, area_slack_nbr[z - 1], [y, 0.0], x)\t#The API used to load zone data in PSS/E\n\n    GetICard(bpa_"
  },
  {
    "id": "chunk_801",
    "text": "used to load zone data in PSS/E\n\n    GetICard(bpa_str_ar, area_str, area_slack_nbr)\t#To get the I cards\n\n    for x, y in owner_str.items():\n        ierr = psspy.owner_data(y, x)\t#The API used to load owner data in PSS/E\n\n    GetRZCard(bpa_str_ar)\t#To get RZ cards\n\n    psspy.progress(\"\\n\\nConversion completed\\n\")\n\n    bpa_file.close()\t#To close the BPA file\n#[brnflows_csv.py]  Export BRANCH FLOWS to COMMA SEPARATED FILE (CSV)\n# ====================================================================="
  },
  {
    "id": "chunk_802",
    "text": "=================================================================================\n'''\nThis is an example file showing how to use \"subsystem data retrieval APIs\nfrom Python to save branch flows to Comma Separated File.\n    Input : Solved PSS(R)E saved case file name\n    Output: CSV file name to save\n    When 'savfile' is provided, FNSL with default options is used to solve the case.\n    When 'savfile' is not provided, it uses solved Case from PSS(R)E memory.\n    When 'csvfile' is provided, branch"
  },
  {
    "id": "chunk_803",
    "text": "R)E memory.\n    When 'csvfile' is provided, branch flows is saved in ASCII text file 'csvfile'.\n    When 'csvfile' is not provided, it produces report in PSS(R)E report window.\n\nThe subsystem data retrieval APIs return values as List of Lists. For example:\nWhen \"abusint\" API is called with \"istrings\" as defined below:\n    istrings = ['number','type','area','zone','owner','dummy']\n    ierr, idata = psspy.abusint(sid, flag_bus, istrings)\nThe returned list will have format:\n    idata=[[list of 'num"
  },
  {
    "id": "chunk_804",
    "text": "ed list will have format:\n    idata=[[list of 'number'],[list of 'type'],[],[],[],[list of 'dummy']]\n\nThis example is written such that, such returned lists are converted into dictionary with\nkeys as strings specified in \"istrings\". This makes it easier to refer and use these lists.\n    ibuses = array2dict(istrings, idata)\n\nSo ibuses['number'] gives the bus numbers returned by \"abusint\".\n\n---------------------------------------------------------------------------------\nHow to use this file?\n\nAs "
  },
  {
    "id": "chunk_805",
    "text": "-----------------------\nHow to use this file?\n\nAs showed in __main__ (end of this file)\n- Enable PSSE version specific environment, as an example:\n    import psse35\n\n- call function\n    run_brnflowscsv()\n    You may want to change input arguments when you call this function.\n    run_brnflowscsv(savfile, csvfile)\n\n'''\n# ----------------------------------------------------------------------------------------------------\nimport os\n\n# -----------------------------------------------------------------"
  },
  {
    "id": "chunk_806",
    "text": "-------------------------------------------------------------------------------------\ndef array2dict(dict_keys, dict_values):\n    '''Convert array to dictionary of arrays.\n    Returns dictionary as {dict_keys:dict_values}\n    '''\n    tmpdict = {}\n    for i in range(len(dict_keys)):\n        tmpdict[dict_keys[i].lower()] = dict_values[i]\n    return tmpdict\n\n# ----------------------------------------------------------------------------------------------------\ndef busindexes(busnum, busnumlist):\n   "
  },
  {
    "id": "chunk_807",
    "text": "----------\ndef busindexes(busnum, busnumlist):\n    '''Find indexes of a bus in list of buses.\n    Returns list with indexes of 'busnum' in 'busnumlist'.\n    '''\n    busidxes = []\n    startidx = 0\n    buscounts = busnumlist.count(busnum)\n    if buscounts:\n        for i in range(buscounts):\n            tmpidx = busnumlist.index(busnum,startidx)\n            busidxes.append(tmpidx)\n            startidx = tmpidx+1\n    return busidxes\n\n# ----------------------------------------------------------------"
  },
  {
    "id": "chunk_808",
    "text": "--------------------------------------------------------------------------------------\ndef splitstring_commaspace(tmpstr):\n    '''Split string first at comma and then by space. Example:\n    Input  tmpstr = a1       a2,  ,a4 a5 ,,,a8,a9\n    Output strlst = ['a1', 'a2', ' ', 'a4', 'a5', ' ', ' ', 'a8', 'a9']\n    '''\n    strlst = []\n    commalst = tmpstr.split(',')\n    for each in commalst:\n        eachlst = each.split()\n        if eachlst:\n            strlst.extend(eachlst)\n        else:\n         "
  },
  {
    "id": "chunk_809",
    "text": "    strlst.extend(eachlst)\n        else:\n            strlst.extend(' ')\n\n    return strlst\n\n# ----------------------------------------------------------------------------------------------------\ndef brnflows_csv(savfile,csvfile):\n    '''Generates power flow result report.\n    When 'savfile' is provided, FNSL with default options is used to solve the case.\n    When 'savfile' is not provided, it uses solved Case from PSS(R)E memory.\n    When 'csvfile' is provided, report is saved in ASCII text fil"
  },
  {
    "id": "chunk_810",
    "text": "le' is provided, report is saved in ASCII text file 'csvfile'.\n    When 'csvfile' is not provided, it produces report in PSS(R)E report window.\n    '''\n\n    import psspy\n    psspy.psseinit()\n\n    # Set Save and CSV files according to input file names\n    if savfile:\n        ierr = psspy.case(savfile)\n        if ierr != 0: return\n        fpath, fext = os.path.splitext(savfile)\n        if not fext: savfile = fpath + '.sav'\n    else:   # saved case file not provided, check if working case is in mem"
  },
  {
    "id": "chunk_811",
    "text": "file not provided, check if working case is in memory\n        ierr, nbuses = psspy.abuscount(-1,2)\n        if ierr != 0:\n            print('\\n No working case in memory.')\n            print(' Either provide a Saved case file name or open Saved case in PSSE.')\n            return\n        savfile, snapfile = psspy.sfiles()\n\n    if csvfile:  # open CSV file to write\n        csvfile_h = open(csvfile,'w')\n        report    = csvfile_h.write\n    else:        # send results to PSS(R)E report window\n    "
  },
  {
    "id": "chunk_812",
    "text": "      # send results to PSS(R)E report window\n        psspy.beginreport()\n        report = psspy.report\n\n    # ================================================================================================\n    # PART 1: Get the required results data\n    # ================================================================================================\n\n    # Select what to report\n    if psspy.bsysisdef(0):\n        sid = 0\n    else:   # Select subsytem with all buses\n        sid = -1\n\n    flag_b"
  },
  {
    "id": "chunk_813",
    "text": "bsytem with all buses\n        sid = -1\n\n    flag_brflow  = 1    # in-service\n    owner_brflow = 1    # use bus ownership, ignored if sid is -ve\n    ties_brflow  = 5    # ignored if sid is -ve\n\n    # ------------------------------------------------------------------------------------------------\n    # Branch Flow Data\n    # Branch Flow Data - Integer\n    istrings = ['fromnumber','tonumber','status','nmeternumber','owners','own1','own2','own3','own4']\n    ierr, idata = psspy.aflowint(sid, owner_br"
  },
  {
    "id": "chunk_814",
    "text": "4']\n    ierr, idata = psspy.aflowint(sid, owner_brflow, ties_brflow, flag_brflow, istrings)\n    if ierr != 0: return\n    iflow = array2dict(istrings, idata)\n    # Branch Flow Data - Real\n    rstrings = ['amps','pucur','pctrate','pctratea','pctrateb','pctratec','pctmvarate',\n                'pctmvaratea','pctmvarateb',#'pctmvaratec','fract1','fract2','fract3',\n                'fract4','rate','ratea','rateb','ratec',\n                'p','q','mva','ploss','qloss',\n                'o_p','o_q','o_mva"
  },
  {
    "id": "chunk_815",
    "text": "ploss','qloss',\n                'o_p','o_q','o_mva','o_ploss','o_qloss'\n                ]\n    ierr, rdata = psspy.aflowreal(sid, owner_brflow, ties_brflow, flag_brflow, rstrings)\n    if ierr != 0: return\n    rflow = array2dict(rstrings, rdata)\n    # Branch Flow Data - Complex\n    xstrings = ['pq','pqloss','o_pq','o_pqloss']\n    ierr, xdata = psspy.aflowcplx(sid, owner_brflow, ties_brflow, flag_brflow, xstrings)\n    if ierr != 0: return\n    xflow = array2dict(xstrings, xdata)\n    # Branch Flow Da"
  },
  {
    "id": "chunk_816",
    "text": "= array2dict(xstrings, xdata)\n    # Branch Flow Data - Character\n    cstrings = ['id','fromname','fromexname','toname','toexname','nmetername','nmeterexname']\n    ierr, cdata = psspy.aflowchar(sid, owner_brflow, ties_brflow, flag_brflow, cstrings)\n    if ierr != 0: return\n    cflow = array2dict(cstrings, cdata)\n\n    # ================================================================================================\n    # PART 2: Write acquired results to Report file\n    # ========================="
  },
  {
    "id": "chunk_817",
    "text": "lts to Report file\n    # ================================================================================================\n\n    report(\"Branch flows from Saved case: %s\\n\" %savfile)\n\n    clnttls = \"%6s,%18s,%6s,%18s,%3s,%3s,%9s,%9s,%9s,%6s,%8s,%8s\\n\" %('FRMBUS',\n             'FROMBUSEXNAME','TOBUS','TOBUSEXNAME','CKT','STS','MW','MVAR','MVA','%I','MWLOSS','MVARLOSS')\n    report(clnttls)\n    for i in range(len(iflow['fromnumber'])):\n        fromnum    = iflow['fromnumber'][i]\n        fromexname = "
  },
  {
    "id": "chunk_818",
    "text": "    = iflow['fromnumber'][i]\n        fromexname = cflow['fromexname'][i]\n        tonum      = iflow['tonumber'][i]\n        toexname   = cflow['toexname'][i]\n        ckt        = cflow['id'][i]\n        status     = iflow['status'][i]\n        p          = rflow['p'][i]\n        q          = rflow['q'][i]\n        mva        = rflow['mva'][i]\n        ploss      = rflow['ploss'][i]\n        qloss      = rflow['qloss'][i]\n        pcti       = rflow['pctrate'][i]\n        report(\"%(fromnum)6d,%(fromexname"
  },
  {
    "id": "chunk_819",
    "text": "ate'][i]\n        report(\"%(fromnum)6d,%(fromexname)18s,%(tonum)6d,%(toexname)18s,%(ckt)3s,%(status)3d,\\\n%(p)9.2F,%(q)9.2F,%(mva)9.2F,%(pcti)6.2F,%(ploss)8.2F,%(qloss)8.2F\\n\" %vars())\n    # ------------------------------------------------------------------------------------------------\n    if csvfile:\n        csvfile_h.close()\n        print('\\n Done .... Power Flow Results Report saved to file %s' % csvfile)\n    else:\n        print('\\n Done .... Power Flow Results Report created in Report window."
  },
  {
    "id": "chunk_820",
    "text": "ower Flow Results Report created in Report window.')\n\n# =====================================================================================================\n\ndef check_psse_example_folder(csvfile):\n    # if called from PSSE's Example Folder, create report in subfolder 'Output_Pyscript'\n    rptpath, rptfnam = os.path.split(csvfile)\n    if not rptpath:\n        rptpath = os.getcwd()\n        cwd = rptpath.lower()\n        i = cwd.find('pti')\n        j = cwd.find('psse')\n        k = cwd.find('example"
  },
  {
    "id": "chunk_821",
    "text": "j = cwd.find('psse')\n        k = cwd.find('example')\n        if i>0 and j>i and k>j:     # called from Example folder\n            outdir = os.path.join(os.getcwd(), 'Output_Pyscript')\n            if not os.path.exists(outdir): os.mkdir(outdir)\n        else:\n            outdir = os.getcwd()\n        csvfile  = os.path.join(outdir, rptfnam)\n\n    return csvfile\n\n# =====================================================================================================\n\ndef run_brnflows_csv(savfile='savn"
  },
  {
    "id": "chunk_822",
    "text": "==============\n\ndef run_brnflows_csv(savfile='savnw.sav', csvfile='brnflows_csv_savnw.csv'):\n\n    csvfile  = check_psse_example_folder(csvfile)\n\n    brnflows_csv(savfile, csvfile)\n\n# ====================================================================================================\n# ====================================================================================================\nif __name__ == '__main__':\n\n    import psse35\n    run_brnflows_csv()\n\n# ========================================="
  },
  {
    "id": "chunk_823",
    "text": "csv()\n\n# ====================================================================================================\n#[dyntools_demo.py]  Demo for using functions from dyntools module\n# ====================================================================================================\n'''\n'dyntools' module provide access to data in PSS(R)E Dynamic Simulation Channel Output file.\nThis module has functions:\n- to get channel data in Python scripts for further processing\n- to get channel information and t"
  },
  {
    "id": "chunk_824",
    "text": "ther processing\n- to get channel information and their min/max range\n- to export data to text files, excel spreadsheets\n- to open multiple channel output files and post process their data using Python scripts\n- to plot selected channels\n- to plot and insert plots in word document\n\nThis is an example file showing how to use various functions available in dyntools module.\n\nOther Python modules 'matplotlib', 'numpy' and 'python win32 extension' are required to be\nable to use 'dyntools' module.\nSelf"
  },
  {
    "id": "chunk_825",
    "text": "required to be\nable to use 'dyntools' module.\nSelf installation EXE files for these modules are available at:\n   PSSE User Support Web Page and follow link 'Python Modules used by PSSE Python Utilities'.\n\n- This version of the dyntools module is developed and tested using these open source modules.\n  Python 3.7.3 [64 bit]\n  matplotlib-3.1.1\n  numpy-1.16.4\n  pywin32-224\n\n  Versions later than these may work.\n\n---------------------------------------------------------------------------------\nHow to"
  },
  {
    "id": "chunk_826",
    "text": "-------------------------------------------\nHow to use this file?\n- Open Python IDLE (or any Python Interpreter shell)\n- Open this file\n- run (F5)\n\nNote: Do NOT run this file from PSS(R)E GUI. The 'xyplots' function from dyntools can\nsave plots to eps, png, pdf or ps files. However, creating only 'eps' files from inside\nPSS(R)E GUI works. This is because different backends matplotlib uses to create different\nplot types.\nWhen run from any Python interpreter (outside PSS(R)E GUI) plots can be save"
  },
  {
    "id": "chunk_827",
    "text": "nterpreter (outside PSS(R)E GUI) plots can be saved to any of\nthese four (eps, png, pdf or ps) file types.\n\nGet information on functions available in dyntools as:\nimport dyntools\nhelp(dyntools)\n\n---------------------------------------------------------------------------------\nHow to use PSSE and Python modules like numpy, matplotlib together?\n(a) In your python script, call following function before any of these modules are imported.\n    psspy.set_fpcw_py()\n(b) Call following function before exi"
  },
  {
    "id": "chunk_828",
    "text": "t_fpcw_py()\n(b) Call following function before exiting your python script.\n    psspy.set_fpcw_psse()\nTo get details why this is needed, get help(..) on either of these functions.\nRefer function test2_subplots_one_trace(..) in this script for usage of these functions.\n\n'''\n\nimport os, sys, collections\n\n# =============================================================================================\ndef get_demotest_file_names(outdir, outvrsn):\n\n    if outvrsn==0:\n        extn = '.out'\n        prgfi"
  },
  {
    "id": "chunk_829",
    "text": "if outvrsn==0:\n        extn = '.out'\n        prgfile  = os.path.join(outdir,'progress.txt')\n    else:\n        extn = '.outx'\n        prgfile  = os.path.join(outdir,'progressX.txt')\n\n    outfile1 = os.path.join(outdir,'bus154_fault{}'.format(extn))\n    outfile2 = os.path.join(outdir,'bus3018_gentrip{}'.format(extn))\n    outfile3 = os.path.join(outdir,'brn3005_3007_trip{}'.format(extn))\n\n    return outfile1, outfile2, outfile3, prgfile\n\n# ==========================================================="
  },
  {
    "id": "chunk_830",
    "text": "====================================================================================\n# PSSE version Example folder\ndef get_example_folder():\n    import psspy\n    pn = os.path.dirname(psspy.__file__)\n    p, jnk = os.path.split(pn)\n    examdir = os.path.join(p, 'Example')\n    return examdir\n\n# =============================================================================================\n# Run Dynamic simulation on SAVNW to generate .out files\n\ndef run_savnw_simulation(datapath, outfile1, outfile2, "
  },
  {
    "id": "chunk_831",
    "text": "un_savnw_simulation(datapath, outfile1, outfile2, outfile3, prgfile, outvrsn):\n\n    import psspy\n    psspy.psseinit()\n\n    examdir = get_example_folder()\n\n    savfile = 'savcnv.sav'\n    snpfile = 'savnw.snp'\n\n    if not datapath: datapath = get_example_folder()\n\n    savfile = os.path.join(datapath, savfile)\n    snpfile = os.path.join(datapath, snpfile)\n\n    psspy.lines_per_page_one_device(1,10000000)\n    psspy.progress_output(2,prgfile,[0,0])\n\n    ierr = psspy.case(savfile)\n    if ierr:\n        "
  },
  {
    "id": "chunk_832",
    "text": "  ierr = psspy.case(savfile)\n    if ierr:\n        psspy.progress_output(1,\"\",[0,0])\n        print(\" psspy.case Error\")\n        return\n    ierr = psspy.rstr(snpfile)\n    if ierr:\n        psspy.progress_output(1,\"\",[0,0])\n        print(\" psspy.rstr Error\")\n        return\n\n    psspy.set_chnfil_type(outvrsn)\n\n    psspy.strt(0,outfile1)\n    psspy.run(0, 1.0,1000,1,0)\n    psspy.dist_bus_fault(154,1, 230.0,[0.0,-0.2E+10])\n    psspy.run(0, 1.05,1000,1,0)\n    psspy.dist_clear_fault(1)\n    psspy.run(0, 5."
  },
  {
    "id": "chunk_833",
    "text": "\n    psspy.dist_clear_fault(1)\n    psspy.run(0, 5.0,1000,1,0)\n\n    psspy.case(savfile)\n    psspy.rstr(snpfile)\n    psspy.strt(0,outfile2)\n    psspy.run(0, 1.0,1000,1,0)\n    psspy.dist_machine_trip(3018,'1')\n    psspy.run(0, 5.0,1000,1,0)\n\n    psspy.case(savfile)\n    psspy.rstr(snpfile)\n    psspy.strt(0,outfile3)\n    psspy.run(0, 1.0,1000,1,0)\n    psspy.dist_branch_trip(3005,3007,'1')\n    psspy.run(0, 5.0,1000,1,0)\n\n    psspy.lines_per_page_one_device(2,10000000)\n    psspy.progress_output(1,\"\",[0"
  },
  {
    "id": "chunk_834",
    "text": "vice(2,10000000)\n    psspy.progress_output(1,\"\",[0,0])\n\n# =============================================================================================\n# 0. Run savnw dynamics simulation to create .out files\n\ndef test0_run_simulation(datapath=None, outpath=None, outvrsn=0):\n\n    outfile1, outfile2, outfile3, prgfile = get_demotest_file_names(outpath, outvrsn)\n    run_savnw_simulation(datapath, outfile1, outfile2, outfile3, prgfile, outvrsn)\n\n    print(\" Test0:Done SAVNW dynamics simulation\")\n\n# "
  },
  {
    "id": "chunk_835",
    "text": "print(\" Test0:Done SAVNW dynamics simulation\")\n\n# =============================================================================================\n# 1. Data extraction/information\n\ndef test1_data_extraction(outpath=None, show=True, outvrsn=0, prg2file=True):\n\n    import psspy\n    import dyntools\n\n    outfile1, outfile2, outfile3, prgfile = get_demotest_file_names(outpath, outvrsn)\n\n    # create object\n    chnfobj = dyntools.CHNF(outfile1, outvrsn=outvrsn)\n\n    if chnfobj.ierr: return\n\n    if prg2fi"
  },
  {
    "id": "chunk_836",
    "text": "tvrsn)\n\n    if chnfobj.ierr: return\n\n    if prg2file:\n        p, nx = os.path.split(outfile1)\n        n, x  = os.path.split(nx)\n        rptnam = \"{}_test1_output.txt\".format(n)\n        if outpath:\n            rptfile = os.path.join(outpath, rptnam)\n        else:\n            rptfile = os.path.join(p, rptnam)\n        rptfile_h = open(rptfile,'w')\n        report = rptfile_h.write\n    else:\n        report = sys.stdout.write\n\n    report('\\n Test1:Testing call to get_data\\n')\n    #sh_ttl, ch_id, ch_da"
  },
  {
    "id": "chunk_837",
    "text": "ing call to get_data\\n')\n    #sh_ttl, ch_id, ch_data = chnfobj.get_data()\n    sh_ttl, ch_id, ch_data = chnfobj.get_data(['time', 4, 5, 55])\n    #sh_ttl, ch_id, ch_data = chnfobj.get_data('')\n    #sh_ttl, ch_id, ch_data = chnfobj.get_data([4, 5, 55])\n    s_in = [str(ch) for ch in ch_data.keys()]\n    s_ch = ', '.join(s_in)\n    report(sh_ttl)\n    report(\"{}\".format(ch_id))\n    report(\" Test1:Data extracted for Channels = {}\\n\".format(s_ch))\n\n    report('\\n Test1:Testing call to get_id\\n')\n    sh_tt"
  },
  {
    "id": "chunk_838",
    "text": "ort('\\n Test1:Testing call to get_id\\n')\n    sh_ttl, ch_id = chnfobj.get_id()\n    report(sh_ttl)\n    report(\"{}\".format(ch_id))\n    report('\\n')\n\n    report('\\n Test1:Testing call to get_range\\n')\n    ch_range = chnfobj.get_range()\n    report(\"{}\".format(ch_range))\n    report('\\n')\n\n    report('\\n Test1:Testing call to get_scale\\n')\n    ch_scale = chnfobj.get_scale()\n    report(\"{}\".format(ch_scale))\n    report('\\n')\n\n    if not prg2file:\n        report('\\n Test1:Testing call to print_scale\\n')\n"
  },
  {
    "id": "chunk_839",
    "text": " report('\\n Test1:Testing call to print_scale\\n')\n        chnfobj.print_scale()\n        report('\\n')\n\n    pn, x = os.path.splitext(outfile1)\n\n    report('\\n Test1:Testing call to txtout\\n')\n    chnfobj.txtout(channels=[1,4], txtfile=pn)\n    report('\\n')\n\n    report('\\n Test1:Testing call to csvout\\n')\n    chnfobj.csvout(channels=[1,4,41,5], csvfile=pn)\n    report('\\n')\n\n    report('\\n Test1:Testing call to xlsout\\n')\n    try:\n        chnfobj.xlsout(channels=[2,3,4,7,8,10], show=show, xlsfile=pn)"
  },
  {
    "id": "chunk_840",
    "text": "ut(channels=[2,3,4,7,8,10], show=show, xlsfile=pn)\n    except:\n        pass\n\n    if prg2file:\n        rptfile_h.close()\n        txt = ' Test1_data_extraction report saved to file:\\n    {}\\n'.format(rptfile)\n        print(txt)\n\n# =============================================================================================\n# 2. Multiple subplots in a figure, but one trace in each subplot\n#    Channels specified with normal dictionary\n\n# See how \"set_plot_legend_options\" method can be used to place"
  },
  {
    "id": "chunk_841",
    "text": "t_plot_legend_options\" method can be used to place and format legends\n\ndef test2_subplots_one_trace(outpath=None, show=True, outvrsn=0):\n\n    import psspy\n    import dyntools\n    psspy.set_fpcw_py()     # To use PSSE, numpy and matplotlib, this is needed.\n\n    outfile1, outfile2, outfile3, prgfile = get_demotest_file_names(outpath, outvrsn)\n\n    chnfobj = dyntools.CHNF(outfile1, outfile2, outvrsn=outvrsn)\n\n    chnfobj.set_plot_page_options(size='letter', orientation='portrait')\n    chnfobj.set_p"
  },
  {
    "id": "chunk_842",
    "text": "letter', orientation='portrait')\n    chnfobj.set_plot_markers('square', 'triangle_up', 'thin_diamond', 'plus', 'x',\n                             'circle', 'star', 'hexagon1')\n    chnfobj.set_plot_line_styles('solid', 'dashed', 'dashdot', 'dotted')\n    chnfobj.set_plot_line_colors('blue', 'red', 'black', 'green', 'cyan', 'magenta', 'pink', 'purple')\n\n    optnfmt  = {'rows':2,'columns':2,'dpi':300,'showttl':True, 'showoutfnam':True, 'showlogo':True,\n                'legendtype':1, 'addmarker':True"
  },
  {
    "id": "chunk_843",
    "text": ",\n                'legendtype':1, 'addmarker':True}\n\n    optnchn1 = {1:{'chns':6,                'title':'Ch#6,bus154_fault, P(pu)'},\n                2:{'chns':[6, 'v*100'],     'title':'Ch#6,bus154_fault, P(MW)'},\n                3:{'chns':11,               'title':'Ch#11,bus154_fault'},\n                4:{'chns':40,               'title':'Ch#40,bus154_fault'},\n                5:{'chns':26,               'title':'Ch#26,bus154_fault, Frequency (pu)'},\n                6:{'chns':[26, '(1+v)*60'], "
  },
  {
    "id": "chunk_844",
    "text": "u)'},\n                6:{'chns':[26, '(1+v)*60'], 'title':'Ch#26,bus154_fault, Frequency (Hz)'},\n                }\n    pn,x     = os.path.splitext(outfile1)\n    pltfile1 = pn+'.pdf'\n\n    optnchn2 = {1:{'chns':{outfile2:6},                'title':'Channel 6 from bus3018_gentrip, P(pu)'},\n                2:{'chns':{outfile2:[6, 'v*100']},     'title':'Channel 6 from bus3018_gentrip, P(MW)'},\n                3:{'chns':{outfile2:11}},\n                4:{'chns':{outfile2:16}},\n                5:{'chn"
  },
  {
    "id": "chunk_845",
    "text": " 4:{'chns':{outfile2:16}},\n                5:{'chns':{outfile2:26},               'title':'Ch#26,bus3018_gentrip, Frequency (pu)'},\n                6:{'chns':{outfile2:[26, '(1+v)*60']}, 'title':'Ch#26,bus3018_gentrip, Frequency (Hz)'},\n                }\n    pn,x     = os.path.splitext(outfile2)\n    pltfile2 = pn+'.png'\n\n    figfiles1 = chnfobj.xyplots(optnchn1,optnfmt,pltfile1)\n\n    chnfobj.set_plot_legend_options(loc='lower center', borderpad=0.2, labelspacing=0.5,\n                            "
  },
  {
    "id": "chunk_846",
    "text": ".2, labelspacing=0.5,\n                                    handlelength=1.5, handletextpad=0.5, fontsize=8, frame=False)\n\n    optnfmt  = {'rows':3,'columns':1,'dpi':300,'showttl':False, 'showoutfnam':True, 'showlogo':False,\n                'legendtype':2, 'addmarker':False}\n\n    figfiles2 = chnfobj.xyplots(optnchn2,optnfmt,pltfile2)\n\n    if figfiles1 or figfiles2:\n        txt = ' Test2:Plot files saved:\\n'\n        if figfiles1: txt += \"     {}\\n\".format(figfiles1[0])\n        if figfiles2: txt += "
  },
  {
    "id": "chunk_847",
    "text": "format(figfiles1[0])\n        if figfiles2: txt += \"     {}\\n\".format(figfiles2[0])\n        print(txt)\n\n    if show:\n        chnfobj.plots_show()\n    else:\n        chnfobj.plots_close()\n\n    psspy.set_fpcw_psse()   # To use PSSE, numpy and matplotlib, this is needed.\n\n# =============================================================================================\n# 3. Multiple subplots in a figure and more than one trace in each subplot\n#    Channels specified with normal dictionary\n\ndef test3_sub"
  },
  {
    "id": "chunk_848",
    "text": "ls specified with normal dictionary\n\ndef test3_subplots_mult_trace(outpath=None, show=True, outvrsn=0):\n\n    import psspy\n    import dyntools\n    psspy.set_fpcw_py()     # To use PSSE, numpy and matplotlib, this is needed.\n\n    outfile1, outfile2, outfile3, prgfile = get_demotest_file_names(outpath, outvrsn)\n\n    chnfobj = dyntools.CHNF(outfile1, outfile2, outfile3, outvrsn=outvrsn)\n\n    chnfobj.set_plot_page_options(size='letter', orientation='portrait')\n    chnfobj.set_plot_markers('square', '"
  },
  {
    "id": "chunk_849",
    "text": "ortrait')\n    chnfobj.set_plot_markers('square', 'triangle_up', 'thin_diamond', 'plus', 'x',\n                             'circle', 'star', 'hexagon1')\n    chnfobj.set_plot_line_styles('solid', 'dashed', 'dashdot', 'dotted')\n    chnfobj.set_plot_line_colors('blue', 'red', 'black', 'green', 'cyan', 'magenta', 'pink', 'purple')\n\n    optnfmt  = {'rows':2,'columns':2,'dpi':300,'showttl':False, 'showoutfnam':True, 'showlogo':False,\n                'legendtype':2, 'addmarker':True}\n\n    optnchn1 = {1:"
  },
  {
    "id": "chunk_850",
    "text": "gendtype':2, 'addmarker':True}\n\n    optnchn1 = {1:{'chns':[1]},2:{'chns':[2]},3:{'chns':[3]},4:{'chns':[4]},5:{'chns':[5]}}\n    pn,x     = os.path.splitext(outfile1)\n    pltfile1 = pn+'.png'\n\n    optnchn2 = {1:{'chns':{outfile2:1}},\n                2:{'chns':{'v82_test1_bus_fault.out':3}},\n                3:{'chns':4},\n                4:{'chns':[5]}\n               }\n    pn,x     = os.path.splitext(outfile2)\n    pltfile2 = pn+'.pdf'\n\n    optnchn3 = {1:{'chns':{outfile1:1}},\n                2:{'ch"
  },
  {
    "id": "chunk_851",
    "text": "= {1:{'chns':{outfile1:1}},\n                2:{'chns':{outfile2:[1,5]}},\n                3:{'chns':{outfile3:3}},\n                4:{'chns':[4,'v-v0',5,'v-v0']},  # arbitrary function\n               }\n    pn,x     = os.path.splitext(outfile3)\n    pltfile3 = pn+'.png'\n\n    figfiles1 = chnfobj.xyplots(optnchn1,optnfmt,pltfile1)\n    figfiles2 = chnfobj.xyplots(optnchn2,optnfmt,pltfile2)\n    figfiles3 = chnfobj.xyplots(optnchn3,optnfmt,pltfile3)\n\n    figfiles = figfiles1[:]\n    figfiles.extend(figfi"
  },
  {
    "id": "chunk_852",
    "text": " figfiles = figfiles1[:]\n    figfiles.extend(figfiles2)\n    figfiles.extend(figfiles3)\n    if figfiles:\n        txt = ' Test3:Plot files saved:\\n'\n        for f in figfiles:\n            txt += \"    {}\\n\".format(f)\n        print(txt)\n\n    if show:\n        chnfobj.plots_show()\n    else:\n        chnfobj.plots_close()\n\n    psspy.set_fpcw_psse()   # To use PSSE, numpy and matplotlib, this is needed.\n\n# =============================================================================================\n# 4. "
  },
  {
    "id": "chunk_853",
    "text": "============================================\n# 4. Multiple subplots in a figure, but one trace in each subplot\n#    Channels specified with Ordered dictionary\n\ndef test4_subplots_mult_trace_OrderedDict(outpath=None, show=True, outvrsn=0):\n\n    import psspy\n    import dyntools\n    psspy.set_fpcw_py()     # To use PSSE, numpy and matplotlib, this is needed.\n\n    outfile1, outfile2, outfile3, prgfile = get_demotest_file_names(outpath, outvrsn)\n\n    chnfobj = dyntools.CHNF(outfile1, outfile2, outfil"
  },
  {
    "id": "chunk_854",
    "text": "chnfobj = dyntools.CHNF(outfile1, outfile2, outfile3, outvrsn=outvrsn)\n\n    chnfobj.set_plot_page_options(size='letter', orientation='portrait')\n    chnfobj.set_plot_markers('square', 'triangle_up', 'thin_diamond', 'plus', 'x',\n                             'circle', 'star', 'hexagon1')\n    chnfobj.set_plot_line_styles('solid', 'dashed', 'dashdot', 'dotted')\n    chnfobj.set_plot_line_colors('blue', 'red', 'black', 'green', 'cyan', 'magenta', 'pink', 'purple')\n\n    optnfmt  = {'rows':2,'columns':1"
  },
  {
    "id": "chunk_855",
    "text": "', 'purple')\n\n    optnfmt  = {'rows':2,'columns':1,'dpi':300,'showttl':False, 'showoutfnam':True, 'showlogo':False,\n                'legendtype':2, 'addmarker':True}\n\n    optnchn  = {1:{'chns':collections.OrderedDict([(outfile1,26), (outfile2,26), (outfile3,26)]),\n                   'title':'Frequency(pu)'},\n                2:{'chns':collections.OrderedDict([(outfile1,[26, '(1+v)*60']),\n                                                   (outfile2,[26, '(1+v)*60']),\n                              "
  },
  {
    "id": "chunk_856",
    "text": ",[26, '(1+v)*60']),\n                                                   (outfile3,[26, '(1+v)*60'])]),\n                   'title':'Frequency(Hz)'}\n               }\n    p,nx     = os.path.split(outfile1)\n    pltfile  = os.path.join(p, 'plot_chns_ordereddict.png')\n\n    figfiles = chnfobj.xyplots(optnchn,optnfmt,pltfile)\n\n    if figfiles:\n        txt = ' Test4:Plot files saved:\\n'\n        for f in figfiles:\n            txt += \"    {}\\n\".format(f)\n        print(txt)\n\n    if show:\n        chnfobj.plot"
  },
  {
    "id": "chunk_857",
    "text": "     print(txt)\n\n    if show:\n        chnfobj.plots_show()\n    else:\n        chnfobj.plots_close()\n\n    psspy.set_fpcw_psse()   # To use PSSE, numpy and matplotlib, this is needed.\n\n# =============================================================================================\n# 5. Do XY plots and insert them into word file\n# Does not work because win32 API to Word does not work.\n\ndef test5_plots2word(outpath=None, show=True, outvrsn=0):\n\n    import psspy\n    import dyntools\n    psspy.set_fpcw_p"
  },
  {
    "id": "chunk_858",
    "text": "ort psspy\n    import dyntools\n    psspy.set_fpcw_py()     # To use PSSE, numpy and matplotlib, this is needed.\n\n    outfile1, outfile2, outfile3, prgfile = get_demotest_file_names(outpath, outvrsn)\n\n    chnfobj = dyntools.CHNF(outfile1, outfile2, outfile3, outvrsn=outvrsn)\n\n    p,nx       = os.path.split(outfile1)\n    docfile    = os.path.join(p,'savnw_response')\n    overwrite  = True\n    caption    = True\n    align      = 'center'\n    captionpos = 'below'\n    height     = 0.0\n    width      = 0"
  },
  {
    "id": "chunk_859",
    "text": " = 'below'\n    height     = 0.0\n    width      = 0.0\n    rotate     = 0.0\n\n    optnfmt  = {'rows':3,'columns':1,'dpi':300,'showttl':True}\n\n    optnchn  = {1:{'chns':{outfile1:1,  outfile2:1,  outfile3:1} },\n                2:{'chns':{outfile1:[7,'v*100'],  outfile2:[7,'v*100'],  outfile3:[7,'v*100']} },\n                3:{'chns':{outfile1:17, outfile2:17, outfile3:17} },\n                4:{'chns':[1,2,3,4,5]},\n                5:{'chns':{outfile2:[26,'(1+v)*60',27,'(1+v)*60',28,'(1+v)*60',29,'(1+"
  },
  {
    "id": "chunk_860",
    "text": "[26,'(1+v)*60',27,'(1+v)*60',28,'(1+v)*60',29,'(1+v)*60']},\n                   'title':'Frequency(Hz)'},\n                6:{'chns':{outfile3:[1,2,3,4,5]} },\n               }\n    ierr, docfile = chnfobj.xyplots2doc(optnchn,optnfmt,docfile,show,overwrite,caption,align,\n                        captionpos,height,width,rotate)\n\n    if not ierr:\n        txt  = ' Test5:Plots saved to file:\\n    {}'.format(docfile)\n        print(txt)\n    else:\n        txt  = ' Test5:Error saving plots to Word = {}'.form"
  },
  {
    "id": "chunk_861",
    "text": "t  = ' Test5:Error saving plots to Word = {}'.format(ierr)\n        print(txt)\n\n    psspy.set_fpcw_psse()   # To use PSSE, numpy and matplotlib, this is needed.\n\n# =============================================================================================\n# Run all tests and save plot and report files.\n\ndef run_all_tests(outvrsn, datapath=None, prg2file=True):\n\n    show = False\n\n    run_tests('all', outvrsn, show, datapath=datapath, prg2file=prg2file)\n\n# ========================================"
  },
  {
    "id": "chunk_862",
    "text": "2file)\n\n# =============================================================================================\n\ndef run_tests(which, outvrsn, show, datapath=None, prg2file=True):\n\n    import psspy\n\n    datapath = datapath\n\n    outdnam  = \"dyntools_demo_output_outvrn{}\".format(outvrsn)\n    outpath  = os.path.join(os.getcwd(), outdnam)\n    if not os.path.exists(outpath): os.mkdir(outpath)\n\n    if which in [0, 'all']:\n        print(\" <<<<<< Begin TEST=0 >>>>>>\")\n        test0_run_simulation(datapath, outp"
  },
  {
    "id": "chunk_863",
    "text": ">>>>\")\n        test0_run_simulation(datapath, outpath, outvrsn)\n        print(\" Output files folder:{}\".format(outpath))\n\n    if which in [1, 'all']:\n        print(\" <<<<<< Begin TEST=1 >>>>>>\")\n        test1_data_extraction(outpath=outpath, show=show, outvrsn=outvrsn, prg2file=prg2file)\n\n    if which in [2, 'all']:\n        print(\" <<<<<< Begin TEST=2 >>>>>>\")\n        test2_subplots_one_trace(outpath, show, outvrsn)\n\n    if which in [3, 'all']:\n        print(\" <<<<<< Begin TEST=3 >>>>>>\")\n      "
  },
  {
    "id": "chunk_864",
    "text": "       print(\" <<<<<< Begin TEST=3 >>>>>>\")\n        test3_subplots_mult_trace(outpath, show, outvrsn)\n\n    if which in [4, 'all']:\n        print(\" <<<<<< Begin TEST=4 >>>>>>\")\n        test4_subplots_mult_trace_OrderedDict(outpath, show, outvrsn)\n\n    if which in [5, 'all']:\n        print(\" <<<<<< Begin TEST=5 >>>>>>\")\n        try:\n            test5_plots2word(outpath, show, outvrsn)\n        except:\n            pass\n\n# =============================================================================="
  },
  {
    "id": "chunk_865",
    "text": "=================================================================\n\nif __name__ == '__main__':\n\n    import psse35\n\n    show = True     # True  --> create, save and show Excel spreadsheets and Plots when done\n                    # False --> create, save but do not show Excel spreadsheets and Plots when done\n\n                    # Channel file format\n    outvrsn = 0     # =0, for no Extended Channel output file type (.out)\n                    # =1, for Extended Channel output file type (.outx) (def"
  },
  {
    "id": "chunk_866",
    "text": "for Extended Channel output file type (.outx) (default)\n\n    prg2file = False\n\n    #(a) Run one test a time\n    #\n    # 1) which=0\n    # Need to run \"test0_run_simulation(..)\" before running other tests.\n    #\n    # 2)\n    # which = 1 or 2 or 3 or 4 or 5\n    # After running \"test0_run_simulation(..)\", run other tests one at a time with\n\n    # which = 0\n    # run_tests(which, outvrsn, show, prg2file)\n\n    #(b) Run all tests\n    #    Just uncomment next line to run all tests in this file.\n    #run"
  },
  {
    "id": "chunk_867",
    "text": " next line to run all tests in this file.\n    #run_all_tests(outvrsn)\n\n# =============================================================================================\n#[excelpy_howto_qv_export.py]  Get QV solution and Export to Excel using excelpy Module\n# ====================================================================================================\n'''\nThis is an example file showing how to use excelpy Module to populate Excel Spreadsheets.\nAs an example, here PSSE QV solution is exported"
  },
  {
    "id": "chunk_868",
    "text": ".\nAs an example, here PSSE QV solution is exported to Excel.\n\nGet more info on as:\n    help(arrbox.qv_pp.QV_PP)\n    help(excelpy)\n\n---------------------------------------------------------------------------------\nHow to use this file?\n\nAs showed in __main__ (end of this file)\n- Enable PSSE version specific environment, as an example:\n    import psseXX\n    where XX is PSSE version number like 34, 35, 3500, 3501.\n    \n- call funtion\n    run_export(qvfile)\n    or\n    run_export(qvfile, overwriteshe"
  },
  {
    "id": "chunk_869",
    "text": "qvfile)\n    or\n    run_export(qvfile, overwritesheet=True, show=True, outpath=os.getcwd())\n\nExcel file is saved to a file name derived from qvfile name.\n'''\n\nimport os\n\nshtlst = ['bus voltage', 'summary', 'generator dispatch', 'mismatch']\n\n# ====================================================================================================\ndef qv_summary(xlsobj,sheet,smry):\n    '''\n    Use this to create ->\n    QV worksheet: 'Summary'\n    '''\n    xlsobj.set_active_sheet(sheet)\n    row, col = 1,"
  },
  {
    "id": "chunk_870",
    "text": "  xlsobj.set_active_sheet(sheet)\n    row, col = 1, 1\n    xlsobj.set_cell((row,col),\"QV SOLUTION RESULTS\",fontStyle=\"bold\",fontSize=14, fontColor=\"blue\")\n\n    tmplst=[\n        smry.casetitle.line1,\n        smry.casetitle.line2,\n        'QV output file                             = %s' % smry.file.qv,\n        'Saved Case file                            = %s' % smry.file.sav]\n\n    if smry.file.thr:\n        tmplst.append('Load throwover file                        = %s' % smry.file.thr)\n\n    tlst = "
  },
  {
    "id": "chunk_871",
    "text": "               = %s' % smry.file.thr)\n\n    tlst = [\n        'DFAX file                                  = %s' % smry.file.dfx,\n        'Subsystem file                             = %s' % smry.file.sub,\n        'Monitored Element file                     = %s' % smry.file.mon,\n        'Contingency Description file               = %s' % smry.file.con]\n\n    tmplst.extend(tlst)\n\n    if smry.file.inl:\n        tmplst.append('Inertia and Governor Response file         = %s' % smry.file.inl)\n    if smry"
  },
  {
    "id": "chunk_872",
    "text": "se file         = %s' % smry.file.inl)\n    if smry.file.zip:\n        tmplst.append('Incremental Save Case Archive file         = %s' % smry.file.zip)\n\n    tlst = [\n        ' ',                                                                       # blank row\n        'Number of Contingencies+Base Case          = %d' % smry.qvsize.ncase,\n        'Number of Monitored Generators(Plants)     = %d' % smry.qvsize.nmgnbus,\n        'Number of Voltage Monitored Buses          = %d' % smry.qvsize.nmvbus,\n "
  },
  {
    "id": "chunk_873",
    "text": "tored Buses          = %d' % smry.qvsize.nmvbus,\n        'Number of Voltage Monitored Records        = %d' % smry.qvsize.nmvrec,\n        'Number of maximum voltage setpoint changes = %d' % smry.qvsize.nmxvstp,\n        ]\n\n    tmplst.extend(tlst)\n\n    row_optn_ttl = len(tmplst) + 2 + 2 # 2 for top title+blank row and 2 for blank row+opt ttl\n    jnklst=[' ', 'QV Solution Options:']\n    for i in range(len(smry.options)):\n        j=smry.options[i]\n        ti=str(i+1).rjust(2)\n        tj=str(j)\n      "
  },
  {
    "id": "chunk_874",
    "text": "     ti=str(i+1).rjust(2)\n        tj=str(j)\n        t1=arrbox.qv_pp._QV_INT_OPTIONS_NAMES[i]\n        if (i+1)==arrbox.qv_pp._QV_INT_OPTIONS_STUDY_BUS_INDEX:\n            jnklst.append(\"option(%(ti)s): %(t1)s =%(tj)s\" % vars())\n        else:\n            t2=arrbox.qv_pp._QV_INT_OPTIONS_LIST[i][j]\n            jnklst.append(\"option(%(ti)s): %(t1)s =%(tj)s =%(t2)s\" % vars())\n\n    tmplst.extend(jnklst)\n    row_vals_ttl = len(tmplst) + 2 + 2 # 2 for top title+blank row and 2 for blank row+val ttl\n\n    j"
  },
  {
    "id": "chunk_875",
    "text": "title+blank row and 2 for blank row+val ttl\n\n    jnklst=[' ', 'QV Solution Values:']\n    for i in range(len(smry.realvalues)):\n        ti=str(i+1)\n        tn=arrbox.qv_pp._QV_REAL_VALUES_NAMES[i]\n        tv=\"%g\" % smry.realvalues[i]\n        jnklst.append(\"value(%(ti)s): %(tn)s =%(tv)s\" % vars())\n\n    tmplst.extend(jnklst)\n    del jnklst\n\n    row += 2\n    bottomRow,rightCol = xlsobj.set_range(row,col,tmplst,transpose=True)\n    xlsobj.font_color((row,col,row+1,col),'brown')\n    xlsobj.font_color(("
  },
  {
    "id": "chunk_876",
    "text": "ow,col,row+1,col),'brown')\n    xlsobj.font_color((row_optn_ttl,col),'red')\n    xlsobj.font_color((row_vals_ttl,col),'red')\n\n    if smry.qvsize.ncase:\n        row = bottomRow+2\n        xlsobj.set_cell((row,col),\"QV Contingencies\",fontStyle=\"Bold\",fontSize=12, fontColor=\"red\")\n\n        conlst = [['CON#', 'LABEL', 'Min Vstp', 'Max Vstp', 'Min MVAR', 'Max MVAR',\n                   'Max Mismatch', 'DESCRIPTION']]\n        # determine rows for which QV is failed maxmsm>smry.realvalues[0]\n        rfrm ="
  },
  {
    "id": "chunk_877",
    "text": "is failed maxmsm>smry.realvalues[0]\n        rfrm = row+1\n        rto  = row+1\n        failrows = []\n        for i in range(smry.qvsize.ncase):\n            rfrm += 1\n            rto  += 1\n            if i==0:\n                srnum = ' '\n            else:\n                srnum = str(i)\n            nam  = smry.colabel[i]\n            minvstp = smry.minvstp[i]\n            maxvstp = smry.maxvstp[i]\n            minmvar = smry.minmvar[i]\n            maxmvar = smry.maxmvar[i]\n            maxmsm  = smry.m"
  },
  {
    "id": "chunk_878",
    "text": "var = smry.maxmvar[i]\n            maxmsm  = smry.maxmsm[i]\n            for j in range(len(smry.codesc[i])):\n                dsc = smry.codesc[i][j]\n                if j==0:\n                    conlst.append([srnum,nam,minvstp,maxvstp,minmvar,maxmvar,maxmsm,dsc])\n                else:\n                    conlst.append(['' ,'' ,'' ,'' ,'' ,'' ,'' ,dsc])\n                    rto += 1\n            if maxmsm>smry.realvalues[0]:\n                failrows.append([rfrm, rto])\n            else:\n            "
  },
  {
    "id": "chunk_879",
    "text": "append([rfrm, rto])\n            else:\n                failrows.append([0, 0])\n            rfrm = rto\n\n        row += 1\n        bottomRow,rightCol = xlsobj.set_range(row,col,conlst)\n        xlsobj.font_color((row,col,row,rightCol), \"dgreen\")\n        xlsobj.font((row,col+2,bottomRow,col+3),numberFormat='0.00')  # Min Vstp and Max Vstp\n        xlsobj.font((row,col+4,bottomRow,col+6),numberFormat='0.000') # Min MVAR, Max MVAR and Max MSM\n        xlsobj.align((row,col),'right')\n        xlsobj.font((r"
  },
  {
    "id": "chunk_880",
    "text": "bj.align((row,col),'right')\n        xlsobj.font((row,col,row,rightCol),fontStyle=('Bold',))\n        xlsobj.autofit_columns((row,col+1,row,rightCol))\n        for each in failrows:\n            r1 = each[0]\n            r2 = each[1]\n            if r1 and r2:\n                xlsobj.font((r1,col,r2,rightCol),fontColor=\"cyan\",fontStyle='bold')\n    else:\n        xlsobj.set_cell((row,col),\"No Contingencies..\",fontStyle=\"Bold\",fontSize=12, fontColor=\"red\")\n\n# =============================================="
  },
  {
    "id": "chunk_881",
    "text": "\n\n# ====================================================================================================\ndef qv_mismath(xlsobj,sheet,lbl,ttl,row,rowttl,mwtransfer,mvaworst,mvatotal,cnvflag,cnvcond):\n    '''\n    Use this to create ->\n    QV worksheet: 'Mismatch'\n    '''\n    \n    # assemble data in columns: 1st=MW Transfer, 2nd=MVAWORST and 3rd=MVATOTAL\n    contitle = 'CONTINGENCY: ' + lbl.strip() + 5*' ' + ttl # Contingency Label\n    cnvyesno = []\n    noclns   = []\n    i = 1\n    for each in cnvfl"
  },
  {
    "id": "chunk_882",
    "text": "\n    noclns   = []\n    i = 1\n    for each in cnvflag:\n        i += 1\n        if each:\n            cnvyesno.append('YES')\n            noclns.append(0)\n        else:\n            cnvyesno.append('NO')\n            noclns.append(i)\n\n    tmplst = [ rowttl ]\n    for i in range(len(mwtransfer)):\n        tmplst.append([mwtransfer[i],mvaworst[i],mvatotal[i],cnvyesno[i],cnvcond[i]])\n\n    xlsobj.set_active_sheet(sheet)\n    col = 1\n    # added 1 to row in violation check for 'contitle' row\n    xlsobj.set_cel"
  },
  {
    "id": "chunk_883",
    "text": "lation check for 'contitle' row\n    xlsobj.set_cell((row,col+1),contitle,fontStyle='bold',fontSize=12,fontColor=\"dgreen\")\n    row += 1\n    bottomRow,rightCol = xlsobj.set_range(row,col,tmplst,transpose=True,numberFormat=\"0.00000\")\n    xlsobj.font((row,col,row,rightCol),fontColor=\"red\",fontStyle='bold',numberFormat=\"0.000\")\n    xlsobj.align((row,col,row,rightCol),'h_center')\n    xlsobj.align((row+3,col,row+3,rightCol),'h_center')\n    xlsobj.align((row,col,bottomRow,col),'right')\n    xlsobj.font(("
  },
  {
    "id": "chunk_884",
    "text": "(row,col,bottomRow,col),'right')\n    xlsobj.font((row+1,col,bottomRow,col),fontColor=\"blue\",fontStyle='bold')\n    for each in noclns:\n        if each:\n            xlsobj.font((row+3,each,bottomRow,each),fontColor=\"cyan\",fontStyle='bold')\n\n    row = bottomRow + 2 # one blank row\n\n    return row\n\n# ====================================================================================================\ndef qv_one(xlsobj,sheet,lbl,ttl,row,rowttl,mwtransfer,solnvalue,options,cnvflag=[]):\n    '''\n    Use "
  },
  {
    "id": "chunk_885",
    "text": "er,solnvalue,options,cnvflag=[]):\n    '''\n    Use this to create ->\n    QV worksheets: 'Bus Voltage', 'Generator Dispatch'\n    '''\n\n    contitle = 'CONTINGENCY: ' + lbl.strip() + 5*' ' + ttl # Contingency Label\n    namesplit = options[0]\n    nttlclns  = options[1]\n    transpose = options[2]\n\n    # determine non-converged solution columns\n    noclns = []\n    i = nttlclns\n    for each in cnvflag:\n        i += 1\n        if each:\n            noclns.append(0)\n        else:\n            noclns.append(i"
  },
  {
    "id": "chunk_886",
    "text": "ppend(0)\n        else:\n            noclns.append(i)\n\n    # assemble data in columns: 1st=MW Transfer, rest=solution values\n    t = []\n    for i in range(len(mwtransfer)):\n        t1 = list(solnvalue[i])\n        t1.insert(0,mwtransfer[i])\n        t.append(t1)\n        \n    tmplst = t\n    tmplst.insert(0,rowttl)\n    xlsobj.set_active_sheet(sheet)\n    col = 1\n    xlsobj.set_cell((row,col+nttlclns),contitle,fontStyle='bold',fontSize=12,fontColor=\"dgreen\")\n    row += 1\n    bottomRow,rightCol = xlsobj."
  },
  {
    "id": "chunk_887",
    "text": "en\")\n    row += 1\n    bottomRow,rightCol = xlsobj.set_range(row,col,tmplst,transpose=transpose)\n    xlsobj.font((row,col+nttlclns-1,row,rightCol),fontColor=\"red\",fontStyle='bold')\n    xlsobj.font((row,col+nttlclns,bottomRow,rightCol),numberFormat=\"0.000\")\n    xlsobj.align((row,col,row,rightCol),'h_center')\n    if namesplit: xlsobj.merge((row,col,row,nttlclns))\n    xlsobj.align((row,col),'right')\n    xlsobj.font((row+1,col,bottomRow,nttlclns),fontColor=\"blue\",fontStyle='bold')\n    for each in noc"
  },
  {
    "id": "chunk_888",
    "text": "Color=\"blue\",fontStyle='bold')\n    for each in noclns:\n        if each:\n            xlsobj.font((row+1,each,bottomRow,each),fontColor=\"cyan\")\n    row = bottomRow + 2 # one blank row\n\n    return row\n\n# ====================================================================================================\n\ndef run_export(qvfile, overwritesheet=True, show=True, outpath=os.getcwd()):\n    import arrbox.qv_pp\n    import excelpy\n    \n    if not os.path.exists(qvfile):\n        msgstr = \" Error - QV file do"
  },
  {
    "id": "chunk_889",
    "text": "sts(qvfile):\n        msgstr = \" Error - QV file does not exist, no export.\\n     {}.\" .format(qvfile)\n        print(msgstr)\n        return\n        \n    p, nx = os.path.split(qvfile)\n    xlnam, x = os.path.splitext(nx)\n    xlnam = \"{}_qv\".format(xlnam)\n    xlsfile = os.path.join(outpath, xlnam)\n\n    # -----------------------------------------------------------\n    xlsobj = excelpy.workbook(xlsfile, shtlst[0], overwritesheet=overwritesheet)\n    if show:\n        xlsobj.show()\n    else:\n        xlso"
  },
  {
    "id": "chunk_890",
    "text": "show:\n        xlsobj.show()\n    else:\n        xlsobj.hide()\n\n    xlsobj.show_alerts(0) # do not show pop-up alerts\n    xlsfnam = xlsobj.XLSFNAM\n\n    for shtnam in shtlst[1:]:\n        xlsobj.worksheet_add_end(shtnam, overwritesheet=overwritesheet)\n    \n    xlsobj.page_format(orientation=\"landscape\",left=1.0,right=1.0,\n                       top=0.5,bottom=0.5,header=0.25,footer=0.25)\n    xlsobj.page_footer(left='page number of page total', right='date, time')\n    xlsobj.page_header(center='file n"
  },
  {
    "id": "chunk_891",
    "text": "date, time')\n    xlsobj.page_header(center='file name:sheet name')\n    xlsobj.font_sheet()\n\n    # -----------------------------------------------------------\n    # Retrive QV data\n    qvobj = arrbox.qv_pp.QV_PP(qvfile)\n    smry = qvobj.summary()\n\n    qv_summary(xlsobj, 'summary', smry)\n\n    row_msm = 1\n    msmlabel = ['VOLTAGE SETPOINT->', 'LARGEST MVA MISMATCH', 'TOTAL MVA MISMATCH', 'CONVERGED', 'CONVERGE CONDITION']\n\n    row_vlt = 1\n    options_vlt = [False,1,True]\n    mvbuslabel = list(smry."
  },
  {
    "id": "chunk_892",
    "text": "s_vlt = [False,1,True]\n    mvbuslabel = list(smry.mvbuslabel)\n    mvbuslabel.insert(0,'VOLTAGE SETPOINT->')\n\n    row_gen = 1\n    options_gen = [False,1,True]\n    mgenbuslabel = list(smry.mgenbus)\n    mgenbuslabel.insert(0,'VOLTAGE SETPOINT->')\n    \n    ret_ierr = 0\n    for lbl in smry.colabel:\n        soln = qvobj.solution(lbl)\n        if soln==None: continue                 # contingency solution not found, move to next\n        if soln.ierr !=0: ret_ierr = soln.ierr  # return any non-zero ierr\n"
  },
  {
    "id": "chunk_893",
    "text": " ret_ierr = soln.ierr  # return any non-zero ierr\n\n        row_msm = qv_mismath(xlsobj, 'mismatch',lbl,'Mismatch (MVA)',\n                             row_msm,msmlabel,soln.vsetpoint,soln.mvaworst,soln.mvatotal,\n                             soln.cnvflag, soln.cnvcond)\n        \n        row_vlt = qv_one(xlsobj,'bus voltage',lbl,'Voltage (pu)',\n                         row_vlt,mvbuslabel,soln.vsetpoint,soln.volts,options_vlt,soln.cnvflag)\n\n        row_gen = qv_one(xlsobj,'generator dispatch',lbl,'Pl"
  },
  {
    "id": "chunk_894",
    "text": "w_gen = qv_one(xlsobj,'generator dispatch',lbl,'Plant (MVAR)',\n                         row_gen,mgenbuslabel,soln.vsetpoint,soln.mgenmvar,options_gen,soln.cnvflag)\n\n    # --------------------------------------\n    # Format worksheets\n    xlsobj.autofit_columns((1,1),'mismatch')\n    xlsobj.autofit_columns((1,1),'bus voltage')\n    xlsobj.autofit_columns((1,1),'generator dispatch')\n\n    if show: xlsobj.set_active_sheet('bus voltage')\n    \n    # ------------------------------------------------------"
  },
  {
    "id": "chunk_895",
    "text": "-------------------------------------------------------\n    # Save the workbook and close the Excel application\n    xlsfile = xlsobj.save()\n\n    if not show:\n        xlsobj.close()\n        msgstr = \"\\n Done ...QV Export saved to file:\\n     {}.\" .format(xlsfnam)\n        print(msgstr)\n\n# ====================================================================================================\nif (__name__ == \"__main__\"):\n    pass\n    # Change appropriately 'psseXX' and 'qvfile' values below.\n    import"
  },
  {
    "id": "chunk_896",
    "text": "ely 'psseXX' and 'qvfile' values below.\n    import psseXX\n    qvfile = \"savnw.qv\"\n    run_export(qvfile, overwritesheet=True, show=True)\n#[gic_demo.py]    GIC Analysis in PSSE\n# =====================================================================================================\n'''This is an example file showing how to run different GIC Events with and without supplemental\nevent moving boxes.\n\n---------------------------------------------------------------------------------\nHow to use this file"
  },
  {
    "id": "chunk_897",
    "text": "-----------------------------\nHow to use this file?\n\nAs showed in __main__ (end of this file)\n- Enable PSSE version specific environment, as an example [where XX is psse version number]:\n    import psseXX\n\n- call function\n    Run various functions from this file as desired.\n    See notes in _run_one_test_api(..) (end of this file).\n'''\n\n\"\"\"\nUse any of these keywords to run GIC_8.\nKeyword               Default          Description\n                                     # INTGOPTNS[]\ntielevels      "
  },
  {
    "id": "chunk_898",
    "text": "                     # INTGOPTNS[]\ntielevels           = 0              #  1  Number of levels of inter-tie buses to add to study subsystem\nstudy_year          = 0              #  2  Year number to scale benchmark event GMD storm. These scaling factors account in the influence of geomagnetic latitude on the estimated geoelectric field magnitude and are provided in NERC TPL-007.\nsid_supp            = 0              #  3  Subsystem sid for supplemental GMD event\nthermal_ana_optn    = 0            "
  },
  {
    "id": "chunk_899",
    "text": "ntal GMD event\nthermal_ana_optn    = 0              #  4  Option for Transformer Thermal Analysis\ndegscan_pf_optn     = 0              #  5  Option to run power flow for each degree scan calculation\nboundary_trn        = 0              #  6  Option to include buses of boundary transformers in study subsystem\nworstcase_trn       = 0              #  7  Option for Transformers to include in worst case determination\nsupp_evt            = 0              #  8  Option for Supplemental event and moving "
  },
  {
    "id": "chunk_900",
    "text": "   #  8  Option for Supplemental event and moving box\nsupp_box_num        = 0              #  9  Option for number of Supplemental event moving boxes. It is not used when intgoptns(8)=0 and intgoptns(8)=4\nbrn_seg_efld        = 0              # 10  Option for treatment of the transmission line that intersect with Supplemental event moving box\n                                     # REALOPTNS[]\nefield_mag          = 8.0            #  1  electric field magnitude in units defined by charoptns(2), not"
  },
  {
    "id": "chunk_901",
    "text": "ld magnitude in units defined by charoptns(2), not used when charoptns(1)=nonuniform or supplemental\nefield_deg          = 0              #  2  electric field direction in degrees, range 0 to 360 degrees, not used when charoptns(1)=nonuniform or supplemental\nsubstation_r        = 0.1            #  3  substation grounding dc resistance in ohms\nbranch_xbyr         = 30             #  4  transmission line X/R ratio, must be > 0, used to calculate branch DC resistance if R=0.0 in network data\ntransf"
  },
  {
    "id": "chunk_902",
    "text": "anch DC resistance if R=0.0 in network data\ntransformer_xbyr    = 30             #  5  transformer winding X/R ratio, must be > 0, used to calculate winding DC resistance if R=0.0 in network data\nefield_mag_supp     = 12.0           #  6  supplemental event electric field magnitude in units defined by charoptns(2), not used when charoptns(1)=nonuniform\nefield_deg_supp     = 0.0            #  7  local GMD hot spots electric field direction in degrees, range 0 to 360 degrees, not used when charopt"
  },
  {
    "id": "chunk_903",
    "text": "ees, range 0 to 360 degrees, not used when charoptns(1)=nonuniform\nbranch_rac2rdc      = 1.0            #  8  transmission line AC to DC resistance conversion factor, must be > 0\ntransformer_rac2rdc = 1.0            #  9  transformer winding AC to DC resistance conversion factor, must be > 0\ndegscan_step        = 10.0           # 10  Degree Scan step size, range 1.0 to 180 degrees\nmagscan_step        = 4.0            # 11   Magnitude Scan step size, must be > 1.0 V/km\npf_qpct_step        = 100.0"
  },
  {
    "id": "chunk_904",
    "text": "ze, must be > 1.0 V/km\npf_qpct_step        = 100.0          # 12   Percent GMD Mvar loss step size. Total GMD Mvar losses added incrementally to the base case to obtain power flow solution, must be > 1.0\nmagscan_max         = 20.0           # 13   Magnitude Scan maximum storm strength, must be > 1.0\nsupp_box_ns_km      = 100.0          # 14   Supplemental event moving box North-South length in km, must be > 1.0, used when intgoptns(8)>0\nsupp_box_ew_km      = 500.0          # 15   Supplemental ev"
  },
  {
    "id": "chunk_905",
    "text": "ew_km      = 500.0          # 15   Supplemental event moving box East-West length in km, must be > 1.0, used when intgoptns(8)>0\nsupp_box_lon_c      = 0.0            # 16   Supplemental event moving box center point longitude in degrees, used only when intgoptns(8)=4\nsupp_box_lat_c      = 0.0            # 17   Supplemental event moving box center point latitude in degrees, used only when intgoptns(8)=4\n                                     # CHAROPTNS[]\nefield_type         = \"uniform\"      #  1  "
  },
  {
    "id": "chunk_906",
    "text": "PTNS[]\nefield_type         = \"uniform\"      #  1  Electric Field Type\nefield_unit         = \"v/km\"         #  2  Units of Electric Field Magnitude\naddfile_optn        = \"rdch\"         #  3  Option to add GIC updates to base case\ngic2mvar_optn       = \"kfactors\"     #  4  Option to select method for GIC to Mvar Calculation\nearth_model_name    = \"\"             #  5  Earth Model Name. A Standard or User defined model name must be provided when Benchmark Event or Non-uniform electric field is to be "
  },
  {
    "id": "chunk_907",
    "text": "mark Event or Non-uniform electric field is to be modeled or Transformer Thermal Analysis is to be performed.\nscan_storm_event    = \"\"             #  6  Option to scan storm event scenarios\npower_flow_optn     = \"\"             #  7 Option to solve Power Flow with GIC losses added to the base case\n                                     # EJETOPTNS[]\nejet_million_amps   = 1.0            #  1  eletrojet current in million amperes, must be > 0\nejet_halfwidth_km   = 200.0          #  2  Cauchy distribu"
  },
  {
    "id": "chunk_908",
    "text": "fwidth_km   = 200.0          #  2  Cauchy distribution half-width in km, must be > 0\nejet_period_min     = 5.0            #  3  period of variation in minutes, must be > 0\nejet_height_km      = 100.0          #  4  height of current in km, must be > 0\nejet_center_deg     = 54.0           #  5  latitude of center of electrojet in degrees\n                                     # FILEOPTNS[]\naddfile             = \"\"             #  2  GIC updates to Base Case file name (output).\npurgfile            = "
  },
  {
    "id": "chunk_909",
    "text": "se Case file name (output).\npurgfile            = \"\"             #  3  RDCH file to remove GIC updates from GIC updated case in working memory to set it back to Base Case network condition (output).\nrnwkfile            = \"\"             #  4  GIC dc resistive network raw file. This represents the dc network used to calculate GIC flow (output).\npygicfile           = \"nooutput\"     #  5  GIC Results map data file for given Efield magnitude and degrees OR Efield magnitude and degrees scans which giv"
  },
  {
    "id": "chunk_910",
    "text": "es OR Efield magnitude and degrees scans which give maximum Var losses when scans are performed (output).  This is used by GICMAPS to plot GIC results on network map.\ngictfile            = \"nooutput\"     #  6  Transformer Thermal Analysis GIC(t) CSV file (output).\n                                     # REPTOPTNS[]\nrptoptn             = -1             #  1  what to report\nrptbrn_indv         = 1              #  2  report induced branch voltages\nrptdc_busv          = 1              #  3  report DC"
  },
  {
    "id": "chunk_911",
    "text": "tdc_busv          = 1              #  3  report DC bus voltages\nrptbrn_gic          = 1              #  4  report branch GIC flows\nrpttrn_gic          = 1              #  5  report transformer GIC flows\nrptstn_gic          = 1              #  6  report substation GIC flows\nrpttrn_q            = 1              #  7  report transformer losses\nrpt_sid             = 0              #  8  Subsystem sid for report\n\"\"\"\n\nimport sys, os, time, collections\n\n# ==============================================="
  },
  {
    "id": "chunk_912",
    "text": "\n# =========================================================================\n\ndef start_timer():\n    '''start_time = start_timer()\n    Start timer and return time in seconds since the Epoch.\n    '''\n    start_time = time.time()\n    return start_time\n\n# -------------------------------------------------------------------------\n\ndef finish_timer(start_time):\n    '''timstr = finish_timer(start_time)\n    Finish timer and return elapsed time as string.\n    where start_time is value returned by start_t"
  },
  {
    "id": "chunk_913",
    "text": "\n    where start_time is value returned by start_timer().\n    '''\n    finish_time = time.time()\n    elapsed_sec = finish_time - start_time\n    hr,mn1 = divmod(elapsed_sec,3600)\n    mn,sc  = divmod(mn1,60)\n    timstr = \" Elapsed time: Hours=%d , Minutes=%d, Seconds=%g\\n\" % (hr, mn, sc)\n    return timstr\n\n# =========================================================================\n\n# PSSE version Example folder\ndef get_example_folder():\n    import psspy\n    pn = os.path.dirname(psspy.__file__)\n    "
  },
  {
    "id": "chunk_914",
    "text": "sspy\n    pn = os.path.dirname(psspy.__file__)\n    p, jnk = os.path.split(pn)\n    examdir = os.path.join(p, 'Example')\n    return examdir\n\n# -------------------------------------------------------------------------\n\ndef get_output_dir(outpath=''):\n    if outpath:\n        outdir = outpath\n        if not os.path.exists(outdir): os.mkdir(outdir)\n    else:\n        outdir = os.path.dirname(__file__)\n        outdir = os.path.join(outdir, 'gic_demo_output')\n        if not os.path.exists(outdir): os.mkdi"
  },
  {
    "id": "chunk_915",
    "text": "t')\n        if not os.path.exists(outdir): os.mkdir(outdir)\n\n    return outdir\n\n# -------------------------------------------------------------------------\n\ndef get_output_filename(fname, outpath=''):\n\n    outdir = get_output_dir(outpath)\n    retvfile = os.path.join(outdir, fname)\n\n    return retvfile\n\n# =========================================================================\n\ndef run_gic(sid, allbus, outnam, outdir, prg2file, rpt2file, **kwds):\n\n    import psspy\n\n    _i = psspy.getdefaultint()"
  },
  {
    "id": "chunk_916",
    "text": "\n\n    import psspy\n\n    _i = psspy.getdefaultint()\n    _f = psspy.getdefaultreal()\n\n    name,major,minor,modlvl,date,stat = psspy.psseversion()\n    vrsn = \"v{}{}{}\".format(major,minor,modlvl)\n\n    if 'efield_type' not in kwds: kwds['efield_type'] = \"benchmark\"\n\n    # add suffix to prg/rpt names (to make them unique, so they are not overwritten.)\n    optn_nam_dict = collections.OrderedDict([\n        ('efield_deg'      , 'deg' ),\n        ('scan_storm_event', ''    ),\n        ('power_flow_optn' , '"
  },
  {
    "id": "chunk_917",
    "text": "rm_event', ''    ),\n        ('power_flow_optn' , ''    ),\n        ('boundary_trn'    , 'btrn'),\n        ('worstcase_trn'   , 'wtrn'),\n        ('supp_evt'        , 'optnbx' ),\n        ('brn_seg_efld'    , 'brnseg'),\n        ])\n\n    sid_supp, supp_evt, brn_seg = 0, 0, 0\n    if 'sid_supp' in kwds: sid_supp = kwds['sid_supp']\n    if 'supp_evt' in kwds: supp_evt = kwds['supp_evt']\n    if 'supp_box_num' in kwds: supp_box_num = kwds['supp_box_num']\n    if 'supp_box_lon_c' in kwds: supp_box_lon_c = kwds"
  },
  {
    "id": "chunk_918",
    "text": "if 'supp_box_lon_c' in kwds: supp_box_lon_c = kwds['supp_box_lon_c']\n    if 'supp_box_lat_c' in kwds: supp_box_lat_c = kwds['supp_box_lat_c']\n    if 'brn_seg_efld' in kwds:brn_seg = kwds['brn_seg_efld']\n\n    s_brnseg = ''\n    subdir = ''\n    outfsfx = kwds['efield_type'][0]\n    if (supp_evt==1 and sid_supp>0)             or \\\n       (supp_evt in [2,3,4] and supp_box_num>0) or \\\n       (supp_evt==5 and abs(supp_box_lon_c)>0 and abs(supp_box_lat_c)>0):\n        outfsfx += \"+s\"\n        s_brnseg = \"b"
  },
  {
    "id": "chunk_919",
    "text": ">0):\n        outfsfx += \"+s\"\n        s_brnseg = \"bseg{}\".format(brn_seg)\n        if supp_evt in [2,3] and supp_box_num>0:\n            subdir = \"supp_opbx{}_numbx{}_brnseg{}\".format(supp_evt, supp_box_num, brn_seg)\n\n    for k, s_nam in optn_nam_dict.items():\n        if k in kwds:\n            vin = kwds[k]\n            if vin:\n                if s_nam:\n                    if supp_evt==1:\n                        outfsfx += \"_sid\"\n                    else:\n                        outfsfx += \"_{}{}\".f"
  },
  {
    "id": "chunk_920",
    "text": "else:\n                        outfsfx += \"_{}{}\".format(s_nam, vin)\n                else:\n                    outfsfx += \"_{}\".format(vin)\n\n    if s_brnseg:\n        outfsfx += \"_{}\".format(s_brnseg)\n\n    outdir = get_output_dir(outdir)\n    if subdir:\n        outdir = os.path.join(outdir, subdir)\n        if not os.path.exists(outdir): os.mkdir(outdir)\n\n    if prg2file:\n        nam = \"{}_{}_progress.txt\".format(outnam, outfsfx)\n        prgfile = os.path.join(outdir, nam)\n\n    if rpt2file:\n        "
  },
  {
    "id": "chunk_921",
    "text": ".path.join(outdir, nam)\n\n    if rpt2file:\n        nam = \"{}_{}_report.txt\".format(outnam, outfsfx)\n        rptfile = os.path.join(outdir, nam)\n\n    # Create output file names when they are not provided\n    for sfx in ['add', 'purg', 'rnwk', 'pygic', 'gict']:\n        k = \"{}file\".format(sfx)\n        if k not in kwds:\n            s0 = sfx\n            if sfx=='pygic': s0 = 'map'\n            fnam = \"{}_{}_{}\".format(outnam, outfsfx, s0)\n            kwds[k] = os.path.join(outdir, fnam)\n\n    # run act"
  },
  {
    "id": "chunk_922",
    "text": "wds[k] = os.path.join(outdir, fnam)\n\n    # run activity gic_8\n    if prg2file: psspy.progress_output(2,prgfile,[0,0])\n    if rpt2file: psspy.report_output(2,rptfile,[0,0])\n\n    start_time = start_timer()\n    psspy.gic_8(sid, allbus, **kwds)\n    timstr = finish_timer(start_time)\n\n    if prg2file: psspy.progress_output(1,\"\",[0,0])\n    if rpt2file: psspy.report_output(1,\"\",[0,0])\n\n    print(timstr)\n\n    if rpt2file:\n        print(\"  --------- Report saved to: {} \".format(rptfile))\n\n# =============="
  },
  {
    "id": "chunk_923",
    "text": " saved to: {} \".format(rptfile))\n\n# =========================================================================\n\ndef run_test_sample(**optns):\n    import psspy\n    psspy.psseinit()\n\n    gicfilevrsn = optns.get('gicfilevrsn', 4)\n\n    if gicfilevrsn>4:\n        savfnam = r'sample_nb.sav'      # SAV file with Node Breaker Modeling\n        gicfnam = r'sample_fv5.gic'     # GIC file version 5\n    else:\n        savfnam = r'sample.sav'         # SAV file with NO Node Breaker Modeling\n        gicfnam = r's"
  },
  {
    "id": "chunk_924",
    "text": "ith NO Node Breaker Modeling\n        gicfnam = r'sample_fv4.gic'     # GIC file version 4\n\n    examdir = get_example_folder()\n\n    savfile = os.path.join(examdir, savfnam)\n    gicfile = os.path.join(examdir, gicfnam)\n\n    sid      = 0\n    allbus   = 1\n\n    outnam, jnk = os.path.splitext(savfnam)\n\n    outdir   = get_output_dir()\n    prg2file = True\n    rpt2file = True\n\n    study_year = 2019\n    earth_model_name = 'SHIELD'\n\n    kwds = {}\n    kwds['study_year'] = study_year\n    kwds['earth_model_na"
  },
  {
    "id": "chunk_925",
    "text": "study_year'] = study_year\n    kwds['earth_model_name'] = earth_model_name\n    kwds['addfile']  = ''\n    kwds['purgfile'] = ''\n\n    for k, v in optns.items():\n        if k=='gicfilevrsn': continue\n        kwds[k] = v\n\n    if 'thermal_ana_optn' not in kwds:\n        kwds['thermal_ana_optn'] = -1\n\n    psspy.case(savfile)\n    psspy.gic_read(gicfile)\n\n    if 'sid_supp' in kwds:\n        kwds['sid_supp'] = 4\n        areas = [5]\n        ierr = psspy.bsys(kwds['sid_supp'], numarea=len(areas), areas=areas)"
  },
  {
    "id": "chunk_926",
    "text": "kwds['sid_supp'], numarea=len(areas), areas=areas)\n\n    run_gic(sid, allbus, outnam, outdir, prg2file, rpt2file, **kwds)\n\n# =========================================================================\n\ndef run_gicmaps(pygicfile):\n    import arrbox.gicmaps\n\n    outdir   = get_output_dir()\n    fpth, nx = os.path.split(pygicfile)\n    outnam, fxtn = os.path.splitext(nx)\n    if not fpth: pygicfile = os.path.join(outdir, pygicfile)\n\n    outdir_maps = os.path.join(outdir, 'maps')\n    if not os.path.exists"
  },
  {
    "id": "chunk_927",
    "text": "ath.join(outdir, 'maps')\n    if not os.path.exists(outdir_maps): os.mkdir(outdir_maps)\n\n    gicmapsobj = arrbox.gicmaps.GICMAPS(pygicfile)\n\n    if gicmapsobj.ierr: return\n\n    gicmapsobj.enable_draw_supp_box()\n\n    pngfile = get_output_filename(\"{}_ssflow.png\".format(outnam), outdir_maps)\n\n    sublst = list(gicmapsobj.pygicobj.substation.keys())\n    gicmapsobj.annotate_substations(sublst, color='blue', fontsize=10)\n\n    ax, fig, basemap, anptobj = gicmapsobj.plot_substation_gicflows(pngfile, mar"
  },
  {
    "id": "chunk_928",
    "text": "= gicmapsobj.plot_substation_gicflows(pngfile, markersize=20)\n\n    oufile_seg = get_output_filename(\"{}_brnsegments.txt\".format(outnam), outdir_maps)\n    gicmapsobj.report_supp_box_line_segments(rptfile=oufile_seg)\n\n    oufile_evt = get_output_filename(\"{}_element_events.txt\".format(outnam), outdir_maps)\n    gicmapsobj.report_network_element_events(rptfile=oufile_evt)\n\n    gicmapsobj.plots_show()\n\n# =========================================================================\n\ndef _template_sample()"
  },
  {
    "id": "chunk_929",
    "text": "==========================\n\ndef _template_sample():\n    # 1) Benchmark event\n    #    No storm scan, No supplemental event, No power flow solution\n    run_test_sample(efield_type='benchmark', gicfilevrsn=5)\n\n    # 2) Supplemental event\n    #    No storm scan, No power flow solution\n    run_test_sample(efield_type='supplemental', gicfilevrsn=5)\n\n    # 3) Benchmark + Supplemental event\n    #    Supplemental event defined by subsystem\n    #    No storm scan, No power flow solution\n    run_test_samp"
  },
  {
    "id": "chunk_930",
    "text": "orm scan, No power flow solution\n    run_test_sample(efield_type='benchmark', supp_evt=1, sid_supp=4, gicfilevrsn=5)\n\n    # 4) Benchmark + Supplemental event\n    #    Supplemental event defined by Moving Box,\n    #    Rank substations with maximum GIC flows as center of the moving box\n    #    No storm scan, No power flow solution\n    run_test_sample(efield_type='benchmark', supp_evt=2, supp_box_num=2, gicfilevrsn=5)\n\n    # 5) Benchmark + Supplemental event\n    #    Supplemental event defined by"
  },
  {
    "id": "chunk_931",
    "text": "ental event\n    #    Supplemental event defined by Moving Box,\n    #    Rank transformers with maximum GIC flows as center of the moving box\n    #    No storm scan, No power flow solution\n    run_test_sample(efield_type='benchmark', supp_evt=3, supp_box_num=2, gicfilevrsn=5)\n\n    # 6) Benchmark + Supplemental event\n    #    Supplemental event defined by Moving Box,\n    #    Use substation number provided as center of the moving box\n    #    No storm scan, No power flow solution\n    run_test_samp"
  },
  {
    "id": "chunk_932",
    "text": "orm scan, No power flow solution\n    run_test_sample(efield_type='benchmark', supp_evt=4, supp_box_num=10, gicfilevrsn=5)\n\n    # 7) Benchmark + Supplemental event\n    #    Supplemental event defined by Moving Box,\n    #    Use location provided as center of the moving box\n    #    No storm scan, No power flow solution\n    run_test_sample(efield_type='benchmark', supp_evt=5, supp_box_lon_c=-82.0, supp_box_lat_c=32.0, gicfilevrsn=5)\n\n    # 8) Benchmark + Supplemental event\n    #    Supplemental ev"
  },
  {
    "id": "chunk_933",
    "text": "mark + Supplemental event\n    #    Supplemental event defined by Moving Box,\n    #    Rank substations with maximum GIC flows as center of the moving box\n\n    #    Degree Scan with specified settings [step=1 deg, add Qloss in steps of 100%]\n    #    FDNS - run PowerFlow for each scan step\n    #       Number of degree scans = 1+ 180/degscan_step = 181\n    #       Number PF due % Qstep = 100/pf_qpct_step = 5\n    #       Number PF due to moving boxes = supp_box_num = 20\n    #    Number of GIC calcu"
  },
  {
    "id": "chunk_934",
    "text": "s = supp_box_num = 20\n    #    Number of GIC calculations = 181 (for ranking) + 181*20 (one each supp box) = 3801\n    #    Number of PF solved = 181*20*5 = 18100\n##    run_test_sample(efield_type='benchmark', supp_evt=2, supp_box_num=20,\n##                    scan_storm_event=\"scan_deg\", power_flow_optn='fdns',\n##                    degscan_pf_optn=1, degscan_step=1, pf_qpct_step=20,\n##                    gicfilevrsn=5)\n\n    print(\" all done - _template_sample\")\n\n# =============================="
  },
  {
    "id": "chunk_935",
    "text": "emplate_sample\")\n\n# =========================================================================\ndef _run_one_test_api():\n    # Just run one of these calls as desired.\n\n    run_test_sample(efield_type='benchmark')\n    run_test_sample(efield_type='benchmark', gicfilevrsn=5)\n    run_test_sample(efield_type='benchmark', gicfilevrsn=4)\n    run_test_sample(efield_type='supplemental')\n    run_test_sample(efield_type='benchmark', supp_evt=1, sid_supp=4)\n    run_test_sample(efield_type='benchmark', supp_ev"
  },
  {
    "id": "chunk_936",
    "text": "  run_test_sample(efield_type='benchmark', supp_evt=2, supp_box_num=2)\n    run_test_sample(efield_type='benchmark', supp_evt=3, supp_box_num=2)\n    run_test_sample(efield_type='benchmark', supp_evt=4, supp_box_num=10)\n    run_test_sample(efield_type='benchmark', supp_evt=5, supp_box_lon_c=-82.0, supp_box_lat_c=32.0)\n    run_test_sample(efield_type='benchmark', supp_evt=2, supp_box_num=20,\n                    scan_storm_event=\"scan_deg\", power_flow_optn='fdns',\n                    degscan_pf_optn"
  },
  {
    "id": "chunk_937",
    "text": "w_optn='fdns',\n                    degscan_pf_optn=1, degscan_step=1, pf_qpct_step=20)\n\n    # Creat a function similar to \"run_test_sample(..)\"\n    # - to use any power flow study cases\n    # - define common arguments\n    # - output directory etc\n    # Then use that function to run the GIC study of interest.\n\n# =========================================================================\ndef _run_one_test_maps():\n    # Just run one of these calls as desired.\n    # The 'pygic' files created by tests "
  },
  {
    "id": "chunk_938",
    "text": "desired.\n    # The 'pygic' files created by tests in \"_run_one_test_api\" serve as input\n    # for these tests.\n\n    run_gicmaps(r\"sample_b+s_sid_bseg0_map(deg)-oldVrsn.pygic\")\n    run_gicmaps(r\"sample_b_map(deg).pygic\")\n    run_gicmaps(r\"sample_s_map(deg).pygic\")\n    run_gicmaps(r\"sample_b+s_sid_bseg0_map(deg).pygic\")\n    run_gicmaps(r\"sample_b+s_optnbx4_bseg0_map(deg).pygic\")\n    run_gicmaps(r\"sample_b+s_optnbx5_bseg0_map(deg).pygic\")\n    run_gicmaps(r\".\\gic_demo_output\\supp_opbx2_numbx2_brnseg"
  },
  {
    "id": "chunk_939",
    "text": "cmaps(r\".\\gic_demo_output\\supp_opbx2_numbx2_brnseg0\\sample_b+s_optnbx2_bseg0_map(deg)_supp_box1.pygic\")\n    run_gicmaps(r\".\\gic_demo_output\\supp_opbx2_numbx2_brnseg0\\sample_b+s_optnbx2_bseg0_map(deg)_supp_box2.pygic\")\n    run_gicmaps(r\".\\gic_demo_output\\supp_opbx3_numbx2_brnseg0\\sample_b+s_optnbx3_bseg0_map(deg)_supp_box1.pygic\")\n    run_gicmaps(r\".\\gic_demo_output\\supp_opbx3_numbx2_brnseg0\\sample_b+s_optnbx3_bseg0_map(deg)_supp_box2.pygic\")\n\n# ==================================================="
  },
  {
    "id": "chunk_940",
    "text": "========================================================================\nif __name__==\"__main__\":\n    pass\n    #import psse35\n#[gic_report.py]    GIC Analysis in PSSE\n# =====================================================================================================\n'''This is an example file showing how to:\n- Create GIC data file templates in Excel spreadsheets and create GIC data file from those\n  Excel spredsheets\n- Perform GIC analysis, post process GIC results, create customized GIC ana"
  },
  {
    "id": "chunk_941",
    "text": "ost process GIC results, create customized GIC analysis reports\n- Perform GIC analysis, post process GIC results, export GIC analysis results to Excel\n- Map GIC results on network maps\n\nPython module \"gicdata\" is used for creating GIC data files.\n    See help(gicdata) for details.\n\nResult retrival Python module \"pssarrays\" is converted to Python package \"arrbox\".\nThis is done to provide object access instead of function access.\n\nUsing Python package \"arrbox\" it is possible to create multiple obj"
  },
  {
    "id": "chunk_942",
    "text": "age \"arrbox\" it is possible to create multiple objects and compare\nPSSE results.\n\nNow Python module 'pssarrays' provide aliases to modules in package \"arrbox\".\n\nGIC related objects 'GIC' and 'GICMAPS' in module 'pssarrays' will work as is (that is\nwithout any code changes in your script). However, better way to access them is from\npackage arrbox as shown in this script.\n\nSee detailed help on GIC related objects in arrbox as:\nimport arrbox.gic;help(arrbox.gic.GIC)\nimport arrbox.gicmaps;help(arrbo"
  },
  {
    "id": "chunk_943",
    "text": "p(arrbox.gic.GIC)\nimport arrbox.gicmaps;help(arrbox.gicmaps.GICMAPS)\n\n---------------------------------------------------------------------------------\nHow to use this file?\n\nAs showed in __main__ (end of this file)\n- Enable PSSE version specific environment, as an example:\n    import psse35\n\n- call funtion\n    Run various functions from this file as desired. See notes in _run_one_test(..) (end of this file).\n\nSee function gic_results_on_network_map_custom(..) to know how you can decorate defaul"
  },
  {
    "id": "chunk_944",
    "text": "map_custom(..) to know how you can decorate default plots with\ndata point annotations or any other custom settings.\n\n---------------------------------------------------------------------------------\nHow to use PSSE and Python modules like numpy, matplotlib, Basemap together?\n(a) In your python script, call following function before any of these modules are imported.\n    psspy.set_fpcw_py()\n(b) Call following function before exiting your python script.\n    psspy.set_fpcw_psse()\nTo get details why"
  },
  {
    "id": "chunk_945",
    "text": "ript.\n    psspy.set_fpcw_psse()\nTo get details why this is needed, get help(..) on either of these functions.\nRefer function gic_results_on_network_map(..) in this script for usage of these functions.\n'''\n\n# -----------------------------------------------------------------------------------------------------\n\nimport sys, os, time\n\n# -----------------------------------------------------------------------------------------------------\n# PSSE version Example folder\ndef get_example_folder():\n    imp"
  },
  {
    "id": "chunk_946",
    "text": "n Example folder\ndef get_example_folder():\n    import psspy\n    pn = os.path.dirname(psspy.__file__)\n    p, jnk = os.path.split(pn)\n    examdir = os.path.join(p, 'Example')\n    return examdir\n\n# -----------------------------------------------------------------------------------------------------\n\ndef get_output_dir(outpath):\n    # if called from PSSE's Example Folder, create report in subfolder 'Output_Pyscript'\n\n    if outpath:\n        outdir = outpath\n        if not os.path.exists(outdir): os."
  },
  {
    "id": "chunk_947",
    "text": "outpath\n        if not os.path.exists(outdir): os.mkdir(outdir)\n    else:\n        outdir = os.getcwd()\n\n    outdir = os.path.join(outdir, 'gic_report_output')\n    if not os.path.exists(outdir): os.mkdir(outdir)\n\n    return outdir\n\n# -----------------------------------------------------------------------------------------------------\n\ndef get_output_filename(outpath, fname):\n\n    outdir = get_output_dir(outpath)\n    retvfile = os.path.join(outdir, fname)\n\n    return retvfile\n\n# ------------------"
  },
  {
    "id": "chunk_948",
    "text": " fname)\n\n    return retvfile\n\n# -----------------------------------------------------------------------------------------------------\n\ndef _get_outfnam_event(pfx, efield_type, efield_mag, efield_deg, scan_storm_event):\n\n    if efield_type=='nonuniform':\n        outfnam = r\"{}_{}\".format(pfx, efield_type[0])\n    else:\n        if scan_storm_event:\n            outfnam = r\"{}_{}_{:g}(mag)_{:g}(deg)_{}\".format(pfx, efield_type[0], efield_mag, efield_deg, scan_storm_event)\n        else:\n            ou"
  },
  {
    "id": "chunk_949",
    "text": "eg, scan_storm_event)\n        else:\n            outfnam = r\"{}_{}_{:g}(mag)_{:g}(deg)\".format(pfx, efield_type[0], efield_mag, efield_deg)\n\n    return outfnam\n\n# -----------------------------------------------------------------------------------------------------\n\ndef _get_formatted_real_value(vin):\n\n    if vin<_BIGREL:\n        rstr = \"{:12.5f}\".format(vin)\n    else:\n        rstr = \"{:12s}\".format(' ')\n\n    return rstr\n\n# --------------------------------------------------------------------------"
  },
  {
    "id": "chunk_950",
    "text": "-----------------------------------------------------------------------------\ndef _get_filenam_sfx(areas):\n\n    if areas:\n        s_lst = [\"{}\".format(e) for e in areas[:3]]\n        s_sfx = \"\".join(s_lst)\n    else:\n        s_sfx = 'all'\n\n    return s_sfx\n\n# -----------------------------------------------------------------------------------------------------\ndef create_gicdata_template_sample(datapath=None, outpath=None, areas=[], showexcel=True):\n    \"\"\" Create GIC data Excel template using samp"
  },
  {
    "id": "chunk_951",
    "text": "\n    \"\"\" Create GIC data Excel template using sample.sav file from PSSE Example folder.\n\"\"\"\n    import psspy, gicdata\n\n    f_sfx = _get_filenam_sfx(areas)\n\n    savfile   = 'sample.sav'\n    excelfile = 'gicdata_sample_template_{}'.format(f_sfx)\n\n    if not datapath: datapath = get_example_folder()\n\n    savfile = os.path.join(datapath, savfile)\n    excelfile = get_output_filename(outpath, excelfile)\n\n    basekv    = []\n    areas     = areas\n    buses     = []\n    owners    = []\n    zones     = []\n"
  },
  {
    "id": "chunk_952",
    "text": "es     = []\n    owners    = []\n    zones     = []\n    tielevels = 0\n\n    psspy.psseinit()\n\n    excelfile = gicdata.template_excel(savfile, excelfile, basekv=basekv, areas=areas, buses=buses, owners=owners, zones=zones,\n                           tielevels=tielevels, showexcel=showexcel)\n    return excelfile\n\n# -----------------------------------------------------------------------------------------------------\ndef transfer_gicdata_sample(datapath=None, outpath=None, areas=[], showexcel=True):\n  "
  },
  {
    "id": "chunk_953",
    "text": "=None, outpath=None, areas=[], showexcel=True):\n    \"\"\" Transfer GIC data from .gic file into blank GIC data Excel template.\n\"\"\"\n    import psspy, gicdata\n\n    f_sfx = _get_filenam_sfx(areas)\n\n    gicfile_in   = 'sample_fv4.gic'\n    tmplfile_in  = 'gicdata_sample_template_{}.xlsx'.format(f_sfx)\n    excelfile_ou = 'gicdata_sample_{}.xlsx'.format(f_sfx)\n\n    if not datapath: datapath = get_example_folder()\n\n    gicfile_in   = os.path.join(datapath, gicfile_in)\n    tmplfile_in  = get_output_filenam"
  },
  {
    "id": "chunk_954",
    "text": " gicfile_in)\n    tmplfile_in  = get_output_filename(outpath, tmplfile_in)\n    excelfile_ou = get_output_filename(outpath, excelfile_ou)\n\n    showexcel = showexcel\n    dbgout    = False\n    prgfile   = None\n    xlsfile = gicdata.transfer_data(gicfile_in, tmplfile_in, excelfile_ou,\n                    showexcel=showexcel, prgfile=prgfile, dbgout=dbgout)\n\n    return xlsfile\n\n# -----------------------------------------------------------------------------------------------------\ndef gicdata_excel2gic"
  },
  {
    "id": "chunk_955",
    "text": "----------------------------\ndef gicdata_excel2gicfile(outpath=None, areas=[]):\n    \"\"\" Create GIC data text file (.gic) from GIC data Excel file.\n\"\"\"\n    import gicdata\n\n    f_sfx = _get_filenam_sfx(areas)\n    excelfile = 'gicdata_sample_{}.xlsx'.format(f_sfx)\n    gicfile = 'gicdata_sample_{}.gic'.format(f_sfx)\n\n    excelfile = get_output_filename(outpath, excelfile)\n    gicfile = get_output_filename(outpath, gicfile)\n\n    gicdata.excel2gicfile(excelfile, gicfile)\n\n    return gicfile\n\n# -------"
  },
  {
    "id": "chunk_956",
    "text": "excelfile, gicfile)\n\n    return gicfile\n\n# -----------------------------------------------------------------------------------------------------\ndef gicdata_gicfile2excel(outpath=None, areas=[], showexcel=True):\n    \"\"\" Create GIC data Excel file from GIC data text file (.gic).\n\"\"\"\n    import gicdata\n\n    f_sfx = _get_filenam_sfx(areas)\n\n    gicfile = 'gicdata_sample_{}.gic'.format(f_sfx)\n    excelfile = 'gicdata_sample_{}(txt2xl).xlsx'.format(f_sfx)\n\n    gicfile = get_output_filename(outpath, g"
  },
  {
    "id": "chunk_957",
    "text": "sfx)\n\n    gicfile = get_output_filename(outpath, gicfile)\n    excelfile = get_output_filename(outpath, excelfile)\n\n    gicdata.gicfile2excel(gicfile, excelfile, showexcel=showexcel)\n\n    return gicfile\n\n# -----------------------------------------------------------------------------------------------------\ndef gicdata_merge(outpath=None, showexcel=True):\n    \"\"\" Merge GIC data Excel files into one GIC data Excel file.\n\"\"\"\n    import gicdata\n\n    flist = ['gicdata_sample_123.xlsx', 'gicdata_sample"
  },
  {
    "id": "chunk_958",
    "text": "list = ['gicdata_sample_123.xlsx', 'gicdata_sample_456.xlsx']\n    xl_list = []\n    for fnam in flist:\n        fou = get_output_filename(outpath, fnam)\n        xl_list.append(fou)\n\n    outxlnam   = \"merged_sample.xlsx\"\n    prgfnam    = \"merged_sample_progress.txt\"\n\n    outexcel = get_output_filename(outpath, outxlnam)\n    prgfile  = get_output_filename(outpath, prgfnam)\n    dbgout   = False\n\n    #Allowed kwds: outexcel='', showexcel=False, prgfile=None, dbgout=False\n    xlsfile = gicdata.merge_da"
  },
  {
    "id": "chunk_959",
    "text": "=None, dbgout=False\n    xlsfile = gicdata.merge_data_excel(*xl_list, outexcel=outexcel, showexcel=showexcel,\n                                       prgfile=prgfile, dbgout=dbgout)\n\n    return xlsfile\n\n# -----------------------------------------------------------------------------------------------------\ndef run_gic_ieee_test_case(efield_mag, efield_deg, efield_type, scan_storm_event, datapath=None, outpath=None):\n    \"\"\" Use IEEE GIC Test Case provided in PSSE Example folder and run GIC calculat"
  },
  {
    "id": "chunk_960",
    "text": "ovided in PSSE Example folder and run GIC calculations using arrbox.gic.GIC object.\nReturns results in gicboj.\n\"\"\"\n    import psspy\n    import arrbox.gic\n\n    savfile = 'ieee_gic_test_case.sav'\n    gicfile = 'ieee_gic_test_case.gic'\n\n    if not datapath: datapath = get_example_folder()\n\n    savfile = os.path.join(datapath, savfile)\n    gicfile = os.path.join(datapath, gicfile)\n\n    outdir = get_output_dir(outpath)\n\n    if efield_type=='benchmark':\n        efield_mag = 8.0\n    else:\n        efiel"
  },
  {
    "id": "chunk_961",
    "text": ":\n        efield_mag = 8.0\n    else:\n        efield_mag = 1.0\n\n    efield_deg = 0.0\n\n    outfnam   = _get_outfnam_event(\"ieee\", efield_type, efield_mag, efield_deg, scan_storm_event)\n    prgfile   = os.path.join(outdir, outfnam+'progress.txt')\n    pygicfile = os.path.join(outdir, outfnam+'_map.pygic')\n    gictfile  = os.path.join(outdir, outfnam+'_gict.csv')\n\n    ejet_million_amps = 1.0\n    ejet_halfwidth_km = 200.0\n    ejet_period_min   = 5.0\n    ejet_height_km    = 100.0\n    ejet_center_deg   "
  },
  {
    "id": "chunk_962",
    "text": "  ejet_height_km    = 100.0\n    ejet_center_deg   = 54.0\n\n    earth_model_name = 'shield'\n\n    efield_unit      = 'V/km'\n    substation_r     = 0.1\n    branch_xbyr      = 30.0\n    transformer_xbyr = 30.0\n    addfile          = ''\n    addfile_optn     = 'rdch'\n    purgfile         = ''\n    rnwkfile         = ''\n\n    basekv    = []  # specify subsystem options\n    areas     = []\n    buses     = []\n    owners    = []\n    zones     = []\n    tielevels = 0\n\n    power_flow_optn  = ''   # specify power "
  },
  {
    "id": "chunk_963",
    "text": " = 0\n\n    power_flow_optn  = ''   # specify power flow solution options\n    pf_itmxn   = 100\n    pf_toln    = 0.1\n    pf_tap     = 0\n    pf_area    = 0\n    pf_phshft  = 0\n    pf_dctap   = 1\n    pf_swsh    = 1\n    pf_flat    = 0\n    pf_varlmt  = 99\n    pf_nondiv  = 0\n\n    psspy.psseinit()\n\n    psspy.lines_per_page_one_device(1,10000000)\n    psspy.progress_output(2,prgfile,[0,0])\n    psspy.alert_output(2,prgfile,[0,0])\n\n    psspy.case(savfile)\n    psspy.gic_read(gicfile)\n    sid = 0\n    busall = 1"
  },
  {
    "id": "chunk_964",
    "text": "psspy.gic_read(gicfile)\n    sid = 0\n    busall = 1\n\n    # run gic analysis\n    gicobj = arrbox.gic.GIC(sid, busall, efield_mag=efield_mag, efield_deg=efield_deg,\n        tielevels=tielevels, study_year=0, thermal_ana_optn=-1,\n        substation_r=substation_r, branch_xbyr=branch_xbyr, transformer_xbyr=transformer_xbyr,\n        efield_mag_local=0.0, efield_deg_local=0.0,\n        branch_rac2rdc=1.0, transformer_rac2rdc=1.0,\n        efield_type=efield_type, efield_unit=efield_unit, addfile_optn=add"
  },
  {
    "id": "chunk_965",
    "text": "ld_type, efield_unit=efield_unit, addfile_optn=addfile_optn,\n        gic2mvar_optn='kfactors', earth_model_name=earth_model_name, scan_storm_event=scan_storm_event,\n        power_flow_optn=power_flow_optn,\n        ejet_million_amps=ejet_million_amps, ejet_halfwidth_km=ejet_halfwidth_km, ejet_period_min=ejet_period_min,\n        ejet_height_km=ejet_height_km, ejet_center_deg=ejet_center_deg,\n        addfile=addfile, purgfile=purgfile, rnwkfile=rnwkfile, pygicfile=pygicfile, gictfile=gictfile,\n    "
  },
  {
    "id": "chunk_966",
    "text": "file, pygicfile=pygicfile, gictfile=gictfile,\n        basekv=basekv, areas=areas, buses=buses, owners=owners, zones=zones,\n        basekv_local=[], areas_local=[], buses_local=[], owners_local=[], zones_local=[],\n        pf_itmxn=pf_itmxn, pf_toln=pf_toln, pf_tap=pf_tap,\n        pf_area=pf_area, pf_phshft=pf_phshft, pf_dctap=pf_dctap,\n        pf_swsh=pf_swsh, pf_flat=pf_flat, pf_varlmt=pf_varlmt,\n        pf_nondiv=pf_nondiv,\n        )\n\n    psspy.lines_per_page_one_device(2,10000000)\n    psspy.pr"
  },
  {
    "id": "chunk_967",
    "text": "lines_per_page_one_device(2,10000000)\n    psspy.progress_output(1,\"\",[0,0])\n    psspy.alert_output(1,\"\",[0,0])\n\n    return gicobj\n\n# -----------------------------------------------------------------------------------------------------\ndef run_gic_sample_case(efield_mag, efield_deg, efield_type, scan_storm_event, power_flow_optn, datapath=None, outpath=None):\n    \"\"\" Use sample Case provided in PSSE Example folder and run GIC calculations using arrbox.gic.GIC object.\nReturns results in gicboj.\n\"\""
  },
  {
    "id": "chunk_968",
    "text": "rbox.gic.GIC object.\nReturns results in gicboj.\n\"\"\"\n    import psspy\n    import arrbox.gic\n\n    savfile = 'sample.sav'\n    gicfile = 'sample_fv4.gic'\n\n    outdir = get_output_dir(outpath)\n\n    if not datapath: datapath = get_example_folder()\n\n    savfile = os.path.join(datapath, savfile)\n    gicfile = os.path.join(datapath, gicfile)\n\n    if efield_type=='benchmark':\n        efield_mag = 8.0\n    else:\n        efield_mag = 1.0\n\n    efield_deg = 0.0\n\n    outfnam   = _get_outfnam_event(\"sample\", efi"
  },
  {
    "id": "chunk_969",
    "text": "\n\n    outfnam   = _get_outfnam_event(\"sample\", efield_type, efield_mag, efield_deg, scan_storm_event)\n    prgfile   = os.path.join(outdir, outfnam+'progress.txt')\n    pygicfile = os.path.join(outdir, outfnam+'_map.pygic')\n    gictfile  = os.path.join(outdir, outfnam+'_gict.csv')\n\n    ejet_million_amps = 1.0\n    ejet_halfwidth_km = 200.0\n    ejet_period_min   = 5.0\n    ejet_height_km    = 100.0\n    ejet_center_deg   = 54.0\n\n    earth_model_name = 'shield'\n\n    efield_unit      = 'V/km'\n    substa"
  },
  {
    "id": "chunk_970",
    "text": "'shield'\n\n    efield_unit      = 'V/km'\n    substation_r     = 0.1\n    branch_xbyr      = 30.0\n    transformer_xbyr = 30.0\n    addfile          = ''\n    addfile_optn     = 'rdch'\n    purgfile         = ''\n    rnwkfile         = ''\n\n    basekv    = []  # specify subsystem options\n    areas     = []\n    buses     = []\n    owners    = []\n    zones     = []\n    tielevels = 0\n\n    pf_itmxn   = 100    # specify power flow solution options\n    pf_toln    = 0.1\n    pf_tap     = 0\n    pf_area    = 0\n    "
  },
  {
    "id": "chunk_971",
    "text": "  = 0.1\n    pf_tap     = 0\n    pf_area    = 0\n    pf_phshft  = 0\n    pf_dctap   = 1\n    pf_swsh    = 1\n    pf_flat    = 0\n    pf_varlmt  = 99\n    pf_nondiv  = 0\n\n    psspy.psseinit()\n\n    psspy.lines_per_page_one_device(1,10000000)\n    psspy.progress_output(2,prgfile,[0,0])\n\n    print(savfile)\n    print(gicfile)\n\n    psspy.case(savfile)\n    psspy.gic_read(gicfile)\n    sid = 0\n    busall = 1\n\n    # run gic analysis\n    gicobj = arrbox.gic.GIC(sid, busall, efield_mag=efield_mag, efield_deg=efield_"
  },
  {
    "id": "chunk_972",
    "text": " busall, efield_mag=efield_mag, efield_deg=efield_deg,\n        tielevels=tielevels, study_year=0, thermal_ana_optn=-1,\n        substation_r=substation_r, branch_xbyr=branch_xbyr, transformer_xbyr=transformer_xbyr,\n        efield_mag_local=0.0, efield_deg_local=0.0,\n        branch_rac2rdc=1.0, transformer_rac2rdc=1.0,\n        efield_type=efield_type, efield_unit=efield_unit, addfile_optn=addfile_optn,\n        gic2mvar_optn='kfactors', earth_model_name=earth_model_name, scan_storm_event=scan_storm"
  },
  {
    "id": "chunk_973",
    "text": "name=earth_model_name, scan_storm_event=scan_storm_event,\n        power_flow_optn=power_flow_optn,\n        ejet_million_amps=ejet_million_amps, ejet_halfwidth_km=ejet_halfwidth_km, ejet_period_min=ejet_period_min,\n        ejet_height_km=ejet_height_km, ejet_center_deg=ejet_center_deg,\n        addfile=addfile, purgfile=purgfile, rnwkfile=rnwkfile, pygicfile=pygicfile, gictfile=gictfile,\n        basekv=basekv, areas=areas, buses=buses, owners=owners, zones=zones,\n        basekv_local=[], areas_loc"
  },
  {
    "id": "chunk_974",
    "text": "s, zones=zones,\n        basekv_local=[], areas_local=[], buses_local=[], owners_local=[], zones_local=[],\n        pf_itmxn=pf_itmxn, pf_toln=pf_toln, pf_tap=pf_tap,\n        pf_area=pf_area, pf_phshft=pf_phshft, pf_dctap=pf_dctap,\n        pf_swsh=pf_swsh, pf_flat=pf_flat, pf_varlmt=pf_varlmt,\n        pf_nondiv=pf_nondiv,\n        )\n\n    psspy.lines_per_page_one_device(2,10000000)\n    psspy.progress_output(1,\"\",[0,0])\n\n    return gicobj\n\n# -----------------------------------------------------------"
  },
  {
    "id": "chunk_975",
    "text": "--------------------------------------------------------------------------------------------\ndef run_gic_ieee_text_report(efield_mag, efield_deg, efield_type, scan_storm_event, datapath=None, outpath=None):\n    \"\"\" Use IEEE GIC Test Case provided in PSSE Example folder, run GIC calculations and create text report.\n\"\"\"\n\n    gicobj = run_gic_ieee_test_case(efield_mag, efield_deg, efield_type, scan_storm_event, datapath, outpath)\n\n    if gicobj.ierr: return\n\n    outdir = get_output_dir(outpath)\n   "
  },
  {
    "id": "chunk_976",
    "text": ": return\n\n    outdir = get_output_dir(outpath)\n    rptnam = _get_outfnam_event(\"ieee\", efield_type, efield_mag, efield_deg, scan_storm_event)\n\n    rptfile  = os.path.join(outdir, rptnam+'.txt')\n    qrptfile = os.path.join(outdir, rptnam+'_qloss.txt')\n\n    gicobj.text_report(rptfile)\n    gicobj.qtotal_report(qrptfile)\n\n    msg = \" Report created in file: {:s}\".format(rptfile)\n    print(msg)\n\n# -----------------------------------------------------------------------------------------------------\nde"
  },
  {
    "id": "chunk_977",
    "text": "-----------------------------------------------\ndef run_gic_ieee_text_report_DIY(datapath=None, outpath=None):\n    \"\"\" Run GIC Analysis on IEEE GIC Test Case provided in PSSE Example folder and create customized report.\n\"\"\"\n    global _BIGREL\n\n    import psspy\n    _BIGREL = psspy.getdefaultreal()     # Largest real value\n\n    efield_mag = 1.0\n    efield_deg = 0.0\n    efield_type = 'uniform'\n    scan_storm_event = ''\n\n    gicobj = run_gic_ieee_test_case(efield_mag, efield_deg, efield_type, scan_s"
  },
  {
    "id": "chunk_978",
    "text": "t_case(efield_mag, efield_deg, efield_type, scan_storm_event, datapath, outpath)\n\n    if gicobj.ierr: return\n\n    outdir = get_output_dir(outpath)\n    rptnam = _get_outfnam_event(\"DIY_ieee\", efield_type, efield_mag, efield_deg, scan_storm_event)\n    rptfile = os.path.join(outdir, rptnam+'.txt')\n\n    rptfobj = open(rptfile, 'w')\n    report  = rptfobj.write\n\n    elecfld_mag = \"{:10.2f}\".format(gicobj.misc.efield_mag)\n    elecfld_mag = elecfld_mag.strip()\n\n    elecfld_unt = gicobj.misc.efield_unit\n"
  },
  {
    "id": "chunk_979",
    "text": "trip()\n\n    elecfld_unt = gicobj.misc.efield_unit\n\n    elecfld_deg = \"{:10.2f}\".format(gicobj.misc.efield_deg)\n    elecfld_deg = elecfld_deg.strip()\n\n    txt  = \"\\n GMD Event: Uniform Electric Field, {} {}, {} deg\\n\".format(elecfld_mag, elecfld_unt, elecfld_deg)\n\n    txt += \"\\n GIC data file: {}\\n\".format(gicobj.gicfile)\n    txt += \" Power flow data file: {}\\n\".format(gicobj.savfile)\n\n    if gicobj.basekv or gicobj.areas or gicobj.buses or gicobj.owners or gicobj.zones:\n        txt += \"\\n Subsys"
  },
  {
    "id": "chunk_980",
    "text": ".owners or gicobj.zones:\n        txt += \"\\n Subsystem used for GIC studiies is defined as:\\n\"\n        if gicobj.basekv: txt += \"     Voltage = {}\\n\".format(str(gicobj.basekv))\n        if gicobj.areas:  txt += \"     Areas   = {}\\n\".format(str(gicobj.areas))\n        if gicobj.buses:  txt += \"     Buses   = {}\\n\".format(str(gicobj.buses))\n        if gicobj.owners: txt += \"     Owners  = {}\\n\".format(str(gicobj.owners))\n        if gicobj.zones:  txt += \"     Zones   = {}\\n\".format(str(gicobj.zones))"
  },
  {
    "id": "chunk_981",
    "text": "+= \"     Zones   = {}\\n\".format(str(gicobj.zones))\n        txt += \"     Subsystem Inter tie Levels = {}\\n\".format(gicobj.tielevels)\n    else:\n        txt += \"\\n Subsystem used for GIC studiies comprises entire network.\\n\"\n\n    txt += \"\\n Number of buses in study subsystem        = {}\\n\".format(gicobj.misc.nbus_study)\n    txt += \" Number of substations in study subsystem  = {}\\n\".format(gicobj.misc.nsubstation_study)\n    txt += \" Number of branches in study subsystem     = {}\\n\".format(gicobj.mis"
  },
  {
    "id": "chunk_982",
    "text": "s in study subsystem     = {}\\n\".format(gicobj.misc.nbranch_study)\n    txt += \" Number of transformers in study subsystem = {}\\n\".format(gicobj.misc.ntransformer_study)\n    report(txt)\n\n    txt  = '\\n Bus DC Voltages\\n'\n    txt += \"    Bus Substation DC Voltage(V)\\n\"\n    report(txt)\n\n    buslist = list(gicobj.bus.keys())\n    buslist.sort()\n    for eachbus in buslist:\n        # all of these work, shows how to use them\n        #print \"attr lower-->\", eachbus, gicobj.bus[eachbus].substation, gicobj"
  },
  {
    "id": "chunk_983",
    "text": "\", eachbus, gicobj.bus[eachbus].substation, gicobj.bus[eachbus].dcvolts\n        #print \"dict lower-->\", eachbus, gicobj.bus[eachbus]['substation'], gicobj.bus[eachbus]['dcvolts']\n        #print \"attr mixed-->\", eachbus, gicobj.bus[eachbus].suBSTation, gicobj.bus[eachbus].dcVolts\n        #print \"dict mixed-->\", eachbus, gicobj.bus[eachbus]['subStation'], gicobj.bus[eachbus]['DCvolts']\n        txt = \" {:6d}     {:6d}  {:12.5f}\\n\".format(eachbus, gicobj.bus[eachbus].substation, gicobj.bus[eachbus]."
  },
  {
    "id": "chunk_984",
    "text": "cobj.bus[eachbus].substation, gicobj.bus[eachbus].dcvolts)\n        report(txt)\n\n    txt  = '\\n Substations DC Voltages and GIC Flows, flowing from Bus to Substation Ground\\n'\n    txt += \" Substation Name         Latitude(deg) Longitude(deg) DC Voltage(V)    GIC(Amps)\\n\"\n    report(txt)\n\n    sslist = list(gicobj.substation.keys())\n    sslist.sort()\n    for ss in sslist:\n        txt = \"     {:6d} {:12s}  {:12.6f}   {:12.6f}  {:12.5f} {:12.5f}\\n\".format(ss, gicobj.substation[ss].name,\n             "
  },
  {
    "id": "chunk_985",
    "text": "rmat(ss, gicobj.substation[ss].name,\n                            gicobj.substation[ss].latitude, gicobj.substation[ss].longitude,\n                            gicobj.substation[ss].dcvolts, gicobj.substation[ss].gic)\n        report(txt)\n\n    # Non-Transformer Branches\n    txt  = '\\n GIC flow in Non-Transformer Branches, flowing from From Bus to To Bus\\n'\n    txt += \" FromBus  ToBus Ckt  Distance(km) per-Phase(A)   3-Phase(A)\\n\"\n    report(txt)\n\n    brnlist = list(gicobj.branch.keys())\n    brnlist"
  },
  {
    "id": "chunk_986",
    "text": "  brnlist = list(gicobj.branch.keys())\n    brnlist.sort()\n    for brn in brnlist:\n        txt = \"  {:6d} {:6d}  {:2s}  {:12.5f} {:12.5f} {:12.5f}\\n\".format(brn[0], brn[1], brn[2],\n                            gicobj.branch[brn].distance, gicobj.branch[brn].gic,\n                            3*gicobj.branch[brn].gic)\n        report(txt)\n\n    # Transformers\n    trnlist = list(gicobj.transformer.keys())\n    trnlist.sort()\n\n    no_2wdg_nrml = \"\\n     No two winding transformers in GIC studied network.\\"
  },
  {
    "id": "chunk_987",
    "text": " two winding transformers in GIC studied network.\\n\"\n    no_2wdg_auto = \"\\n     No two winding auto transformers in GIC studied network.\\n\"\n    no_3wdg_nrml = \"\\n     No three winding transformers in GIC studied network.\\n\"\n    no_3wdg_auto = \"\\n     No three winding auto transformers in GIC studied network.\\n\"\n\n    # Two Winding Transformers - normal\n    txt  = '\\n Two Winding Transformers: Per Phase GIC flow in windings, flowing from winding Bus to Neutral\\n'\n    txt += \" Reactive power loss, "
  },
  {
    "id": "chunk_988",
    "text": "s to Neutral\\n'\n    txt += \" Reactive power loss, represented as constant current load on highest voltage bus in power flow\\n\"\n    txt += \"   Ibus   Jbus Ckt       Igic(A)      Jgic(A)    Effgic(A) Kfactor KftrTyp  Qloss(Mvar)\\n\"\n    report(txt)\n\n    for trn in trnlist:\n        kbus  = trn[2]\n        if kbus: continue\n\n        autoi = gicobj.transformer[trn].wdg1_auto\n        autoj = gicobj.transformer[trn].wdg2_auto\n        if (autoi or autoj): continue\n\n        igic    = _get_formatted_real_va"
  },
  {
    "id": "chunk_989",
    "text": "continue\n\n        igic    = _get_formatted_real_value(gicobj.transformer[trn].wdg1_gic)\n        jgic    = _get_formatted_real_value(gicobj.transformer[trn].wdg2_gic)\n        effgic  = _get_formatted_real_value(gicobj.transformer[trn].eff_gic)\n        qloss   = _get_formatted_real_value(gicobj.transformer[trn].qloss)\n\n        kftrtyp = gicobj._get_kfactor_type(gicobj.transformer[trn].kfactor_type)\n\n        txt = \" {:6d} {:6d}  {:2s}  {:s} {:s} {:s} {:7.3f} {:s} {:s}\\n\".format(trn[0], trn[1], trn["
  },
  {
    "id": "chunk_990",
    "text": "} {:7.3f} {:s} {:s}\\n\".format(trn[0], trn[1], trn[3], igic, jgic, effgic,\n                            gicobj.transformer[trn].kfactor, kftrtyp, qloss)\n        report(txt)\n        if no_2wdg_nrml: no_2wdg_nrml=''\n\n    if no_2wdg_nrml: report(no_2wdg_nrml)\n\n    # Two Winding Transformers - auto\n    txt  = '\\n Two Winding Auto Transformers: Per Phase GIC flow in windings, flowing from winding Bus to Neutral\\n'\n    txt += \" Reactive power loss, represented as constant current load on Series Winding "
  },
  {
    "id": "chunk_991",
    "text": "sented as constant current load on Series Winding bus in power flow\\n\"\n    txt += \" Common Series Ckt Common gic(A) Series gic(A)    Effgic(A) Kfactor KftrTyp  Qloss(Mvar)\\n\"\n    report(txt)\n    for trn in trnlist:\n        kbus  = trn[2]\n        if kbus: continue\n\n        autoi = gicobj.transformer[trn].wdg1_auto\n        autoj = gicobj.transformer[trn].wdg2_auto\n        if ( (not autoi) or (not autoj) ): continue\n        if autoi==1:\n            ibus = trn[0]\n            jbus = trn[1]\n        el"
  },
  {
    "id": "chunk_992",
    "text": "ibus = trn[0]\n            jbus = trn[1]\n        else:\n            ibus = trn[1]\n            jbus = trn[0]\n\n        igic    = _get_formatted_real_value(gicobj.transformer[trn].wdg1_gic)\n        jgic    = _get_formatted_real_value(gicobj.transformer[trn].wdg2_gic)\n        effgic  = _get_formatted_real_value(gicobj.transformer[trn].eff_gic)\n        qloss   = _get_formatted_real_value(gicobj.transformer[trn].qloss)\n\n        kftrtyp = gicobj._get_kfactor_type(gicobj.transformer[trn].kfactor_type)\n\n  "
  },
  {
    "id": "chunk_993",
    "text": "tor_type(gicobj.transformer[trn].kfactor_type)\n\n        txt = \" {:6d} {:6d}  {:2s}  {:s}  {:s} {:s} {:7.3f} {:s} {:s}\\n\".format(ibus, jbus, trn[3], igic, jgic, effgic,\n                            gicobj.transformer[trn].kfactor, kftrtyp, qloss)\n        report(txt)\n        if no_2wdg_auto: no_2wdg_auto=''\n\n    if no_2wdg_auto: report(no_2wdg_auto)\n\n    # Three Winding Transformers - normal\n    txt  = '\\n Three Winding Transformers: Per Phase GIC flow in windings, flowing from winding Bus to Neutr"
  },
  {
    "id": "chunk_994",
    "text": "low in windings, flowing from winding Bus to Neutral\\n'\n    txt += \" Reactive power loss, represented as constant current load on highest voltage bus in power flow\\n\"\n    txt += \"   Ibus   Jbus   Kbus Ckt       Igic(A)      Jgic(A)      Kgic(A)    Effgic(A) Kfactor KftrTyp  Qloss(Mvar)\\n\"\n    report(txt)\n\n    for trn in trnlist:\n        kbus  = trn[2]\n        if not kbus: continue\n\n        autoi = gicobj.transformer[trn].wdg1_auto\n        autoj = gicobj.transformer[trn].wdg2_auto\n        autok ="
  },
  {
    "id": "chunk_995",
    "text": " gicobj.transformer[trn].wdg2_auto\n        autok = gicobj.transformer[trn].wdg3_auto\n        if (autoi or autoj or autok): continue\n\n        igic    = _get_formatted_real_value(gicobj.transformer[trn].wdg1_gic)\n        jgic    = _get_formatted_real_value(gicobj.transformer[trn].wdg2_gic)\n        kgic    = _get_formatted_real_value(gicobj.transformer[trn].wdg3_gic)\n        effgic  = _get_formatted_real_value(gicobj.transformer[trn].eff_gic)\n        qloss   = _get_formatted_real_value(gicobj.trans"
  },
  {
    "id": "chunk_996",
    "text": "  qloss   = _get_formatted_real_value(gicobj.transformer[trn].qloss)\n\n        kftrtyp = gicobj._get_kfactor_type(gicobj.transformer[trn].kfactor_type)\n\n        txt = \" {:6d} {:6d} {:6d}  {:2s}  {:s} {:s} {:s} {:s} {:7.3f} {:s} {:s}\\n\".format(trn[0], trn[1], trn[2], trn[3], igic, jgic, kgic, effgic,\n                            gicobj.transformer[trn].kfactor, kftrtyp, qloss)\n        report(txt)\n        if no_3wdg_nrml: no_3wdg_nrml=''\n\n    if no_3wdg_nrml: report(no_3wdg_nrml)\n\n    # Three Windin"
  },
  {
    "id": "chunk_997",
    "text": "wdg_nrml: report(no_3wdg_nrml)\n\n    # Three Winding Transformers - auto\n    txt  = '\\n Three Winding Auto Transformers: Per Phase GIC flow in windings, flowing from winding Bus to Neutral\\n'\n    txt += \" Reactive power loss, represented as constant current load on highest voltage bus in power flow\\n\"\n    txt += \" Common Series   Kbus Ckt Common gic(A) Series gic(A)      Kgic(A)    Effgic(A) Kfactor KftrTyp  Qloss(Mvar)\\n\"\n    report(txt)\n    for trn in trnlist:\n        kbus  = trn[2]\n        if "
  },
  {
    "id": "chunk_998",
    "text": "trn in trnlist:\n        kbus  = trn[2]\n        if not kbus: continue\n\n        autoi = gicobj.transformer[trn].wdg1_auto\n        autoj = gicobj.transformer[trn].wdg2_auto\n        if ( (not autoi) or (not autoj) ): continue\n        if autoi==1:\n            ibus = trn[0]\n            jbus = trn[1]\n        else:\n            ibus = trn[1]\n            jbus = trn[0]\n\n        igic    = _get_formatted_real_value(gicobj.transformer[trn].wdg1_gic)\n        jgic    = _get_formatted_real_value(gicobj.transform"
  },
  {
    "id": "chunk_999",
    "text": "ic    = _get_formatted_real_value(gicobj.transformer[trn].wdg2_gic)\n        kgic    = _get_formatted_real_value(gicobj.transformer[trn].wdg3_gic)\n        effgic  = _get_formatted_real_value(gicobj.transformer[trn].eff_gic)\n        qloss   = _get_formatted_real_value(gicobj.transformer[trn].qloss)\n\n        kftrtyp = gicobj._get_kfactor_type(gicobj.transformer[trn].kfactor_type)\n\n        txt = \" {:6d} {:6d} {:6d}  {:2s}  {:s}  {:s} {:s} {:s} {:7.3f} {:s} {:s}\\n\".format(ibus, jbus, kbus, trn[3], ig"
  },
  {
    "id": "chunk_1000",
    "text": "} {:s} {:s}\\n\".format(ibus, jbus, kbus, trn[3], igic, jgic, kgic, effgic,\n                            gicobj.transformer[trn].kfactor, kftrtyp, qloss)\n        report(txt)\n        if no_3wdg_auto: no_3wdg_auto=''\n\n    if no_3wdg_auto: report(no_3wdg_auto)\n\n    # Total Qloss\n    if no_2wdg_nrml:\n        qwdg2_nrml = '        None'\n    else:\n        qwdg2_nrml = \"{:12.5f} Mvar\".format(gicobj.qtotal.wdg2_normal)\n    if no_2wdg_auto:\n        qwdg2_auto = '        None'\n    else:\n        qwdg2_auto = "
  },
  {
    "id": "chunk_1001",
    "text": "o = '        None'\n    else:\n        qwdg2_auto = \"{:12.5f} Mvar\".format(gicobj.qtotal.wdg2_auto)\n    if no_3wdg_nrml:\n        qwdg3_nrml = '        None'\n    else:\n        qwdg3_nrml = \"{:12.5f} Mvar\".format(gicobj.qtotal.wdg3_normal)\n    if no_3wdg_auto:\n        qwdg3_auto = '        None'\n    else:\n        qwdg3_auto = \"{:12.5f} Mvar\".format(gicobj.qtotal.wdg3_auto)\n    txt  = '\\n Transformer Reactive Power Loss Summary\\n'\n    txt += ' Two Winding Transformers        = {:s}\\n'.format(qwdg2_nr"
  },
  {
    "id": "chunk_1002",
    "text": "ding Transformers        = {:s}\\n'.format(qwdg2_nrml)\n    txt += ' Two Winding Auto Transformers   = {:s}\\n'.format(qwdg2_auto)\n    txt += ' Three Winding Transformers      = {:s}\\n'.format(qwdg3_nrml)\n    txt += ' Three Winding Auto Transformers = {:s}\\n'.format(qwdg3_auto)\n    txt += '                           Total = {:12.5f} Mvar\\n'.format(gicobj.qtotal.total)\n    report(txt)\n\n    # done - close report file\n    if rptfile:\n        rptfobj.close()\n        txt = \"\\n GIC analysis output report"
  },
  {
    "id": "chunk_1003",
    "text": "ose()\n        txt = \"\\n GIC analysis output report saved to file: {:s}\\n\".format(rptfile)\n        sys.stdout.write(txt)\n\n# -----------------------------------------------------------------------------------------------------\ndef run_gic_ieee_excel_export_DIY(datapath=None, outpath=None, show=True):\n    \"\"\" Use IEEE GIC Test Case provided in PSSE Example folder, run GIC calculations and export results to spreadsheet.\n\"\"\"\n    import psspy\n    import excelpy\n\n    _BIGREL = psspy.getdefaultreal()   "
  },
  {
    "id": "chunk_1004",
    "text": "t excelpy\n\n    _BIGREL = psspy.getdefaultreal()     # Largest real value\n\n    efield_mag = 1.0\n    efield_deg = 0.0\n    efield_type = 'uniform'\n    scan_storm_event = ''\n\n    gicobj = run_gic_ieee_test_case(efield_mag, efield_deg, efield_type, scan_storm_event, datapath, outpath)\n\n    if gicobj.ierr: return\n\n    outdir = get_output_dir(outpath)\n    rptnam = _get_outfnam_event(\"DIY_ieee\", efield_type, efield_mag, efield_deg, scan_storm_event)\n    xlsfile = os.path.join(outdir, rptnam)\n\n    # What"
  },
  {
    "id": "chunk_1005",
    "text": "xlsfile = os.path.join(outdir, rptnam)\n\n    # What to export?\n    overwritesheet = True\n    do_sheets = ['optn', 'bus', 'sub', 'brn', 'trn']\n\n    _EXPORT_QTY_GIC   = {\n    'optn': 'options'     ,\n    'bus' : 'bus'         ,\n    'sub' : 'substation'  ,\n    'brn' : 'branch'      ,\n    'trn' : 'transformer' ,\n    }\n\n    _WORKSHT_SEQ_GIC = ['optn','bus','sub','brn','trn']\n\n    _WORKSHT_COLUMN_LABELS_GIC = {\n        'bus': ['Bus', 'Substation', 'DC Voltage(V)'],\n        'sub': ['Substation', 'Name', "
  },
  {
    "id": "chunk_1006",
    "text": "ltage(V)'],\n        'sub': ['Substation', 'Name', 'Latitude(deg)', 'Longitude(deg)', 'DC Voltage(V)', 'GIC(Amps)'],\n        'brn': ['FromBus', 'ToBus', 'Ckt', 'Distance(km)', 'per-Phase(A)', '3-Phase(A)'],\n        'trn_nrml': ['Ibus', 'Jbus', 'Kbus', 'Ckt', 'Igic(A)', 'Jgic(A)', 'Kgic(A)', 'Effgic(A)', 'Kfactor', 'KftrTyp', 'Qloss(Mvar)'],\n        'trn_auto': ['Common', 'Series', 'Kbus', 'Ckt', 'Common gic(A)', 'Series gic(A)', 'Kgic(A)', 'Effgic(A)', 'Kfactor', 'KftrTyp', 'Qloss(Mvar)'],\n      "
  },
  {
    "id": "chunk_1007",
    "text": "(A)', 'Kfactor', 'KftrTyp', 'Qloss(Mvar)'],\n        }\n\n    _WORKSHT_INFO_TXT_GIC = {\n        'bus': ['Bus DC Voltages'],\n        'sub': ['Substations DC Voltages and GIC Flows, flowing from Bus to Substation Ground'],\n        'brn': ['GIC flow in Non-Transformer Branches, flowing from From Bus to To Bus'],\n        'trn_nrml': ['Transformers: Per Phase GIC flow in windings, flowing from winding Bus to Neutral',\n                     'Reactive power loss, represented as constant current load on hig"
  },
  {
    "id": "chunk_1008",
    "text": " loss, represented as constant current load on highest voltage bus in power flow'],\n        'trn_auto': ['Auto Transformers: Per Phase GIC flow in windings, flowing from winding Bus to Neutral',\n                     'Reactive power loss, represented as constant current load on Series Winding bus in power flow'],\n        }\n\n    gicshts = []\n    for each in _WORKSHT_SEQ_GIC:\n        if each in do_sheets:\n            if each=='trn':\n                gicshts.extend( [ _EXPORT_QTY_GIC[each], 'auto '+_"
  },
  {
    "id": "chunk_1009",
    "text": "gicshts.extend( [ _EXPORT_QTY_GIC[each], 'auto '+_EXPORT_QTY_GIC[each] ] )\n            else:\n                gicshts.append(_EXPORT_QTY_GIC[each])\n\n    for i, shtnam in enumerate(gicshts):\n        if i==0:\n            xlsobj = excelpy.workbook(xlsfile, shtnam, overwritesheet=overwritesheet)\n            if show:\n                xlsobj.show()\n            else:\n                xlsobj.hide()\n\n            xlsobj.show_alerts(0) # do not show pop-up alerts\n            xlsfnam = xlsobj.XLSFNAM\n        e"
  },
  {
    "id": "chunk_1010",
    "text": "rts\n            xlsfnam = xlsobj.XLSFNAM\n        else:\n            xlsobj.worksheet_add_end(shtnam, overwritesheet=overwritesheet)\n        xlsobj.page_format(orientation=\"landscape\",left=1.0,right=1.0,\n                           top=0.5,bottom=0.5,header=0.25,footer=0.25)\n        xlsobj.page_footer(left='page number of page total', right='date, time')\n        xlsobj.page_header(center='file name:sheet name')\n        xlsobj.font_sheet()\n\n    if not xlsobj:\n        print(\"Excel file and worksheets"
  },
  {
    "id": "chunk_1011",
    "text": "t xlsobj:\n        print(\"Excel file and worksheets not created.\\n\")\n\n    # Options\n    do_key = 'optn'\n    if do_key in do_sheets:\n\n        elecfld_mag = \"{:10.2f}\".format(gicobj.misc.efield_mag)\n        elecfld_mag = elecfld_mag.strip()\n\n        elecfld_unt = gicobj.misc.efield_unit\n\n        elecfld_deg = \"{:10.2f}\".format(gicobj.misc.efield_deg)\n        elecfld_deg = elecfld_deg.strip()\n\n        txt  = \"\\n GMD Event: Uniform Electric Field, {:s} {:s}, {:s} deg\\n\".format(elecfld_mag, elecfld_un"
  },
  {
    "id": "chunk_1012",
    "text": "} {:s}, {:s} deg\\n\".format(elecfld_mag, elecfld_unt, elecfld_deg)\n\n        txt += \"\\n GIC data file: {:s}\\n\".format(gicobj.gicfile)\n        txt += \" Power flow data file: {:s}\\n\".format(gicobj.savfile)\n\n        if gicobj.basekv or gicobj.areas or gicobj.buses or gicobj.owners or gicobj.zones:\n            txt += \"\\n Subsystem used for GIC studies is defined as:\\n\"\n            if gicobj.basekv: txt += \"     Voltage = {:s}\\n\".format(str(gicobj.basekv))\n            if gicobj.areas:  txt += \"     Are"
  },
  {
    "id": "chunk_1013",
    "text": "v))\n            if gicobj.areas:  txt += \"     Areas   = {:s}\\n\".format(str(gicobj.areas))\n            if gicobj.buses:  txt += \"     Buses   = {:s}\\n\".format(str(gicobj.buses))\n            if gicobj.owners: txt += \"     Owners  = {:s}\\n\".format(str(gicobj.owners))\n            if gicobj.zones:  txt += \"     Zones   = {:s}\\n\".format(str(gicobj.zones))\n            txt += \"     Subsystem Inter tie Levels = {:d}\\n\".format(gicobj.tielevels)\n        else:\n            txt += \"\\n Subsystem used for GIC "
  },
  {
    "id": "chunk_1014",
    "text": "se:\n            txt += \"\\n Subsystem used for GIC studies comprises entire network.\\n\"\n\n        txt += \"\\n Number of buses in study subsystem        = {:d}\\n\".format(gicobj.misc.nbus_study)\n        txt += \" Number of substations in study subsystem  = {:d}\\n\".format(gicobj.misc.nsubstation_study)\n        txt += \" Number of branches in study subsystem     = {:d}\\n\".format(gicobj.misc.nbranch_study)\n        txt += \" Number of transformers in study subsystem = {:d}\\n\".format(gicobj.misc.ntransformer"
  },
  {
    "id": "chunk_1015",
    "text": "ubsystem = {:d}\\n\".format(gicobj.misc.ntransformer_study)\n\n        optnlist = txt.split(\"\\n\")\n\n        xlsobj.set_active_sheet(_EXPORT_QTY_GIC[do_key])\n        br, rc = 1, 1\n        br, rc = xlsobj.set_range(br, rc, optnlist, transpose=True)\n\n    # DC Bus voltages\n    do_key = 'bus'\n    if do_key in do_sheets:\n        buslist = list(gicobj.bus.keys())\n        buslist.sort()\n        rowdata = [_WORKSHT_COLUMN_LABELS_GIC[do_key]]\n        for eachbus in buslist:\n            tlst = [eachbus, gicobj."
  },
  {
    "id": "chunk_1016",
    "text": "s in buslist:\n            tlst = [eachbus, gicobj.bus[eachbus].substation, gicobj.bus[eachbus].dcvolts]\n            rowdata.append(tlst)\n\n        xlsobj.set_active_sheet(_EXPORT_QTY_GIC[do_key])\n        br0, rc0 = 3, 1\n        br, rc = xlsobj.set_range(br0, rc0, rowdata)\n        del rowdata\n        xlsobj.autofit_columns((br0,rc0,br0,rc))\n        xlsobj.font_color((br0,rc0,br0,rc),\"red\")\n        xlsobj.align_rows((br0, rc0),alignv='right')    #label row\n        xlsobj.set_cell((1,1),_WORKSHT_INF"
  },
  {
    "id": "chunk_1017",
    "text": "bel row\n        xlsobj.set_cell((1,1),_WORKSHT_INFO_TXT_GIC[do_key][0],fontStyle=\"bold\",fontSize=12, fontColor=\"blue\")\n\n    # Substation\n    do_key = 'sub'\n    if do_key in do_sheets:\n        sslist = list(gicobj.substation.keys())\n        sslist.sort()\n        rowdata = [_WORKSHT_COLUMN_LABELS_GIC[do_key]]\n        for ss in sslist:\n            tlst = [ss, gicobj.substation[ss].name, gicobj.substation[ss].latitude, gicobj.substation[ss].longitude,\n                    gicobj.substation[ss].dcvolt"
  },
  {
    "id": "chunk_1018",
    "text": ",\n                    gicobj.substation[ss].dcvolts, gicobj.substation[ss].gic]\n            rowdata.append(tlst)\n\n        xlsobj.set_active_sheet(_EXPORT_QTY_GIC[do_key])\n        br0, rc0 = 3, 1\n        br, rc = xlsobj.set_range(br0, rc0, rowdata)\n        del rowdata\n        xlsobj.autofit_columns((br0,rc0,br0,rc))\n        xlsobj.font_color((br0,rc0,br0,rc),\"red\")\n        xlsobj.align_rows((br0, rc0),alignv='right')    #label row\n        xlsobj.set_cell((1,1),_WORKSHT_INFO_TXT_GIC[do_key][0],fon"
  },
  {
    "id": "chunk_1019",
    "text": "et_cell((1,1),_WORKSHT_INFO_TXT_GIC[do_key][0],fontStyle=\"bold\",fontSize=12, fontColor=\"blue\")\n\n\n    # Non-Transformer Branches\n    do_key = 'brn'\n    if do_key in do_sheets:\n        brnlist = list(gicobj.branch.keys())\n        brnlist.sort()\n        rowdata = [_WORKSHT_COLUMN_LABELS_GIC[do_key]]\n        for brn in brnlist:\n            tlst = [brn[0], brn[1], brn[2], gicobj.branch[brn].distance, gicobj.branch[brn].gic,3*gicobj.branch[brn].gic]\n            rowdata.append(tlst)\n\n        xlsobj.set"
  },
  {
    "id": "chunk_1020",
    "text": "          rowdata.append(tlst)\n\n        xlsobj.set_active_sheet(_EXPORT_QTY_GIC[do_key])\n        br0, rc0 = 3, 1\n        br, rc = xlsobj.set_range(br0, rc0, rowdata)\n        del rowdata\n        xlsobj.autofit_columns((br0,rc0,br0,rc))\n        xlsobj.font_color((br0,rc0,br0,rc),\"red\")\n        xlsobj.align_rows((br0, rc0),alignv='right')    #label row\n        xlsobj.set_cell((1,1),_WORKSHT_INFO_TXT_GIC[do_key][0],fontStyle=\"bold\",fontSize=12, fontColor=\"blue\")\n\n    # Transformers\n    do_key = 'trn"
  },
  {
    "id": "chunk_1021",
    "text": "olor=\"blue\")\n\n    # Transformers\n    do_key = 'trn'\n    if do_key in do_sheets:\n        do_key_nrml = 'trn_nrml'\n        do_key_auto = 'trn_auto'\n\n        trnlist = list(gicobj.transformer.keys())\n        trnlist.sort()\n\n        rowdata_nrml = [_WORKSHT_COLUMN_LABELS_GIC[do_key_nrml]]\n        rowdata_auto = [_WORKSHT_COLUMN_LABELS_GIC[do_key_auto]]\n\n        for trn in trnlist:\n            kbus  = trn[2]\n            igic  = gicobj.transformer[trn].wdg1_gic\n            jgic  = gicobj.transformer[t"
  },
  {
    "id": "chunk_1022",
    "text": ".wdg1_gic\n            jgic  = gicobj.transformer[trn].wdg2_gic\n            if kbus:\n                kgic = gicobj.transformer[trn].wdg3_gic\n            else:\n                kgic = None\n\n            effgic  = gicobj.transformer[trn].eff_gic\n            qloss   = gicobj.transformer[trn].qloss\n            kftr    = gicobj.transformer[trn].kfactor\n            kftrtyp = gicobj._get_kfactor_type(gicobj.transformer[trn].kfactor_type)\n\n            autoi = gicobj.transformer[trn].wdg1_auto\n            a"
  },
  {
    "id": "chunk_1023",
    "text": " = gicobj.transformer[trn].wdg1_auto\n            autoj = gicobj.transformer[trn].wdg2_auto\n            if autoi or autoj:\n                if autoi==1:\n                    ibus = trn[0]\n                    jbus = trn[1]\n                else:\n                    ibus = trn[1]\n                    jbus = trn[0]\n            else:\n                ibus = trn[0]\n                jbus = trn[1]\n\n            if igic:\n                if igic>=_BIGREL: igic = ''\n            else:\n                igic = ''\n\n  "
  },
  {
    "id": "chunk_1024",
    "text": "''\n            else:\n                igic = ''\n\n            if jgic:\n                if jgic>=_BIGREL: jgic = ''\n            else:\n                jgic = ''\n\n            if kgic:\n                if kgic>=_BIGREL: kgic = ''\n            else:\n                kgic = ''\n\n            if effgic:\n                if effgic>=_BIGREL: effgic = ''\n            else:\n                effgic = ''\n\n            if qloss:\n                if qloss>=_BIGREL: qloss = ''\n            else:\n                qloss = ''\n\n"
  },
  {
    "id": "chunk_1025",
    "text": " ''\n            else:\n                qloss = ''\n\n            tlst = [ibus, jbus, kbus, trn[3], igic, jgic, kgic, effgic, kftr, kftrtyp, qloss]\n            if autoi or autoj:\n                rowdata_auto.append(tlst)\n            else:\n                rowdata_nrml.append(tlst)\n\n        # Total Qloss\n        txt  = ' Transformer Reactive Power Loss Summary\\n'\n        txt += ' Two Winding Transformers        = {:g} Mvar\\n' .format(gicobj.qtotal.wdg2_normal)\n        txt += ' Two Winding Auto Transfo"
  },
  {
    "id": "chunk_1026",
    "text": "_normal)\n        txt += ' Two Winding Auto Transformers   = {:g} Mvar\\n' .format(gicobj.qtotal.wdg2_auto)\n        txt += ' Three Winding Transformers      = {:g} Mvar\\n' .format(gicobj.qtotal.wdg3_normal)\n        txt += ' Three Winding Auto Transformers = {:g} Mvar\\n' .format(gicobj.qtotal.wdg3_auto)\n        txt += '                           Total = {:g} Mvar'   .format(gicobj.qtotal.total)\n        qlosslist = txt.split(\"\\n\")\n\n        # normal transformers\n        xlsobj.set_active_sheet(_EXPOR"
  },
  {
    "id": "chunk_1027",
    "text": "ransformers\n        xlsobj.set_active_sheet(_EXPORT_QTY_GIC[do_key])\n        br0, rc0 = 4, 1\n        br, rc = xlsobj.set_range(br0, rc0, rowdata_nrml)\n        del rowdata_nrml\n        xlsobj.autofit_columns((br0,rc0,br0,rc))\n        xlsobj.font_color((br0,rc0,br0,rc),\"red\")\n        xlsobj.align_rows((br0, rc0),alignv='right')    #label row\n        xlsobj.set_cell((1,1),_WORKSHT_INFO_TXT_GIC[do_key_nrml][0],fontStyle=\"bold\",fontSize=12, fontColor=\"blue\")\n        xlsobj.set_cell((2,1),_WORKSHT_INF"
  },
  {
    "id": "chunk_1028",
    "text": "\"blue\")\n        xlsobj.set_cell((2,1),_WORKSHT_INFO_TXT_GIC[do_key_nrml][1],fontStyle=\"bold\",fontSize=12, fontColor=\"blue\")\n\n        br, rc = br+2, 1\n        br, rc = xlsobj.set_range(br, rc, qlosslist, transpose=True)\n\n        # auto transformers\n        xlsobj.set_active_sheet('auto '+_EXPORT_QTY_GIC[do_key])\n        br0, rc0 = 4, 1\n        br, rc = xlsobj.set_range(br0, rc0, rowdata_auto)\n        del rowdata_auto\n        xlsobj.autofit_columns((br0,rc0,br0,rc))\n        xlsobj.font_color((br0,"
  },
  {
    "id": "chunk_1029",
    "text": "((br0,rc0,br0,rc))\n        xlsobj.font_color((br0,rc0,br0,rc),\"red\")\n        xlsobj.align_rows((br0, rc0),alignv='right')    #label row\n        xlsobj.set_cell((1,1),_WORKSHT_INFO_TXT_GIC[do_key_auto][0],fontStyle=\"bold\",fontSize=12, fontColor=\"blue\")\n        xlsobj.set_cell((2,1),_WORKSHT_INFO_TXT_GIC[do_key_auto][1],fontStyle=\"bold\",fontSize=12, fontColor=\"blue\")\n\n        br, rc = br+2, 1\n        br, rc = xlsobj.set_range(br, rc, qlosslist, transpose=True)\n\n    # done exporting\n    xlsobj.save"
  },
  {
    "id": "chunk_1030",
    "text": "nspose=True)\n\n    # done exporting\n    xlsobj.save(xlsfile)\n\n    if not show:\n        txt = \"\\n GIC analysis output report saved to file: \\n    {0}\\n\".format(xlsobj.XLSFNAM)\n        xlsobj.close()\n        sys.stdout.write(txt)\n\n# -----------------------------------------------------------------------------------------------------\ndef run_gic_sample_text_report(efield_mag, efield_deg, efield_type, scan_storm_event, power_flow_optn, datapath=None, outpath=None):\n    \"\"\" Use sample Case provided in"
  },
  {
    "id": "chunk_1031",
    "text": "outpath=None):\n    \"\"\" Use sample Case provided in PSSE Example folder, run GIC calculations and create text report.\n\"\"\"\n\n    gicobj = run_gic_sample_case(efield_mag, efield_deg, efield_type, scan_storm_event, power_flow_optn, datapath, outpath)\n\n    if gicobj.ierr: return\n\n    outdir = get_output_dir(outpath)\n    rptnam = _get_outfnam_event(\"sample\", efield_type, efield_mag, efield_deg, scan_storm_event)\n    if power_flow_optn:  rptnam += '_pf'\n\n    rptfile  = os.path.join(outdir, rptnam+'.txt'"
  },
  {
    "id": "chunk_1032",
    "text": "\n    rptfile  = os.path.join(outdir, rptnam+'.txt')\n    qrptfile = os.path.join(outdir, rptnam+'_qloss.txt')\n\n    gicobj.text_report(rptfile)\n    gicobj.qtotal_report(qrptfile)\n\n    msg = \"\\n Report created in file: {:s}\".format(rptfile)\n    print(msg)\n\n# -----------------------------------------------------------------------------------------------------\ndef run_gic_sample_excel_export(efield_mag, efield_deg, efield_type, scan_storm_event, power_flow_optn, show=True,\n                           "
  },
  {
    "id": "chunk_1033",
    "text": "_flow_optn, show=True,\n                                datapath=None, outpath=None):\n    \"\"\" Use sample Case provided in PSSE Example folder, run GIC calculations and export results to spreadsheet.\n\"\"\"\n    gicobj = run_gic_sample_case(efield_mag, efield_deg, efield_type, scan_storm_event, power_flow_optn, datapath, outpath)\n\n    if gicobj.ierr: return\n\n    outdir = get_output_dir(outpath)\n    rptnam = _get_outfnam_event(\"sample\", efield_type, efield_mag, efield_deg, scan_storm_event)\n    if powe"
  },
  {
    "id": "chunk_1034",
    "text": "eld_mag, efield_deg, scan_storm_event)\n    if power_flow_optn:  rptnam += '_pf'\n\n    xlfile = os.path.join(outdir, rptnam)\n    string = ''\n    overwritesheet = True\n    xlfile = gicobj.excel_export(string, xlfile, show, overwritesheet)\n\n    msg = \"\\n Spreadsheet created in file:\\n    {0}\".format(xlfile)\n    print(msg)\n\n# -----------------------------------------------------------------------------------------------------\ndef gic_results_on_network_map(pygicfile, outpath=None, outfext='.pdf', sho"
  },
  {
    "id": "chunk_1035",
    "text": "k_map(pygicfile, outpath=None, outfext='.pdf', show=True):\n    \"\"\" Plot GIC results on map.\n\"\"\"\n    import collections\n    import psspy\n\n    psspy.set_fpcw_py()     # To use PSSE, numpy and matplotlib, this is needed.\n    import arrbox.gicmaps\n\n    outdir = get_output_dir(outpath)\n\n    p, nx = os.path.split(pygicfile)\n    pyfnam, x = os.path.splitext(nx)\n\n    if not p:\n        if not os.path.exists(pygicfile):\n            pygicfile = os.path.join(outdir, pygicfile)\n\n    pltfiles = collections.Or"
  },
  {
    "id": "chunk_1036",
    "text": "(outdir, pygicfile)\n\n    pltfiles = collections.OrderedDict()\n    for k in ['busvpu_base','busvpu_gic', 'ssgic1', 'ssgic2', 'brngic',\n              'qtline', 'qtline', 'qtbar', 'effgic', 'effgicmax']:\n        if outfext=='.pdf':\n            pltfiles[k] = None\n        else:\n            fnam = \"{}_{}{}\".format(pyfnam, k, outfext)\n            pltfiles[k] = os.path.join(outdir, fnam)\n\n    gicmapsobj  = arrbox.gicmaps.GICMAPS(pygicfile)\n\n    if gicmapsobj.ierr: return\n\n    if outfext=='.pdf':\n       "
  },
  {
    "id": "chunk_1037",
    "text": "sobj.ierr: return\n\n    if outfext=='.pdf':\n        fnam = \"{}_allplots{}\".format(pyfnam, outfext)\n        pdffile = os.path.join(outdir, fnam)\n        gicmapsobj.pdf_open(pdffile)\n\n    gicmapsobj.plot_bus_voltages(figfile=pltfiles['busvpu_base'], case='base', limit='min', markersize=100)\n\n    gicmapsobj.plot_bus_voltages(figfile=pltfiles['busvpu_gic'], case='gic', limit='min', markersize=100)\n\n    # combine substations GICs flowing in and out on one legend\n    gicmapsobj.plot_substation_gicflows"
  },
  {
    "id": "chunk_1038",
    "text": "one legend\n    gicmapsobj.plot_substation_gicflows(figfile=pltfiles['ssgic1'], markersize=20)\n\n    # separate substations GICs flowing in and out on two legends\n    gicmapsobj.set_legend_options_ss_gic_values(loc=None)\n    gicmapsobj.plot_substation_gicflows(figfile=pltfiles['ssgic2'], markersize=20)\n\n    gicmapsobj.plot_branch_gicflows(figfile=pltfiles['brngic'])\n\n    gicmapsobj.plot_qtotal(figfile=pltfiles['qtline'])\n\n    gicmapsobj.plot_qtotal_barchart(figfile=pltfiles['qtbar'])\n\n    gicmapso"
  },
  {
    "id": "chunk_1039",
    "text": "_barchart(figfile=pltfiles['qtbar'])\n\n    gicmapsobj.plot_effgic(figfile=pltfiles['effgic'], gicmax=False)\n\n    gicmapsobj.plot_effgic(figfile=pltfiles['effgicmax'], gicmax=True)\n\n    if show:\n        gicmapsobj.plots_show()\n    else:\n        gicmapsobj.plots_close()\n\n    if outfext=='.pdf':\n        gicmapsobj.pdf_close()\n\n    if outfext=='.pdf':\n        msg  = \"\\n GIC analysis custom plots saved in file:\\n    {}\\n\".format(pdffile)\n    else:\n        msg  = \"\\n GIC analysis custom plot [{}] files"
  },
  {
    "id": "chunk_1040",
    "text": "    msg  = \"\\n GIC analysis custom plot [{}] files saved in folder:\\n    {}\\n\".format(outfext, outdir)\n\n    print(msg)\n    psspy.set_fpcw_psse()   # To use PSSE, numpy and matplotlib, this is needed.\n\n# -----------------------------------------------------------------------------------------------------\ndef gic_results_on_network_map_custom(pygicfile, outpath=None, outfext='.pdf', show=True):\n    \"\"\" Plot GIC results on map with custom legends, annotations.\n\"\"\"\n    import collections\n    import "
  },
  {
    "id": "chunk_1041",
    "text": "nnotations.\n\"\"\"\n    import collections\n    import psspy\n\n    psspy.set_fpcw_py()\n    import arrbox.gicmaps\n\n    outdir = get_output_dir(outpath)\n\n    p, nx = os.path.split(pygicfile)\n    pyfnam, x = os.path.splitext(nx)\n\n    if not p:\n        if not os.path.exists(pygicfile):\n            pygicfile = os.path.join(outdir, pygicfile)\n\n    outnam  = '{}_custom'.format(pyfnam)\n\n    pltfiles = collections.OrderedDict()\n    for k in ['busvpu_base','busvpu_gic', 'ssgic1', 'ssgic2', 'brngic',\n           "
  },
  {
    "id": "chunk_1042",
    "text": "pu_gic', 'ssgic1', 'ssgic2', 'brngic',\n              'qtline', 'qtline', 'qtbar', 'effgic', 'effgicmax']:\n        if outfext!='.pdf':\n            fnam = \"{}_{}{}\".format(outnam, k, outfext)\n            pltfiles[k] = os.path.join(outdir, fnam)\n\n    gicmapsobj = arrbox.gicmaps.GICMAPS(pygicfile)\n\n    if gicmapsobj.ierr: return\n\n    if outfext=='.pdf':\n        fnam = \"{}_allplots{}\".format(outnam, outfext)\n        pdffile = os.path.join(outdir, fnam)\n        pdf2fobj = gicmapsobj.pdf2_open(pdffile)"
  },
  {
    "id": "chunk_1043",
    "text": ")\n        pdf2fobj = gicmapsobj.pdf2_open(pdffile)  # open pdf2 object to save custom plots to pdf file\n\n    gicmapsobj.set_figure_size(6,4.8)\n\n    gicmapsobj.set_state_boundary_options(show=True, color='#CCCCCC', linewidth=1.0)\n    gicmapsobj.set_latitude_options(show=True, color='#CCFFFF', linewidth=2.0, dashes=[1, 1], fontsize=10)\n    gicmapsobj.set_longitude_options(show=True, color='#CCFFFF', linewidth=2.0, dashes=[1, 3], fontsize=10)\n\n    gicmapsobj.annotate_substations([1,2,3,4,5,6,7,8,9,"
  },
  {
    "id": "chunk_1044",
    "text": "icmapsobj.annotate_substations([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18], color='blue', fontsize=10)\n\n    # Plot1 - GIC case bus voltage\n    pf_flag = gicmapsobj.pygicobj.power_flow_solution_flag\n    if pf_flag==0:\n        case = 'gic'\n        if outfext!='.pdf': figfile = pltfiles['busvpu_gic']\n        ttl = 'Bus Voltages - GIC Case'\n    else:\n        case = 'base'\n        if outfext!='.pdf': figfile = pltfiles['busvpu_base']\n        ttl = 'Bus Voltages - Base Case'\n    ax, fig, basemap, a"
  },
  {
    "id": "chunk_1045",
    "text": "'Bus Voltages - Base Case'\n    ax, fig, basemap, anptobj = gicmapsobj.plot_bus_voltages(figfile=None, case=case, limit='min', markersize=100,\n                                 title=ttl)\n    if ax is None:\n        if outfext=='.pdf':\n            gicmapsobj.pdf_close()\n        return\n\n    # data point annotation\n    anptobj.set_options(xytext=(-15,-40), textcoords='offset points')\n    anptobj.set_annote_from_key(5)                          # use SS number as key\n    #anptobj.set_annote_from_key('s"
  },
  {
    "id": "chunk_1046",
    "text": " number as key\n    #anptobj.set_annote_from_key('ss05_mississippi')        # use SS name as key\n    anptobj.set_options(xytext=(-40,-100), textcoords='offset points')\n    anptobj.set_annote_from_key(7)                          # use SS number as key\n    #anptobj.set_annote_from_key('ss07_yukon')\n    anptobj.set_options(xytext=(-20,25), textcoords='offset points')\n    anptobj.set_annote_from_key(13)                         # use SS number as key\n    #anptobj.set_annote_from_key('ss13_oxus')      "
  },
  {
    "id": "chunk_1047",
    "text": "   #anptobj.set_annote_from_key('ss13_oxus')               # use SS number as key\n    anptobj.set_options(xytext=(-40,25), textcoords='offset points')\n    #anptobj.set_annote_from_key(15)                        # use SS number as key\n    anptobj.set_annote_from_key('ss15_heilong')             # use SS number as key\n\n    # custom annotation\n    gicmapsobj.annotate_text('LabelLeft', -89, 30.2, ax, basemap, xycoords='long_lat', color='cyan', fontsize=15)\n    x, y = gicmapsobj.datapoint_xy_from_long"
  },
  {
    "id": "chunk_1048",
    "text": "e=15)\n    x, y = gicmapsobj.datapoint_xy_from_longitude_latiude(basemap, -84, 30.2)\n    gicmapsobj.annotate_text('LabelRight', x, y, ax, basemap, xycoords='data', color='magenta', fontsize=15)\n\n    if outfext=='.pdf':\n        gicmapsobj.pdf2_add_figure(pdf2fobj, fig)               # add custom plot to pdf file\n    else:\n        fig.savefig(figfile, dpi=300, bbox_inches='tight')   # save custom plot to file\n\n    # Plot2 - Base case bus voltage\n    if pf_flag==0:\n        ax, fig, basemap, anptobj "
  },
  {
    "id": "chunk_1049",
    "text": " if pf_flag==0:\n        ax, fig, basemap, anptobj = gicmapsobj.plot_bus_voltages(figfile=None,  case='base', limit='min', markersize=100,\n                                     title='Bus Voltages - Base Case')\n        anptobj.set_options(xytext=(-50,-50), textcoords='offset points')\n        anptobj.set_annote_from_key(15)\n\n        if outfext=='.pdf':\n            gicmapsobj.pdf2_add_figure(pdf2fobj, fig)\n        else:\n            fig.savefig(pltfiles['busvpu_base'], dpi=300, bbox_inches='tight')\n\n"
  },
  {
    "id": "chunk_1050",
    "text": "es['busvpu_base'], dpi=300, bbox_inches='tight')\n\n    # Plot3 - substations GICs (combine GICs flowing in and out on one legend)\n    ax, fig, basemap, anptobj = gicmapsobj.plot_substation_gicflows(figfile=None, markersize=20)\n\n    anptobj.set_options(xytext=(-65,40), textcoords='offset points')\n    anptobj.set_annote_from_key('ss01_nile')\n    anptobj.set_options(xytext=(-60,-70), textcoords='offset points')\n    anptobj.set_annote_from_key('ss02_yangtze')\n    anptobj.set_options(xytext=(-60,-70),"
  },
  {
    "id": "chunk_1051",
    "text": "angtze')\n    anptobj.set_options(xytext=(-60,-70), textcoords='offset points')\n    anptobj.set_annote_from_key('ss03_arkansas')\n    anptobj.set_options(xytext=(-20,-35), textcoords='offset points')\n    anptobj.set_annote_from_key('ss09_indus')\n\n    if outfext=='.pdf':\n        gicmapsobj.pdf2_add_figure(pdf2fobj, fig)\n    else:\n        fig.savefig(pltfiles['ssgic1'], dpi=300, bbox_inches='tight')\n\n    # Plot4 - substations GICs (separate GICs flowing in and out on two legends)\n    gicmapsobj.set_"
  },
  {
    "id": "chunk_1052",
    "text": "ing in and out on two legends)\n    gicmapsobj.set_legend_options_ss_gic_values(loc=None)\n    ax, fig, basemap, anptobj = gicmapsobj.plot_substation_gicflows(figfile=None, markersize=20)\n    anptobj.set_options(xytext=(-50,-50), textcoords='offset points')\n    anptobj.set_annote_from_key(1)\n    anptobj.set_annote_from_key(3)\n    anptobj.set_annote_from_key(8)\n\n    if outfext=='.pdf':\n        gicmapsobj.pdf2_add_figure(pdf2fobj, fig)\n    else:\n        fig.savefig(pltfiles['ssgic2'], dpi=300, bbox_"
  },
  {
    "id": "chunk_1053",
    "text": "    fig.savefig(pltfiles['ssgic2'], dpi=300, bbox_inches='tight')\n\n    # Plot5 - Effective GIC\n    ax, fig, anptobj = gicmapsobj.plot_effgic(figfile=None, gicmax=False)\n    anptobj.set_options(xytext=(-30,-30), textcoords='offset points')\n    anptobj.set_annote_from_key('catdog_xmer')          # use transformer name as key\n    anptobj.set_annote_from_key((3018, 3008, '11'))     # use transformer id tuple: (wdg1bus, wdg2bus, 'ckt')\n                                                        # or (wdg"
  },
  {
    "id": "chunk_1054",
    "text": "                                         # or (wdg1bus, wdg2bus, wdg3bus, 'ckt')\n    anptobj.set_options(xytext=(-65,30), textcoords='offset points')\n    anptobj.set_annote_from_key((203, 202, 't7'))\n\n    if outfext=='.pdf':\n        gicmapsobj.pdf2_add_figure(pdf2fobj, fig)\n    else:\n        fig.savefig(pltfiles['effgic'], dpi=300, bbox_inches='tight')\n\n    # Plot6 - Maximum Effective GIC\n    ax, fig, anptobj = gicmapsobj.plot_effgic(figfile=None, gicmax=True)\n    anptobj.set_options(xytext=(-30"
  },
  {
    "id": "chunk_1055",
    "text": ", gicmax=True)\n    anptobj.set_options(xytext=(-30,-40), textcoords='offset points')\n    anptobj.set_annote_from_key('catdog_xmer')\n    anptobj.set_options(xytext=(-30,-60), textcoords='offset points')\n    anptobj.set_annote_from_key(('urb tx'))\n    anptobj.set_options(xytext=(-10,20), textcoords='offset points')\n    anptobj.set_annote_from_key(('mid ltc'))\n\n    if outfext=='.pdf':\n        gicmapsobj.pdf2_add_figure(pdf2fobj, fig)\n    else:\n        fig.savefig(pltfiles['effgicmax'], dpi=300, bbo"
  },
  {
    "id": "chunk_1056",
    "text": "   fig.savefig(pltfiles['effgicmax'], dpi=300, bbox_inches='tight')\n\n    if show:\n        gicmapsobj.plots_show()\n    else:\n        gicmapsobj.plots_close()\n\n    if outfext=='.pdf':\n        gicmapsobj.pdf2_close(pdf2fobj)\n\n    if outfext=='.pdf':\n        msg  = \"\\n GIC analysis custom plots saved in file:\\n    {}\\n\".format(pdffile)\n    else:\n        msg  = \"\\n GIC analysis custom plot [{}] files saved in folder:\\n    {}\\n\".format(outfext, outdir)\n\n    print(msg)\n    psspy.set_fpcw_psse()\n\n# ----"
  },
  {
    "id": "chunk_1057",
    "text": "\n\n    print(msg)\n    psspy.set_fpcw_psse()\n\n# -----------------------------------------------------------------------------------------------------\ndef gict_result_plots(gictfile, outpath=None, top_trn=10, nrows=2, ncols=2, outfext='.pdf', show=True):\n    \"\"\" Plot GIC Thermal results.\ntop_trn - plot so many transformers with maximum GICs\nnrows   - numbers of rows in plot figure\nncols   - numbers of columns in plot figure\nnrows X ncols subplots are drawn on one figure.\n\"\"\"\n    import collections\n"
  },
  {
    "id": "chunk_1058",
    "text": "e drawn on one figure.\n\"\"\"\n    import collections\n    import psspy\n\n    psspy.set_fpcw_py()\n    import arrbox.gicthermal\n\n    outdir = get_output_dir(outpath)\n\n    p, nx = os.path.split(gictfile)\n    pyfnam, x = os.path.splitext(nx)\n\n    if not p:\n        if not os.path.exists(gictfile):\n            gictfile = os.path.join(outdir, gictfile)\n\n    outnam  = '{}'.format(pyfnam)\n\n    pltfiles = collections.OrderedDict()\n    for k in ['evt','trn']:\n        if outfext=='.pdf':\n            pltfiles[k] "
  },
  {
    "id": "chunk_1059",
    "text": "      if outfext=='.pdf':\n            pltfiles[k] = None\n        else:\n            fnam = \"{}_{}{}\".format(outnam, k, outfext)\n            pltfiles[k] = os.path.join(outdir, fnam)\n\n    thermalobj = arrbox.gicthermal.GICTHERMAL(gictfile)\n\n    if thermalobj.ierr: return\n\n    if outfext=='.pdf':\n        fnam = \"{}_allplots{}\".format(outnam, outfext)\n        pdffile = os.path.join(outdir, fnam)\n        thermalobj.pdf_open(pdffile)\n\n    evtnamlst, figdict, axdict = thermalobj.plot_events(figfile=pltf"
  },
  {
    "id": "chunk_1060",
    "text": "dict, axdict = thermalobj.plot_events(figfile=pltfiles['evt'], show=show)\n\n    figlst, axdict = thermalobj.plot_transformer_gict(figfile=pltfiles['trn'], top=top_trn, nrows=nrows, ncols=ncols, show=show)\n\n    if show:\n        thermalobj.plots_show()\n    else:\n        thermalobj.plots_close()\n\n    if outfext=='.pdf':\n        thermalobj.pdf_close()\n\n    if outfext=='.pdf':\n        msg  = \"\\n GIC Transformer Thermal GICT(t) profile plots saved in file:\\n    {}\\n\".format(pdffile)\n    else:\n        m"
  },
  {
    "id": "chunk_1061",
    "text": "le:\\n    {}\\n\".format(pdffile)\n    else:\n        msg  = \"\\n GIC Transformer Thermal GICT(t) profile plot [{}] files saved in folder:\\n    {}\\n\".format(outfext, outdir)\n\n    print(msg)\n    psspy.set_fpcw_psse()\n\n# =============================================================================================================\n\ndef run_all_tests(datapath=None, outpath=None, efields='ubn', scan='d', pf='fdns', outfext='.pdf'):\n\n    outdir = get_output_dir(outpath)\n\n    efield_type_lst = []\n    scan_lst"
  },
  {
    "id": "chunk_1062",
    "text": "ir(outpath)\n\n    efield_type_lst = []\n    scan_lst = []\n    pf_lst = []\n\n    if efields:\n        s_efld = efields.lower()\n        if 'u' in s_efld: efield_type_lst.append('uniform')\n        if 'b' in s_efld: efield_type_lst.append('benchmark')\n        if 'n' in s_efld: efield_type_lst.append('nonuniform')\n\n    if scan:\n        s_scan = scan.lower()\n        if 'd' in s_scan: scan_lst.append('scan_deg')\n        if 'm' in s_scan: scan_lst.append('scan_mag')\n        if 'd_m' in s_scan: scan_lst.appe"
  },
  {
    "id": "chunk_1063",
    "text": "an_mag')\n        if 'd_m' in s_scan: scan_lst.append('scan_d_m')\n\n    if pf:\n        pf_lst.append(pf)\n\n    if not efield_type_lst: efield_type_lst = ['uniform']\n    if not scan_lst: scan_lst = ['']\n    if not pf_lst: pf_lst = ['']\n\n    # -----------------------------------------\n\n    print (\"\\n >>>>>>>>>>>>> Running create_gicdata_template_sample\")\n    excelfile = create_gicdata_template_sample(datapath, outpath, showexcel=False)\n\n    print (\"\\n >>>>>>>>>>>>> Running excel2gicfile\")\n    gicdata"
  },
  {
    "id": "chunk_1064",
    "text": " >>>>>>>>>>>>> Running excel2gicfile\")\n    gicdata_excel2gicfile(outpath)\n\n    efield_mag = 1.0\n    efield_deg = 0.0\n\n    print (\"\\n >>>>>>>>>>>>> Running run_gic_ieee_text_report\")\n    for efield_type in efield_type_lst:\n        for scan_storm_event in scan_lst:\n            run_gic_ieee_text_report(efield_mag, efield_deg, efield_type, scan_storm_event,datapath, outpath)\n            break\n\n    print (\"\\n >>>>>>>>>>>>> Running run_gic_sample_text_report\")\n    for efield_type in efield_type_lst:\n "
  },
  {
    "id": "chunk_1065",
    "text": "report\")\n    for efield_type in efield_type_lst:\n        for scan_storm_event in scan_lst:\n            for power_flow_optn in pf_lst:\n                run_gic_sample_text_report(efield_mag, efield_deg, efield_type,\n                                           scan_storm_event, power_flow_optn, datapath, outpath)\n                break\n\n    print (\"\\n >>>>>>>>>>>>> Running run_gic_ieee_text_report_DIY\")\n    run_gic_ieee_text_report_DIY(datapath, outpath)\n\n    print (\"\\n >>>>>>>>>>>>> Running run_gic_"
  },
  {
    "id": "chunk_1066",
    "text": "th)\n\n    print (\"\\n >>>>>>>>>>>>> Running run_gic_ieee_excel_export_DIY\")\n    run_gic_ieee_excel_export_DIY(datapath, outpath, show=False)\n\n\n    print (\"\\n >>>>>>>>>>>>> Running run_gic_sample_excel_export, uniform, no scan, no powerflow\")\n    run_gic_sample_excel_export(efield_mag=1.0, efield_deg=0.0, efield_type='uniform', scan_storm_event='',\n                                power_flow_optn='',     show=False, datapath=datapath, outpath=outpath)\n\n    print (\"\\n >>>>>>>>>>>>> Running run_gic_sa"
  },
  {
    "id": "chunk_1067",
    "text": ")\n\n    print (\"\\n >>>>>>>>>>>>> Running run_gic_sample_excel_export, uniform, scan_deg, fdns\")\n    run_gic_sample_excel_export(efield_mag=1.0, efield_deg=0.0, efield_type='uniform', scan_storm_event='scan_deg',\n                                power_flow_optn='fdns', show=False, datapath=datapath, outpath=outpath)\n\n\n    pygicfile = ''\n    for fnam in os.listdir(outdir):\n        n, x = os.path.splitext(fnam)\n        if x=='.pygic':\n            i = n.find('sample')\n            if i>=0:\n            "
  },
  {
    "id": "chunk_1068",
    "text": "n.find('sample')\n            if i>=0:\n                pygicfile = os.path.join(outdir, fnam)\n                break\n\n    print (\"\\n >>>>>>>>>>>>> Running gic_results_on_network_map\")\n    if pygicfile:\n        gic_results_on_network_map(pygicfile, outpath, outfext=outfext, show=False)\n    else:\n        print (\"    mapdata file does not exist.\\n    {}\\n\".format(pygicfile))\n\n    print (\"\\n >>>>>>>>>>>>> Running gic_results_on_network_map_custom\")\n    if pygicfile:\n        gic_results_on_network_map_"
  },
  {
    "id": "chunk_1069",
    "text": " if pygicfile:\n        gic_results_on_network_map_custom(pygicfile, outpath, outfext=outfext, show=False)\n    else:\n        print (\"    mapdata file does not exist.\\n    {}\\n\".format(pygicfile))\n\n    gictfile = ''\n    for fnam in os.listdir(outdir):\n        n, x = os.path.splitext(fnam)\n        if x=='.csv':\n            i = n.find('sample')\n            if i>=0:\n                gictfile = os.path.join(outdir, fnam)\n                break\n\n    print (\"\\n >>>>>>>>>>>>> Running gicthermal\")\n    if gi"
  },
  {
    "id": "chunk_1070",
    "text": " (\"\\n >>>>>>>>>>>>> Running gicthermal\")\n    if gictfile:\n        gict_result_plots(gictfile, outpath, outfext=outfext, show=False)\n    else:\n        print (\"    GIC results gict CSV file does not exist.\\n\")\n\n# =============================================================================================================\n\ndef run_gicdata_templates(outpath=None):\n    excelfile = create_gicdata_template_sample(outpath=outpath, areas=[], showexcel=True)\n    excelfile = create_gicdata_template_sample("
  },
  {
    "id": "chunk_1071",
    "text": "e)\n    excelfile = create_gicdata_template_sample(outpath=outpath, areas=[1,2,3], showexcel=False)\n    excelfile = create_gicdata_template_sample(outpath=outpath, areas=[4,5,6], showexcel=False)\n\n# =============================================================================================================\n\ndef run_gicdata_transfer(outpath=None):\n    excelfile = transfer_gicdata_sample(outpath=outpath, areas=[], showexcel=False)\n    excelfile = transfer_gicdata_sample(outpath=outpath, areas=[1,2"
  },
  {
    "id": "chunk_1072",
    "text": "ransfer_gicdata_sample(outpath=outpath, areas=[1,2,3], showexcel=False)\n    excelfile = transfer_gicdata_sample(outpath=outpath, areas=[4,5,6], showexcel=False)\n\n# =============================================================================================================\n\ndef run_gicdata_excel2gicfile(outpath=None):\n    gicfile = gicdata_excel2gicfile(outpath=outpath, areas=[])\n    gicfile = gicdata_excel2gicfile(outpath=outpath, areas=[1,2,3])\n    gicfile = gicdata_excel2gicfile(outpath=outpa"
  },
  {
    "id": "chunk_1073",
    "text": "\n    gicfile = gicdata_excel2gicfile(outpath=outpath, areas=[4,5,6])\n\n# =============================================================================================================\n\ndef run_gicdata_gicfile2excel(outpath=None):\n    excelfile = gicdata_gicfile2excel(outpath=outpath, areas=[], showexcel=False)\n    excelfile = gicdata_gicfile2excel(outpath=outpath, areas=[1,2,3], showexcel=False)\n    excelfile = gicdata_gicfile2excel(outpath=outpath, areas=[4,5,6], showexcel=False)\n\n# ============="
  },
  {
    "id": "chunk_1074",
    "text": ", areas=[4,5,6], showexcel=False)\n\n# =============================================================================================================\n\ndef run_gicdata_merge(outpath=None):\n    excelfile = gicdata_merge(outpath=outpath, showexcel=False)\n\n# =============================================================================================================\n\ndef run_gicdata_all(outpath=None):\n    \"\"\" Run all gicdata tests.\n\"\"\"\n    run_gicdata_templates(outpath)\n    run_gicdata_transfer(outpath"
  },
  {
    "id": "chunk_1075",
    "text": "emplates(outpath)\n    run_gicdata_transfer(outpath)\n    run_gicdata_excel2gicfile(outpath)\n    run_gicdata_gicfile2excel(outpath)\n    run_gicdata_merge(outpath)\n\n# =============================================================================================================\ndef _run_one_test():\n\n    # Run these one by one in __main__ (just copy each line in __main__ and run).\n    #\n    # - Function create_gicdata_template_sample() must be run before running gicdata_excel2gicfile().\n    # - Functi"
  },
  {
    "id": "chunk_1076",
    "text": "re running gicdata_excel2gicfile().\n    # - Functions run_gic_ieee_text_report(..) and run_gic_sample_text_report(..) return pygicfile name.\n    #   Use that as input to gic_results_on_network_map(..) and gic_results_on_network_map_custom(..).\n\n    # GIC data tests\n    run_gicdata_templates()\n    run_gicdata_transfer()\n    run_gicdata_excel2gicfile()\n    run_gicdata_gicfile2excel()\n    run_gicdata_merge()\n\n    # GIC calculation tests\n    run_gic_ieee_text_report(efield_mag=1.0, efield_deg=0.0, e"
  },
  {
    "id": "chunk_1077",
    "text": "ieee_text_report(efield_mag=1.0, efield_deg=0.0, efield_type='uniform',    scan_storm_event='')\n    run_gic_ieee_text_report(efield_mag=1.0, efield_deg=0.0, efield_type='uniform',    scan_storm_event='scan_deg')\n    run_gic_ieee_text_report(efield_mag=8.0, efield_deg=0.0, efield_type='benchmark',  scan_storm_event='')\n    run_gic_ieee_text_report(efield_mag=8.0, efield_deg=0.0, efield_type='benchmark',  scan_storm_event='scan_deg')\n    run_gic_ieee_text_report(efield_mag=1.0, efield_deg=0.0, efi"
  },
  {
    "id": "chunk_1078",
    "text": "ee_text_report(efield_mag=1.0, efield_deg=0.0, efield_type='nonuniform', scan_storm_event='')\n    run_gic_ieee_text_report(efield_mag=1.0, efield_deg=0.0, efield_type='nonuniform', scan_storm_event='scan_deg')    # scan not allowed, so does not scan\n\n    run_gic_sample_text_report(efield_mag=1.0, efield_deg=0.0, efield_type='uniform',    scan_storm_event='',         power_flow_optn='')\n    run_gic_sample_text_report(efield_mag=1.0, efield_deg=0.0, efield_type='uniform',    scan_storm_event='scan"
  },
  {
    "id": "chunk_1079",
    "text": ", efield_type='uniform',    scan_storm_event='scan_deg', power_flow_optn='fdns')\n    run_gic_sample_text_report(efield_mag=8.0, efield_deg=0.0, efield_type='benchmark',  scan_storm_event='',         power_flow_optn='')\n    run_gic_sample_text_report(efield_mag=8.0, efield_deg=0.0, efield_type='benchmark',  scan_storm_event='scan_deg', power_flow_optn='fdns')\n    run_gic_sample_text_report(efield_mag=8.0, efield_deg=0.0, efield_type='benchmark',  scan_storm_event='scan_mag', power_flow_optn='fdns"
  },
  {
    "id": "chunk_1080",
    "text": "scan_storm_event='scan_mag', power_flow_optn='fdns')\n    run_gic_sample_text_report(efield_mag=8.0, efield_deg=0.0, efield_type='benchmark',  scan_storm_event='scan_d_m', power_flow_optn='fdns')\n    run_gic_sample_text_report(efield_mag=1.0, efield_deg=0.0, efield_type='nonuniform', scan_storm_event='',         power_flow_optn='')\n    run_gic_sample_text_report(efield_mag=1.0, efield_deg=0.0, efield_type='nonuniform', scan_storm_event='scan_deg', power_flow_optn='fdns') # scan not allowed, so do"
  },
  {
    "id": "chunk_1081",
    "text": " power_flow_optn='fdns') # scan not allowed, so does not scan\n\n    run_gic_ieee_text_report_DIY()\n    run_gic_ieee_excel_export_DIY(show=True)\n\n    run_gic_sample_excel_export(efield_mag=1.0, efield_deg=0.0, efield_type='uniform',   scan_storm_event='',         power_flow_optn='',     show=True)\n    run_gic_sample_excel_export(efield_mag=8.0, efield_deg=0.0, efield_type='benchmark', scan_storm_event='scan_deg', power_flow_optn='fdns', show=True)\n    run_gic_sample_excel_export(efield_mag=8.0, ef"
  },
  {
    "id": "chunk_1082",
    "text": "    run_gic_sample_excel_export(efield_mag=8.0, efield_deg=0.0, efield_type='benchmark', scan_storm_event='scan_d_m', power_flow_optn='fdns', show=True)\n\n    pygicfile = r\"sample_b_8(mag)_0(deg)_scan_d_m_map(deg).pygic\"\n    gic_results_on_network_map(pygicfile, show=False)\n\n    pygicfile = r\"sample_b_8(mag)_0(deg)_scan_d_m_map(deg).pygic\"\n    gic_results_on_network_map_custom(pygicfile, show=False)\n\n    # ---------------------------------\n    run_all_tests(datapath=datapath, outpath=outpath, efi"
  },
  {
    "id": "chunk_1083",
    "text": "_all_tests(datapath=datapath, outpath=outpath, efields='ubn', scan='d_m', pf='fdns')\n    run_all_tests(datapath=None, outpath=None, efields='b', scan='', pf='', outfext='.png')\n\n# =============================================================================================================\nif __name__ == '__main__':\n    pass\n    import psse35\n#[harmonics_demo.py]    Harmonics Analysis in PSSE\n# =====================================================================================================\n'"
  },
  {
    "id": "chunk_1084",
    "text": "================================================\n'''This is an example file showing how to run Harmonics Analysis.\n   Plot frequency scan results.\n\n---------------------------------------------------------------------------------\nHow to use this file?\n\nAs showed in __main__ (end of this file)\n- Enable PSSE version specific environment, as an example [where XX is psse version number]:\n    import psseXX\n\n- call function\n    Run various functions from this file as desired.\n    Refer test1(..) ... f"
  },
  {
    "id": "chunk_1085",
    "text": "om this file as desired.\n    Refer test1(..) ... functions towards end of this file.\n'''\n\n\"\"\"\nUse any of these keywords to run har_analysis_2.\nKeyword     Default     Description\n                      # INTGAR[]\nfscanoptn   = 1       # 1 frequency scan option: 0 no; =1 yes\ndstnoptn    = 1       # 2 distortion calculations option: 0 no; =1 yes\n\nlinmdl      = 0       # 3 line model option:  =0 nominal pi; =1 long line with skin effect;\n                      #                       =2 long line but"
  },
  {
    "id": "chunk_1086",
    "text": "          #                       =2 long line but no skin effect\ndstnbuop    = 0       # 4 bus option in dstn: =0 all buses; =1 only study subsystem buses\ndstnrptop   = 0       # 5 bus option in dstn: =0 only THDs; =1 THDs + contributions\nimachimpop  = 0       # 6 induction machine impedance option =0 from power flow data; =1 from sequene data\ndcimpop     = 0       # 7 2TDC, VSCDC and MTDC equivalent impedance option in fscan =0 block; 1=consider\ntriplenop   = 0       # 8 Triplen Harmonics Opti"
  },
  {
    "id": "chunk_1087",
    "text": "r\ntriplenop   = 0       # 8 Triplen Harmonics Option in distortion calculations =0 ignore; =1 consider\ngenimpop    = 0       # 9 generatir impedance option:  =0 Use ZSORCE impedance from power flow data\n                      #                                =1 Use subtransient impedance from sequence data\n                      #                                =2 Use transient impedance from sequence data\n                      #                                =3 Use synchronous impedance from seq"
  },
  {
    "id": "chunk_1088",
    "text": "             =3 Use synchronous impedance from sequence data\n                      #                                =4 Use negative sequence impedance from sequence data\nmdltypop    = 0       # 10 harmonics Model Type Option, allowed 0 or 1\nload_mdltyp = 0       # 11 load model type\ngen_mdltyp  = 0       # 12 gen model type\nbrnsh_mdltyp= 0       # 13 branch shunt model type\ntrn_mdltyp  = 0       # 14 trn model type\nfctsh_mdltyp= 0       # 15 facts shunt model type\nfctse_mdltyp= 0       # 16 fact"
  },
  {
    "id": "chunk_1089",
    "text": "s shunt model type\nfctse_mdltyp= 0       # 16 facts series model type\nimach_mdltyp= 0       # 17 induction machine model type\n\n                      # REALAR[]\nhord_min    =  0.1    # 1 Minimum Harmonic Order\nhord_max    = 50.0    # 2 Maximum Harmonic Order\nhord_stp    =  0.1    # 3 Harmonic Order Step\n                      # FILEAR[]\nhrsfile     = ''      # 1 Binary Results File Name (.hrs)\ndstnfile    = ''      # 2 Distortion Calculation Report File Name (.txt)\nresnfile    = ''      # 3 Freque"
  },
  {
    "id": "chunk_1090",
    "text": " File Name (.txt)\nresnfile    = ''      # 3 Frequency Scan Resonance Report File Name (.txt)\n\"\"\"\n\nimport sys, os, math, traceback, textwrap\n\n_COLOR_PREFERENCE = ['orange', 'green', 'blue', 'red']\n_COLOR_PREFERENCE_BUS = ['red', 'blue']\n_ALLOWED_FIG_FILE_TYPES = ['eps', 'jpeg', 'jpg', 'pdf', 'pgf', 'png', 'ps', 'raw', 'rgba', 'svg', 'svgz', 'tif', 'tiff']\n\n# ==============================================================================\n\n# This data is from file CASE1TB.XLS of IEEE Task Force on H"
  },
  {
    "id": "chunk_1091",
    "text": "a is from file CASE1TB.XLS of IEEE Task Force on Harmonics Modeling & Simulation\n# Frequency Scan Thevenin Impedance\n# Distributed Line Model: ZRdist, ZXdist, Zdist\n# Pi Line Model: Zpi\n\n#    HORD       , ZRdist        ,  ZXdist       , Zdist , Zpi\n_ieee_tf_scan_results = [\n    [1.00\t, 0.0534\t, 0.2197\t, 0.226\t, 0.226  ],\n    [1.33\t, 0.0793\t, 0.3239\t, 0.334\t, 0.334  ],\n    [1.67\t, 0.1371\t, 0.4711\t, 0.491\t, 0.492  ],\n    [2.00\t, 0.2075\t, 0.5667\t, 0.603\t, 0.606  ],\n    [2.33\t, 0.5381\t, 0.9926\t, 1.1"
  },
  {
    "id": "chunk_1092",
    "text": ".603\t, 0.606  ],\n    [2.33\t, 0.5381\t, 0.9926\t, 1.129\t, 1.136  ],\n    [2.67\t, 1.7230\t, 1.1320\t, 2.062\t, 2.081  ],\n    [3.00\t, 2.0150\t, -0.9333\t, 2.221\t, 2.217  ],\n    [3.33\t, 0.7628\t, -1.0731\t, 1.317\t, 1.312  ],\n    [3.67\t, 0.3951\t, -0.7590\t, 0.856\t, 0.855  ],\n    [4.00\t, 0.3626\t, -0.5387\t, 0.649\t, 0.652  ],\n    [4.33\t, 0.3141\t, -0.7507\t, 0.814\t, 0.806  ],\n    [4.67\t, 0.0891\t, -0.5594\t, 0.566\t, 0.564  ],\n    [5.00\t, 0.0570\t, -0.4405\t, 0.444\t, 0.443  ],\n    [5.33\t, 0.0460\t, -0.3673\t, 0.370\t, 0.370"
  },
  {
    "id": "chunk_1093",
    "text": "3  ],\n    [5.33\t, 0.0460\t, -0.3673\t, 0.370\t, 0.370  ],\n    [5.67\t, 0.0430\t, -0.3170\t, 0.320\t, 0.320  ],\n    [6.00\t, 0.0378\t, -0.2885\t, 0.291\t, 0.291  ],\n    [6.33\t, 0.0219\t, -0.2551\t, 0.256\t, 0.256  ],\n    [6.67\t, 0.0166\t, -0.2223\t, 0.223\t, 0.224  ],\n    [7.00\t, 0.0144\t, -0.1957\t, 0.196\t, 0.197  ],\n    [7.33\t, 0.0131\t, -0.1732\t, 0.174\t, 0.175  ],\n    [7.67\t, 0.0122\t, -0.1537\t, 0.154\t, 0.155  ],\n    [8.00\t, 0.0116\t, -0.1364\t, 0.137\t, 0.138  ],\n    [8.33\t, 0.0112\t, -0.1211\t, 0.122\t, 0.123  ],\n    "
  },
  {
    "id": "chunk_1094",
    "text": " [8.33\t, 0.0112\t, -0.1211\t, 0.122\t, 0.123  ],\n    [8.67\t, 0.0105\t, -0.1076\t, 0.108\t, 0.109  ],\n    [9.00\t, 0.0091\t, -0.0949\t, 0.095\t, 0.096  ],\n    [9.33\t, 0.0077\t, -0.0823\t, 0.083\t, 0.084  ],\n    [9.67\t, 0.0072\t, -0.0702\t, 0.071\t, 0.071  ],\n    [10.00\t, 0.0071\t, -0.0593\t, 0.060\t, 0.060  ],\n    [10.33\t, 0.0067\t, -0.0498\t, 0.050\t, 0.050  ],\n    [10.67\t, 0.0051\t, -0.0409\t, 0.041\t, 0.041  ],\n    [11.00\t, 0.0029\t, -0.0311\t, 0.031\t, 0.031  ],\n    [11.33\t, 0.0014\t, -0.0207\t, 0.021\t, 0.021  ],\n    [11."
  },
  {
    "id": "chunk_1095",
    "text": "33\t, 0.0014\t, -0.0207\t, 0.021\t, 0.021  ],\n    [11.67\t, 0.0008\t, -0.0105\t, 0.011\t, 0.010  ],\n    [12.00\t, 0.0007\t, -0.0009\t, 0.001\t, 0.001  ],\n    [12.33\t, 0.0007\t, 0.0081\t, 0.008\t, 0.008  ],\n    [12.67\t, 0.0008\t, 0.0168\t, 0.017\t, 0.017  ],\n    [13.00\t, 0.0008\t, 0.0251\t, 0.025\t, 0.025  ],\n    [13.33\t, 0.0009\t, 0.0331\t, 0.033\t, 0.033  ],\n    [13.67\t, 0.0010\t, 0.0410\t, 0.041\t, 0.041  ],\n    [14.00\t, 0.0010\t, 0.0487\t, 0.049\t, 0.049  ],\n    [14.33\t, 0.0010\t, 0.0562\t, 0.056\t, 0.057  ],\n    [14.67\t, 0."
  },
  {
    "id": "chunk_1096",
    "text": ".0010\t, 0.0562\t, 0.056\t, 0.057  ],\n    [14.67\t, 0.0010\t, 0.0636\t, 0.064\t, 0.065  ],\n    [15.00\t, 0.0010\t, 0.0709\t, 0.071\t, 0.072  ],\n    [15.33\t, 0.0010\t, 0.0782\t, 0.078\t, 0.080  ],\n    [15.67\t, 0.0009\t, 0.0855\t, 0.085\t, 0.087  ],\n    [16.00\t, 0.0009\t, 0.0927\t, 0.093\t, 0.095  ],\n    [16.33\t, 0.0009\t, 0.0998\t, 0.100\t, 0.102  ],\n    [16.67\t, 0.0009\t, 0.1070\t, 0.107\t, 0.110  ],\n    [17.00\t, 0.0010\t, 0.1141\t, 0.114\t, 0.117  ],\n    [17.33\t, 0.0010\t, 0.1213\t, 0.121\t, 0.124  ],\n    [17.66\t, 0.0010\t, 0."
  },
  {
    "id": "chunk_1097",
    "text": ".1213\t, 0.121\t, 0.124  ],\n    [17.66\t, 0.0010\t, 0.1285\t, 0.129\t, 0.132  ],\n    [18.00\t, 0.0010\t, 0.1357\t, 0.136\t, 0.139  ],\n    [18.33\t, 0.0011\t, 0.1430\t, 0.143\t, 0.147  ],\n    [18.66\t, 0.0011\t, 0.1504\t, 0.150\t, 0.154  ],\n    [19.00\t, 0.0012\t, 0.1579\t, 0.158\t, 0.162  ],\n    [19.33\t, 0.0012\t, 0.1654\t, 0.165\t, 0.170  ],\n    [19.66\t, 0.0013\t, 0.1732\t, 0.173\t, 0.178  ],\n    [20.00\t, 0.0014\t, 0.1811\t, 0.181\t, 0.186  ],\n    [20.33\t, 0.0015\t, 0.1892\t, 0.189\t, 0.194  ],\n    [20.66\t, 0.0016\t, 0.1975\t, 0."
  },
  {
    "id": "chunk_1098",
    "text": ".189\t, 0.194  ],\n    [20.66\t, 0.0016\t, 0.1975\t, 0.198\t, 0.203  ],\n    [21.00\t, 0.0018\t, 0.2062\t, 0.206\t, 0.211  ],\n    [21.33\t, 0.0019\t, 0.2153\t, 0.215\t, 0.218  ],\n    [21.66\t, 0.0022\t, 0.2247\t, 0.225\t, 0.224  ],\n    [22.00\t, 0.0025\t, 0.2348\t, 0.235\t, 0.229  ],\n    [22.33\t, 0.0029\t, 0.2456\t, 0.246\t, 0.236  ],\n    [22.66\t, 0.0034\t, 0.2573\t, 0.257\t, 0.245  ],\n    [23.00\t, 0.0041\t, 0.2703\t, 0.270\t, 0.254  ],\n    [23.33\t, 0.0052\t, 0.2850\t, 0.285\t, 0.263  ],\n    [23.66\t, 0.0068\t, 0.3023\t, 0.302\t, 0.2"
  },
  {
    "id": "chunk_1099",
    "text": "263  ],\n    [23.66\t, 0.0068\t, 0.3023\t, 0.302\t, 0.273  ],\n    [24.00\t, 0.0094\t, 0.3239\t, 0.324\t, 0.282  ],\n    [24.33\t, 0.0142\t, 0.3530\t, 0.353\t, 0.292  ],\n    [24.66\t, 0.0258\t, 0.3988\t, 0.400\t, 0.302  ],\n    [25.00\t, 0.0767\t, 0.4914\t, 0.497\t, 0.313  ],\n    [25.33\t, 0.3804\t, 0.4516\t, 0.590\t, 0.324  ],\n    [25.66\t, 0.2886\t, 0.2076\t, 0.355\t, 0.336  ],\n    [26.00\t, 0.1861\t, 0.1507\t, 0.239\t, 0.350  ],\n    [26.33\t, 0.0983\t, 0.1640\t, 0.191\t, 0.366  ],\n    [26.66\t, 0.0543\t, 0.2017\t, 0.209\t, 0.391  ],\n  "
  },
  {
    "id": "chunk_1100",
    "text": "   [26.66\t, 0.0543\t, 0.2017\t, 0.209\t, 0.391  ],\n    [27.00\t, 0.0341\t, 0.2359\t, 0.238\t, 0.384  ],\n    [27.33\t, 0.0239\t, 0.2646\t, 0.266\t, 0.348  ],\n    [27.66\t, 0.0184\t, 0.2898\t, 0.290\t, 0.374  ],\n    [28.00\t, 0.0152\t, 0.3130\t, 0.313\t, 0.392  ],\n    [28.33\t, 0.0133\t, 0.3355\t, 0.336\t, 0.407  ],\n    [28.66\t, 0.0122\t, 0.3581\t, 0.358\t, 0.422  ],\n    [29.00\t, 0.0117\t, 0.3815\t, 0.382\t, 0.437  ],\n    [29.33\t, 0.0118\t, 0.4067\t, 0.407\t, 0.451  ],\n    [29.66\t, 0.0123\t, 0.4343\t, 0.434\t, 0.466  ],\n    [30.00\t"
  },
  {
    "id": "chunk_1101",
    "text": "\t, 0.0123\t, 0.4343\t, 0.434\t, 0.466  ],\n    [30.00\t, 0.0133\t, 0.4655\t, 0.466\t, 0.481  ],\n    [30.33\t, 0.0151\t, 0.5019\t, 0.502\t, 0.497  ],\n    [30.66\t, 0.0179\t, 0.5456\t, 0.546\t, 0.513  ],\n    [31.00\t, 0.0225\t, 0.6004\t, 0.601\t, 0.530  ],\n    [31.33\t, 0.0301\t, 0.6723\t, 0.673\t, 0.547  ],\n    [31.66\t, 0.0439\t, 0.7735\t, 0.775\t, 0.565  ],\n    [32.00\t, 0.0731\t, 0.9304\t, 0.933\t, 0.583  ],\n    [32.33\t, 0.1517\t, 1.2148\t, 1.224\t, 0.603  ],\n    [32.66\t, 0.5070\t, 1.8932\t, 1.960\t, 0.623  ],\n    [33.00\t, 4.5494\t"
  },
  {
    "id": "chunk_1102",
    "text": "\t, 1.8932\t, 1.960\t, 0.623  ],\n    [33.00\t, 4.5494\t, 1.5400\t, 4.803\t, 0.645  ],\n    [33.33\t, 0.7725\t, -1.1678\t, 1.400\t, 0.667  ],\n    [33.66\t, 0.2861\t, -0.3206\t, 0.430\t, 0.691  ],\n    [34.00\t, 0.3196\t, 0.1241\t, 0.343\t, 0.716  ],\n    [34.33\t, 0.9273\t, 0.2502\t, 0.960\t, 0.743  ],\n    [34.66\t, 0.5444\t, -0.5749\t, 0.792\t, 0.771  ],\n    [35.00\t, 0.1669\t, -0.3331\t, 0.373\t, 0.801  ],\n    [35.33\t, 0.0812\t, -0.1640\t, 0.183\t, 0.834  ],\n    [35.66\t, 0.0508\t, -0.0578\t, 0.077\t, 0.870  ],\n    [36.00\t, 0.0367\t, 0"
  },
  {
    "id": "chunk_1103",
    "text": "0.0578\t, 0.077\t, 0.870  ],\n    [36.00\t, 0.0367\t, 0.0179\t, 0.041\t, 0.909  ],\n    [36.33\t, 0.0293\t, 0.0777\t, 0.083\t, 0.952  ],\n    [36.66\t, 0.0255\t, 0.1291\t, 0.132\t, 1.001  ],\n    [37.00\t, 0.0242\t, 0.1773\t, 0.179\t, 1.058  ],\n    [37.33\t, 0.0257\t, 0.2270\t, 0.228\t, 1.125  ],\n    [37.66\t, 0.0320\t, 0.2852\t, 0.287\t, 1.201  ],\n    [38.00\t, 0.0506\t, 0.3663\t, 0.370\t, 1.266  ],\n    [38.33\t, 0.1213\t, 0.5124\t, 0.527\t, 1.224  ],\n    [38.66\t, 0.6464\t, 0.7361\t, 0.980\t, 1.079  ],\n    [39.00\t, 0.4533\t, -0.3164\t, "
  },
  {
    "id": "chunk_1104",
    "text": "0.980\t, 1.079  ],\n    [39.00\t, 0.4533\t, -0.3164\t, 0.553\t, 1.047  ],\n    [39.33\t, 0.1071\t, -0.0794\t, 0.133\t, 1.102  ],\n    [39.66\t, 0.0490\t, 0.0401\t, 0.063\t, 1.178  ],\n    [40.00\t, 0.0302\t, 0.1057\t, 0.110\t, 1.260  ],\n    ]\n\n# Reference:\n# \"Test Systems for Harmonics Modeling and Simulation\",\n# IEEE Transactions on Power Delivery, Vol. 11, No. 1, January 1996, Pages 466-474\n#     Bus, Nominal kV,  LF Volts pu, LF Ang deg,  THD%\n_ieee_tf_dstn_pf_thd_results = [\n    [   1,      230.0,       1.0600, "
  },
  {
    "id": "chunk_1105",
    "text": "_results = [\n    [   1,      230.0,       1.0600,       0.00,  1.767 ],\n    [   2,      230.0,       1.0450,      -5.68,  2.177 ],\n    [   3,      230.0,       1.0427,     -15.30,  1.516 ],\n    [   4,      230.0,       1.0282,     -11.41,  0.755 ],\n    [   5,      230.0,       1.0337,      -9.82,  1.462 ],\n    [   6,      115.0,       1.0700,     -15.87,  0.468 ],\n    [   7,      230.0,       1.0193,     -14.47,  0.423 ],\n    [   8,       13.8,       1.0209,     -14.49,  0.522 ],\n    [   9,     "
  },
  {
    "id": "chunk_1106",
    "text": "     1.0209,     -14.49,  0.522 ],\n    [   9,      115.0,       1.0147,     -16.09,  0.482 ],\n    [  10,      115.0,       1.0168,     -16.33,  0.421 ],\n    [  11,      115.0,       1.0394,     -16.21,  0.394 ],\n    [  12,      115.0,       1.0528,     -16.72,  0.391 ],\n    [  13,      115.0,       1.0458,     -16.73,  0.376 ],\n    [  14,      115.0,       1.0154,     -17.39,  0.343 ],\n    [ 301,       35.4,       1.0417,     -16.18,  9.169 ],\n    [ 302,       35.4,       1.0417,     -16.18,  9."
  },
  {
    "id": "chunk_1107",
    "text": "  [ 302,       35.4,       1.0417,     -16.18,  9.169 ],\n    ]\n\n#   Hord,   %mag,    deg\n_ieee_tf_dstn_cursrc_hvdc = [\n    [  1, 100.00, -49.56 ],\n    [  5,  19.41, -67.77 ],\n    [  7,  13.09,  11.9  ],\n    [ 11,   7.58,  -7.13 ],\n    [ 13,   5.86,  68.57 ],\n    [ 17,   3.79,  46.53 ],\n    [ 19,   3.29, 116.46 ],\n    [ 23,   2.26,  87.47 ],\n    [ 25,   2.41, 159.32 ],\n    [ 29,   1.93, 126.79 ],\n    ]\n\n_ieee_tf_dstn_cursrc_tcr = [\n    [  1, 100.00,   46.92 ],\n    [  5,   7.02, -124.40 ],\n    [  "
  },
  {
    "id": "chunk_1108",
    "text": "0,   46.92 ],\n    [  5,   7.02, -124.40 ],\n    [  7,   2.50,  -29.87 ],\n    [ 11,   1.36,  -23.75 ],\n    [ 13,   0.75,   71.50 ],\n    [ 17,   0.62,   77.12 ],\n    [ 19,   0.32,  173.43 ],\n    [ 23,   0.43,  178.02 ],\n    [ 25,   0.13,  -83.45 ],\n    [ 29,   0.40,  -80.45 ],\n    ]\n\n# ===========================================================================================\n# IEEE 519-2022 and IEEE 519-2014\n#\n# Table 1 - Voltage Distortion Limits\n# All values should be in percent of the rated pow"
  },
  {
    "id": "chunk_1109",
    "text": "# All values should be in percent of the rated power frequency voltage at the PCC.\n# Applies to voltage harmonics whose frequencies are integer multiples of the power frequency.\n_ieee519_table1_thd_limits = {\n    1.0  : {'indv': 5.0, 'thd': 8.0},                   # V <= 1.0 kV\n    69.0 : {'indv': 3.0, 'thd': 5.0},                   # 1 kV < V <= 69.0 kV\n    161.0: {'indv': 1.5, 'thd': 2.5},                   # 69.0 kV < V <= 161.0 kV\n    999.0: {'indv': 1.0, 'thd': 1.5, 'thd_hvdc': 2.0},  # 161"
  },
  {
    "id": "chunk_1110",
    "text": "{'indv': 1.0, 'thd': 1.5, 'thd_hvdc': 2.0},  # 161.0 kV < V\n    }\n\n_ieee519_vlimits = list(_ieee519_table1_thd_limits.keys())\n_ieee519_vlimits.sort()\n\n# ==============================================================================\n\ndef get_ieee_tf_scan_results():\n    \"\"\"Get IEEE Harmonics Task Force Test Case Frequency Scan Results.\n    \"\"\"\n    hord_lst, zcal_lst, zdst_lst, zpi_lst = [], [], [], []\n    for eachlist in _ieee_tf_scan_results:\n        h, zr, zx, z1d, z1pi = eachlist\n        zrx = "
  },
  {
    "id": "chunk_1111",
    "text": "    h, zr, zx, z1d, z1pi = eachlist\n        zrx = complex(zr, zx)\n        z = abs(zrx)\n        hord_lst.append(h)\n        zcal_lst.append(z)\n        zdst_lst.append(z1d)\n        zpi_lst.append(z1pi)\n\n    return hord_lst, zcal_lst, zdst_lst, zpi_lst\n\n# ==============================================================================\n\ndef get_ieee_tf_dstn_pf_thd_results():\n    \"\"\"Get IEEE Harmonics Task Force Test Case Distortion Calculation Results.\n    \"\"\"\n    tf_keytup = ('bus', 'basekv', 'vmag', "
  },
  {
    "id": "chunk_1112",
    "text": "    \"\"\"\n    tf_keytup = ('bus', 'basekv', 'vmag', 'vang', 'thd')\n\n    tfresults_pf_thd_dict = {}\n    for row in _ieee_tf_dstn_pf_thd_results:\n        for dk, val in zip(tf_keytup, row):\n            if dk=='bus':\n                bus = val\n                tfresults_pf_thd_dict[bus] = {}\n            else:\n                tfresults_pf_thd_dict[bus][dk] = val\n\n    return tfresults_pf_thd_dict\n\n# ==============================================================================\n\ndef get_ieee_tf_dstn_cursr"
  },
  {
    "id": "chunk_1113",
    "text": "======================\n\ndef get_ieee_tf_dstn_cursrc():\n    \"\"\"Get IEEE Harmonics Task Force Test Case Harmonic Current Source Spectrum.\n    \"\"\"\n\n    tfresults_cursrc_dict = {'hvdc':{}, 'tcr':{}}\n\n    for eachrow in _ieee_tf_dstn_cursrc_hvdc:\n        hord, imag, iang = eachrow\n        tfresults_cursrc_dict['hvdc'][hord] = {'imag':imag, 'iang':iang}\n\n    tfresults_cursrc_tcr_dict = {}\n    for eachrow in _ieee_tf_dstn_cursrc_tcr:\n        hord, imag, iang = eachrow\n        tfresults_cursrc_dict['tcr"
  },
  {
    "id": "chunk_1114",
    "text": " iang = eachrow\n        tfresults_cursrc_dict['tcr'][hord] = {'imag':imag, 'iang':iang}\n\n    return tfresults_cursrc_dict\n\n# ==============================================================================\n\ndef get_resn_legends(peak_lst_h, peak_lst_rx, valley_lst_h=None, valley_lst_rx=None):\n    \"\"\"Get Frequency Scan Resonance legends.\n    \"\"\"\n    txtlst = []\n    txtlst.append(\"\")\n    txtlst.append(\"Parallel (peaks)\")\n    if peak_lst_rx:\n        txtlst.append(\"Hord, Z\")\n        for h, pu in zip(pe"
  },
  {
    "id": "chunk_1115",
    "text": "tlst.append(\"Hord, Z\")\n        for h, pu in zip(peak_lst_h, peak_lst_rx):\n            txt = \"{:g}, {:g}\".format(h, pu)\n            txtlst.append(txt)\n    else:\n        txt = \" None\"\n        txtlst.append(txt)\n\n    if valley_lst_h:\n        txtlst.append(\"\")\n        txtlst.append(\"Series (valleys)\")\n        if valley_lst_rx:\n            txtlst.append(\"H,  Z\")\n            for h, pu in zip(valley_lst_h, valley_lst_rx):\n                txt = \"{:4.2f}, {:5.3f}\".format(h, pu)\n                txtlst.app"
  },
  {
    "id": "chunk_1116",
    "text": " {:5.3f}\".format(h, pu)\n                txtlst.append(txt)\n        else:\n            txt = \" None\"\n            txtlst.append(txt)\n\n    return txtlst\n\n# ==============================================================================\ndef _write_verbose_report(txt, report):\n    if report is not None:\n        report(txt)\n\nclass _SimpleObject(object):\n    \"\"\"Used for creating dummy object and set attributes as needed.\n    \"\"\"\n    pass\n\ndef _set_rsn_object(**kwds):\n    rsnobj = _SimpleObject()\n    for "
  },
  {
    "id": "chunk_1117",
    "text": "ect(**kwds):\n    rsnobj = _SimpleObject()\n    for k in ['x1', 'y1', 'x2', 'y2', 'inam', 'hidx', 'rflg']:\n        setattr(rsnobj, k, kwds[k])\n    return rsnobj\n\ndef _set_resn_pt_state(pctc, pctmx1, dpctpn1, pctmx2, dpctpn2, dltp=None, dltn=None):\n    ok1, ok2 = False, False\n\n    ok_pctc1 = pctc>=pctmx1\n    ok_pctc2 = pctc>=pctmx2\n\n    if dltp is not None:\n        ok_dltp1 = dltp>=dpctpn1\n        ok_dltp2 = dltp>=dpctpn2\n\n    if dltn is not None:\n        ok_dltn1 = dltn>=dpctpn1\n        ok_dltn2 ="
  },
  {
    "id": "chunk_1118",
    "text": "       ok_dltn1 = dltn>=dpctpn1\n        ok_dltn2 = dltn>=dpctpn2\n\n    if dltp is None:\n        ok1 = ok_pctc1 and ok_dltn1\n        ok2 = ok_pctc2 and ok_dltn2\n    elif dltn is None:\n        ok1 = ok_pctc1 and ok_dltp1\n        ok2 = ok_pctc2 and ok_dltp2\n    else:\n        ok1 = ok_pctc1 and (ok_dltp1 or ok_dltn1)\n        ok2 = ok_pctc2 and (ok_dltp2 or ok_dltn2)\n\n    found = ok1 or ok2\n\n    return found\n\ndef _filter_rsn_pkvls(resn_pkvls, ymxpk, pctmx1, dpctpn1, pctmx2, dpctpn2, report):\n\n    resn"
  },
  {
    "id": "chunk_1119",
    "text": "tmx1, dpctpn1, pctmx2, dpctpn2, report):\n\n    resn_pks_hord, resn_pks_zmag = [], []\n\n    txtlst = []\n    txtlst.append(\"\")\n    txtlst.append(\"Parallel (peaks)\")\n\n    if not resn_pkvls:\n        txt = \" None\"\n        txtlst.append(txt)\n\n        txt = \"\\n\".join(txtlst)\n        _write_verbose_report(txt, report)\n\n        return resn_pks_hord, resn_pks_zmag\n\n    # ------------\n\n    nnlst = len(resn_pkvls)\n\n    txtlst.append(\"   X1,     Y1,     X2,     Y2,  %Ymax,  %dltY,  Found\")\n\n    for ii in range"
  },
  {
    "id": "chunk_1120",
    "text": " Y2,  %Ymax,  %dltY,  Found\")\n\n    for ii in range(nnlst):\n\n        pt_crnt = resn_pkvls[ii]\n        inam = pt_crnt.inam\n        if inam!='peak': continue\n\n        ipt_p = False\n        ipt_n = False\n\n        if ii==0:\n            if nnlst>1:\n                ipt_n = True\n                pt_next = resn_pkvls[ii+1]\n        elif ii==nnlst-1:\n            ipt_p = True\n            pt_prev = resn_pkvls[ii-1]\n        else:\n            ipt_p = True\n            ipt_n = True\n            pt_prev = resn_pkvl"
  },
  {
    "id": "chunk_1121",
    "text": "      ipt_n = True\n            pt_prev = resn_pkvls[ii-1]\n            pt_next = resn_pkvls[ii+1]\n\n        pctc = pt_crnt.y2*100/ymxpk                 # current value in percent of max\n\n        found = False\n        if ii==0:\n            if ipt_n:\n                dltn = abs(pt_crnt.y2 - pt_next.y2)*100/pt_crnt.y2\n                found = _set_resn_pt_state(pctc, pctmx1, dpctpn1, pctmx2, dpctpn2, dltn=dltn)\n        elif ii==nnlst-1:\n            dltp = abs(pt_crnt.y2 - pt_prev.y2)*100/pt_crnt.y2\n   "
  },
  {
    "id": "chunk_1122",
    "text": " = abs(pt_crnt.y2 - pt_prev.y2)*100/pt_crnt.y2\n            found = _set_resn_pt_state(pctc, pctmx1, dpctpn1, pctmx2, dpctpn2, dltp=dltp)\n        else:\n            dltp = abs(pt_crnt.y2 - pt_prev.y2)*100/pt_crnt.y2\n            dltn = abs(pt_crnt.y2 - pt_next.y2)*100/pt_crnt.y2\n            found = _set_resn_pt_state(pctc, pctmx1, dpctpn1, pctmx2, dpctpn2, dltp=dltp, dltn=dltn)\n\n        if found:\n            resn_pkvls[ii].rflg = 1\n\n        if ipt_p:\n            txt = \" {:4.1f}, {:6.3f}, {:6.3f}, {"
  },
  {
    "id": "chunk_1123",
    "text": ":\n            txt = \" {:4.1f}, {:6.3f}, {:6.3f}, {:6.3f}, {:6s}, {:6.2f}\".format(pt_prev.x1, pt_prev.y1, pt_prev.x2, pt_prev.y2, '', dltp)\n            txtlst.append(txt)\n\n        txt = \" {:4.1f}, {:6.3f}, {:6.3f}, {:6.3f}, {:6.2f}, {:6s},  {}\".format(pt_crnt.x1, pt_crnt.y1, pt_crnt.x2, pt_crnt.y2, pctc, '', found)\n        txtlst.append(txt)\n\n        if ipt_n:\n            txt = \" {:4.1f}, {:6.3f}, {:6.3f}, {:6.3f}, {:6s}, {:6.2f}\".format(pt_next.x1, pt_next.y1, pt_next.x2, pt_next.y2, '', dltn)\n "
  },
  {
    "id": "chunk_1124",
    "text": "1, pt_next.y1, pt_next.x2, pt_next.y2, '', dltn)\n            txtlst.append(txt)\n\n        txtlst.append(\"\")\n\n    txt = \"\\n\".join(txtlst)\n    _write_verbose_report(txt, report)\n\n    # done filtering\n    for rsnobj in resn_pkvls:\n        inam = rsnobj.inam\n        rflg = rsnobj.rflg\n        if inam=='peak' and rflg==1:\n            resn_pks_hord.append(rsnobj.x2)\n            resn_pks_zmag.append(rsnobj.y2)\n\n    return resn_pks_hord, resn_pks_zmag\n\ndef check_resonance(hlst, zlst, pctmx1, dpctpn1, pct"
  },
  {
    "id": "chunk_1125",
    "text": "f check_resonance(hlst, zlst, pctmx1, dpctpn1, pctmx2, dpctpn2, report=None):\n    \"\"\"Check and find Frequency Scan Resonances.\n    \"\"\"\n\n    resn_pkvls = []\n    nhord = len(hlst)\n    for hh in range(nhord):\n        hord = hlst[hh]\n        zmag = zlst[hh]\n        if hh==0:\n            x1, y1 = hord, zmag\n            xb, yb = hord, zmag    # beginning point\n            ymxpk  = zmag\n        else:\n            x2, y2 = hord, zmag\n            m2 = (y1-y2)/(x1-x2)\n            if hh>1:\n                i"
  },
  {
    "id": "chunk_1126",
    "text": "y2)/(x1-x2)\n            if hh>1:\n                if m1>0 and m2<0:           # found peak\n                    inam = 'peak'\n                    if y1>y2:\n                        pt = 0\n                    else:\n                        pt = 1\n                elif m1<0 and m2>0:         # found valley\n                    inam = 'valy'\n                    if y1<y2:\n                        pt = 0\n                    else:\n                        pt = 1\n                else:\n                    inam "
  },
  {
    "id": "chunk_1127",
    "text": " 1\n                else:\n                    inam = 'none'\n\n                if inam!='none':\n                    if pt==0:\n                        xn = x1\n                        yn = y1\n                        hidx = hh-1\n                    else:\n                        xn = x2\n                        yn = y2\n                        hidx = hh\n\n                    if inam=='peak' and yn>ymxpk:\n                        ymxpk = yn\n\n                    rsnobj = _set_rsn_object(x1=xb, y1=yb, x2=xn, "
  },
  {
    "id": "chunk_1128",
    "text": "    rsnobj = _set_rsn_object(x1=xb, y1=yb, x2=xn, y2=yn, inam=inam, hidx=hidx, rflg=0)\n                    resn_pkvls.append(rsnobj)\n\n                    # next segment begin point\n                    xb, yb = xn, yn\n\n            # update and go to next point\n            m1, x1, y1 = m2, x2, y2\n\n    # Filter Peak Resonance Points\n    resn_pks_hord, resn_pks_zmag = _filter_rsn_pkvls(resn_pkvls, ymxpk, pctmx1, dpctpn1, pctmx2, dpctpn2, report)\n    _write_verbose_report('\\n', report)\n\n    return re"
  },
  {
    "id": "chunk_1129",
    "text": "_write_verbose_report('\\n', report)\n\n    return resn_pks_hord, resn_pks_zmag\n\n# ==============================================================================\n\ndef get_fscan_csvdata(csvfile):\n    \"\"\"Get frequency scan Thevenin Impedance data from PSSE results file.\n    \"\"\"\n    import csv\n\n    thevz_dict = {}\n    with open(csvfile, newline='') as fobj:\n        reader = csv.reader(fobj)\n        for row in reader:\n            bus   = row[0]\n            sec   = row[1]\n            nam   = row[2]\n    "
  },
  {
    "id": "chunk_1130",
    "text": "    sec   = row[1]\n            nam   = row[2]\n            basekv= row[3]\n            desc  = row[4].strip()\n            if desc=='HORD':\n                thevz_dict['hord'] = [float(v) for v in row[5:]]\n            else:\n                iext = int(bus)\n                try:\n                    isec = int(sec)\n                except:\n                    isec = 0\n                if isec>0:\n                    dkey = (iext, isec)\n                else:\n                    dkey = iext\n                i"
  },
  {
    "id": "chunk_1131",
    "text": "\n                    dkey = iext\n                if desc=='pu abs(thevz)':\n                    bnam = nam.strip()\n                    bkv  = float(basekv)\n                    thevz_dict[dkey] = {'basekv': bkv, 'name': bnam}\n                    thevz_dict[dkey]['mag'] = [float(v) for v in row[5:]]\n                elif desc=='deg phase(thevz)':\n                    thevz_dict[dkey]['phase'] = [float(v) for v in row[5:]]\n                else:\n                    txt = \"Reading Harmonics FSCAN CSVFIL"
  },
  {
    "id": "chunk_1132",
    "text": "             txt = \"Reading Harmonics FSCAN CSVFILE error, should not come here.\"\n                    raise Exception(txt)\n\n    return thevz_dict\n\n# ==============================================================================\n\ndef get_hord_thevz_list(thevz_dict, busnum=None):\n    \"\"\"Get frequency scan Thevenin impedance harmonic orders.\n    \"\"\"\n    found = False\n    klst = list(thevz_dict.keys())\n    for k in klst:\n        if k=='hord': continue\n        if busnum is None:\n            busnum = "
  },
  {
    "id": "chunk_1133",
    "text": "e\n        if busnum is None:\n            busnum = k\n            found = True\n            break\n        else:\n            if k==busnum:\n                found = True\n                break\n\n    if found:\n        hord_lst = thevz_dict['hord'][:]\n        thevz_mag_lst = thevz_dict[busnum]['mag'][:]\n        thevz_phs_lst = thevz_dict[busnum]['phase'][:]\n        ierr = False\n    else:\n        ierr = True\n        hord_lst, thevz_mag_lst, thevz_phs_lst = [], [], []\n\n    return ierr, hord_lst, thevz_mag_l"
  },
  {
    "id": "chunk_1134",
    "text": "[], [], []\n\n    return ierr, hord_lst, thevz_mag_lst, thevz_phs_lst\n\n# ==============================================================================\n\ndef get_dstn_csvdata_volt(csvfile):\n    \"\"\"Get Distortion Calculations Bus Voltage THD data from PSSE results file.\n    \"\"\"\n    import csv\n\n    dkeytup = ('hord', 'bus', 'sec', 'basekv', 'vrpu', 'vxpu', 'vmagpu', 'vangdeg', 'thd_indv')\n    dtyptup = ('r'   , 'i'  , 'i'  , 'r'     , 'r'   , 'r'   , 'r'     , 'r'      , 'r'       )\n\n    errmsg0 = \" "
  },
  {
    "id": "chunk_1135",
    "text": "'r'     , 'r'      , 'r'       )\n\n    errmsg0 = \" Error: Reading Harmonics Distortion Calculations Bus Voltage CSV file:\\n    {}\\n\".format(csvfile)\n\n    _NCLNS = len(dkeytup)\n\n    volt_dict = {}\n    with open(csvfile, newline='') as fobj:\n        reader = csv.reader(fobj)\n        nrow = 0\n        for row in reader:\n            nrow += 1\n            if nrow==1: continue # skip column header line\n            nclns = len(row)\n            if nclns!=_NCLNS:\n                txt = \"    ROW {} has {} da"
  },
  {
    "id": "chunk_1136",
    "text": "NCLNS:\n                txt = \"    ROW {} has {} data items. It should have {} data items.\".format(nrow, nclns, _NCLNS)\n                errmsg = \"{}{}\".format(errmsg0, txt)\n                raise Exception(errmsg)\n            tempdct = {}\n            for dk, dt, v0 in zip(dkeytup, dtyptup, row):\n                if dt=='s':\n                    val = v0\n                elif dt=='i':\n                    if dk=='sec':\n                        try:\n                            val = int(v0)\n             "
  },
  {
    "id": "chunk_1137",
    "text": "                       val = int(v0)\n                        except:\n                            val = 0\n                    else:\n                        val = int(v0)\n                else:\n                    val = float(v0)\n                tempdct[dk] = val\n\n            hord = tempdct['hord']\n            ibus = tempdct['bus']\n            isec = tempdct['sec']\n            bus_sec = (ibus, isec)\n\n            if bus_sec not in volt_dict:\n                volt_dict[bus_sec] = {}\n\n            if ho"
  },
  {
    "id": "chunk_1138",
    "text": "        volt_dict[bus_sec] = {}\n\n            if hord not in volt_dict[bus_sec]:\n                volt_dict[bus_sec][hord] = {}\n            else:\n                txt = \"    Duplicate harmonic order={} data found for '{}', at {}\".format(hord, desc, srcktup)\n                errmsg = \"{}{}\".format(errmsg0, txt)\n                raise Exception(errmsg)\n\n            if hord==1.0:\n                kk = 'thd'\n            else:\n                kk = 'indv'\n            volt_dict[bus_sec][hord]['basekv'] = tem"
  },
  {
    "id": "chunk_1139",
    "text": "          volt_dict[bus_sec][hord]['basekv'] = tempdct['basekv']\n            volt_dict[bus_sec][hord]['vmag']   = tempdct['vmagpu']\n            volt_dict[bus_sec][hord]['vang']   = tempdct['vangdeg']\n            # When hord=1.0, pct is THD, else pct is indv\n            volt_dict[bus_sec][hord]['pct']    = tempdct['thd_indv']\n\n    # add this test here\n##    txt = \"    Fundamental harmonic order data not found for bus={}, section={}\".format(ibus, isec)\n##    errmsg = \"{}{}\".format(errmsg0, txt)\n##"
  },
  {
    "id": "chunk_1140",
    "text": "sec)\n##    errmsg = \"{}{}\".format(errmsg0, txt)\n##    raise Exception(errmsg)\n\n    return volt_dict\n\n# ==================================================================================================\n\ndef get_dstn_csvdata_cursrc(csvfile):\n    \"\"\"Get Distortion Calculations Harmonic Current Source Spectrum data from PSSE results file.\n    \"\"\"\n    import csv\n\n    dkeytup = ('hord', 'ibus', 'isec', 'jbus', 'jsec', 'kbus', 'ksec', 'ckt', 'irpu', 'ixpu', 'imagpu', 'iangdeg', 'thd_indv', 'desc')\n   "
  },
  {
    "id": "chunk_1141",
    "text": "xpu', 'imagpu', 'iangdeg', 'thd_indv', 'desc')\n    dtyptup = ('r'   , 'i'   , 'i'   , 'i'   , 'i'   , 'i'   , 'i'   , 's'  , 'r'   , 'r'   , 'r'     , 'r'      , 'r'       , 's'   )\n\n    errmsg0 = \" Error: Reading Harmonics Distortion Calculations Bus Voltage CSV file:\\n    {}\\n\".format(csvfile)\n\n    _NCLNS = len(dkeytup)\n\n    cursrc_dict = {}\n    with open(csvfile, newline='') as fobj:\n        reader = csv.reader(fobj)\n        nrow = 0\n        for row in reader:\n            nrow += 1\n          "
  },
  {
    "id": "chunk_1142",
    "text": "or row in reader:\n            nrow += 1\n            if nrow==1: continue # skip column header line\n            nclns = len(row)\n            if nclns!=_NCLNS:\n                txt = \"    ROW {} has {} data items. It should have {} data items.\".format(nrow, nclns, _NCLNS)\n                errmsg = \"{}{}\".format(errmsg0, txt)\n                raise Exception(errmsg)\n            tempdct = {}\n            srcklst = []\n            for dk, dt, v0 in zip(dkeytup, dtyptup, row):\n                if dt=='s':\n "
  },
  {
    "id": "chunk_1143",
    "text": "ytup, dtyptup, row):\n                if dt=='s':\n                    val = v0.strip().lower()\n                elif dt=='i':\n                    if dk in ['isec', 'jbus', 'jsec', 'kbus', 'ksec']:\n                        try:\n                            val = int(v0)\n                        except:\n                            val = 0\n                    else:\n                        val = int(v0)\n                else:\n                    val = float(v0)\n\n                if dk in ['ibus', 'isec', '"
  },
  {
    "id": "chunk_1144",
    "text": "t(v0)\n\n                if dk in ['ibus', 'isec', 'jbus', 'jsec', 'kbus', 'ksec']:\n                    if val>0:\n                        srcklst.append(val)\n                elif dk in ['ckt']:\n                    if val:\n                        srcklst.append(val)\n                else:\n                    tempdct[dk] = val\n\n            srcktup = tuple(srcklst)\n            hord = tempdct['hord']\n            desc = tempdct['desc']\n\n            if desc not in cursrc_dict:\n                cursrc_dict"
  },
  {
    "id": "chunk_1145",
    "text": "sc not in cursrc_dict:\n                cursrc_dict[desc] = {}\n\n            if srcktup not in cursrc_dict[desc]:\n                cursrc_dict[desc][srcktup] = {}\n\n            if hord not in cursrc_dict[desc][srcktup]:\n                cursrc_dict[desc][srcktup][hord] = {}\n            else:\n                txt = \"    Duplicate harmonic order={} data found for '{}', at {}\".format(hord, desc, srcktup)\n                errmsg = \"{}{}\".format(errmsg0, txt)\n                raise Exception(errmsg)\n\n       "
  },
  {
    "id": "chunk_1146",
    "text": ")\n                raise Exception(errmsg)\n\n            if hord==1.0:\n                kk = 'thd'\n            else:\n                kk = 'indv'\n            cursrc_dict[desc][srcktup][hord]['imag'] = tempdct['imagpu']\n            cursrc_dict[desc][srcktup][hord]['iang'] = tempdct['iangdeg']\n            cursrc_dict[desc][srcktup][hord][kk]     = tempdct['thd_indv']\n\n    # add this test here\n##    txt = \"    Fundamental harmonic order data not found for '{}', at {}\".format(desc, srcktup)\n##    errmsg"
  },
  {
    "id": "chunk_1147",
    "text": "or '{}', at {}\".format(desc, srcktup)\n##    errmsg = \"{}{}\".format(errmsg0, txt)\n##    raise Exception(errmsg)\n\n    return cursrc_dict\n\n# ==================================================================================================\n\ndef _get_dstn_volt_ieee519_busgrps(volt_dict):\n\n    hord = 1.0  # just consider HORD=1.0 to get bus information\n\n    ierr = 0\n    ieee519_vlmt_dict  = {}\n    case_bus_vlmt_dict = {}\n    for ii, lmtkv in enumerate(_ieee519_vlimits):\n        if ii==0:\n            "
  },
  {
    "id": "chunk_1148",
    "text": "(_ieee519_vlimits):\n        if ii==0:\n            vmn, vmx = 0, lmtkv\n        else:\n            vmn, vmx = _ieee519_vlimits[ii-1], lmtkv\n\n        if vmn<=0.0:\n            s_lmt = \"kV <= {}\".format(vmx)\n        elif vmx>=999.0:\n            s_lmt = \"{} < kV\".format(vmn)\n        else:\n            s_lmt = \"{} < kV <= {}\".format(vmn, vmx)\n\n        ieee519_vlmt_dict[ii] = {'lmtkv':lmtkv, 'vmin':vmn, 'vmax':vmx, 'lmt_lgd':s_lmt}\n\n    buses_not_added_to_grps = []\n    for bus_sec, vdict in volt_dict.item"
  },
  {
    "id": "chunk_1149",
    "text": "grps = []\n    for bus_sec, vdict in volt_dict.items():\n        buskv = vdict[hord]['basekv']\n        found = False\n        for ii, lmtkv in enumerate(_ieee519_vlimits):\n            if ii==0:\n                vmn, vmx = 0, lmtkv\n            else:\n                vmn, vmx = _ieee519_vlimits[ii-1], lmtkv\n\n            if buskv>vmn and buskv<=vmx:\n                case_bus_vlmt_dict[bus_sec] = ii\n                found = True\n                break\n\n        if not found:\n            buses_not_added_to_gr"
  },
  {
    "id": "chunk_1150",
    "text": "   if not found:\n            buses_not_added_to_grps.append(bus_sec) # should never happen\n\n    if buses_not_added_to_grps:\n        txtlst = []\n        for each in buses_not_added_to_grps:\n            txt = \"{}\".format(each)\n            txtlst.append(txt)\n        txt = \" Error - These (bus, sec) are not added to IEEE 519 Voltage THD Bus Groups:\"\n        print(txt)\n        alltxt = \", \".join(txtlst)\n        tlnlst = textwrap.wrap(alltxt, width=90, initial_indent=\"    \", subsequent_indent=\"    \")\n"
  },
  {
    "id": "chunk_1151",
    "text": " initial_indent=\"    \", subsequent_indent=\"    \")\n        tlntxt = \"\\n\".join(tlnlst)\n        print(tlntxt)\n\n    if not case_bus_vlmt_dict:\n        ierr = 1\n\n    return ierr, ieee519_vlmt_dict, case_bus_vlmt_dict\n\n# =========================================================================\n\ndef get_dstn_volt_study_bus_results(volt_dict, *buses):\n    \"\"\"Return distortion results assembled in arrays for XY plots for specified study buses.\n    ierr, ieee519_vlmt_dict, each_bus_xy, all_bus_xy = get_ds"
  },
  {
    "id": "chunk_1152",
    "text": "eee519_vlmt_dict, each_bus_xy, all_bus_xy = get_dstn_volt_study_bus_results(volt_dict, *buses)\n    \"\"\"\n\n    ierr = 0\n    each_bus_xy = {}\n    all_bus_xy = {}\n\n    ierr, ieee519_vlmt_dict, case_bus_vlmt_dict = _get_dstn_volt_ieee519_busgrps(volt_dict)\n    if ierr:\n        return ierr, ieee519_vlmt_dict, each_bus_xy, all_bus_xy\n\n    case_bus_exst_dict = {}\n    for bus_sec, lmtidx in case_bus_vlmt_dict.items():\n        bus, sec = bus_sec\n        case_bus_exst_dict[bus] = 1\n\n    if not buses: buses "
  },
  {
    "id": "chunk_1153",
    "text": "e_bus_exst_dict[bus] = 1\n\n    if not buses: buses = [-1]\n\n    stdy_bus_dict = {}\n    if len(buses)==1 and buses[0]==-1:\n        for bus, flag in case_bus_exst_dict.items():\n            stdy_bus_dict[bus] = 1\n    else:\n        for bus in buses:\n            if bus in case_bus_exst_dict:\n                stdy_bus_dict[bus] = 1\n\n    for bus_sec, vdict in volt_dict.items():\n        bus, sec = bus_sec\n        if bus not in stdy_bus_dict: continue\n        if sec:\n            xt = \"{}-{}\".format(bus, sec"
  },
  {
    "id": "chunk_1154",
    "text": "  if sec:\n            xt = \"{}-{}\".format(bus, sec)\n        else:\n            xt = \"{}\".format(bus)\n\n        idx = case_bus_vlmt_dict[bus_sec]\n\n        # Each bus THD and INDV for all HORD\n        # 'pct' key contains both THD and INDV\n        each_bus_xy[bus_sec] = {'xnam':xt, 'hord':[], 'pct':[], 'lmtidx':idx}\n        for hord, vdct2 in vdict.items():\n            each_bus_xy[bus_sec]['hord'].append(hord)\n            each_bus_xy[bus_sec]['pct'].append(vdct2['pct'])\n\n    # THD and max INDV for a"
  },
  {
    "id": "chunk_1155",
    "text": "append(vdct2['pct'])\n\n    # THD and max INDV for all buses\n\n    for kk in ['bus_sec', 'xnam', 'thd', 'indv', 'indv_hord', 'lmtidx']:\n        all_bus_xy[kk] = []\n\n    for bus_sec, vdict in each_bus_xy.items():\n        all_bus_xy['bus_sec'].append(bus_sec)\n        all_bus_xy['xnam'].append(vdict['xnam'])\n        all_bus_xy['lmtidx'].append(vdict['lmtidx'])\n\n        mx_indv = 0.0\n        mx_indv_hord = 0.0\n        for hord, pct in zip(vdict['hord'], vdict['pct']):\n            if hord==1.0:\n        "
  },
  {
    "id": "chunk_1156",
    "text": " vdict['pct']):\n            if hord==1.0:\n                thd = pct\n            else:\n                if pct>mx_indv:\n                    mx_indv = pct\n                    mx_indv_hord = hord\n\n        all_bus_xy['thd'].append(thd)\n        all_bus_xy['indv'].append(mx_indv)\n        all_bus_xy['indv_hord'].append(mx_indv_hord)\n\n##    print(\"\\n each_bus_xy\\n\", each_bus_xy)\n##    print(\"\\n all_bus_xy\\n\",  all_bus_xy)\n\n    return ierr, ieee519_vlmt_dict, each_bus_xy, all_bus_xy\n\n# ==================="
  },
  {
    "id": "chunk_1157",
    "text": "ct, each_bus_xy, all_bus_xy\n\n# ==================================================================================================\n\ndef compare_dstn_ieee_test_and_tf(outpath, csvfile_volt, csvfile_cursrc):\n    # Compare PSSE Distortion Calculation Results and IEEE Task Force Results\n\n    if not os.path.exists(csvfile_volt):\n        msg0 = \" Distortion Calculation comparison table for IEEE Test case not done.\"\n        msg  = \" File not found.{}\\n    {}\".format(msg0, csvfile_volt)\n        print(msg"
  },
  {
    "id": "chunk_1158",
    "text": "  {}\".format(msg0, csvfile_volt)\n        print(msg)\n        return\n\n    # get task force results table in dictionary\n    tfresults_pf_thd_dict = get_ieee_tf_dstn_pf_thd_results()\n    tfresults_cursrc_dict = get_ieee_tf_dstn_cursrc()\n\n    # get distotion bus volts CSV data in dictionary\n    volt_dict   = get_dstn_csvdata_volt(csvfile_volt)\n    cursrc_dict = get_dstn_csvdata_cursrc(csvfile_cursrc)\n\n    # create comparison table\n    errmsg0 = \" Error: Processing Harmonics Distortion Calculations Bu"
  },
  {
    "id": "chunk_1159",
    "text": "r: Processing Harmonics Distortion Calculations Bus Voltage CSV file:\\n    {}\\n\".format(csvfile_volt)\n\n    hdr1 = \" IEEE Task Force (TF) Harmonics Test Case: TF and PSSE Results Comparison\\n\"\n    hdr2 = \" (1) Power Flow Solution Bus Voltages and Harmonics %THD\\n\"\n    hdr3 = \"    Bus |nominal| IEEE TF| IEEE TF|IEEE TF|  PSSE  |  PSSE  | PSSE  |   DIFF   |   DIFF   |   DIFF   |\"\n    hdr4 = \" Number |  kV   |  V pu  |  V deg | THD % |  V pu  |  V deg | THD % |   V pu   |   V deg  |   THD %  |\\n\"\n\n "
  },
  {
    "id": "chunk_1160",
    "text": "g | THD % |   V pu   |   V deg  |   THD %  |\\n\"\n\n    oubflst = []\n    oubflst.append(hdr1)\n    oubflst.append(hdr2)\n    oubflst.append(hdr3)\n    oubflst.append(hdr4)\n\n    buslist = list(tfresults_pf_thd_dict.keys())\n    buslist.sort()\n    for bus in buslist:\n        tfdct = tfresults_pf_thd_dict[bus]\n        tf_basekv = tfdct['basekv']\n        tf_mag    = tfdct['vmag']\n        tf_ang    = tfdct['vang']\n        tf_thd    = tfdct['thd']\n\n        sec = 0\n        bus_sec = (bus, sec)\n        dstndct"
  },
  {
    "id": "chunk_1161",
    "text": "c = 0\n        bus_sec = (bus, sec)\n        dstndct = volt_dict[bus_sec]\n\n        hord = 1.0\n\n        p_basekv = dstndct[hord]['basekv']\n        p_mag    = dstndct[hord]['vmag']\n        p_ang    = dstndct[hord]['vang']\n        p_thd    = dstndct[hord]['pct']\n\n        if p_basekv!=tf_basekv:\n            txt1 = \"    Nominal bus voltage does not match for bus={}\\n\".format(bus)\n            txt2 = \"    Bus voltage (kV)  TF paper={}, PSSE case={}\\n\".format(tf_basekv, p_basekv)\n            errmsg = \"{}{"
  },
  {
    "id": "chunk_1162",
    "text": "mat(tf_basekv, p_basekv)\n            errmsg = \"{}{}{}\".format(errmsg0, txt1, txt2)\n            raise Exception(errmsg)\n\n        tf_txt = \"{:6d} | {:5.1f} | {:6.4f} | {:6.2f} | {:5.3f} |\".format(bus, tf_basekv, tf_mag, tf_ang, tf_thd)\n        p_txt  = \"{:6.4f} | {:6.2f} | {:5.3f} |\".format(p_mag, p_ang, p_thd)\n\n        df_mag = tf_mag - p_mag\n        df_ang = tf_ang - p_ang\n        df_thd = tf_thd - p_thd\n        df_txt = \"{:8.5f} | {:8.4f} | {:8.5f} |\".format(df_mag, df_ang, df_thd)\n\n        txt"
  },
  {
    "id": "chunk_1163",
    "text": "5f} |\".format(df_mag, df_ang, df_thd)\n\n        txt = \" {} {} {}\".format(tf_txt, p_txt, df_txt)\n        oubflst.append(txt)\n\n    hdr1 = \"\\n (2) Harmonic Current Source Spectrum applied for Distortion Calculations\\n\"\n    hdr2 = \" Hord |    Bus |  IEEE TF |  IEEE TF |   PSSE   |   PSSE   |   DIFF   |\"\n    hdr3 = \"      | Number |   %I     |   I deg  |   %I     |   I deg  |   %I     |\\n\"\n\n    oubflst.append(hdr1)\n    oubflst.append(hdr2)\n    oubflst.append(hdr3)\n\n    p_keylist = list(cursrc_dict['lo"
  },
  {
    "id": "chunk_1164",
    "text": "append(hdr3)\n\n    p_keylist = list(cursrc_dict['load'].keys())\n    buslist.sort()\n\n    tf_hord_list = list(tfresults_cursrc_dict['hvdc'].keys())\n    p_elmt = 'load'\n\n    for hord in tf_hord_list:\n        for srcktup in p_keylist:\n            ibus = srcktup[0]\n            if ibus==8:\n                tfk = 'tcr'\n            else:\n                tfk = 'hvdc'\n\n            p_imag  = cursrc_dict[p_elmt][srcktup][hord]['imag']\n            p1_imag = cursrc_dict[p_elmt][srcktup][1.0]['imag']\n           "
  },
  {
    "id": "chunk_1165",
    "text": "src_dict[p_elmt][srcktup][1.0]['imag']\n            p_pct   = p_imag*100/p1_imag\n\n            p_iang  = cursrc_dict[p_elmt][srcktup][hord]['iang']\n\n            tf_imag = tfresults_cursrc_dict[tfk][hord]['imag']\n            tf_iang = tfresults_cursrc_dict[tfk][hord]['iang']\n\n            df_pct  = tf_imag - p_pct\n\n            txt = \" {:4.1f} | {:6d} | {:8.2f} | {:8.2f} | {:8.2f} | {:8.2f} | {:8.5f} |\".format(hord, ibus, tf_imag, tf_iang, p_pct, p_iang, df_pct)\n            oubflst.append(txt)\n\n    #"
  },
  {
    "id": "chunk_1166",
    "text": "ng, df_pct)\n            oubflst.append(txt)\n\n    #\n    txt1 = \"\\n For multiple harmonic sources, the phase angles of harmonic current injections are\"\n    txt2 = \" re-calculated considering power flow solution phase angle, spectrum phase angles and\"\n    txt3 = \" harmonic order. Hence TF spectrum phase angles and PSSE phase angles are different.\"\n    oubflst.extend([txt1, txt2, txt3])\n\n    # write to output file\n    pth, nx  = os.path.split(csvfile_volt)\n    nam, xtn = os.path.splitext(nx)\n    ouf"
  },
  {
    "id": "chunk_1167",
    "text": "_volt)\n    nam, xtn = os.path.splitext(nx)\n    oufname = \"{}_tf_THD_compare.txt\".format(nam)\n    outfile = os.path.join(outpath, oufname)\n    outfobj = open(outfile, 'w')\n\n    oubflst.append(\"\")\n    alltxt = \"\\n\".join(oubflst)\n    outfobj.write(alltxt)\n    outfobj.close()\n\n    msg = \" IEEE Task Force Harmonics Test Case: TF and PSSE Results Comparison saved to file:\\n    {}\\n\".format(outfile)\n    print(msg)\n\n# ==============================================================================\n\ndef pl"
  },
  {
    "id": "chunk_1168",
    "text": "==========================================\n\ndef plot_main_fscan_ieee_test_and_tf(outpath, **kwds):\n    \"\"\"Plot IEEE Test Case frequency scan impedance.\n    Results from PSSE and IEEE Task Force are plotted.\n    \"\"\"\n\n    import matplotlib.pyplot as plt\n    from matplotlib.backends.backend_pdf import PdfPages\n\n    filetyp = kwds.get('filetyp', 'png')\n    verbose = kwds.get('verbose', False)\n    pctmx1  = kwds.get('pctmx1',  60.0)\n    dpctpn1 = kwds.get('dpctpn1', 75.0)\n    pctmx2  = kwds.get('pctm"
  },
  {
    "id": "chunk_1169",
    "text": ".get('dpctpn1', 75.0)\n    pctmx2  = kwds.get('pctmx2',  20.0)\n    dpctpn2 = kwds.get('dpctpn2', 85.0)\n\n    flag_show = kwds.get('flag_show', True)\n\n    casnam = \"ieee_tf_psse\"\n    busnum = 3\n\n    hmajor = []\n    for ii in range(0, 41, 5):\n        hmajor.append(ii)\n\n    ymajor = [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5]\n\n    csv_dict = {\n        1: {'nam': \"ieee_testcase_linmdl=0_fscan.csv\", 'ttl': \"nominal PI\"},\n        2: {'nam': \"ieee_testcase_linmdl=1_fscan.csv\", 'ttl': \"long line di"
  },
  {
    "id": "chunk_1170",
    "text": "testcase_linmdl=1_fscan.csv\", 'ttl': \"long line distibuted with skin effect\"},\n        3: {'nam': \"ieee_testcase_linmdl=2_fscan.csv\", 'ttl': \"long line distibuted but no skin effect\"},\n        }\n\n    csv_exists_dict = {}\n    for k, vdict in csv_dict.items():\n        nam = vdict['nam']\n        csvfile = os.path.join(outpath, nam)\n        if os.path.exists(csvfile):\n            csv_exists_dict[k] = vdict\n\n    if not csv_exists_dict:\n        msg = \"\\n Error- IEEE Test Harmonics Frequency Scan resul"
  },
  {
    "id": "chunk_1171",
    "text": "\\n Error- IEEE Test Harmonics Frequency Scan result files not found, not ploted, terminated:\\n    {}\".format(outpath)\n        print(msg)\n        return\n\n    # PSSE results\n    ierr_pi, ierr_dst_skin, ierr_dst = True, True, True\n    ii = 0\n    for k, vdict in csv_exists_dict.items():\n        nam = vdict['nam']\n        ttl = vdict['ttl']\n        csvfile = os.path.join(outpath, nam)\n        thevz_dict = get_fscan_csvdata(csvfile)\n        ierr, hlst, zlst, phlst = get_hord_thevz_list(thevz_dict, bus"
  },
  {
    "id": "chunk_1172",
    "text": " zlst, phlst = get_hord_thevz_list(thevz_dict, busnum)\n        if not ierr:\n            if ii==0:\n                hlst_pi = hlst[:]\n                zlst_pi = zlst[:]\n                ttl_pi = ttl\n                ierr_pi = False\n            elif ii==1:\n                hlst_dst_skin = hlst[:]\n                zlst_dst_skin = zlst[:]\n                ttl_dst_skin = ttl\n                ierr_dst_skin = False\n            elif ii==2:\n                hlst_dst = hlst[:]\n                zlst_dst = zlst[:]\n  "
  },
  {
    "id": "chunk_1173",
    "text": "st = hlst[:]\n                zlst_dst = zlst[:]\n                ttl_dst  = ttl\n                ierr_dst = False\n        ii += 1\n\n    if ierr_pi or ierr_dst:\n        print(\" Error -- PSSE getting results data\")\n        return\n\n    tf_hlst, tf_zlst_cal, tf_zlst_dst, tf_zlst_pi = get_ieee_tf_scan_results()\n\n    peak_lst_h, peak_lst_rx = check_resonance(hlst_dst, zlst_dst, pctmx1, dpctpn1, pctmx2, dpctpn2)\n    resn_lgd_lst = get_resn_legends(peak_lst_h, peak_lst_rx)\n    resn_lgd_lst.insert(0, \"Reson"
  },
  {
    "id": "chunk_1174",
    "text": "_h, peak_lst_rx)\n    resn_lgd_lst.insert(0, \"Resonance: distibuted but no skin\")\n    resn_lgd = \"\\n\".join(resn_lgd_lst)\n\n    clr_lst = ['red', 'blue', 'black', 'green', 'magenta']\n    sty_lst = ['-', ':', '--', '-.', '-']\n    wdt_lst = [2, 2, 1, 1, 1]\n\n    fig, ax = plt.subplots(1,1)\n    fig.set_size_inches(8.0, 9.0)\n\n    ii=0\n    ax.plot(hlst_dst, zlst_dst, label=ttl_dst+' - PSSE', color=clr_lst[ii], linestyle=sty_lst[ii], linewidth=wdt_lst[ii])\n\n    ii=1\n    ax.plot(tf_hlst, tf_zlst_dst, label"
  },
  {
    "id": "chunk_1175",
    "text": "\n\n    ii=1\n    ax.plot(tf_hlst, tf_zlst_dst, label=ttl_dst+' - IEEE Task Force', color=clr_lst[ii], linestyle=sty_lst[ii], linewidth=wdt_lst[ii])\n\n    ii=2\n    ax.plot(hlst_pi, zlst_pi, label=ttl_pi+' - PSSE', color=clr_lst[ii], linestyle=sty_lst[ii], linewidth=wdt_lst[ii])\n\n    ii=3\n    ax.plot(tf_hlst, tf_zlst_pi, label=ttl_pi+' - IEEE Task Force', color=clr_lst[ii], linestyle=sty_lst[ii], linewidth=wdt_lst[ii])\n\n    ax.set_xticks(hmajor)\n    ax.set_yticks(ymajor)\n    #ax.set_yscale('log')\n   "
  },
  {
    "id": "chunk_1176",
    "text": "x.set_yticks(ymajor)\n    #ax.set_yscale('log')\n    ax.set_xlabel(\"Harmonic Order\")\n    ax.set_ylabel(\"Harmonic Impedance (pu)\")\n    ax.set_title(\"IEEE 14 Bus Harmonics Test System\")\n    ax.grid(True, which='both')\n    ax.legend()\n    ax.annotate(resn_lgd, (10, 1.75), fontfamily='monospace')\n\n    if filetyp=='pdf':\n        pdffile = os.path.join(outpath, \"{}.pdf\".format(casnam))\n        pdfobj  = PdfPages(pdffile)\n    else:\n        figfile = os.path.join(outpath, \"{}.png\".format(casnam))\n\n    if "
  },
  {
    "id": "chunk_1177",
    "text": "th.join(outpath, \"{}.png\".format(casnam))\n\n    if filetyp=='pdf':\n        pdfobj.savefig(fig, bbox_inches='tight')\n        pdfobj.close()\n        print(\" Plots saved: {}\".format(pdffile))\n    else:\n        fig.savefig(figfile, bbox_inches='tight')\n        print(\" Plots saved: {}\".format(figfile))\n\n    if filetyp!='pdf':\n        if flag_show:\n            plt.show()\n        else:\n            plt.close('all')\n\n# ==============================================================================\n\ndef plo"
  },
  {
    "id": "chunk_1178",
    "text": "=========================================\n\ndef plot_main_fscan_ieee_test(outpath, **kwds):\n    \"\"\"Plot IEEE Test Case frequency scan Thevenin impedance.\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.backends.backend_pdf import PdfPages\n\n    filetyp = kwds.get('filetyp', 'png')\n    verbose = kwds.get('verbose', False)\n    pctmx1  = kwds.get('pctmx1',  60.0)\n    dpctpn1 = kwds.get('dpctpn1', 75.0)\n    pctmx2  = kwds.get('pctmx2',  20.0)\n    dpctpn2 = kwds.get('dpctpn2', 85.0)\n\n  "
  },
  {
    "id": "chunk_1179",
    "text": " 20.0)\n    dpctpn2 = kwds.get('dpctpn2', 85.0)\n\n    flag_show = kwds.get('flag_show', True)\n\n    if verbose:\n        report = sys.stdout.write\n    else:\n        report = None\n\n    csv_dict = {\n        1: {'nam': \"ieee_testcase_linmdl=0_fscan.csv\", 'ttl': \"nominal PI\"},\n        2: {'nam': \"ieee_testcase_linmdl=1_fscan.csv\", 'ttl': \"long line distibuted with skin effect\"},\n        3: {'nam': \"ieee_testcase_linmdl=2_fscan.csv\", 'ttl': \"long line distibuted but no skin effect\"},\n        }\n\n    csv_e"
  },
  {
    "id": "chunk_1180",
    "text": "tibuted but no skin effect\"},\n        }\n\n    csv_exists_dict = {}\n    for k, vdict in csv_dict.items():\n        nam = vdict['nam']\n        csvfile = os.path.join(outpath, nam)\n        if os.path.exists(csvfile):\n            csv_exists_dict[k] = vdict\n\n    if not csv_exists_dict:\n        msg = \"\\n Error- IEEE Test Harmonics Frequency Scan result files not found, not ploted, terminated:\\n    {}\".format(outpath)\n        print(msg)\n        return\n\n    hmajor = []\n    for ii in range(0, 41, 5):\n     "
  },
  {
    "id": "chunk_1181",
    "text": "  hmajor = []\n    for ii in range(0, 41, 5):\n        hmajor.append(ii)\n\n    ymajor = [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5]\n\n    busnum = 3\n\n    clr_lst = ['black', 'green', 'red']\n    sty_lst = ['--', ':', '-']\n    wdt_lst = [2, 3, 1]\n\n    resn_lgd = ''\n    fig, ax = plt.subplots(1,1)\n    fig.set_size_inches(8.0, 9.0)\n    ii = 0\n    for k, vdict in csv_exists_dict.items():\n        nam = vdict['nam']\n        ttl = vdict['ttl']\n        csvfile = os.path.join(outpath, nam)\n        thev"
  },
  {
    "id": "chunk_1182",
    "text": " csvfile = os.path.join(outpath, nam)\n        thevz_dict = get_fscan_csvdata(csvfile)\n        ierr, hlst, zlst, phlst = get_hord_thevz_list(thevz_dict, busnum)\n        if not ierr:\n            ax.plot(hlst, zlst, label=ttl, color=clr_lst[ii], linestyle=sty_lst[ii], linewidth=wdt_lst[ii])\n            if k==3:\n                peak_lst_h, peak_lst_rx = check_resonance(hlst, zlst, pctmx1, dpctpn1, pctmx2, dpctpn2, report=report)\n                resn_lgd_lst = get_resn_legends(peak_lst_h, peak_lst_rx"
  },
  {
    "id": "chunk_1183",
    "text": "lgd_lst = get_resn_legends(peak_lst_h, peak_lst_rx)\n                resn_lgd_lst.insert(0, \"Resonance: linmdl-distibuted but no skin\")\n                resn_lgd = \"\\n\".join(resn_lgd_lst)\n\n        ii += 1\n\n    ax.set_xticks(hmajor)\n    ax.set_yticks(ymajor)\n    #ax.set_yscale('log')\n    ax.set_xlabel(\"Harmonic Order\")\n    ax.set_ylabel(\"Harmonic Impedance (pu)\")\n    ax.set_title(\"IEEE 14 Bus Harmonics Test System\")\n    ax.grid(True, which='both')\n    ax.legend()\n    if resn_lgd: ax.annotate(resn_l"
  },
  {
    "id": "chunk_1184",
    "text": "   ax.legend()\n    if resn_lgd: ax.annotate(resn_lgd, (10, 1.75), fontfamily='monospace')\n\n    casnam = 'ieee_test'\n    if filetyp=='pdf':\n        pdffile = os.path.join(outpath, \"{}_fscan.pdf\".format(casnam))\n        pdfobj  = PdfPages(pdffile)\n    else:\n        figfile = os.path.join(outpath, \"{}_fscan.png\".format(casnam))\n\n    if filetyp=='pdf':\n        pdfobj.savefig(fig, bbox_inches='tight')\n        pdfobj.close()\n        print(\" Plots saved: {}\".format(pdffile))\n    else:\n        fig.savef"
  },
  {
    "id": "chunk_1185",
    "text": ": {}\".format(pdffile))\n    else:\n        fig.savefig(figfile, bbox_inches='tight')\n        print(\" Plots saved: {}\".format(figfile))\n\n    if filetyp!='pdf':\n        if flag_show:\n            plt.show()\n        else:\n            plt.close('all')\n\n# =========================================================================\n\ndef _har_ana_ieee_test(**kwds):\n    \"\"\"Run PSSE Harmonic Analysis using IEEE Test Case.\n    Allowed kwds:\n\n    outpath  = os.getcwd(), Folder name to save outfile files\n    rpt2"
  },
  {
    "id": "chunk_1186",
    "text": "tcwd(), Folder name to save outfile files\n    rpt2file = False, Save Report to file\n\n    Thresholds to filter Thevenin Impedance\n        dft_thresholds = True, Use defualt thresholds\n\n        pctmx1  = kwds.get('pctmx1' , 60.0)\n        dpctpn1 = kwds.get('dpctpn1', 75.0)\n        pctmx2  = kwds.get('pctmx2' , 20.0)\n        dpctpn2 = kwds.get('dpctpn2', 85.0)\n    \"\"\"\n    import psspy\n\n    name,major,minor,modlvl,date,stat = psspy.psseversion()\n\n    kwds_api = {}\n    kwds_api['anaoptn'   ] = 0\n    "
  },
  {
    "id": "chunk_1187",
    "text": " kwds_api = {}\n    kwds_api['anaoptn'   ] = 0\n    kwds_api['dstnbuop'  ] = 0\n    kwds_api['dstnrptop' ] = 1\n    kwds_api['imachimpop'] = 0\n    kwds_api['dcimpop'   ] = 0\n    kwds_api['triplenop' ] = 0\n    kwds_api['genimpop'  ] = 0\n\n    kwds_api['hord_min' ] = 0.0\n    kwds_api['hord_max' ] = 40.0\n    kwds_api['hord_stp' ] = 0.33\n\n    kwds_api['hrsfile'  ] = ''\n\n    fscan_buslist = [3]\n    sid = 3\n    busall = 0\n    psspy.bsys(sid, numbus=len(fscan_buslist), buses=fscan_buslist)\n\n    outpath = kw"
  },
  {
    "id": "chunk_1188",
    "text": "n_buslist), buses=fscan_buslist)\n\n    outpath = kwds.get('outpath', os.getcwd())\n    rpt2file = kwds.get('rpt2file', False)\n    dft_thresholds = kwds.get('dft_thresholds', True)\n\n    inherit = kwds.get('inherit', False)\n    if inherit:\n        kwds_api['load_mdltyp'] = 7\n\n    if not dft_thresholds:\n        pctmx1  = kwds.get('pctmx1' , 60.0)\n        dpctpn1 = kwds.get('dpctpn1', 75.0)\n        pctmx2  = kwds.get('pctmx2' , 20.0)\n        dpctpn2 = kwds.get('dpctpn2', 85.0)\n\n        s_pctmx1  = \"{:"
  },
  {
    "id": "chunk_1189",
    "text": "kwds.get('dpctpn2', 85.0)\n\n        s_pctmx1  = \"{:g}\".format(pctmx1)\n        s_dpctpn1 = \"{:g}\".format(dpctpn1)\n        s_pctmx2  = \"{:g}\".format(pctmx2)\n        s_dpctpn2 = \"{:g}\".format(dpctpn2)\n        usr_thresholds = \"thresholds_usr_{}_{}_{}_{}\".format(s_pctmx1, dpctpn1, s_pctmx2, dpctpn2)\n\n    for linmdl in [0, 1, 2]:\n        outnam = \"ieee_testcase_linmdl={}\".format(linmdl)\n        if dft_thresholds:\n            if not inherit:\n                outpath1 = os.path.join(outpath,\"dft_threshol"
  },
  {
    "id": "chunk_1190",
    "text": "     outpath1 = os.path.join(outpath,\"dft_thresholds\")\n            else:\n                outpath1 = os.path.join(outpath,\"dft_thresholds_inherit\")\n        else:\n            outpath1 = os.path.join(outpath,usr_thresholds)\n\n        if not os.path.exists(outpath1): os.makedirs(outpath1)\n\n        if rpt2file:\n            dstnfile = os.path.join(outpath1, \"{}_dstn.txt\".format(outnam))\n            resnfile = os.path.join(outpath1, \"{}_resn.txt\".format(outnam))\n        else:\n            dstnfile = ''\n "
  },
  {
    "id": "chunk_1191",
    "text": "outnam))\n        else:\n            dstnfile = ''\n            resnfile = ''\n\n        kwds_api['linmdl']   = linmdl\n        kwds_api['dstnfile'] = dstnfile\n        kwds_api['resnfile'] = resnfile\n\n        if dft_thresholds:\n            psspy.har_set_resn_thresholds_default()\n        else:\n            psspy.har_set_resn_thresholds(pctmx1=pctmx1, dpctpn1=dpctpn1, pctmx2=pctmx2, dpctpn2=dpctpn2)\n\n        ierr = psspy.har_analysis_2(sid, busall, **kwds_api)\n\n        if not ierr:\n            if kwds_ap"
  },
  {
    "id": "chunk_1192",
    "text": "_api)\n\n        if not ierr:\n            if kwds_api['anaoptn'] in [0, 1]:\n                fscan_csvfile = os.path.join(outpath1, \"{}_fscan.csv\".format(outnam))\n                psspy.har_export_fscan(fscan_csvfile)\n\n                msg = \"\\n Frequency Scan Thevenin impedance exported to file:\\n    {}\".format(fscan_csvfile)\n                print(msg)\n\n            ok350402 = major==35 and minor>=4 and modlvl>=2\n            ok3505   = major>=35 and minor>=5\n            ok3600   = major>=36\n\n        "
  },
  {
    "id": "chunk_1193",
    "text": "inor>=5\n            ok3600   = major>=36\n\n            if ok350402 or ok3505 or ok3600:\n                if kwds_api['anaoptn'] in [0, 2]:\n                    dstn_csvfile = os.path.join(outpath1, \"{}_dstn.csv\".format(outnam))\n                    voltoptn, flowoptn, cursrcoptn = 2, 2, 2\n                    psspy.har_export_dstn(dstn_csvfile, voltoptn=voltoptn, flowoptn=flowoptn, cursrcoptn=cursrcoptn )\n\n                    pn, xtn = os.path.splitext(dstn_csvfile)\n                    msg  = \"\\n Dis"
  },
  {
    "id": "chunk_1194",
    "text": "t(dstn_csvfile)\n                    msg  = \"\\n Distortion calculation results exported to files:\\n\"\n                    msg += \"    {}_volt{}\\n\".format(pn, xtn)\n                    msg += \"    {}_flow{}\\n\".format(pn, xtn)\n                    msg += \"    {}_cursrc{}\\n\".format(pn, xtn)\n                    print(msg)\n\n# =========================================================================\n\ndef _ieee_test_get_names(datapath, outpath):\n\n    if datapath is None:        # use Example folder\n       "
  },
  {
    "id": "chunk_1195",
    "text": "apath is None:        # use Example folder\n        exampath = os.path.dirname(__file__)\n        datapath = exampath\n\n    savfile = os.path.join(datapath, 'ieee_harmonics_test_case.sav')\n    harfile = os.path.join(datapath, 'ieee_harmonics_test_case_har.rawx')\n\n    if not os.path.exists(savfile):\n        msg = \"\\n Error- File not found, terminated:\\n    {}\".format(savfile)\n        print(msg)\n\n    if not os.path.exists(harfile):\n        msg = \"\\n Error- File not found, terminated:\\n    {}\".format("
  },
  {
    "id": "chunk_1196",
    "text": "rror- File not found, terminated:\\n    {}\".format(harfile)\n        print(msg)\n\n    if outpath is None:\n        exampath = os.path.dirname(__file__)\n        outpath  = os.path.join(exampath, r'output_harmonics_demo\\ieee')\n        if not os.path.exists(outpath): os.makedirs(outpath)\n\n    return savfile, harfile, outpath\n\n# =========================================================================\n\ndef run_ieee_test(datapath=None, outpath=None):\n    \"\"\"Run PSSE Harmonic Analysis using IEEE Test Case"
  },
  {
    "id": "chunk_1197",
    "text": "\"\"\"Run PSSE Harmonic Analysis using IEEE Test Case.\n    \"\"\"\n    import psspy\n\n    psspy.psseinit()\n\n    savfile, harfile, outpath = _ieee_test_get_names(datapath=datapath, outpath=outpath)\n    psspy.case(savfile)\n    psspy.readrawx(harfile, 'harmonics', 'new')\n\n    _har_ana_ieee_test(outpath=outpath, rpt2file=True)\n\n# =========================================================================\n\ndef run_ieee_test_inherit(datapath=None, outpath=None):\n    \"\"\"Run PSSE Harmonic Analysis using IEEE Test"
  },
  {
    "id": "chunk_1198",
    "text": "\n    \"\"\"Run PSSE Harmonic Analysis using IEEE Test Case.\n    \"\"\"\n    import psspy\n\n    psspy.psseinit()\n\n    savfile, harfile, outpath = _ieee_test_get_names(datapath=datapath, outpath=outpath)\n    hnam, hext = os.path.splitext(harfile)\n    harfile = \"{}_inherit{}\".format(hnam, hext)\n    if not os.path.exists(harfile):\n        msg = \" Error - harmonics data file not found, calculations terminated\\n    {}\".format(harfile)\n        print(msg)\n    psspy.case(savfile)\n    psspy.readrawx(harfile, 'har"
  },
  {
    "id": "chunk_1199",
    "text": "spy.case(savfile)\n    psspy.readrawx(harfile, 'harmonics', 'new')\n\n    _har_ana_ieee_test(outpath=outpath, rpt2file=True, inherit=True)\n\n# =========================================================================\n\ndef run_ieee_test_thevz_thresholds(datapath=None, outpath=None):\n    \"\"\"Run PSSE Harmonic Analysis using IEEE Test Case.\n    \"\"\"\n    import psspy\n\n    psspy.psseinit()\n\n    savfile, harfile, outpath = _ieee_test_get_names(datapath=datapath, outpath=outpath)\n    psspy.case(savfile)\n    "
  },
  {
    "id": "chunk_1200",
    "text": "ath, outpath=outpath)\n    psspy.case(savfile)\n    psspy.readrawx(harfile, 'harmonics', 'new')\n\n    kwds = {}\n    kwds['outpath' ] = outpath\n    kwds['rpt2file' ] = True\n    kwds['dft_thresholds' ] = False\n\n    kwds['pctmx1' ] = 60.0\n    kwds['dpctpn1'] = 75.0\n    kwds['pctmx2' ] = 20.0\n    kwds['dpctpn2'] = 65.0\n\n    _har_ana_ieee_test(**kwds)\n\n# =========================================================================\ndef plot_fscan_ieee_test(outpath=None, **kwds):\n    \"\"\"Plot PSSE Harmonic Ana"
  },
  {
    "id": "chunk_1201",
    "text": "tpath=None, **kwds):\n    \"\"\"Plot PSSE Harmonic Analysis Frequency Scan results of IEEE Test Case.\n    \"\"\"\n    if outpath is None:\n        exampath = os.path.dirname(__file__)\n        outpath  = os.path.join(exampath, r'output_harmonics_demo\\ieee\\dft_thresholds')\n    if not os.path.exists(outpath):\n        msg = \"\\n Error- IEEE Harmonics Frequency Scan results folder not found, terminated:\\n    {}\".format(outpath)\n        print(msg)\n        return\n\n##    kwds = {}\n##    kwds['filetyp'] = 'png'\n##"
  },
  {
    "id": "chunk_1202",
    "text": "\n\n##    kwds = {}\n##    kwds['filetyp'] = 'png'\n##    kwds['verbose'] = verbose\n##    kwds['pctmx1' ] = pctmx1\n##    kwds['dpctpn1'] = dpctpn1\n##    kwds['pctmx2' ] = pctmx2\n##    kwds['dpctpn2'] = dpctpn2\n\n    plot_main_fscan_ieee_test(outpath, **kwds)\n\n# =========================================================================\ndef plot_fscan_ieee_test_tf_psse(outpath=None, **kwds):\n    \"\"\"Plot Frequency Scan results of PSSE Harmonic Analysis and IEEE Task Force for IEEE Test Case.\n    \"\"\"\n    "
  },
  {
    "id": "chunk_1203",
    "text": "d IEEE Task Force for IEEE Test Case.\n    \"\"\"\n    if outpath is None:\n        exampath = os.path.dirname(__file__)\n        outpath  = os.path.join(exampath, r'output_harmonics_demo\\ieee\\dft_thresholds')\n    if not os.path.exists(outpath):\n        msg = \"\\n Error- IEEE Harmonics Frequency Scan results folder not found, terminated:\\n    {}\".format(outpath)\n        print(msg)\n        return\n\n##    kwds = {}\n##    kwds['filetyp'] = 'png'\n##    kwds['verbose'] = verbose\n##    kwds['pctmx1' ] = pctmx1"
  },
  {
    "id": "chunk_1204",
    "text": "verbose'] = verbose\n##    kwds['pctmx1' ] = pctmx1\n##    kwds['dpctpn1'] = dpctpn1\n##    kwds['pctmx2' ] = pctmx2\n##    kwds['dpctpn2'] = dpctpn2\n\n    plot_main_fscan_ieee_test_and_tf(outpath, **kwds)\n\n# =========================================================================\ndef compare_dstn_ieee_test(outpath=None, inherit=False):\n\n    if outpath is None:\n        exampath = os.path.dirname(__file__)\n        if not inherit:\n            outpath  = os.path.join(exampath, r'output_harmonics_demo\\i"
  },
  {
    "id": "chunk_1205",
    "text": "= os.path.join(exampath, r'output_harmonics_demo\\ieee\\dft_thresholds')\n        else:\n            outpath  = os.path.join(exampath, r'output_harmonics_demo\\ieee\\dft_thresholds_inherit')\n\n    if not os.path.exists(outpath):\n        msg = \"\\n Error- IEEE Harmonics Distortion Calculations results folder not found, terminated:\\n    {}\".format(outpath)\n        print(msg)\n        return\n\n    csvnam_volt   = \"ieee_testcase_linmdl=2_dstn_volt.csv\"\n    csvnam_flow   = \"ieee_testcase_linmdl=2_dstn_flow.csv"
  },
  {
    "id": "chunk_1206",
    "text": "nam_flow   = \"ieee_testcase_linmdl=2_dstn_flow.csv\"\n    csvnam_cursrc = \"ieee_testcase_linmdl=2_dstn_cursrc.csv\"\n\n    csvfile_volt   = os.path.join(outpath, csvnam_volt)\n    csvfile_cursrc = os.path.join(outpath, csvnam_cursrc)\n    compare_dstn_ieee_test_and_tf(outpath, csvfile_volt, csvfile_cursrc)\n\n# =========================================================================\ndef plot_dstn_ieee_test_volt_ieee519(outpath=None, *buses, **kwds):\n    \"\"\"Plot PSSE Harmonic Distortion Calculations resu"
  },
  {
    "id": "chunk_1207",
    "text": "\"\"\"Plot PSSE Harmonic Distortion Calculations results of IEEE Test Case.\n    \"\"\"\n    if outpath is None:\n        exampath = os.path.dirname(__file__)\n        outpath  = os.path.join(exampath, r'output_harmonics_demo\\ieee\\dft_thresholds')\n    if not os.path.exists(outpath):\n        msg = \"\\n Error- IEEE Harmonics Distortion Calculations results folder not found, terminated:\\n    {}\".format(outpath)\n        print(msg)\n        return\n\n    csvfnam = r\"ieee_testcase_linmdl=2_dstn_volt.csv\"\n    csvfil"
  },
  {
    "id": "chunk_1208",
    "text": "r\"ieee_testcase_linmdl=2_dstn_volt.csv\"\n    csvfile = os.path.join(outpath, csvfnam)\n\n    figfnam = 'ieee_testcase_linmdl=2_dstn_volt'\n    figfile = os.path.join(outpath, figfnam)\n\n    kwds2 = {}\n    kwds2['figfiletyp'  ] = kwds.get('figfiletyp'  , 'pdf'   )\n    kwds2['figfile'     ] = kwds.get('figfile'     , figfile )\n    kwds2['flag_thd'    ] = kwds.get('flag_thd'    , True    )\n    kwds2['flag_indv'   ] = kwds.get('flag_indv'   , True    )\n    kwds2['flag_busgrps'] = kwds.get('flag_busgrps',"
  },
  {
    "id": "chunk_1209",
    "text": "  kwds2['flag_busgrps'] = kwds.get('flag_busgrps', False   )\n    kwds2['plt_buses'   ] = kwds.get('plt_buses'   , [-1]    )\n    kwds2['flag_show'   ] = kwds.get('flag_show'   , True    )\n\n    plot_distortion_volt_ieee519(csvfile, *buses, **kwds2)\n\n# =========================================================================\n\ndef _run_har_ana_main(*fscanbuses, **kwds):\n    # Run Harmonic Analysis using working case\n    import psspy\n\n    name,major,minor,modlvl,date,stat = psspy.psseversion()\n\n    #"
  },
  {
    "id": "chunk_1210",
    "text": "inor,modlvl,date,stat = psspy.psseversion()\n\n    # subsystem\n    onezerobus = False\n    if fscanbuses:\n        if len(fscanbuses)==1:\n            if fscanbuses[0]==0:\n                onezerobus = True\n\n    if fscanbuses:\n        if not onezerobus:\n            sid = 3\n            busall = 0\n            psspy.bsys(sid, numbus=len(fscanbuses), buses=fscanbuses)\n        else:\n            # no scan, just run distortion calculations\n            sid = 0\n            busall = 0\n    else:\n        totbus ="
  },
  {
    "id": "chunk_1211",
    "text": "\n            busall = 0\n    else:\n        totbus = psspy.totbus()\n        # if case has <100 buses, run scan on all buses\n        if totbus<100:\n            sid = 0\n            busall = 1\n        else:\n            # no scan, just run distortion calculations\n            sid = 0\n            busall = 0\n\n    ierr = True\n    outfdict = {}\n    outfdict['dstn'] = ''\n    outfdict['resn'] = ''\n    outfdict['scan'] = ''\n\n    anaoptn = kwds.get('anaoptn', 0)\n    if sid==0 and busall==0:\n        if anaoptn="
  },
  {
    "id": "chunk_1212",
    "text": ")\n    if sid==0 and busall==0:\n        if anaoptn==0:\n            kwds['anaoptn'] = 2  # only distortion anlysis\n        elif anaoptn==2:\n            pass\n        else:\n            msg = \"\\n Error- Specify frequency scan buses, terminated\"\n            print(msg)\n            return ierr, outfdict\n\n    outfnam  = kwds.get('outfnam' , '')\n    outpath  = kwds.get('outpath' , '')\n\n    if not outfnam:\n        savfile, snpfile = psspy.sfiles()\n        if not savfile:\n            outfnam = \"tmpout\"\n    "
  },
  {
    "id": "chunk_1213",
    "text": "f not savfile:\n            outfnam = \"tmpout\"\n        else:\n            p, nx = os.path.split(savfile)\n            outfnam, xtn = os.path.splitext(nx)\n\n    if outpath:\n        if not os.path.exists(outpath): os.makedirs(outpath)\n        dstnfile = os.path.join(outpath, \"{}_dstn.txt\".format(outfnam))\n        resnfile = os.path.join(outpath, \"{}_resn.txt\".format(outfnam))\n    else:\n        dstnfile = ''\n        resnfile = ''\n\n    kwds['hrsfile']  = ''\n    kwds['dstnfile'] = dstnfile\n    kwds['resn"
  },
  {
    "id": "chunk_1214",
    "text": " ''\n    kwds['dstnfile'] = dstnfile\n    kwds['resnfile'] = resnfile\n\n    if 'outpath' in kwds: del kwds['outpath']\n    if 'outfnam' in kwds: del kwds['outfnam']\n\n    ierr = psspy.har_analysis(sid, busall, **kwds)\n\n    fscan_csvfile = ''\n    dstn_volt_csvfile = ''\n    dstn_flow_csvfile = ''\n    dstn_cursrc_csvfile = ''\n\n    if not ierr and outpath:\n        if anaoptn in [0,1]:\n            if not ierr and outpath:\n                fscan_csvfile = os.path.join(outpath, \"{}_fscan.csv\".format(outfnam)"
  },
  {
    "id": "chunk_1215",
    "text": ".path.join(outpath, \"{}_fscan.csv\".format(outfnam))\n                psspy.har_export_fscan(fscan_csvfile)\n                msg = \"\\n Frequency Scan Thevenin impedance saved to file:\\n    {}\".format(fscan_csvfile)\n                print(msg)\n\n        ok350402 = major==35 and minor>=4 and modlvl>=2\n        ok3505   = major>=35 and minor>=5\n        ok3600   = major>=36\n\n        if ok350402 or ok3505 or ok3600:\n            if anaoptn in [0, 2]:\n                dstn_csvfile = os.path.join(outpath, \"{}_"
  },
  {
    "id": "chunk_1216",
    "text": "         dstn_csvfile = os.path.join(outpath, \"{}_dstn.csv\".format(outfnam))\n                voltoptn, flowoptn, cursrcoptn = 2, 2, 2\n\n                psspy.har_export_dstn(dstn_csvfile, voltoptn=voltoptn, flowoptn=flowoptn, cursrcoptn=cursrcoptn )\n\n                pn, xtn = os.path.splitext(dstn_csvfile)\n                dstn_volt_csvfile = r\"{}_volt{}\".format(pn, xtn)\n                dstn_flow_csvfile = r\"{}_flow{}\".format(pn, xtn)\n                dstn_cursrc_csvfile = r\"{}_cursrc{}\".format(pn,"
  },
  {
    "id": "chunk_1217",
    "text": "   dstn_cursrc_csvfile = r\"{}_cursrc{}\".format(pn, xtn)\n\n                msg += r\"    {}\\n\".format(dstn_volt_csvfile)\n                msg += r\"    {}\\n\".format(dstn_flow_csvfile)\n                msg += r\"    {}\\n\".format(dstn_cursrc_csvfile)\n                print(msg)\n\n    outfdict['dstn'] = dstnfile\n    outfdict['resn'] = resnfile\n    outfdict['scan'] = fscan_csvfile\n    outfdict['dstn_volt'] = dstnfile\n    outfdict['dstn_flow'] = resnfile\n    outfdict['dstn_cursrc'] = fscan_csvfile\n\n    return"
  },
  {
    "id": "chunk_1218",
    "text": "utfdict['dstn_cursrc'] = fscan_csvfile\n\n    return ierr, outfdict\n\n# =========================================================================\ndef run_har_analysis(savfile, *fscanbuses, **kwds):\n    \"\"\"Run PSSE Harmonic Analysis using savfile and harfile provided.\n\n    Arguments:\n        savfile (str): PSSE Saved Case file name\n\n        fscanbuses (int): One or bus numbers at which frequency scan done\n\n        kwds (dict):  All PSSE har_analysis() API keywords plus followng\n            are allow"
  },
  {
    "id": "chunk_1219",
    "text": ") API keywords plus followng\n            are allowed key words.\n\n            harfile (str) : PSSE harmonics data (.har) file\n            outpath (str) : Output Results File Folder name\n            outfnam (str) : Output Results File Name prefix\n    \"\"\"\n\n    import psspy\n\n    if not os.path.exists(savfile):\n        msg = \"\\n Error- File not found, terminated:\\n    {}\".format(savfile)\n        print(msg)\n        return True, {}\n\n    harfile = kwds.get('harfile', '')\n    if harfile:\n        if not o"
  },
  {
    "id": "chunk_1220",
    "text": "et('harfile', '')\n    if harfile:\n        if not os.path.exists(harfile):\n            msg = \"\\n Error- File not found, ignored:\\n    {}\".format(harfile)\n            print(msg)\n            harfile = ''\n\n    psspy.psseinit()\n\n    ierr = psspy.case(savfile)\n    if ierr:\n        msg = \"\\n Error- reading SAV file, terminated:\\n    {}\".format(savfile)\n        print(msg)\n        return True, {}\n\n    if harfile:\n        ierr = psspy.readrawx(harfile, 'harmonics', 'new')\n        if ierr:\n            msg "
  },
  {
    "id": "chunk_1221",
    "text": "rmonics', 'new')\n        if ierr:\n            msg = \"\\n Error- reading Harmonics data file, terminated:\\n    {}\".format(harfile)\n            print(msg)\n            return True, {}\n\n    if 'harfile' in kwds: del kwds['harfile']\n    ierr, outfdict = _run_har_ana_main(*fscanbuses, **kwds)\n\n    return ierr, outfdict\n\n# ==============================================================================\n\ndef _plot_fscan_one(ax, hlst, zlst, **kwds):\n    #  main plot function\n    basemva  = kwds.get('basemva"
  },
  {
    "id": "chunk_1222",
    "text": "ain plot function\n    basemva  = kwds.get('basemva' , 100.0)\n    basekv   = kwds.get('basekv'  , None)\n    hmajor   = kwds.get('hmajor'  , [])\n    ymajor   = kwds.get('ymajor'  , [])\n    plotzpu  = kwds.get('plotzpu' , False)\n    title    = kwds.get('title'   , '')\n    add_xlbl = kwds.get('add_xlbl', None)\n    add_lgnd = kwds.get('add_lgnd', False)\n    annot_xy = kwds.get('annot_xy', (0.5, 0.5))\n\n    pctmx1  = kwds.get('pctmx1' , 60.0)\n    dpctpn1 = kwds.get('dpctpn1', 75.0)\n    pctmx2  = kwds.g"
  },
  {
    "id": "chunk_1223",
    "text": "1 = kwds.get('dpctpn1', 75.0)\n    pctmx2  = kwds.get('pctmx1' , 20.0)\n    dpctpn2 = kwds.get('dpctpn1', 85.0)\n    report  = kwds.get('report' , None)\n\n    if add_lgnd:\n        peak_lst_h, peak_lst_rx = check_resonance(hlst, zlst, pctmx1, dpctpn1, pctmx2, dpctpn2, report)\n\n    ylbl = \"Thevenin Impedance (pu)\"\n    if not plotzpu:\n        if basemva and basekv:\n            zbase = basekv*basekv/basemva\n            zlst_ohm = [zbase*each for each in zlst]\n            zlst = zlst_ohm[:]\n            d"
  },
  {
    "id": "chunk_1224",
    "text": "zlst]\n            zlst = zlst_ohm[:]\n            del zlst_ohm\n            ylbl = \"Thevenin Impedance (ohm)\"\n\n            if add_lgnd:\n                peak_lst_rx_ohm = [zbase*each for each in peak_lst_rx]\n                peak_lst_rx = peak_lst_rx_ohm[:]\n                del peak_lst_rx_ohm\n\n    if add_lgnd:\n        resn_lgd_lst = get_resn_legends(peak_lst_h, peak_lst_rx)\n        resn_lgd = \"\\n\".join(resn_lgd_lst)\n\n    if add_lgnd:\n        ax.plot(hlst, zlst, label=resn_lgd)\n    else:\n        ax.p"
  },
  {
    "id": "chunk_1225",
    "text": "hlst, zlst, label=resn_lgd)\n    else:\n        ax.plot(hlst, zlst)\n    #ax.set_yscale('log')\n    if hmajor: ax.set_xticks(hmajor)\n    if ymajor: ax.set_yticks(ymajor)\n    if (add_xlbl): ax.set_xlabel(\"Harmonic Order\")\n    ax.set_ylabel(ylbl)\n\n    ax.grid(True, which='both')\n\n    if add_lgnd:\n        ax.legend(loc='best')\n\n    if title: ax.set_title(title)\n\n# =========================================================================\n\ndef _set_output_figfile_name(outfigfile, figfiletyp):\n\n    figfil"
  },
  {
    "id": "chunk_1226",
    "text": "_figfile_name(outfigfile, figfiletyp):\n\n    figfiletyp_in = figfiletyp\n    if figfiletyp_in:\n        if figfiletyp_in not in _ALLOWED_FIG_FILE_TYPES:\n            figfiletyp_in = ''\n\n    opth, nx = os.path.split(outfigfile)\n    n, x = os.path.splitext(nx)\n\n    if x:\n        figfiletyp_fl = ''\n        xlw = x.lower().strip()\n        if xlw:\n            if xlw[1:] in _ALLOWED_FIG_FILE_TYPES:\n                figfiletyp_fl = xlw[1:]\n\n    if figfiletyp_in:\n        figfiletyp = figfiletyp_in\n    elif f"
  },
  {
    "id": "chunk_1227",
    "text": "_in:\n        figfiletyp = figfiletyp_in\n    elif figfiletyp_fl:\n        figfiletyp = figfiletyp_fl\n    else:\n        figfiletyp = 'pdf'\n\n    xlw = \".{}\".format(figfiletyp)\n\n    if not opth: opth = os.getcwd()\n    outfigfile = os.path.join(opth, \"{}{}\".format(n, xlw))\n\n    return outfigfile, figfiletyp\n\n# =========================================================================\n\ndef plot_frequency_scan(busnum, *csvfiles, **kwds):\n    \"\"\"Plot Harmonics Frequency Scan Thevenin Impedance.\n    for on"
  },
  {
    "id": "chunk_1228",
    "text": "nics Frequency Scan Thevenin Impedance.\n    for one bus from multiple Frequency Scan Result Files\n\n    Arguments:\n        busnum (int): Bus Number. The 'csvfiles' provided must have Thevenin Impedance\n            for this bus.\n\n        csvfiles (str): One or more CSV files that contain Frequency Scan results.\n            These files are created by api psspy.har_export_fscan(..).\n\n        kwds (dict):  Followng are allowed key words.\n\n            (A) These keywords are for plot figure options.\n\n "
  },
  {
    "id": "chunk_1229",
    "text": "(A) These keywords are for plot figure options.\n\n            figfiletyp (str): File type to which plots are saved.\n                              ='pdfobj' -- files are saved to already created pdfobj\n                              [Create pdfobj = PdfPages(pdffile). This is done so\n                              as to save many plots to one pdffile.]\n                              ='pdf', 'png', 'jpg' etc. [all allowed file types].\n                              (default: '')\n            figfile (st"
  },
  {
    "id": "chunk_1230",
    "text": "             (default: '')\n            figfile (str)   : Name of the file or pdfobj to save plots\n                              When file name is not provided plot is not saved.\n                              (default: '')\n            flag_show (bool): Flag (True or False), Option to show plots on screen or not.\n                              (default: True)\n            basemva (float) : Base MVA (used to calculate Thev Z in ohms)\n                              (default: 100.0)\n            basekv  "
  },
  {
    "id": "chunk_1231",
    "text": "             (default: 100.0)\n            basekv  (float) : Base kV of the bus (used to calculate Thev Z in ohms)\n                              (default: No default allowed)\n            hmajor  (float) : List of Harmonics Orders (used to draw X axis grid)\n                              (default: [])\n            ymajor  (float) : List of Thev Z (used to draw X axis grid)\n                              (default: [])\n            ttl_lst (str)   : Title list (one for each csvfile provided)\n           "
  },
  {
    "id": "chunk_1232",
    "text": "e list (one for each csvfile provided)\n                              When one title is provided, same title is used for all.\n                              (default: [])\n            plotzpu (bool)  : True for Plot PU Thev Z\n                              (default: False)\n            add_lgnd (bool) : True to add resonance rrequeny legend\n                              (default: False)\n            annot_xy (tuple): Resonance Frequency legend location\n                              Specify normalized "
  },
  {
    "id": "chunk_1233",
    "text": "\n                              Specify normalized (0 through 1) XY co-ordinates of a point\n                              (default: (0.5, 0.5))\n            subplts (bool)  : True, plot as subplots for more than one csvfiles.\n                              (default: True) Subplots are drawn with 3 rows and 1 column.\n            fwidth  (float) : Figure Width in inches\n                              (default: matplotlib rcParms default figure width)\n            fheight (float) : Figure Height in inch"
  },
  {
    "id": "chunk_1234",
    "text": "           fheight (float) : Figure Height in inches\n                              (default: matplotlib rcParms default figure height)\n\n            (B) These keywords are for filtering and reporting Thevenin Impedance Peaks.\n\n            - Criterion 1 to select Thevenin Impedance Peak - slow rising peak point\n            pctmx1 (float)     : current point in percent of maximum peak value\n                                 (default:60.0)\n            dpctpn1 (float)    : delta previous and delta nex"
  },
  {
    "id": "chunk_1235",
    "text": " dpctpn1 (float)    : delta previous and delta next points in percent of current point\n                                 (default:75.0)\n\n            - Criterion 2 to select Thevenin Impedance Peak - fast rising peak point\n            pctmx2 (float)     : current point in percent of maximum peak value\n                                 (default:20.0)\n            dpctpn2 (float)    : delta previous and delta next points in percent of current point\n                                 (default:85.0)\n\n    "
  },
  {
    "id": "chunk_1236",
    "text": "                              (default:85.0)\n\n            verbose (bool)     : Show verbose (detailed) output of Thevenin Impedance filtering\n                                 (default: False)\n            verbose_file (str) : File name to write verbose output.\n                                 (default: '')\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.backends.backend_pdf import PdfPages\n\n    # Use outfigfile to save output figure file and\n    # also use its path to find csvfile"
  },
  {
    "id": "chunk_1237",
    "text": "e file and\n    # also use its path to find csvfile when csvfile path is not provided.\n    csvpath = ''\n\n    figfiletyp = kwds.get('figfiletyp', '')\n    figfiletyp = figfiletyp.lower()\n\n    outfigfile = kwds.get('figfile', '')\n    flag_show  = kwds.get('flag_show', True)\n\n    if outfigfile:\n        if figfiletyp=='pdfobj':\n            pass\n        else:\n            outfigfile, figfiletyp = _set_output_figfile_name(outfigfile, figfiletyp)\n    else:\n        figfiletyp = ''\n\n    title = ''\n    has_t"
  },
  {
    "id": "chunk_1238",
    "text": "\n        figfiletyp = ''\n\n    title = ''\n    has_ttl4each = False\n    ttl_lst = kwds.get('ttl_lst', [])\n    nttl = len(ttl_lst)\n    ncsv = len(csvfiles)\n    if nttl==ncsv:\n        has_ttl4each = True\n    elif nttl==1 and ncsv>1:\n        title = ttl_lst[0]\n\n    exists_csvfiles = []\n    exists_titles   = []\n    for ii, csvnam in enumerate(csvfiles):\n        if has_ttl4each:\n            ttl = ttl_lst[ii]\n        else:\n            ttl = title\n        if os.path.exists(csvnam):\n            exists_csv"
  },
  {
    "id": "chunk_1239",
    "text": " if os.path.exists(csvnam):\n            exists_csvfiles.append(csvnam)\n            exists_titles.append(ttl)\n        else:\n            p, nx = os.path.split(csvnam)\n            if not p and csvpath:\n                csvnam2 = os.path.join(csvpath, nx)\n                if os.path.exists(csvnam2):\n                    exists_csvfiles.append(csvnam2)\n                    exists_titles.append(ttl)\n            else:\n                msg = \" File not found: {}\".format(csvnam)\n                print(msg)\n\n  "
  },
  {
    "id": "chunk_1240",
    "text": " {}\".format(csvnam)\n                print(msg)\n\n    if not exists_csvfiles:\n        return\n\n    fwidth  = kwds.get('fwidth',  None)\n    fheight = kwds.get('fheight', None)\n    subplts = kwds.get('subplts', True)\n\n    verbose  = kwds.get('verbose', False)\n    verbose_file = kwds.get('verbose_file', '')\n    report = None\n    if verbose:\n        if verbose_file:\n            verbose_fobj = open(verbose_file, 'w')\n            report = verbose_fobj.write\n        else:\n            report = sys.stdout.w"
  },
  {
    "id": "chunk_1241",
    "text": "te\n        else:\n            report = sys.stdout.write\n\n    if subplts:\n        if fwidth is None or fheight is None:\n            fwidth, fheight = 8.0, 9.0\n\n    nfigs = len(exists_csvfiles)\n    if not subplts:\n        npages = nfigs\n        nrows = 1\n    else:\n        if nfigs>3:\n            npages = int(math.ceil(nfigs/3.0))   # three subplots per page\n            nrows = 3\n        else:\n            npages = 1\n            nrows = nfigs\n\n    if outfigfile and figfiletyp=='pdf':\n        pdffile "
  },
  {
    "id": "chunk_1242",
    "text": "outfigfile and figfiletyp=='pdf':\n        pdffile = outfigfile\n        pdfobj = PdfPages(pdffile)\n    elif outfigfile and figfiletyp=='pdfobj':\n        pdfobj = outfigfile\n\n    nn = 0\n    for pp in range(npages):\n        fig, axlst = plt.subplots(nrows,1)\n        if nrows==1: axlst = [axlst]\n        fig.subplots_adjust(hspace=0.25)\n        if fwidth is not None or fheight is not None:\n            fig.set_size_inches(fwidth, fheight)\n\n        for nr in range(nrows):\n            ii = pp*nrows + nr"
  },
  {
    "id": "chunk_1243",
    "text": "nr in range(nrows):\n            ii = pp*nrows + nr\n            if ii<nfigs:\n                csvfile = exists_csvfiles[ii]\n                ttl = exists_titles[ii]\n                ax = axlst[nr]\n                if (nr+1==nrows):\n                    add_xlbl = True\n                else:\n                    add_xlbl = False\n\n                kwds['title'] = ttl\n                kwds['add_xlbl'] = add_xlbl\n                kwds['report'] = report\n\n                thevz_dict = get_fscan_csvdata(csvfile)\n"
  },
  {
    "id": "chunk_1244",
    "text": "          thevz_dict = get_fscan_csvdata(csvfile)\n                ierr, hlst, zlst, phlst = get_hord_thevz_list(thevz_dict, busnum)\n                if not ierr:\n                    _plot_fscan_one(ax, hlst, zlst, **kwds)\n            else:\n                axlst[nr].set_visible(False)\n\n        if outfigfile:\n            if figfiletyp=='pdf':\n                pdfobj.savefig(fig, bbox_inches='tight')\n            elif figfiletyp=='pdfobj':\n                try:\n                    pdfobj.savefig(fig, b"
  },
  {
    "id": "chunk_1245",
    "text": "    try:\n                    pdfobj.savefig(fig, bbox_inches='tight')\n                except:\n                    traceback.print_last()\n            else:\n                if npages>1:\n                    pn, x = os.path.splitext(outfigfile)\n                    zn = \"{}\".format(pp).zfill(2)\n                    tmpfnam = \"{}_{}{}\".format(pn,zn,x)\n                else:\n                    tmpfnam = outfigfile\n                fig.savefig(tmpfnam, bbox_inches='tight')\n\n    if outfigfile:\n        if f"
  },
  {
    "id": "chunk_1246",
    "text": "x_inches='tight')\n\n    if outfigfile:\n        if figfiletyp=='pdf':\n            pdfobj.close()\n\n        if figfiletyp=='pdfobj':\n            plt.close(fig=fig)\n        else:\n            print(\" Plots saved: {}\".format(outfigfile))\n\n    if verbose:\n        if verbose_file:\n            verbose_fobj.close()\n\n    if figfiletyp!='pdfobj':\n        if flag_show:\n            plt.show()\n        else:\n            plt.close('all')\n\n# ========================================================================="
  },
  {
    "id": "chunk_1247",
    "text": "==================================================\n\ndef plot_distortion_volt_ieee519(csvfile, *buses, **kwds):\n    \"\"\"Plot Distortion Calculations Bus Voltages THD and Individual Harmonic levels with\n    IEEE 519 Voltage Distortion Limits.\n    Arguments:\n        csvfile (str): CSV file that contain Distortion Calculations Bus Voltages results.\n            This file is created by api psspy.har_export_dstn(..).\n            No default allowed.\n\n        buses (int): One or more Study Bus Numbers. TH"
  },
  {
    "id": "chunk_1248",
    "text": "    buses (int): One or more Study Bus Numbers. THD and Individual harmonic levels are plotted\n            for these many buses when provided.\n            (default - consider all buses)\n\n        kwds (dict):  Followng are allowed key words.\n\n            (A) These keywords are for plot figure options.\n\n            figfiletyp (str)   : File type to which plots are saved.\n                                 ='pdfobj' -- files are saved to already created pdfobj\n                                 [Create"
  },
  {
    "id": "chunk_1249",
    "text": "ed pdfobj\n                                 [Create pdfobj = PdfPages(pdffile). This is done so\n                                 as to save many plots to one pdffile.]\n                                 ='pdf', 'png', 'jpg' etc. [all allowed file types].\n                                 (default: '')\n            figfile (str)      : Name of the file or pdfobj to save plots\n                                 When file name is not provided plot is not saved.\n                                 (default: '"
  },
  {
    "id": "chunk_1250",
    "text": "aved.\n                                 (default: '')\n            flag_thd (bool)    : Flag (True or False), Option to plot THD of all study buses.\n                                 (default: True)\n            flag_indv (bool)   : Flag (True or False), Option to plot maximum individual harmonic levels\n                                 of all study buses. For each bus, maximum individual harmonic level among all\n                                 harmonic orders is found and plotted.\n                 "
  },
  {
    "id": "chunk_1251",
    "text": "nic orders is found and plotted.\n                                 (default: True)\n            flag_busgrps (bool): Flag (True or False) Option to plot bus THD and INDV of bus groups.\n                                 True -- Group buses as per their nominal voltage and IEEE 519 - Table 1\n                                 voltage at PCC. Plot those bus groups in separate figures.\n                                 False -- Plot all buses in one figure.\n                                 (default: True)"
  },
  {
    "id": "chunk_1252",
    "text": ".\n                                 (default: True)\n            plt_buses (list)   : List of bus numbers (subset of Study Bus Numbers) to plot harmonic distortions.\n                                 Bus THD and INDV harmonic distortions are plotted on the same figure.\n                                 A separate figure created for each bus.\n                                 Specify =[-1] or =-1 to plot all study buses.\n                                 (default: [])\n            flag_show (bool)   : F"
  },
  {
    "id": "chunk_1253",
    "text": "  (default: [])\n            flag_show (bool)   : Flag (True or False), Option to show plots on screen or not.\n                                 (default: True)\n            flag_xtick (bool)  : Flag (True or False), Option to Lable and Tick all X axis bus numbers.\n                                 (default: True). Set this false if plotting for many numbers. Plot\n                                 automatically assigns few labels and ticks in that case.\n    \"\"\"\n\n    import matplotlib.pyplot as plt\n  "
  },
  {
    "id": "chunk_1254",
    "text": "e.\n    \"\"\"\n\n    import matplotlib.pyplot as plt\n    from matplotlib.backends.backend_pdf import PdfPages\n\n    if not os.path.exists(csvfile):\n        msg = \" Distortion Bus Volts file not found: {}\".format(csvfile)\n        print(msg)\n        return\n\n    volt_dict = get_dstn_csvdata_volt(csvfile)\n\n    # get organized Distortion results data\n    ierr, ieee519_vlmt_dict, each_bus_xy, all_bus_xy = get_dstn_volt_study_bus_results(volt_dict, *buses)\n    if ierr==1:\n        msg = \" IEEE 519 Bus Groups "
  },
  {
    "id": "chunk_1255",
    "text": "  if ierr==1:\n        msg = \" IEEE 519 Bus Groups not found in Distortion Bus Volts file: {}\".format(csvfile)\n        print(msg)\n        return\n\n    all_xnam = all_bus_xy['xnam']\n    all_xnum = range(len(all_xnam))\n\n    # separate groups and plot their bars so as to have ONE legend lable for a group\n    bar_grps = {}\n    for idx, xnum, thd, indv, indv_hord in zip(all_bus_xy['lmtidx'], all_xnum, all_bus_xy['thd'],\n                                               all_bus_xy['indv'], all_bus_xy['indv"
  },
  {
    "id": "chunk_1256",
    "text": "              all_bus_xy['indv'], all_bus_xy['indv_hord']):\n        if idx not in bar_grps:\n            bar_grps[idx] = {'xnum':[], 'thd':[], 'indv':[], 'indv_hord':[]}\n        bar_grps[idx]['xnum'].append(xnum)\n        bar_grps[idx]['thd'].append(thd)\n        bar_grps[idx]['indv'].append(indv)\n        bar_grps[idx]['indv_hord'].append(indv_hord)\n\n    # preserve legend order\n    grpidx_ordr = list(bar_grps.keys())\n    grpidx_ordr.sort()\n\n    # Use outfigfile to save output figure file and\n    # "
  },
  {
    "id": "chunk_1257",
    "text": "e outfigfile to save output figure file and\n    # also use its path to find csvfile when csvfile path is not provided.\n\n    figfiletyp = kwds.get('figfiletyp', '')\n    figfiletyp = figfiletyp.lower()\n\n    outfigfile = kwds.get('figfile', '')\n\n    flag_thd     = kwds.get('flag_thd', True)\n    flag_indv    = kwds.get('flag_indv', True)\n    flag_busgrps = kwds.get('flag_busgrps', False)\n    plt_buses    = kwds.get('plt_buses', [])\n    flag_show    = kwds.get('flag_show', True)\n    flag_xtick   = kw"
  },
  {
    "id": "chunk_1258",
    "text": " kwds.get('flag_show', True)\n    flag_xtick   = kwds.get('flag_xtick', True)\n\n    # validate plt_buses\n    ok_pltbus_list = []\n    if plt_buses:\n        bus_ok_dict = {}\n        for bus_sec, vdict in each_bus_xy.items():\n            bus, sec = bus_sec\n            if bus not in bus_ok_dict:\n                bus_ok_dict[bus] = []\n            bus_ok_dict[bus].append(bus_sec)\n\n        if type(plt_buses)==int:\n            buslst = [plt_buses]\n        elif type(plt_buses) in [list, tuple]:\n            "
  },
  {
    "id": "chunk_1259",
    "text": "lif type(plt_buses) in [list, tuple]:\n            buslst = plt_buses[:]\n        else:\n            buslst = []\n            msg = \" Invalid plt_buses={} specified, ignored. Individual Bus plots not done.\".format(plt_buses)\n            print(msg)\n\n        if len(buslst)==1 and buslst[0]==-1:\n            for bus in bus_ok_dict:\n                ok_pltbus_list.extend(bus_ok_dict[bus])\n        else:\n            buslst.sort()\n            for bus in buslst:\n                if bus not in bus_ok_dict:\n    "
  },
  {
    "id": "chunk_1260",
    "text": "t:\n                if bus not in bus_ok_dict:\n                    msg = \" Invalid plt_bus={}, ignored. Bus does not exist in results.\".format(bus)\n                    print(msg)\n                else:\n                    ok_pltbus_list.extend(bus_ok_dict[bus])\n\n    if outfigfile:\n        if figfiletyp=='pdfobj':\n            pass\n        else:\n            outfigfile, figfiletyp = _set_output_figfile_name(outfigfile, figfiletyp)\n    else:\n        figfiletyp = ''\n\n    if outfigfile and figfiletyp=='"
  },
  {
    "id": "chunk_1261",
    "text": "gfiletyp = ''\n\n    if outfigfile and figfiletyp=='pdf':\n        pdffile = outfigfile\n        pdfobj = PdfPages(pdffile)\n    elif outfigfile and figfiletyp=='pdfobj':\n        pdfobj = outfigfile\n\n    fignum = 0\n    if flag_thd:\n        bgn_allbus_thd = False\n        for idx in grpidx_ordr:\n            if flag_busgrps:\n                fignum += 1\n                fig = plt.figure(num=fignum)\n                ax = fig.add_subplot(111)\n                do_lbls = True\n            else:\n                i"
  },
  {
    "id": "chunk_1262",
    "text": "do_lbls = True\n            else:\n                if not bgn_allbus_thd:\n                    bgn_allbus_thd = True\n                    fignum += 1\n                    fig = plt.figure(num=fignum)\n                    ax = fig.add_subplot(111)\n                if idx==grpidx_ordr[-1]:\n                    do_lbls = True\n                else:\n                    do_lbls = False\n\n            lbl     = ieee519_vlmt_dict[idx]['lmt_lgd']\n            lmtkv   = ieee519_vlmt_dict[idx]['lmtkv']\n            lm"
  },
  {
    "id": "chunk_1263",
    "text": "  = ieee519_vlmt_dict[idx]['lmtkv']\n            lmt_thd = _ieee519_table1_thd_limits[lmtkv]['thd']\n            lmt_hvdc = _ieee519_table1_thd_limits[lmtkv].get('thd_hvdc', 0.0)\n            if lmt_hvdc>0.0:\n                lbl = \"{} [{}] [with HVDC={}%]\".format(lmt_thd, lbl, lmt_hvdc)\n            else:\n                lbl = \"{} [{}]\".format(lmt_thd, lbl)\n            clr = _COLOR_PREFERENCE[idx]\n            h = ax.bar(bar_grps[idx]['xnum'], bar_grps[idx]['thd'], width=0.1, label=lbl, color=clr)\n\n "
  },
  {
    "id": "chunk_1264",
    "text": "s[idx]['thd'], width=0.1, label=lbl, color=clr)\n\n            # draw limit lines\n            ax.axhline(y=lmt_thd, color=clr, linestyle='--', linewidth=1.5)\n            if lmt_hvdc>0.0:\n                ax.axhline(y=lmt_hvdc, color=clr, linestyle='--', linewidth=1.5)\n\n            # labels and title\n            if do_lbls:\n                ttl = \" Voltage THD\"\n                ax.set_title(ttl)\n                ax.set_xlabel(\"Bus Numbers\")\n                ax.set_ylabel(\"% THD\")\n                if flag"
  },
  {
    "id": "chunk_1265",
    "text": "    ax.set_ylabel(\"% THD\")\n                if flag_xtick:\n                    ax.set_xticks(all_xnum, all_xnam)\n                h_lgd = ax.legend(title=\"IEEE 519 %THD Limits\")\n                h_lgd.get_frame().set_linewidth(0)\n                h_lgd.set_draggable(True)\n\n                if outfigfile:\n                    if figfiletyp=='pdf':\n                        pdfobj.savefig(fig, bbox_inches='tight')\n                    elif figfiletyp=='pdfobj':\n                        try:\n                "
  },
  {
    "id": "chunk_1266",
    "text": "bj':\n                        try:\n                            pdfobj.savefig(fig, bbox_inches='tight')\n                        except:\n                            traceback.print_last()\n                    else:\n                        pn, x = os.path.splitext(outfigfile)\n                        if flag_busgrps:\n                            tmpfnam = \"{}_thd_{}{}\".format(pn,idx,x)\n                        else:\n                            tmpfnam = \"{}_thd{}\".format(pn,x)\n                        f"
  },
  {
    "id": "chunk_1267",
    "text": " \"{}_thd{}\".format(pn,x)\n                        fig.savefig(tmpfnam, bbox_inches='tight')\n\n    if flag_indv:\n        bgn_allbus_indv = False\n        for idx in grpidx_ordr:\n            if flag_busgrps:\n                fignum += 1\n                fig = plt.figure(num=fignum)\n                ax = fig.add_subplot(111)\n                do_lbls = True\n            else:\n                if not bgn_allbus_indv:\n                    bgn_allbus_indv = True\n                    fignum += 1\n                  "
  },
  {
    "id": "chunk_1268",
    "text": "                    fignum += 1\n                    fig = plt.figure(num=fignum)\n                    ax = fig.add_subplot(111)\n                if idx==grpidx_ordr[-1]:\n                    do_lbls = True\n                else:\n                    do_lbls = False\n\n            lbl     = ieee519_vlmt_dict[idx]['lmt_lgd']\n            lmtkv   = ieee519_vlmt_dict[idx]['lmtkv']\n            lmt_indv= _ieee519_table1_thd_limits[lmtkv]['indv']\n            lbl     = \"{} [{}]\".format(lmt_indv, lbl)\n          "
  },
  {
    "id": "chunk_1269",
    "text": "l     = \"{} [{}]\".format(lmt_indv, lbl)\n            clr = _COLOR_PREFERENCE[idx]\n            h = ax.bar(bar_grps[idx]['xnum'], bar_grps[idx]['indv'], width=0.1, label=lbl, color=clr)\n\n            do_bar_lbl_nam = False\n            if flag_busgrps:\n                do_bar_lbl_nam = True\n            else:\n                if all_xnum[0]==bar_grps[idx]['xnum'][0]:\n                    do_bar_lbl_nam = True\n\n            lbls = []\n            for hord in bar_grps[idx]['indv_hord']:\n                if do"
  },
  {
    "id": "chunk_1270",
    "text": " bar_grps[idx]['indv_hord']:\n                if do_bar_lbl_nam:\n                    lbls.append(\"HORD={}\".format(int(hord)))\n                    do_bar_lbl_nam = False\n                else:\n                    lbls.append(\"{}\".format(int(hord)))\n            if flag_xtick:\n                ax.bar_label(h, labels=lbls, padding=2)\n\n            # draw limit lines\n            ax.axhline(y=lmt_indv, color=clr, linestyle='--', linewidth=1.5)\n\n            # labels and title\n            if do_lbls:\n      "
  },
  {
    "id": "chunk_1271",
    "text": " # labels and title\n            if do_lbls:\n                ttl = \" Voltage Individual Harmonic Levels (maximum)\"\n                ax.set_title(ttl)\n                ax.set_xlabel(\"Bus Numbers\")\n                ax.set_ylabel(\"% INDV\")\n                if flag_xtick:\n                    ax.set_xticks(all_xnum, all_xnam)\n                h_lgd = ax.legend(title=\"IEEE 519 %INDV Limits\")\n                h_lgd.get_frame().set_linewidth(0)\n                h_lgd.set_draggable(True)\n\n                if outf"
  },
  {
    "id": "chunk_1272",
    "text": "h_lgd.set_draggable(True)\n\n                if outfigfile:\n                    if figfiletyp=='pdf':\n                        pdfobj.savefig(fig, bbox_inches='tight')\n                    elif figfiletyp=='pdfobj':\n                        try:\n                            pdfobj.savefig(fig, bbox_inches='tight')\n                        except:\n                            traceback.print_last()\n                    else:\n                        pn, x = os.path.splitext(outfigfile)\n                    "
  },
  {
    "id": "chunk_1273",
    "text": " os.path.splitext(outfigfile)\n                        if flag_busgrps:\n                            tmpfnam = \"{}_indv_{}{}\".format(pn,idx,x)\n                        else:\n                            tmpfnam = \"{}_indv{}\".format(pn,x)\n                        fig.savefig(tmpfnam, bbox_inches='tight')\n\n    if ok_pltbus_list:\n        for bus_sec in ok_pltbus_list:\n            vdict = each_bus_xy[bus_sec]\n            xnam  = vdict['xnam']\n\n            idx     = vdict['lmtidx']\n            lmtkv   = i"
  },
  {
    "id": "chunk_1274",
    "text": " idx     = vdict['lmtidx']\n            lmtkv   = ieee519_vlmt_dict[idx]['lmtkv']\n            lmt_thd = _ieee519_table1_thd_limits[lmtkv]['thd']\n            lmt_indv= _ieee519_table1_thd_limits[lmtkv]['indv']\n\n            lbl_thd = \"%THD={}\".format(lmt_thd)\n            lbl_indv = \"%INDV={}\".format(lmt_indv)\n\n            fignum += 1\n            fig = plt.figure(num=fignum)\n            ax = fig.add_subplot(111)\n\n            clr_thd = _COLOR_PREFERENCE_BUS[0]\n            h = ax.bar(vdict['hord'][0],"
  },
  {
    "id": "chunk_1275",
    "text": "CE_BUS[0]\n            h = ax.bar(vdict['hord'][0], vdict['pct'][0], width=0.3, label=lbl_thd, color=clr_thd)\n\n            clr_indv = _COLOR_PREFERENCE_BUS[1]\n            h = ax.bar(vdict['hord'][1:], vdict['pct'][1:], width=0.3, label=lbl_indv, color=clr_indv)\n\n            # draw limit lines if any limit is violated\n            maxpct = max(vdict['pct'])\n            if maxpct>lmt_thd or maxpct>lmt_indv:\n                ax.axhline(y=lmt_thd,  color=clr_thd, linestyle='--', linewidth=1.5)\n        "
  },
  {
    "id": "chunk_1276",
    "text": "r=clr_thd, linestyle='--', linewidth=1.5)\n                ax.axhline(y=lmt_indv, color=clr_indv, linestyle='--', linewidth=1.5)\n\n            ttl = \" Bus={}, Voltage THD and Individual Harmonic Levels\".format(xnam)\n            ax.set_title(ttl)\n            ax.set_xlabel(\"Harmonic Order\")\n            ax.set_ylabel(\"%THD and % INDV\")\n            if flag_xtick:\n                ax.set_xticks(vdict['hord'])\n            h_lgd = ax.legend(title=\"IEEE 519 Limits\")\n            h_lgd.get_frame().set_linewi"
  },
  {
    "id": "chunk_1277",
    "text": " Limits\")\n            h_lgd.get_frame().set_linewidth(0)\n            h_lgd.set_draggable(True)\n\n            if outfigfile:\n                if figfiletyp=='pdf':\n                    pdfobj.savefig(fig, bbox_inches='tight')\n                elif figfiletyp=='pdfobj':\n                    try:\n                        pdfobj.savefig(fig, bbox_inches='tight')\n                    except:\n                        traceback.print_last()\n                else:\n                    pn, x = os.path.splitext(out"
  },
  {
    "id": "chunk_1278",
    "text": ":\n                    pn, x = os.path.splitext(outfigfile)\n                    tmpfnam = \"{}_thd_bus_{}{}\".format(pn,xnam,x)\n                    fig.savefig(tmpfnam, bbox_inches='tight')\n\n    if outfigfile:\n        if figfiletyp=='pdf':\n            pdfobj.close()\n\n        if figfiletyp=='pdfobj':\n            plt.close(fig=fig)\n        else:\n            if figfiletyp=='pdf':\n                print(\" Plots saved: {}\".format(outfigfile))\n            else:\n                pn, x = os.path.splitext(out"
  },
  {
    "id": "chunk_1279",
    "text": "else:\n                pn, x = os.path.splitext(outfigfile)\n                print(\" Plots saved: {}..., File Type={}\".format(pn, x[1:]))\n\n    if figfiletyp!='pdfobj':\n        if flag_show:\n            plt.show()\n        else:\n            plt.close('all')\n\n# =========================================================================\n\ndef test1():\n    \"\"\"Run Harmonics Analysis using IEEE Harmonics Test case.\n    Uses Example folder files.\n    Compare PSSE and TF distortion calculation results.\n    \"\""
  },
  {
    "id": "chunk_1280",
    "text": "PSSE and TF distortion calculation results.\n    \"\"\"\n    run_ieee_test()\n    compare_dstn_ieee_test()\n\ndef test1A():\n    \"\"\"Run Harmonics Analysis using IEEE Harmonics Test case.\n    Specify Load Models from API argument and specify them as inherit in harmonics data file.\n    Uses Example folder files.\n    \"\"\"\n    run_ieee_test_inherit()\n    compare_dstn_ieee_test(inherit=True)\n\ndef test1B():\n    \"\"\"Run Harmonics Analysis using IEEE Harmonics Test case.\n    Also specify thresholds to filter theve"
  },
  {
    "id": "chunk_1281",
    "text": " case.\n    Also specify thresholds to filter thevenin resonance frequencies.\n    Uses Example folder files.\n    \"\"\"\n    run_ieee_test_thevz_thresholds()\n\ndef test2():\n    \"\"\"Plot Harmonics Test PSSE Results.\n    Uses Example folder files.\n    \"\"\"\n    plot_fscan_ieee_test()\n\ndef test2A():\n    \"\"\"Plot Harmonics Test PSSE Results.\n    Also specify thresholds to filter thevenin resonance frequencies.\n    Uses Example folder files.\n    \"\"\"\n    plot_fscan_ieee_test(verbose=True, pctmx1=60.0, dpctpn1=7"
  },
  {
    "id": "chunk_1282",
    "text": "can_ieee_test(verbose=True, pctmx1=60.0, dpctpn1=75.0, pctmx2=20.0, dpctpn2=65.0)\n\ndef test3(figfiletyp='pdf', flag_show=True):\n    \"\"\"Plot Harmonics Test PSSE and harmonics Task Force Results.\n    Also specify thresholds to filter thevenin resonance frequencies.\n    Plot Distortion Calculation Results.\n    Uses Example folder files.\n    \"\"\"\n    plot_fscan_ieee_test_tf_psse(verbose=True, pctmx1=60.0, dpctpn1=75.0, pctmx2=20.0, dpctpn2=65.0, figfiletyp=figfiletyp, flag_show=flag_show)\n    plot_ds"
  },
  {
    "id": "chunk_1283",
    "text": "letyp=figfiletyp, flag_show=flag_show)\n    plot_dstn_ieee_test_volt_ieee519(figfiletyp=figfiletyp, flag_show=flag_show)\n\ndef test3A():\n    \"\"\"Plot Harmonics Test PSSE and harmonics Task Force Results.\n    Uses Example folder files.\n    \"\"\"\n    plot_fscan_ieee_test_tf_psse()\n\ndef test4():\n    \"\"\"Run Harmonics Analysis on Example folder 'sample' case.\n    Output Reports created in Report Window\n    \"\"\"\n    workdir  = os.path.dirname(__file__)\n    datapath = workdir\n    savfile  = os.path.join(data"
  },
  {
    "id": "chunk_1284",
    "text": "atapath = workdir\n    savfile  = os.path.join(datapath, \"sample.sav\")\n    harfile  = os.path.join(datapath, \"sample_har.rawx\")\n    run_har_analysis(savfile, harfile=harfile)\n\ndef test5():\n    \"\"\"Run Harmonics Analysis on Example folder 'sample_zils' case.\n    Output Reports created in 'outpath' folder with savfile name used for file name prefix.\n    \"\"\"\n    workdir  = os.path.dirname(__file__)\n    datapath = workdir\n    savfile  = os.path.join(datapath, \"sample_zils.sav\")\n    harfile  = os.path."
  },
  {
    "id": "chunk_1285",
    "text": "tapath, \"sample_zils.sav\")\n    harfile  = os.path.join(datapath, \"sample_zils_har.rawx\")\n    outpath  = os.path.join(workdir,  \"output_harmonics_demo\", \"sample_zils\")\n    run_har_analysis(savfile, harfile=harfile, outpath=outpath)\n\ndef test6():\n    \"\"\"Run Harmonics Analysis on Example folder 'sample_nb' case.\n    Output Reports created in 'outpath' folder with 'outfnam' used for file name prefix.\n    \"\"\"\n    workdir  = os.path.dirname(__file__)\n    datapath = workdir\n    savfile  = os.path.join("
  },
  {
    "id": "chunk_1286",
    "text": "   datapath = workdir\n    savfile  = os.path.join(datapath, \"sample_nb.sav\")\n    harfile  = os.path.join(datapath, \"sample_har.rawx\")\n    outfnam  = \"sample_nbXX\"\n    outpath  = os.path.join(workdir, \"output_harmonics_demo\", outfnam)\n    run_har_analysis(savfile, harfile=harfile, outpath=outpath, outfnam=outfnam)\n\ndef test7():\n    \"\"\"Run Harmonics Analysis on Example folder 'sample_zils_nb_sec' case.\n    Output Reports created in 'outpath' folder with 'outfnam' used for file name prefix.\n    Als"
  },
  {
    "id": "chunk_1287",
    "text": " with 'outfnam' used for file name prefix.\n    Also specified values to some API arguments.\n    \"\"\"\n    workdir  = os.path.dirname(__file__)\n    datapath = workdir\n    savfile  = os.path.join(datapath, \"sample_zils_nb_sec.sav\")\n    harfile  = os.path.join(datapath, \"sample_zils_har.rawx\")\n    outpath  = os.path.join(workdir, \"output_harmonics_demo\", \"sample_zils_nb_sec\")\n    run_har_analysis(savfile, harfile=harfile, outpath=outpath, linmdl=1,\n                     dstnrptop=1, imachimpop=1, dcim"
  },
  {
    "id": "chunk_1288",
    "text": "                   dstnrptop=1, imachimpop=1, dcimpop=1, triplenop=1)\n\ndef test8():\n    \"\"\"Run Harmonics Analysis on Example folder 'sample_zils_nb_sec' case.\n    Output Reports created in 'outpath' folder with 'outfnam' used for file name prefix.\n    Also specified values to some API arguments.\n    Do frequency scan on few buses.\n    \"\"\"\n    workdir  = os.path.dirname(__file__)\n    datapath = workdir\n    savfile  = os.path.join(datapath, \"sample_zils_nb_sec.sav\")\n    harfile  = os.path.join(dat"
  },
  {
    "id": "chunk_1289",
    "text": "_zils_nb_sec.sav\")\n    harfile  = os.path.join(datapath, \"sample_zils_har.rawx\")\n    outpath  = os.path.join(workdir, \"output_harmonics_demo\", \"sample_zils_nb_sec_few\")\n    run_har_analysis(savfile, 101, 212, 154, harfile=harfile, outpath=outpath, linmdl=1,\n                     dstnrptop=1, imachimpop=1, dcimpop=1, triplenop=1)\n\ndef test9():\n    \"\"\"Plot Frequency Scan, one file\n    \"\"\"\n    kwds = {}\n    kwds['basemva'] = 100.0\n    kwds['basekv']  = 21.6\n    kwds['basehz']  = 60.0\n    kwds['hmajo"
  },
  {
    "id": "chunk_1290",
    "text": " = 21.6\n    kwds['basehz']  = 60.0\n    kwds['hmajor']  = []\n    kwds['ymajor']  = []\n    kwds['ttl_lst'] = ['bus101_ohms (sample_zils_nb_sec_few)']\n    kwds['add_lgnd']= True\n    kwds['plotzpu'] = False\n    workdir  = os.path.dirname(__file__)\n    outpath  = os.path.join(workdir, \"output_harmonics_demo\", \"sample_zils_nb_sec_few\")\n    csvfile1 = os.path.join(outpath, \"sample_zils_nb_sec_fscan.csv\")\n    kwds['figfile'] = os.path.join(outpath, \"fscan_bus101_ohms.png\")\n    kwds['flag_show'] = True\n "
  },
  {
    "id": "chunk_1291",
    "text": "n_bus101_ohms.png\")\n    kwds['flag_show'] = True\n    plot_frequency_scan(101, csvfile1, **kwds)\n\ndef test10():\n    \"\"\"Plot Frequency Scan, two files\n    \"\"\"\n    kwds = {}\n    kwds['basemva'] = 100.0\n    kwds['basekv']  = 21.6\n    kwds['basehz']  = 60.0\n    kwds['hmajor']  = []\n    kwds['ymajor']  = []\n    kwds['ttl_lst'] = ['bus101_ohms (sample_zils_nb_sec_few)', 'bus101_ohms (sample_zils)']\n    kwds['add_lgnd']= True\n    kwds['plotzpu'] = False\n    workdir  = os.path.dirname(__file__)\n    outpa"
  },
  {
    "id": "chunk_1292",
    "text": "    workdir  = os.path.dirname(__file__)\n    outpath  = os.path.join(workdir, \"output_harmonics_demo\", \"sample_zils_nb_sec_few\")\n    csvfile1 = os.path.join(outpath, \"sample_zils_nb_sec_fscan.csv\")\n    outpath  = os.path.join(workdir, \"output_harmonics_demo\", \"sample_zils\")\n    csvfile2 = os.path.join(outpath, \"sample_zils_fscan.csv\")\n    kwds['figfile'] = os.path.join(outpath, \"fscan_bus101_ohms.pdf\")\n    kwds['flag_show'] = True\n    plot_frequency_scan(101, csvfile1, csvfile2, **kwds)\n\ndef tes"
  },
  {
    "id": "chunk_1293",
    "text": "ncy_scan(101, csvfile1, csvfile2, **kwds)\n\ndef test11():\n    \"\"\"Plot Frequency Scan, two files, figfiletype=pdfobj\n    \"\"\"\n    from matplotlib.backends.backend_pdf import PdfPages\n\n    kwds = {}\n    kwds['basemva'] = 100.0\n    kwds['basekv']  = 21.6\n    kwds['basehz']  = 60.0\n    kwds['hmajor']  = []\n    kwds['ymajor']  = []\n    kwds['ttl_lst'] = ['bus101_ohms (sample_zils_nb_sec_few)', 'bus101_ohms (sample_zils)']\n    kwds['add_lgnd']= True\n    kwds['plotzpu'] = False\n    workdir  = os.path.dir"
  },
  {
    "id": "chunk_1294",
    "text": "kwds['plotzpu'] = False\n    workdir  = os.path.dirname(__file__)\n    outpath  = os.path.join(workdir, \"output_harmonics_demo\", \"sample_zils_nb_sec_few\")\n    csvfile1 = os.path.join(outpath, \"sample_zils_nb_sec_fscan.csv\")\n    outpath  = os.path.join(workdir, \"output_harmonics_demo\", \"sample_zils\")\n    csvfile2 = os.path.join(outpath, \"sample_zils_fscan.csv\")\n\n    pdffile = os.path.join(outpath, \"fscan_bus101_ohms_2.pdf\")\n    pdfobj = PdfPages(pdffile)\n\n    kwds['figfiletyp'] = 'pdfobj'\n    kwds["
  },
  {
    "id": "chunk_1295",
    "text": "file)\n\n    kwds['figfiletyp'] = 'pdfobj'\n    kwds['figfile'] = pdfobj\n    kwds['flag_show'] = True\n\n    plot_frequency_scan(101, csvfile1, **kwds)\n    plot_frequency_scan(101, csvfile2, **kwds)\n\n    pdfobj.close()\n    print(\" Plots saved: {}\".format(pdffile))\n\n# ----------------------------\ndef _temp():\n    pass\n    # Available tests\n    # Note 1: Run tests 2, 2A, 3, 3A, 9, 10, 11 from outside of PSSE GUI.\n    # Note 2: Other tests can be run from inside as well as outside of PSSE GUI.\n    # Not"
  },
  {
    "id": "chunk_1296",
    "text": "m inside as well as outside of PSSE GUI.\n    # Note 3: Copy and Modify test4() and later tests to use on any SAV and HAR files.\n    #\n    test1()    # (a) Run Harmonics Analysis using IEEE Test case\n               # (b) Compare PSSE and TF distortion calculation results\n    test1A()   # (a) Run Harmonics Analysis using IEEE Test case, but use inherit load model in data file\n               # (b) Compare PSSE and TF distortion calculation results\n    test1B()   # Run Harmonics Analysis using IEEE "
  },
  {
    "id": "chunk_1297",
    "text": "   test1B()   # Run Harmonics Analysis using IEEE Test case and specify thresholds to filter thevenin resonance frequencies\n    test2()    # Plot IEEE Test case Frequency scan.\n    test2A()   # Plot IEEE Test case PSSE Results and specify thresholds to filter thevenin resonance frequencies\n    test3()    # (a) Plot Harmonics Test case PSSE and harmonics Task Force Frequency scan Results\n               #     with thresholds specified to filter thevenin resonance frequencies.\n               # (b) "
  },
  {
    "id": "chunk_1298",
    "text": "venin resonance frequencies.\n               # (b) Plot distortion calculation results.\n    test3A()   # Plot IEEE Test case PSSE and harmonics Task Force Results (default thresholds)\n    test4()    # Run Harmonics Analysis on Example folder 'sample' case, Output Reports created in Report Window\n    test5()    # Run Harmonics Analysis on Example folder 'sample_zils' case, Output Reports created in files\n    test6()    # Run Harmonics Analysis on Example folder 'sample_nb' case\n    test7()    # Ru"
  },
  {
    "id": "chunk_1299",
    "text": "xample folder 'sample_nb' case\n    test7()    # Run Harmonics Analysis on Example folder 'sample_zils_nb_sec' case\n    test8()    # Run Harmonics Analysis on Example folder 'sample_zils_nb_sec' case and frequency scan on few buses\n    test9()    # Plot Frequency Scan, one file [sample_zils_nb_sec_few]\n    test10()   # Plot Frequency Scan, two files [sample_zils_nb_sec_fscan, sample_zils_fscan]\n    test11()   # Plot Frequency Scan, two files, figfiletype=pdfobj\n\n    # To compare PSSE and IEEE Tes"
  },
  {
    "id": "chunk_1300",
    "text": "iletype=pdfobj\n\n    # To compare PSSE and IEEE Test Case Results, run following tests.\n    test1()    # Run Analysis\n    test3()    # Write DSTN results comparison report, plot FSCAN TF and PSSE results, plot DSTN results\n    # or run test3() with\n    # figfiletyp as below, so as to create png file that can be inserted into DOC report\n    # flag_show as below to create and save plots to files, do not show plots to the screen\n    test3(figfiletyp='png')\n    test3(figfiletyp='png', flag_show=False"
  },
  {
    "id": "chunk_1301",
    "text": "'png')\n    test3(figfiletyp='png', flag_show=False)\n\n# ==============================================================================\nif __name__==\"__main__\":\n    pass\n    # Modify following two lines as desired and run.\n    #import psse3506\n    #test1()    # Run Analysis\n#[harmonics_demo.py]    Harmonics Analysis in PSSE\n# =====================================================================================================\n'''This is an example file showing how to use arrbox.harmonics module to"
  },
  {
    "id": "chunk_1302",
    "text": "file showing how to use arrbox.harmonics module to post process\n   harmonic analysis results.\n\nHow to use this file?\n\nAs showed in __main__ (end of this file)\n- Enable PSSE version specific environment, as an example [where XX is psse version number]:\n    import psseXX\n\n- Refer ieee_test_pp function that shows\n    - how to get frequency scan results in python object\n    - how to get distortion calculation results in python object\n    - set desired voltage distortion limits\n    - create voltage d"
  },
  {
    "id": "chunk_1303",
    "text": "d voltage distortion limits\n    - create voltage distortion limits violations report\n    - plot and decorate frequency scan and voltage distortion results\n\n- Refer API manual arrbox > HAR_PP object for all available methods.\n'''\n\nimport os\nimport sys\n\n# =========================================================================\n\ndef ieee_test_pp(do_fscan_plts=False, do_dstn_plts=False, show_plts=False):\n    \"\"\"Run Harmonics Analysis using IEEE Harmonics Test case.\n    Uses Example folder files.\n  "
  },
  {
    "id": "chunk_1304",
    "text": "onics Test case.\n    Uses Example folder files.\n    \"\"\"\n\n    # Use from Example folder to run har_analysis.\n    import harmonics_demo\n\n    import arrbox.harmonics\n\n    outpath = os.path.dirname(__file__)\n    outpath = os.path.join(outpath, \"output_har_demo_arrbox\")\n    if not os.path.exists(outpath): os.makedirs(outpath)\n\n    harmonics_demo.run_ieee_test(outpath=outpath)\n\n    outpath2 = os.path.join(outpath, \"har_pp\")\n    if not os.path.exists(outpath2): os.makedirs(outpath2)\n\n    prgfile = os.p"
  },
  {
    "id": "chunk_1305",
    "text": "tpath2): os.makedirs(outpath2)\n\n    prgfile = os.path.join(outpath2, \"ieee_test_har_demo_arrbox_progress.txt\")\n    prgfile_fobj = open(prgfile, 'w')\n    progress = prgfile_fobj.write\n\n    harobj = arrbox.harmonics.HAR_PP(progress=progress)\n\n    # Frequency Scan Results\n    ierr = harobj.fscan_obj()\n    fscanobj = harobj.fscan\n\n    buses = list(fscanobj.bus.keys())\n    progress(\"fscanobj.ierr={}\\n\".format(fscanobj.ierr))\n    progress(\"fscanobj.hord=\\n{}\\n\".format(fscanobj.hord))\n\n    for b in bus"
  },
  {
    "id": "chunk_1306",
    "text": "d=\\n{}\\n\".format(fscanobj.hord))\n\n    for b in buses:\n        progress(\"Scanned Bus={}\\n\".format(b))\n        progress(\"{}\\n\".format(fscanobj['bus'][b].keys()))\n        progress(\"name={}, basekv={}\\n\".format(fscanobj.bus[b].name, fscanobj.bus[b].basekv))\n        progress(\"{}\\n\".format(fscanobj.bus[b].mag))\n        progress(\"{}\\n\".format(fscanobj.bus[b].phase))\n\n    # Distortion Calculation Results\n    ierr = harobj.dstn_obj()\n    dstn_vltobj = harobj.dstn.volt\n\n    progress(\"dstn_vltobj.keys()={}"
  },
  {
    "id": "chunk_1307",
    "text": "obj.dstn.volt\n\n    progress(\"dstn_vltobj.keys()={}\\n\".format(dstn_vltobj.keys()))\n\n    progress(\"dstn_vltobj.thd.bus={}\\n{}\\n\".format(len(dstn_vltobj.thd.bus), dstn_vltobj.thd.bus))\n    progress(\"dstn_vltobj.thd.pct={}\\n{}\\n\".format(len(dstn_vltobj.thd.pct), dstn_vltobj.thd.pct))\n\n    progress(\"dstn_vltobj.indv.bus={}\\n{}\\n\".format(len(dstn_vltobj.indv.bus), dstn_vltobj.indv.bus))\n    progress(\"dstn_vltobj.indv.hord_max={}\\n{}\\n\".format(len(dstn_vltobj.indv.hord_max), dstn_vltobj.indv.hord_max))"
  },
  {
    "id": "chunk_1308",
    "text": "vltobj.indv.hord_max), dstn_vltobj.indv.hord_max))\n    progress(\"dstn_vltobj.indv.pct_max={}\\n{}\\n\".format(len(dstn_vltobj.indv.pct_max), dstn_vltobj.indv.pct_max))\n\n    progress(\"dstn_vltobj.bus.keys()={}\\n\".format(dstn_vltobj.bus.keys()))\n    buslist = harobj.dstn.volt.bus\n    for bus in buslist:\n        basekv = harobj.dstn.volt.bus[bus].basekv\n        lmt_thd = harobj.dstn.volt.bus[bus].lmt_thd\n        lmt_indv = harobj.dstn.volt.bus[bus].lmt_indv\n\n        vdict = harobj.dstn.volt.bus[bus].h"
  },
  {
    "id": "chunk_1309",
    "text": "_indv\n\n        vdict = harobj.dstn.volt.bus[bus].hord\n        for hord, vdc2 in  vdict.items():\n            vr, vx, vmag, vang, pct  = vdc2.vr,  vdc2.vx, vdc2.vmag,  vdc2.vang, vdc2.pct\n            txt = \"{}, {}, {}, {}, {}, {}, {}, basekv={}, lmt_indv={}, lmt_thd={}\\n\".\\\n                  format(bus, hord, vr, vx, vmag, vang, pct, basekv, lmt_indv, lmt_thd)\n            progress(txt)\n\n    harobj.show_vlt_dstn_limits()\n\n    vlmt_dict = harobj.get_vlt_dstn_limits()\n    progress(\"vlmt_dict\\n\")\n    "
  },
  {
    "id": "chunk_1310",
    "text": "vlt_dstn_limits()\n    progress(\"vlmt_dict\\n\")\n    for lmtkv, vdct in vlmt_dict.items():\n        progress(\"   key={}, value={}\\n\".format(lmtkv, vdct))\n    progress('\\n')\n\n    progress(\"\\nVoltage violations report - rptoptn=0\\n\")\n    harobj.report_vlt_dstn_limits_violations(rptfile=None)\n\n    progress(\"\\nVoltage violations report - rptoptn=1\\n\")\n    harobj.report_vlt_dstn_limits_violations(rptoptn=1, rptfile=None)\n\n    progress(\"\\nVoltage violations report - rptoptn=2\\n\")\n    harobj.report_vlt_dst"
  },
  {
    "id": "chunk_1311",
    "text": "s report - rptoptn=2\\n\")\n    harobj.report_vlt_dstn_limits_violations(rptoptn=2, rptfile=None)\n\n    prgfile_fobj.close()\n    print(\" Progress Saved to file: {}\".format(prgfile))\n\n    # Frequency Scan Plots\n    if do_fscan_plts:\n        if not harobj.fscan.ierr:\n            fig1, ax1 = harobj.plot_fscan_mag(3, color='r')\n            fig1.savefig(\"zz_001.png\")\n\n            fig1, ax1 = harobj.plot_fscan_mag(3, color='r', marker='D', markevery=(0, 0.2))\n            harobj.plot_decorate(ax1, xmin=10)"
  },
  {
    "id": "chunk_1312",
    "text": "2))\n            harobj.plot_decorate(ax1, xmin=10)\n            fig1.savefig(\"zz_001-1.png\")\n\n            harobj.plot_decorate(ax1, add_legend=True)\n\n            if show_plts:\n                harobj.plot_show()\n            else:\n                harobj.plot_close()\n\n    # Distortion Calculation Plots\n    if do_dstn_plts:\n        if not harobj.dstn.ierr:\n            pdffile = os.path.join(outpath2, 'zplt_dstn_1.pdf')\n            harobj.plot_pdf_open(pdffile)\n            fig1, ax1 = harobj.plot_vlt_"
  },
  {
    "id": "chunk_1313",
    "text": "(pdffile)\n            fig1, ax1 = harobj.plot_vlt_dstn_thd(0, 1, optn_lmtgrp=True, optn_lmtlin=True)\n            #harobj.plot_decorate(ax1, add_legend=True)\n            #harobj.plot_decorate(ax1, add_legend=True, xticks='all')\n            harobj.plot_decorate(ax1, add_legend=True, xticks=[302, 301, 11, 3, 4])\n\n            fig2, ax2 = harobj.plot_vlt_dstn_indv(0, 1, optn_lmtgrp=True, optn_lmtlin=True)\n            harobj.plot_decorate(ax2, add_legend=True, xticks='all')\n\n            fig3, ax3 = ha"
  },
  {
    "id": "chunk_1314",
    "text": "nd=True, xticks='all')\n\n            fig3, ax3 = harobj.plot_vlt_dstn_bus(1)\n            harobj.plot_decorate(ax3, xscale='log', yscale='log')\n\n            harobj.plot_pdf_add_figure(fig1, fig2, fig3)\n            harobj.plot_pdf_close()\n\n            figfile = os.path.join(outpath2, 'zplt_dstn_2.pdf')\n            harobj.plot_save(figfile, fig1, fig2)\n\n            figfile = os.path.join(outpath2, 'zplt21_dstn')\n            harobj.plot_save(figfile, fig1)\n\n            figfile = os.path.join(outpath2"
  },
  {
    "id": "chunk_1315",
    "text": "fig1)\n\n            figfile = os.path.join(outpath2, 'zplt22_dstn')\n            harobj.plot_save(figfile, fig1, fig2)\n\n            figfile = os.path.join(outpath2, 'zplt23_dstn')\n            harobj.plot_save(figfile, fig1, fig2, fig3)\n\n            if show_plts:\n                harobj.plot_show()\n            else:\n                harobj.plot_close()\n\n# =========================================================================\ndef _temp():\n    pass\n    ieee_test_pp()\n    ieee_test_pp(do_fscan_plts=T"
  },
  {
    "id": "chunk_1316",
    "text": "   ieee_test_pp()\n    ieee_test_pp(do_fscan_plts=True, do_dstn_plts=True, show_plts=True)\n\n# ==============================================================================\nif __name__==\"__main__\":\n    pass\n    # Modify following two lines as desired and run.\n    #import psse3506\n    #ieee_test_pp()\n#[iec60909_testnetwork_calculations.py]    Calculation of IEC Test Network 3 Phase Fault Currents by Network Reduction\n# ==============================================================================="
  },
  {
    "id": "chunk_1317",
    "text": "========================================================================\n'''\nThis file calculates 3 Phase Fault Currents for IEC Test Network (IEC 60909-4, Figure 16) by network reduction.\nRefer to Program Application Guide, Volume I, Chapter 10 for schematics and equations.\nIt uses network data from IEC 60909-4 Table 11.\nThis impedance data (corrected if necessary) of the electrical equipment\n(see figure 16) is referred to the 110 kV side. Z(2) = Z(1) = Z\nResults from these calculations are com"
  },
  {
    "id": "chunk_1318",
    "text": "= Z(1) = Z\nResults from these calculations are compared against results from PSS(R)E and those provided in\nIEC 60909-4 Table 12.\n'''\n\nimport os, math, time\nsqrt3 = math.sqrt(3.0)\nsbase = 100.0     # MVA\n\nstr_time = time.strftime(\"%Y%m%d_%H%M%S_\", time.localtime())\nfnamout  = str_time + 'iec60909_testnetwork_calculations.txt'\nfnamout  = os.path.join(os.getcwd(),fnamout)\nfoutobj  = open(fnamout,'w')\n\n# =================================================================================\ndef format_com"
  },
  {
    "id": "chunk_1319",
    "text": "===================================\ndef format_complex(v):\n    vre = v.real\n    vim = abs(v.imag)\n    if v.imag<0:\n        sgn = '-'\n    else:\n        sgn = '+'\n    retv = '%-10.6g %s j %-10.6g' % (vre, sgn, vim)\n    return retv\n\ndef format_z_ratio(vlst,method=None):\n    retvlst = []\n    for v in vlst:\n        vstr = format_complex(v)\n        xbyr = v.imag/v.real\n        if method=='C':\n            xbyr = xbyr/0.4\n        elif method=='DC':\n            xbyr = xbyr/0.055\n        retv = '%s, %-10."
  },
  {
    "id": "chunk_1320",
    "text": "       xbyr = xbyr/0.055\n        retv = '%s, %-10.6g' % (vstr, xbyr)\n        retvlst.append(retv)\n    return retvlst\n\ndef print_complex(nam, v):\n    vstr = format_complex(v)\n    retv = '%-7s = %s\\n' % (nam, vstr)\n    #print retv.strip()\n    return retv\n\ndef print_impedance_xr_ratio(nam, v, adj=1.0):\n    vstr = format_complex(v)\n    xbyr = adj*v.imag/v.real\n    if adj!=1.0:\n        retv = '%-6s = %s  X/R adj = %-10.6g\\n' % (nam, vstr, xbyr)\n    else:\n        retv = '%-6s = %s  X/R     = %-10.6g\\n"
  },
  {
    "id": "chunk_1321",
    "text": "se:\n        retv = '%-6s = %s  X/R     = %-10.6g\\n' % (nam, vstr, xbyr)\n    print(retv.strip())\n    return retv\n\ndef print_fault_current(nam,v):\n    vrect = format_complex(v)\n    vmag = abs(v)\n    vang = math.degrees(math.atan(v.imag/v.real))\n    #retv = '%-6s = %s    OR %-10.6g / %-5.2g deg\\n' % (nam, vrect, vmag, vang)\n    retv = '%-6s = %-10.6g\\n' % (nam, vmag)\n    print(retv.strip())\n    return retv\n\n# =================================================================================\n\ndef pri"
  },
  {
    "id": "chunk_1322",
    "text": "=========================================\n\ndef print_z():\n    dat_from_table11 = True\n    txt = ''\n    txt  += print_complex('zq1',    zq1)\n    txt  += print_complex('zq1t',   zq1t)\n    txt  += print_complex('zq2',    zq2)\n    txt  += print_complex('zt3amv', zt3amv)\n    txt  += print_complex('zt3bmv', zt3bmv)\n    txt  += print_complex('zt3cmv', zt3cmv)\n    txt  += print_complex('zt5mv',  zt5mv)\n    if not dat_from_table11:\n        txt  += print_complex('zt1mv',  zt1mv)\n        txt  += print_comp"
  },
  {
    "id": "chunk_1323",
    "text": "omplex('zt1mv',  zt1mv)\n        txt  += print_complex('zg1',    zg1)\n        txt  += print_complex('zg1t',   zg1t)\n    txt  += print_complex('zs1',     zs1)\n    if not dat_from_table11:\n        txt  += print_complex('zt2mv',  zt2mv)\n        txt  += print_complex('zg2',    zg2)\n        txt  += print_complex('zg2t',   zg2t)\n    txt  += print_complex('zs2',    zs2)\n    txt  += print_complex('zg3',    zg3)\n    txt  += print_complex('zg3t',   zg3t)\n    txt  += print_complex('zm1',    zm1)\n    txt  +="
  },
  {
    "id": "chunk_1324",
    "text": "  txt  += print_complex('zm1',    zm1)\n    txt  += print_complex('zm1t',   zm1t)\n    txt  += print_complex('zm2',    zm2)\n    txt  += print_complex('zm2t',   zm2t)\n    txt  += print_complex('zl1',    zl1)\n    txt  += print_complex('zl2',    zl2)\n    txt  += print_complex('zl3',    zl3)\n    txt  += print_complex('zl4',    zl4)\n    txt  += print_complex('zl5',    zl5)\n    txt  += print_complex('zl6',    zl6)\n    txt  += print_complex('zl6t',   zl6t)\n    return txt\n\ndef print_network_reduction_z(tx"
  },
  {
    "id": "chunk_1325",
    "text": ")\n    return txt\n\ndef print_network_reduction_z(txstr,zdct):\n    for k,v in list(zdct.items()):\n        txstr += print_complex(k,v)\n    return txstr\n\n# =================================================================================\n\ndef table11_data(xftr,peak=False):\n    # peak = True, calculations are for Peak current, use Rgf for generators.\n    \n    global zq1, zq1t, zq2, zt3amv, zt3bmv, zt3cmv, zt5mv, zs1\n    global zs2, zg3, zg3t, zm1, zm1t, zm2, zm2t\n    global zl1, zl2, zl3, zl4, zl5, z"
  },
  {
    "id": "chunk_1326",
    "text": "t, zm2, zm2t\n    global zl1, zl2, zl3, zl4, zl5, zl6, zl6t\n\n    # TABLE 11 Data\n    zq1    =  0.631933 +   6.319335j\n    zq1t   =  0.056874 +   0.568740j\n    zq2    =  0.434454 +   4.344543j\n\n    zt3amv =  0.045714 +   8.096989j\n    zt3bmv =  0.053563 -   0.079062j\n    zt3cmv =  0.408568 +  20.292035j\n\n    zt5mv  =  2.046454 +  49.072241j\n\n    # power station unit 1 data\n    #Ks       = 0.995975\n    #zg1t     = (0.059977324263+12.3433333333j)\n    #zg1t*Ks  = (0.0597359155329+12.2936514167j)\n    "
  },
  {
    "id": "chunk_1327",
    "text": " #zg1t*Ks  = (0.0597359155329+12.2936514167j)\n    #zt1mv*Ks = (0.439058979167+14.0430253611j)\n    #zs1 = Ks*(zg1t + zt1mv) = (0.4987948947+26.3366767778j)\n\n    Ks1    =  0.995975\n    zg1    =  0.059977 +  12.343333j\n    zg1c   =  0.059736 +  12.293651j\n    zt1c   =  0.439059 +  14.043025j\n    #zs1    =  0.498795 +  26.336676j\n    zs1    =  zg1c + zt1c\n\n    # power station unit 2 data\n    #Ks       = 0.876832\n    #zg2t     = (0.65306122449+23.04j)\n    #zg2t*Ks  = (0.572624979592+20.20220928j)\n   "
  },
  {
    "id": "chunk_1328",
    "text": "\n    #zg2t*Ks  = (0.572624979592+20.20220928j)\n    #zt2mv*Ks = (0.63131904+15.1384987665j)\n    #zs2 = Ks*(zg2t + zt2mv) = (1.20394401959+35.3407080465j)\n\n    Ks2    =  0.876832\n    zg2    =  0.653061 +  23.04j\n    zg2c   =  0.572625 +  20.202214j\n    zt2c   =  0.631319 +  15.138499j\n    #zs2    =  1.203944 +  35.340713j\n    zs2    =  zg2c + zt2c\n\n    zg3    =  0.017790 +   1.089623j\n    zg3t   =  2.133964 + 130.705301j\n\n    zm1    =  0.341497 +   3.414968j\n    zm1t   = 40.964124 + 409.641243j\n  "
  },
  {
    "id": "chunk_1329",
    "text": " 3.414968j\n    zm1t   = 40.964124 + 409.641243j\n    zm2    =  0.412137 +   4.121368j\n    zm2t   = 49.437719 + 494.377190j\n\n    zl1    = 2.4   + 7.8j\n    zl2    = 1.2   + 3.9j\n    zl3    = 0.3   + 0.975j\n    zl4    = 0.96  + 3.88j\n    zl5    = 1.8   + 5.79j\n    zl6    = 0.082 + 0.086j\n    zl6t   = 9.836281 + 10.316100j\n\n    # Fictitious resistances RGf may be used for the calculation of the peak short circuit current\n    # RGf = 0.05 X''d for generators with UrG > 1 kV and SrG >= 100 MVA\n    # RG"
  },
  {
    "id": "chunk_1330",
    "text": "rators with UrG > 1 kV and SrG >= 100 MVA\n    # RGf = 0.07 X''d for generators with UrG > 1 kV and SrG < 100 MVA\n    # RGf = 0.15 X''d for generators with UrG <= 1 000 V\n    if peak:\n        # G1 -> 150 MVA, 21 kV\n        # G2 -> 100 MVA, 10.5 kV\n        # RGf = 0.05 X''d\n        zg1  = complex(0.05*zg1.imag, zg1.imag)\n        zg1c = zg1*Ks1\n        zs1  = zg1c + zt1c\n\n        zg2  = complex(0.05*zg2.imag, zg2.imag)\n        zg2c = zg2*Ks2\n        zs2  = zg2c + zt2c\n\n        zg3  = complex(0.07*z"
  },
  {
    "id": "chunk_1331",
    "text": " zs2  = zg2c + zt2c\n\n        zg3  = complex(0.07*zg3.imag, zg3.imag)\n        zg3t = complex(0.07*zg3t.imag, zg3t.imag)\n\n    if xftr != 1.0:\n        zq1    = complex(zq1.real,    zq1.imag*xftr)\n        zq1t   = complex(zq1t.real,   zq1t.imag*xftr)\n        zq2    = complex(zq2.real,    zq2.imag*xftr)\n        zt3amv = complex(zt3amv.real, zt3amv.imag*xftr)\n        zt3bmv = complex(zt3bmv.real, zt3bmv.imag*xftr)\n        zt3cmv = complex(zt3cmv.real, zt3cmv.imag*xftr)\n        zt5mv  = complex(zt5mv.r"
  },
  {
    "id": "chunk_1332",
    "text": "zt3cmv.imag*xftr)\n        zt5mv  = complex(zt5mv.real,  zt5mv.imag*xftr)\n        zs1    = complex(zs1.real,    zs1.imag*xftr)\n        zs2    = complex(zs2.real,    zs2.imag*xftr)\n        zg3    = complex(zg3.real,    zg3.imag*xftr)\n        zg3t   = complex(zg3t.real,   zg3t.imag*xftr)\n        zm1    = complex(zm1.real,    zm1.imag*xftr)\n        zm1t   = complex(zm1t.real,   zm1t.imag*xftr)\n        zm2    = complex(zm2.real,    zm2.imag*xftr)\n        zm2t   = complex(zm2t.real,   zm2t.imag*xftr)\n"
  },
  {
    "id": "chunk_1333",
    "text": "    zm2t   = complex(zm2t.real,   zm2t.imag*xftr)\n        zl1    = complex(zl1.real,    zl1.imag*xftr)\n        zl2    = complex(zl2.real,    zl2.imag*xftr)\n        zl3    = complex(zl3.real,    zl3.imag*xftr)\n        zl4    = complex(zl4.real,    zl4.imag*xftr)\n        zl5    = complex(zl5.real,    zl5.imag*xftr)\n        zl6    = complex(zl6.real,    zl6.imag*xftr)\n        zl6t   = complex(zl6t.real,   zl6t.imag*xftr)\n\n# ==========================================================================="
  },
  {
    "id": "chunk_1334",
    "text": "========================================================\n\ndef parallel(zp,zq):\n    return (zp*zq)/(zp+zq)\n\ndef calculate_3ph_fault_zthev():\n    # Reduction at Bus 5\n    z7g  = parallel(zm1t, zm2t)\n    z6g1 = zl6t + z7g\n    z6g2 = parallel(zg3t, z6g1)\n    z56  = zt5mv/2.0\n    z5g1 = z56 + z6g2\n    z5g2 = parallel(zq2, z5g1)\n\n    rdzstr = ''\n    rdzstr = print_network_reduction_z(rdzstr,{'z7g':z7g, 'z6g1':z6g1, 'z6g2':z6g2, 'z56':z56, 'z5g1':z5g1, 'z5g2':z5g2})\n\n    # Reduction at Bus 2\n    z12t3 "
  },
  {
    "id": "chunk_1335",
    "text": "'z5g2':z5g2})\n\n    # Reduction at Bus 2\n    z12t3   = zt3amv + zt3bmv\n    z12t3t4 = z12t3/2.0\n    z2g1    = zq1t + z12t3t4\n    \n    rdzstr = print_network_reduction_z(rdzstr,{'z12t3':z12t3, 'z12t3t4':z12t3t4, 'z2g1':z2g1})\n\n    # delta to star of buses 2, 3, 5, star point=N1\n    zden1 = zl1 + zl3 + zl4\n    za    = (zl1*zl3) / zden1\n    zb    = (zl1*zl4) / zden1\n    zc    = (zl3*zl4) / zden1\n\n    rdzstr = print_network_reduction_z(rdzstr,{'za':za, 'zb':zb, 'zc':zc})\n\n    # star to delta of buses "
  },
  {
    "id": "chunk_1336",
    "text": " 'zb':zb, 'zc':zc})\n\n    # star to delta of buses N1, 3, 4, and ground\n    znum1 = zb*zs2 + zb*zl2 + zs2*zl2\n    zd = znum1/zs2\n    ze = znum1/zl2\n    zf = znum1/zb\n\n    rdzstr = print_network_reduction_z(rdzstr,{'zd':zd, 'ze':ze, 'zf':zf})\n\n    # delta to star of buses N1, 4, 5, star point=N2\n    zden2 = zc + zd + zl5\n    zg    = (zc*zd)  / zden2\n    zh    = (zd*zl5) / zden2\n    zi    = (zc*zl5) / zden2\n\n    rdzstr = print_network_reduction_z(rdzstr,{'zg':zg, 'zh':zh, 'zi':zi})\n\n    # Zthev at "
  },
  {
    "id": "chunk_1337",
    "text": "zstr,{'zg':zg, 'zh':zh, 'zi':zi})\n\n    # Zthev at Bus 4\n    z1    = z2g1 + za\n    z2    = parallel(z1, ze)\n    z3    = z2 + zg\n    z4    = zi + z5g2\n    z5    = parallel(z3, z4)\n    z6    = z5 + zh\n    z7    = parallel(z6,zf)\n    zthv4 = parallel(z7, zs1)\n\n    rdzstr = print_network_reduction_z(rdzstr,{'z1':z1, 'z2':z2, 'z3':z3, 'z4':z4, 'z5':z5, 'z6':z6, 'z7':z7})\n\n    # Zthev at Bus 5\n    z8    = parallel(zs1,zf)\n    z9    = z8 + zh\n    z10   = parallel(z3,z9)\n    z11   = zi + z10\n    zthv5 = "
  },
  {
    "id": "chunk_1338",
    "text": " parallel(z3,z9)\n    z11   = zi + z10\n    zthv5 = parallel(z11, z5g2)\n\n    rdzstr = print_network_reduction_z(rdzstr,{'z8':z8, 'z9':z9, 'z10':z10, 'z11':z11})\n\n    # Zthev at Bus 2\n    z12   = parallel(z4,z9)\n    z13   = z12 + zg\n    z14   = parallel(z13,ze)\n    z15   = za + z14\n    zthv2 = parallel(z15, z2g1)\n\n    rdzstr = print_network_reduction_z(rdzstr,{'z12':z12, 'z13':z13, 'z14':z14, 'z15':z15})\n\n    # Zthev at Bus 1\n    z16   = z15 + z12t3t4\n    z17   = z16*(400.*400.)/(120.*120.)\n    zth"
  },
  {
    "id": "chunk_1339",
    "text": "t4\n    z17   = z16*(400.*400.)/(120.*120.)\n    zthv1 = parallel(z17, zq1)\n\n    rdzstr = print_network_reduction_z(rdzstr,{'z16':z16, 'z17':z17})\n\n    # Zthev at Bus 6\n    zt5lv = zt5mv*(10.5*10.5)/(115.0*115.0)\n    z21   = parallel(z11, zq2)\n    z21lv = z21*(10.5*10.5)/(115.0*115.0)\n    z22   = z21lv + zt5lv*0.5\n    z24   = parallel(zm1, zm2)\n    z25   = zl6 + z24\n    z26   = parallel(zg3, z25)\n    zthv6 = parallel(z22, z26)\n\n    rdzstr = print_network_reduction_z(rdzstr,{'zt5lv':zt5lv, 'z21':z2"
  },
  {
    "id": "chunk_1340",
    "text": "etwork_reduction_z(rdzstr,{'zt5lv':zt5lv, 'z21':z21, 'z21lv':z21lv, 'z22':z22, 'z24':z24, 'z25':z25, 'z26':z26})\n\n    # Zthev at Bus 7\n    z27   = parallel(z22, zg3)\n    z28   = z27 + zl6\n    zthv7 = parallel(z28, z24)\n\n    rdzstr = print_network_reduction_z(rdzstr,{'z27':z27, 'z28':z28})\n\n    zthev = [zthv1, zthv2, zthv4, zthv5, zthv6, zthv7]\n    \n    return zthev, rdzstr\n\n# =================================================================================\n\ndef calculate_3ph_fault_ik(zthev):\n\n  "
  },
  {
    "id": "chunk_1341",
    "text": "==========\n\ndef calculate_3ph_fault_ik(zthev):\n\n    zthv1 = zthev[0]\n    zthv2 = zthev[1]\n    zthv4 = zthev[2]\n    zthv5 = zthev[3]\n    zthv6 = zthev[4]\n    zthv7 = zthev[5]\n\n    vflt = 1.1*110.0/sqrt3\n    if2   = vflt/zthv2\n    if4   = vflt/zthv4\n    if5   = vflt/zthv5\n\n    vflt1 = 1.1*380.0/sqrt3\n    if1   = vflt1/zthv1\n\n    vfl67 = 1.1*10.0/sqrt3\n    if6   = vfl67/zthv6\n    if7   = vfl67/zthv7\n\n    ik = [if1, if2, if4, if5, if6, if7]\n    return ik\n\n# =========================================="
  },
  {
    "id": "chunk_1342",
    "text": "n ik\n\n# =================================================================================\n\ndef calculate_k_factor_method_B(bus,zc):\n    r = zc.real\n    x = zc.imag\n    rx = r/x\n    rbyx = -3.0*rx\n    k = 1.02 + 0.98*math.exp(rbyx)\n    if bus==7: k = k*1.15   # add safety factor for bus 7 faults\n    if k>2.0: k=2.0\n    return k    \n    \ndef calculate_k_factor_method_C(zc):\n    r = zc.real\n    x = zc.imag\n    rx = r/x\n    rbyx = 0.4*rx\n    rbyx = -3.0*rbyx\n    k = 1.02 + 0.98*math.exp(rbyx)\n    #p"
  },
  {
    "id": "chunk_1343",
    "text": "3.0*rbyx\n    k = 1.02 + 0.98*math.exp(rbyx)\n    #print 'K factor for r/x=%f, is k=%f' % (rbyx,k)\n    return k\n\ndef calculate_ip(buslst,iklst,zclst,method):\n    klst  = []\n    iplst = []\n    for bus,ik,zc in zip(buslst,iklst,zclst):\n        ik = abs(ik)\n        if method=='B':\n            k  = calculate_k_factor_method_B(bus,zc)\n        if method=='C':\n            k  = calculate_k_factor_method_C(zc)\n        ip = k*math.sqrt(2.0)*ik\n        klst.append(k)\n        iplst.append(ip)\n\n    return klst"
  },
  {
    "id": "chunk_1344",
    "text": "ppend(k)\n        iplst.append(ip)\n\n    return klst, iplst\n\ndef back_calculate_k(iklst,iplst):\n    klst = []\n    for ik,ip in zip(iklst,iplst):\n        # ip=k*sprt(2)*ik\n        k = ip/(math.sqrt(2)*ik)\n        klst.append(k)\n    return klst\n\ndef calculate_idc(iklst,zlst):\n    # idc = sprt(2)*ik*e^(-2piftR/X)\n    idclst = []\n    for ik,z in zip(iklst,zlst):\n        r = z.real\n        x = z.imag\n        rx = r/x\n        rx = 0.055*rx\n        rbyx = -2.0*math.pi*50.0*0.1*rx\n        k = math.exp(rby"
  },
  {
    "id": "chunk_1345",
    "text": " -2.0*math.pi*50.0*0.1*rx\n        k = math.exp(rbyx)\n        idc = math.sqrt(2)*abs(ik)*k\n        #print 'dc component: z, k, abs(ik), idc = ',z,k,abs(ik),idc\n        idclst.append(idc)\n    return idclst\n    \n# =================================================================================\n\nfoutobj.write('IEC 60909-4:2000 Figure 16 (Page 121) 3-phase Fault Calculations with Network reduction')\nfoutobj.write(' '+time.asctime())\nfoutobj.write('\\n')\n\nbuses = [1,2,4,5,6,7]\n\n# Base frequency calcul"
  },
  {
    "id": "chunk_1346",
    "text": "')\n\nbuses = [1,2,4,5,6,7]\n\n# Base frequency calculations\nxftr = 1.0\ntable11_data(xftr)\nbase_z = print_z()\n\nzthev_bas, rdzstr_bas = calculate_3ph_fault_zthev()\n\nik_bas = calculate_3ph_fault_ik(zthev_bas)\n\n# Method B\n# Method B peak currents are worse (compared to results in standard) when Rgf is used.\n#xftr = 1.0\n#table11_data(xftr,peak=True)\n#mthdB_z = print_z()\n#zthev_b, rdzstr_b = calculate_3ph_fault_zthev()\n#k_b, ip_b = calculate_ip(buses,ik_bas,zthev_b,method='B')\nk_b, ip_b = calculate_ip(bu"
  },
  {
    "id": "chunk_1347",
    "text": "as,zthev_b,method='B')\nk_b, ip_b = calculate_ip(buses,ik_bas,zthev_bas,method='B')\n\n# Method C\nxftr = 20.0/50.0\ntable11_data(xftr,peak=True)\nmthdC_z = print_z()\n\nzthev_c, rdzstr_c = calculate_3ph_fault_zthev()\nk_c, ip_c = calculate_ip(buses,ik_bas,zthev_c,method='C')\n\n# DC Component\n# tmin=0.1 s, f*t = 50*0.1 = 5, fc/f=0.055\nxftr = 0.055\ntable11_data(xftr,peak=False)\ndc_z = print_z()\n\nzthev_dc, rdzstr_dc = calculate_3ph_fault_zthev()\nidc_cal = calculate_idc(ik_bas,zthev_dc)\n\n# Table 12 from Stan"
  },
  {
    "id": "chunk_1348",
    "text": "lculate_idc(ik_bas,zthev_dc)\n\n# Table 12 from Standard\nik1_tbl12   = 40.6447\nip1_b_tbl12 = 100.5766\nip1_c_tbl12 = 100.5677\nib1_tbl12   = 40.645\n\nik2_tbl12   = 31.7831\nip2_b_tbl12 = 80.8249\nip2_c_tbl12 = 80.6079\nib2_tbl12   = 31.570\n\nik4_tbl12   = 16.2277\nip4_b_tbl12 = 36.8041\nip4_c_tbl12 = 36.8427\nib4_tbl12   = 16.017\n\nik5_tbl12   = 33.1894\nip5_b_tbl12 = 83.6266\nip5_c_tbl12 = 83.4033\nib5_tbl12   = 32.795\n\nik6_tbl12   = 37.5629\nip6_b_tbl12 = 99.1910\nip6_c_tbl12 = 98.1434\nib6_tbl12   = 34.028\n\nik7"
  },
  {
    "id": "chunk_1349",
    "text": "10\nip6_c_tbl12 = 98.1434\nib6_tbl12   = 34.028\n\nik7_tbl12   = 25.5895\nip7_b_tbl12 = 51.3864*1.15\nip7_c_tbl12 = 51.6899\nib7_tbl12   = 23.212\n\nik_tbl12   = [ik1_tbl12,   ik2_tbl12,   ik4_tbl12,   ik5_tbl12,   ik6_tbl12,   ik7_tbl12  ] \nip_b_tbl12 = [ip1_b_tbl12, ip2_b_tbl12, ip4_b_tbl12, ip5_b_tbl12, ip6_b_tbl12, ip7_b_tbl12] \nip_c_tbl12 = [ip1_c_tbl12, ip2_c_tbl12, ip4_c_tbl12, ip5_c_tbl12, ip6_c_tbl12, ip7_c_tbl12] \nib_tbl12   = [ib1_tbl12,   ib2_tbl12,   ib4_tbl12,   ib5_tbl12,   ib6_tbl12,   ib"
  },
  {
    "id": "chunk_1350",
    "text": "tbl12,   ib4_tbl12,   ib5_tbl12,   ib6_tbl12,   ib7_tbl12  ] \n\nk_b_tbl12  = back_calculate_k(ik_tbl12,ip_b_tbl12)\nk_c_tbl12  = back_calculate_k(ik_tbl12,ip_c_tbl12)\n\n# PSS(R)E Results\n# Bus Nums      1        2        4        5        6       7\nik_psse  = [ 40.6447, 31.7830, 16.2277, 33.1894, 37.5628, 25.5894]\nipb_psse = [100.5766, 80.5119, 36.8041, 83.6265, 99.1908, 59.0943]\nipc_psse = [100.5676, 80.6079, 36.8427, 83.4033, 98.1432, 51.6898]\nidc_psse = [  2.7396, 12.7917,  2.6296,  3.9796, 15.1"
  },
  {
    "id": "chunk_1351",
    "text": "_psse = [  2.7396, 12.7917,  2.6296,  3.9796, 15.1072,  0.0671]\nibs_psse = [ 40.6426, 31.5777, 16.0211, 32.8065, 34.0131, 23.1936]\niba_psse = [ 40.7348, 34.0702, 16.2354, 33.0470, 37.2171, 23.1937]\n\n# Print Base frequency and Method C impedances\nbase_z_lst  = base_z.split('\\n')\nmthdC_z_lst = mthdC_z.split('\\n')\ndc_z_lst = dc_z.split('\\n')\n\nrdzstr_bas_lst = rdzstr_bas.split('\\n')\nrdzstr_c_lst   = rdzstr_c.split('\\n')\nrdzstr_dc_lst  = rdzstr_dc.split('\\n')\n\nhdr = r\"\"\"NETWORK ELEMENT IMPEDANCES in "
  },
  {
    "id": "chunk_1352",
    "text": "it('\\n')\n\nhdr = r\"\"\"NETWORK ELEMENT IMPEDANCES in OHMS (COMPARE this to TABLE 11, PP 127)\n|---------- BASE FREQUENCY ------|   |  |---- METHOD C FREQ (fc/f=0.4)---|   |  |--- DC COMPONENT (fc/f=0.055)---|\"\"\"\nfoutobj.write(hdr)\nfoutobj.write('\\n')\n\nfor v1,v2,v3 in zip(base_z_lst, mthdC_z_lst,dc_z_lst):\n    if not v1: continue\n    txt = v1 + '  |  ' + v2 + '  |  ' + v3 + '\\n'\n    foutobj.write(txt)\n    \n\nhdr = r\"\"\"\nNETWORK REDUCTION  CALCULATION IMPEDANCES in OHMS \n|---------- BASE FREQUENCY -----"
  },
  {
    "id": "chunk_1353",
    "text": "PEDANCES in OHMS \n|---------- BASE FREQUENCY ------|   |  |---- METHOD C FREQ (fc/f=0.4)---|   |  |--- DC COMPONENT (fc/f=0.055)---|\"\"\"\nfoutobj.write(hdr)\nfoutobj.write('\\n')\n\nfor v1,v2,v3 in zip(rdzstr_bas_lst, rdzstr_c_lst, rdzstr_dc_lst):\n    if not v1: continue\n    txt = v1 + '  |  ' + v2 + '  |  ' + v3 + '\\n'\n    foutobj.write(txt)\n\nhdr = r\"\"\"\nThevenin Impedance in OHMS calculated with NETWORK REDUCTION (R+jX, X/R ratio)\n|BUS| |---------- BASE FREQUENCY --------|    |   |----- METHOD C FREQ"
  },
  {
    "id": "chunk_1354",
    "text": "SE FREQUENCY --------|    |   |----- METHOD C FREQ (fc/f=0.4)----|    |   |---- DC COMPONENT (fc/f=0.055)----|\"\"\"\nfoutobj.write(hdr)\nfoutobj.write('\\n')\n\nzstrlst_bas = format_z_ratio(zthev_bas)\nzstrlst_c   = format_z_ratio(zthev_c,method='C')\nzstrlst_dc  = format_z_ratio(zthev_dc,method='DC')\nfor b,zstr, zstr_c, zstr_dc in zip(buses,zstrlst_bas,zstrlst_c,zstrlst_dc):\n    foutobj.write('  %d    %s       %s       %s' % (b, zstr, zstr_c, zstr_dc))\n    foutobj.write('\\n')\n\n\nhdr =\"\"\"\n METHOD        B"
  },
  {
    "id": "chunk_1355",
    "text": "   foutobj.write('\\n')\n\n\nhdr =\"\"\"\n METHOD        BUS    I\"k       K ip(50)     ip(50)     K ip(20)     ip(20)      Ib dc\"\"\"\nfoutobj.write(hdr)\nfoutobj.write('\\n')\n\nfor b1,ik,kb,ipb,kc,ipc,idc,ik_t,kb_t,ipb_t,kc_t,ipc_t,ik_e,ipb_e,ipc_e,idc_e in zip(buses, ik_bas, k_b, ip_b, k_c, ip_c, idc_cal,\n                                                            ik_tbl12, k_b_tbl12, ip_b_tbl12, k_c_tbl12, ip_c_tbl12,\n                                                            ik_psse, ipb_psse, ipc_psse, "
  },
  {
    "id": "chunk_1356",
    "text": "                     ik_psse, ipb_psse, ipc_psse, idc_psse):\n    ikabs = abs(ik)\n    s1    = ' '\n    lin1 = \" CALCULATED   %(b1)3d   %(ikabs)-10.4f   %(kb)-10.4f %(ipb)-10.4f   %(kc)-10.4f %(ipc)-10.4f   %(idc)-10.4f\" % vars()\n    lin2 = \" PSS(R)E      %(s1)3s   %(ik_e)-10.4f   %(s1)10s %(ipb_e)-10.4f   %(s1)10s %(ipc_e)-10.4f   %(idc_e)-10.4f\" % vars()\n    lin3 = \" STANDARD     %(s1)3s   %(ik_t)-10.4f   %(kb_t)-10.4f %(ipb_t)-10.4f   %(kc_t)-10.4f %(ipc_t)-10.4f\" % vars()\n    foutobj.write(lin1"
  },
  {
    "id": "chunk_1357",
    "text": "4f %(ipc_t)-10.4f\" % vars()\n    foutobj.write(lin1)\n    foutobj.write('\\n')\n\n    foutobj.write(lin2)\n    foutobj.write('\\n')\n\n    foutobj.write(lin3)\n    foutobj.write('\\n\\n')\n\nfoutobj.close()    \n\nmsg = \" Results saved in file: %s\" % fnamout\nprint(msg)\n# =================================================================================\n#[iecs_demo.py]   Fault Calculations using IECS\n# =====================================================================================================\n'''There a"
  },
  {
    "id": "chunk_1358",
    "text": "=======================================\n'''There are three different ways to calculate faults using IECS.\n1) Using activity IECS (psspy.iecs_4)\n   Runs all types of faults, creates text reports, but no access to results from Python script.\n\n2) Using Python module arrbox.iecs.iecs_currents\n   Runs all types of faults, creates text reports and returns results in python object that can be\n   accessed from Python script.\n   The returned python object\n       a) contain both phase and sequence fault c"
  },
  {
    "id": "chunk_1359",
    "text": "\n       a) contain both phase and sequence fault currents.\n       b) contain faults currents for bus faults only.\n       c) does not contain faults currents for linout and linend faults.\n\n3) Using Python module arrbox.fault.FAULT_SUMMARY\n   Runs all types of faults, creates text reports and returns results in python object that can be\n   accessed from Python script.\n   The returned python object\n       a) contain only total fault currents for faults calculated.\n       b) contain faults currents "
  },
  {
    "id": "chunk_1360",
    "text": "lts calculated.\n       b) contain faults currents for bus, linout and linend faults.\n\nThis is an example file showing how to run IECS fault calculations using either of these methods.\n\n---------------------------------------------------------------------------------\nHow to use this file?\n\nA) As showed in __main__ (end of this file), enable PSSE version specific environment, as an example:\n    import psseXX\n    [Here XX is PSSE major version number.]\n\nB) This file contain following functions that"
  },
  {
    "id": "chunk_1361",
    "text": "r.]\n\nB) This file contain following functions that uses IEC 60909 Test Network file run IECS calculations.\n    run_iecs_4(..)\n    run_iecs_currents_txtrpt(..)\n    run_iecs_currents_xls(..)\n    run_fault_summary_iecs(..)\n\n    Run either of these functions under  __main__ to see how they work.\n\nC) Create similar functions for the network case and faults you want to run.\n\n'''\n# ========================================================================================\n#\n\"\"\"\nUse any of these keywords t"
  },
  {
    "id": "chunk_1362",
    "text": "================\n#\n\"\"\"\nUse any of these keywords to run psspy.iecs or arrbox.iecs.iecs_currents or arrbox.fault.FAULT_SUMMARY.\nKeyword   Default   Description\n                    # STATUS array\nflt3ph   = 0        # 1 0=>omit, 1=>include\nfltlg    = 0        # 2 0=>omit, 1=>include\nfltllg   = 0        # 3 0=>omit, 1=>include\nfltll    = 0        # 4 0=>omit, 1=>include\nrptop    = 1        # 5  -1=>no report, 0=>summary, 1=>total, 2=>contributions 3=>total+contributions\nrptlvl   = 0        # 6  num"
  },
  {
    "id": "chunk_1363",
    "text": "=>total+contributions\nrptlvl   = 0        # 6  number of contribution levels\nfltloc   = 0        # 7  0=>network, 1=>LV bus of power station unit,\n                    #    2=>AUX.XMER (connected to power station unit) LV bus\nlinout   = 0        # 8  0=>omit, 1=>include\nlinend   = 0        # 9  0=>omit, 1=>include\ntpunty   = 0        # 10 0=>N and phi unchanged, 1=>N=1 and phi=0, 2=>N=1 and phi unchanged,\n                    #    3=>N unchanged and phi=0\nlnchrg   = 1        # 11 0=>unchanged, 1=>"
  },
  {
    "id": "chunk_1364",
    "text": "d phi=0\nlnchrg   = 1        # 11 0=>unchanged, 1=>0.0 in +/- sequences, 2=>0.0 in all sequences (line charging)\nshntop   = 1        # 12 0=>unchanged, 1=>0.0 in +/- sequences,\n                    #    2=>0.0 in all sequences (line, fixed, swicthed shunts, xmer magnetization)\ndcload   = 0        # 13 0=>blocked, 1=>represent as load (dc line and FACTS option)\nzcorec   = 0        # 14 0=>ignore, 1=>apply  (zero sequence transformer impedance correction option)\ncfactor  = 0        # 15 0=>Maximum f"
  },
  {
    "id": "chunk_1365",
    "text": "tion option)\ncfactor  = 0        # 15 0=>Maximum fault current, 1=>Minimum fault current,\n                    #    2=>User specified, maximum current, 3=>User specified, minimum current\nloadop   = 0        # 16 0=>unchanged, 1=>0.0 in +/- sequences, 2=>0.0 in all sequences (load)\ngenxop   = 0        # 17 0=>X'' 1=>X', 2=>Xs\n                    # VALUES array\nbrktime  = 0.1      # 0.1 seconds, breaker contact parting time\nucfactor = 1.0      # specified voltage factor c value (used when option cf"
  },
  {
    "id": "chunk_1366",
    "text": "cified voltage factor c value (used when option cfactor= 2 or 3)\n                    # File args\niecfile   = ''\nfcdfile   = ''\nscfile    = 'nooutput'\n\"\"\"\n\n# ========================================================================================\n\nimport sys, os, time, math\n\nbsys_kwds = {'usekv':0, 'basekv':[0.0, 999.0], 'areas':[], 'buses':[],\n             'owners':[], 'zones':[]}\n\ndef fault_bsys(sid, **kwds):\n    import psspy\n\n    if sid==0: return\n\n    actv_kwds = {}  # activity keywords\n    f"
  },
  {
    "id": "chunk_1367",
    "text": "urn\n\n    actv_kwds = {}  # activity keywords\n    for k, v in bsys_kwds.items():\n        if k in kwds:\n            actv_kwds[k] = kwds[k]\n        else:\n            actv_kwds[k] = v\n\n    actv_kwds['sid']      = sid\n    actv_kwds['numarea']  = len(actv_kwds['areas'])\n    actv_kwds['numbus']   = len(actv_kwds['buses'])\n    actv_kwds['numowner'] = len(actv_kwds['owners'])\n    actv_kwds['numzone']  = len(actv_kwds['zones'])\n\n    ierr = psspy.bsys(**actv_kwds)\n\n    return ierr\n\n# ======================"
  },
  {
    "id": "chunk_1368",
    "text": "v_kwds)\n\n    return ierr\n\n# ========================================================================================\n\ndef set_prg_rpt(prgfile='', rptfile=''):\n    import psspy\n    psspy.lines_per_page_one_device(1,10000000)\n    if prgfile: psspy.progress_output(2,prgfile,[0,0])\n    if rptfile: psspy.report_output(2,rptfile,[0,0])\n\n# ========================================================================================\n\ndef reset_prg_rpt():\n    import psspy\n    psspy.lines_per_page_one_device(2"
  },
  {
    "id": "chunk_1369",
    "text": "import psspy\n    psspy.lines_per_page_one_device(2,10000000)\n    psspy.progress_output(1,'',[0,0])\n    psspy.report_output(1,'',[0,0])\n\n# ========================================================================================\n\nclass IECS_DEMO:\n    \"\"\" Run PSSE IECS Calculations\"\"\"\n\n    def __init__(self):\n        import psspy\n        self.ierr = psspy.psseinit(buses=150000)\n\n    # ------------------------------------------------------------------------------------\n    def _frmted_z(self, cnum):"
  },
  {
    "id": "chunk_1370",
    "text": "-------------------\n    def _frmted_z(self, cnum):\n        r=cnum.real\n        x=cnum.imag\n        csign='+j'\n        if x<0:\n            csign='-j'\n            x=abs(x)\n\n        if r==0:\n            rstr=''\n        else:\n            rstr=\"%9.6f\" % r\n\n        if x==0:\n            xstr=''\n            csign=''\n        else:\n            xstr=\"%9.6f\" % x\n\n        zstr = \"%(rstr)s%(csign)s%(xstr)s\" % vars()\n\n        return zstr\n\n    # ------------------------------------------------------------------"
  },
  {
    "id": "chunk_1371",
    "text": "--------------------------------------------------------------------\n    def _frmted_z_xbyr(self, cnum):\n\n        zstr = self._frmted_z(cnum)\n\n        r=cnum.real\n        x=abs(cnum.imag)\n        if r==0:\n            xbyr=''\n        else:\n            xbyr=\"%9.6f\" % (x/r)\n\n        cstr=\"%(zstr)s, %(xbyr)s\" % vars()\n\n        return cstr\n\n    # ------------------------------------------------------------------------------------\n\n    def _crnt_mag(self, fmt, cval):\n        if fmt=='rectangular':\n   "
  },
  {
    "id": "chunk_1372",
    "text": "lf, fmt, cval):\n        if fmt=='rectangular':\n            return abs(cval)\n        else:\n            return cval.real\n\n    # ------------------------------------------------------------------------------------\n\n    def _crnt_mva_mag(self, scfmt, scunit, cval, basekv, sbase):\n        if scfmt=='rectangular':\n            if scunit=='pu':\n                baseamp = (1000.0*sbase)/(math.sqrt(3.0)*basekv)\n                crnt = cval*baseamp\n            else:\n                crnt = cval\n            cr"
  },
  {
    "id": "chunk_1373",
    "text": "  else:\n                crnt = cval\n            crnt = abs(crnt)\n        else:\n            cval = cval.real\n            if scunit=='pu':\n                baseamp = (1000.0*sbase)/(math.sqrt(3.0)*basekv)\n                crnt = cval*baseamp\n            else:\n                crnt = cval\n\n        mva  = math.sqrt(3.0)*basekv*crnt/1000.0\n\n        return crnt, mva\n\n    # ------------------------------------------------------------------------------------\n    def run_iecs_api(self, sid, allbus, **kwds):"
  },
  {
    "id": "chunk_1374",
    "text": "-\n    def run_iecs_api(self, sid, allbus, **kwds):\n        import psspy\n        ierr = psspy.iecs_4(sid, allbus, **kwds)\n\n    # ------------------------------------------------------------------------------------\n    def run_iecs_currents(self, sid, allbus, **kwds):\n        import psspy, arrbox.iecs\n\n        rlst = arrbox.iecs.iecs_currents(sid, allbus, **kwds)\n\n        if rlst.ierr!=0:\n            raise Exception(\"arrbox.iecs.iecs_currents error= {}\\n\".format(rlst.ierr))\n\n        return rlst\n\n "
  },
  {
    "id": "chunk_1375",
    "text": "= {}\\n\".format(rlst.ierr))\n\n        return rlst\n\n    # ------------------------------------------------------------------------------------\n    def run_fault_summary(self, sid, allbus, **kwds):\n        import psspy, arrbox.fault\n\n        fltobj = arrbox.fault.FAULT_SUMMARY('IECS', sid, allbus, **kwds)\n\n        if fltobj.ierr!=0:\n            raise Exception(\"arrbox.fault.FAULT_SUMMARY error= {}\\n\".format(fltobj.ierr))\n\n        return fltobj\n\n    # -------------------------------------------------"
  },
  {
    "id": "chunk_1376",
    "text": " ------------------------------------------------------------------------------------\n    def report_iecs_currents(self, rlst, rptfile=''):\n        import psspy\n\n        if rlst.ierr: return\n\n        if rptfile:\n            p, nx = os.path.split(rptfile)\n            n, x = os.path.splitext(nx)\n            if not x:\n                x = '.txt'\n                nx = n + x\n            if p:\n                rptfile = os.path.join(p, nx)\n            else:\n                rptfile = os.path.join(os.getcw"
  },
  {
    "id": "chunk_1377",
    "text": "e:\n                rptfile = os.path.join(os.getcwd(), nx)\n            rptfile_h = open(rptfile,'w')\n            report    = rptfile_h.write\n        else:\n            psspy.beginreport()\n            report = psspy.report\n\n        flt3ph = rlst.flt3ph\n        fltlg  = rlst.fltlg\n        fltllg = rlst.fltllg\n        fltll  = rlst.fltll\n\n        nfbus=len(rlst.fltbus)\n\n        txtlst = []\n        if not rptfile: txtlst.append('')\n\n        ttlstr=\"PSS(R)E IECS SHORT CIRCUIT CURRENTS\" + 10*' ' + time"
  },
  {
    "id": "chunk_1378",
    "text": "S(R)E IECS SHORT CIRCUIT CURRENTS\" + 10*' ' + time.ctime()\n        ln1str,ln2str=psspy.titldt()\n        maxlen=max(len(ttlstr),len(ln1str),len(ln2str))\n        txtlst.append(ttlstr.center(maxlen))\n        txtlst.append(ln1str.center(maxlen))\n        txtlst.append(ln2str.center(maxlen))\n        txtlst.append('')\n        txtall = \"\\n\".join(txtlst)\n        report(txtall)\n\n        scunit = rlst.scunit\n        scfmt  = rlst.scfmt\n\n        scunit_z = rlst.scunit_z\n        scfmt_z  = rlst.scfmt_z\n\n    "
  },
  {
    "id": "chunk_1379",
    "text": "lst.scunit_z\n        scfmt_z  = rlst.scfmt_z\n\n        if scunit == 'pu':\n            units = 'PU'\n        else:\n            units = 'AMP'\n        unitstr   = units.center(10)\n        clnhdr    = \"   BUS     \" + 6*unitstr\n\n        for i in range(nfbus):\n            txtlst = []\n            txtlst.append('')\n            txtlst.append(\"           <--ia1--> <--ia2--> <--ia0--> <--ia---> <--ib---> <--ic--->\")\n            txtlst.append(clnhdr)\n            fbus   = rlst.fltbus[i]\n            if flt3ph:\n"
  },
  {
    "id": "chunk_1380",
    "text": "   fbus   = rlst.fltbus[i]\n            if flt3ph:\n                ttxt   = \"%6d\" % fbus\n                spc    = '3PH'\n                ia1    = self._crnt_mag(scfmt,rlst.flt3ph[i].ia1)\n                ia2    = self._crnt_mag(scfmt,rlst.flt3ph[i].ia2)\n                ia0    = self._crnt_mag(scfmt,rlst.flt3ph[i].ia0)\n                ia     = self._crnt_mag(scfmt,rlst.flt3ph[i].ia)\n                ib     = self._crnt_mag(scfmt,rlst.flt3ph[i].ib)\n                ic     = self._crnt_mag(scfmt,rlst.fl"
  },
  {
    "id": "chunk_1381",
    "text": "             ic     = self._crnt_mag(scfmt,rlst.flt3ph[i].ic)\n                tmptxt = \"%(ttxt)s %(spc)s %(ia1)9.2f %(ia2)9.2f %(ia0)9.2f %(ia)9.2f %(ib)9.2f %(ic)9.2f\" % vars()\n                txtlst.append(tmptxt)\n\n            if fltlg:\n                if flt3ph:\n                    ttxt = 6*' '\n                else:\n                    ttxt = \"%6d\" % fbus\n                spc    = ' LG'\n                ia1    = self._crnt_mag(scfmt,rlst.fltlg[i].ia1)\n                ia2    = self._crnt_mag(scf"
  },
  {
    "id": "chunk_1382",
    "text": "].ia1)\n                ia2    = self._crnt_mag(scfmt,rlst.fltlg[i].ia2)\n                ia0    = self._crnt_mag(scfmt,rlst.fltlg[i].ia0)\n                ia     = self._crnt_mag(scfmt,rlst.fltlg[i].ia)\n                ib     = self._crnt_mag(scfmt,rlst.fltlg[i].ib)\n                ic     = self._crnt_mag(scfmt,rlst.fltlg[i].ic)\n                tmptxt = \"%(ttxt)s %(spc)s %(ia1)9.2f %(ia2)9.2f %(ia0)9.2f %(ia)9.2f %(ib)9.2f %(ic)9.2f\" % vars()\n                txtlst.append(tmptxt)\n\n            if f"
  },
  {
    "id": "chunk_1383",
    "text": "           txtlst.append(tmptxt)\n\n            if fltllg:\n                if flt3ph or fltlg:\n                    ttxt = 6*' '\n                else:\n                    ttxt = \"%6d\" % fbus\n                spc    = 'LLG'\n                ia1    = self._crnt_mag(scfmt,rlst.fltllg[i].ia1)\n                ia2    = self._crnt_mag(scfmt,rlst.fltllg[i].ia2)\n                ia0    = self._crnt_mag(scfmt,rlst.fltllg[i].ia0)\n                ia     = self._crnt_mag(scfmt,rlst.fltllg[i].ia)\n                ib"
  },
  {
    "id": "chunk_1384",
    "text": "nt_mag(scfmt,rlst.fltllg[i].ia)\n                ib     = self._crnt_mag(scfmt,rlst.fltllg[i].ib)\n                ic     = self._crnt_mag(scfmt,rlst.fltllg[i].ic)\n                tmptxt = \"%(ttxt)s %(spc)s %(ia1)9.2f %(ia2)9.2f %(ia0)9.2f %(ia)9.2f %(ib)9.2f %(ic)9.2f\" % vars()\n                txtlst.append(tmptxt)\n\n            if fltll:\n                if flt3ph or fltlg or fltllg:\n                    ttxt = 6*' '\n                else:\n                    ttxt = \"%6d\" % fbus\n                spc "
  },
  {
    "id": "chunk_1385",
    "text": "          ttxt = \"%6d\" % fbus\n                spc     = ' LL'\n                ia1    = self._crnt_mag(scfmt,rlst.fltll[i].ia1)\n                ia2    = self._crnt_mag(scfmt,rlst.fltll[i].ia2)\n                ia0    = self._crnt_mag(scfmt,rlst.fltll[i].ia0)\n                ia     = self._crnt_mag(scfmt,rlst.fltll[i].ia)\n                ib     = self._crnt_mag(scfmt,rlst.fltll[i].ib)\n                ic     = self._crnt_mag(scfmt,rlst.fltll[i].ic)\n                tmptxt = \"%(ttxt)s %(spc)s %(ia1)9."
  },
  {
    "id": "chunk_1386",
    "text": "               tmptxt = \"%(ttxt)s %(spc)s %(ia1)9.2f %(ia2)9.2f %(ia0)9.2f %(ia)9.2f %(ib)9.2f %(ic)9.2f\" % vars()\n                txtlst.append(tmptxt)\n\n            txtlst.append(\"\\nTHEVENIN IMPEDANCE (pu), X/R\")\n\n            z1str = self._frmted_z_xbyr(rlst.thevzpu[i].z1)\n            z1str =\"Z1: \" + z1str\n            if fltlg or fltllg or fltll:\n                z2str = self._frmted_z_xbyr(rlst.thevzpu[i].z2)\n                z2str =\"Z2: \" + z2str\n                z0str = self._frmted_z_xbyr(rlst"
  },
  {
    "id": "chunk_1387",
    "text": "r\n                z0str = self._frmted_z_xbyr(rlst.thevzpu[i].z0)\n                z0str =\"Z0: \" + z0str\n                tmptxt=\"%(z1str)s    %(z2str)s    %(z0str)s\" % vars()\n            else:\n                tmptxt=\"%(z1str)s\" % vars()\n            txtlst.append(tmptxt)\n\n            if scunit_z!='pu':\n                txtlst.append(\"\\nTHEVENIN IMPEDANCE (ohms), X/R\")\n                z1str = self._frmted_z_xbyr(rlst.thevz[i].z1)\n                z1str =\"Z1: \" + z1str\n                if fltlg or fltl"
  },
  {
    "id": "chunk_1388",
    "text": "r =\"Z1: \" + z1str\n                if fltlg or fltllg or fltll:\n                    z2str = self._frmted_z_xbyr(rlst.thevz[i].z2)\n                    z2str =\"Z2: \" + z2str\n                    z0str = self._frmted_z_xbyr(rlst.thevz[i].z0)\n                    z0str =\"Z0: \" + z0str\n                    tmptxt=\"%(z1str)s    %(z2str)s    %(z0str)s\" % vars()\n                else:\n                    tmptxt=\"%(z1str)s\" % vars()\n                txtlst.append(tmptxt)\n\n            tmptxt=110*'-'\n           "
  },
  {
    "id": "chunk_1389",
    "text": "nd(tmptxt)\n\n            tmptxt=110*'-'\n            txtlst.append(tmptxt)\n            txtlst.append('')\n\n            txtall = \"\\n\".join(txtlst)\n            report(txtall)\n\n        # Maximum Fault Currents\n        inam = ['ia1', 'ia2', 'ia0', 'ia', 'ib', 'ic']\n        unitstr   = units.center(11)\n        unitstr = ''\n        for each in ['ia1', 'ia2', 'ia0', ' ia', ' ib', ' ic']:\n            t = each+'('+units+')'\n            t = ' ' + t.center(9) + ' '\n            unitstr += t\n\n        txtlst = ["
  },
  {
    "id": "chunk_1390",
    "text": "+ ' '\n            unitstr += t\n\n        txtlst = []\n        txtlst.append('')\n\n        clnhdr    = \"   BUS  \" + unitstr + \"  Description\"\n        txtlst.append(\"BREAKER DUTY CURRENTS\")\n        txtlst.append(clnhdr)\n        txtall = \"\\n\".join(txtlst)\n        report(txtall)\n\n        for i in range(nfbus):\n            fbus   = rlst.fltbus[i]\n            ia1    = self._crnt_mag(scfmt,rlst.maxflt[i].ia1)\n            ia2    = self._crnt_mag(scfmt,rlst.maxflt[i].ia2)\n            ia0    = self._crnt_mag"
  },
  {
    "id": "chunk_1391",
    "text": "maxflt[i].ia2)\n            ia0    = self._crnt_mag(scfmt,rlst.maxflt[i].ia0)\n            ia     = self._crnt_mag(scfmt,rlst.maxflt[i].ia)\n            ib     = self._crnt_mag(scfmt,rlst.maxflt[i].ib)\n            ic     = self._crnt_mag(scfmt,rlst.maxflt[i].ic)\n            dsc    = rlst.maxfltdsc[i]\n            if rptfile: report('\\n')\n            tmptxt = \"%(fbus)6d   %(ia1)9.2f  %(ia2)9.2f  %(ia0)9.2f  %(ia)9.2f  %(ib)9.2f  %(ic)9.2f   %(dsc)s\" % vars()\n            report(tmptxt)\n\n        # ----"
  },
  {
    "id": "chunk_1392",
    "text": " vars()\n            report(tmptxt)\n\n        # ------------------------------------------------------------------------------------------------\n        if rptfile:\n            rptfile_h.close()\n            print('\\n Done .... IECS FAULT Report saved to file %s' % rptfile)\n\n    # ------------------------------------------------------------------------------------\n    def excel_iecs_currents(self, rlst, faults_applied, xlsfile=''):\n        import psspy\n        import excelpy\n\n        if rlst.ierr: "
  },
  {
    "id": "chunk_1393",
    "text": "spy\n        import excelpy\n\n        if rlst.ierr: return\n\n        # bus data\n        sid  = -1   # consider subsystem of all buses\n        flag = 1    # consider only in-service buses\n        ierr,(busnums,)   = psspy.abusint(sid,flag,['NUMBER'])\n        ierr,(busbasevs,) = psspy.abusreal(sid,flag,'BASE')\n        ierr,(busvlt,)    = psspy.abuscplx(sid,flag,'VOLTAGE') # pre-fault bus voltages in pu\n        ierr,(busname,)   = psspy.abuschar(sid,flag,'NAME')\n\n        bus_data = {}\n        for bnum"
  },
  {
    "id": "chunk_1394",
    "text": "ag,'NAME')\n\n        bus_data = {}\n        for bnum, bbasev, bvlt, bnam in zip(busnums,busbasevs,busvlt,busname):\n            bus_data[bnum] = {'prefltv': bvlt, 'basekv': bbasev, 'name': bnam}\n\n        flt3ph = rlst.flt3ph\n        fltlg  = rlst.fltlg\n        fltllg = rlst.fltllg\n        fltll  = rlst.fltll\n\n        scunit   = rlst.scunit\n        scfmt    = rlst.scfmt\n        scunit_z = rlst.scunit_z\n        scfmt_z  = rlst.scfmt_z\n\n        nfbus=len(rlst.fltbus)\n\n        xlswbk = excelpy.workbook"
  },
  {
    "id": "chunk_1395",
    "text": "en(rlst.fltbus)\n\n        xlswbk = excelpy.workbook(xlsfile)\n        xlswbk.show()\n\n        savfile, snpfile = psspy.sfiles()\n        line1, line2 = psspy.titldt()\n\n        ttl      = r\"PSSE Short Circuit Calculations Using IECS\"\n        ttl      = ttl + 5*' ' + time.ctime()\n        ttl_file = savfile\n        ttl_line1= line1.strip()\n        ttl_line2= line2.strip()\n\n        cln_mrglst = []\n        cln_heads_r1 = ['BUS', '', 'BASE', 'PREFLT']\n        cln_heads_r2 = ['NUMBER', 'NAME', 'kV', 'kV']\n"
  },
  {
    "id": "chunk_1396",
    "text": "    cln_heads_r2 = ['NUMBER', 'NAME', 'kV', 'kV']\n        for fltok, clnnam in zip([flt3ph, fltlg, fltllg, fltll],\n                                 ['3-PH FAULT', 'LG FAULT', 'LLG FAULT', 'LL FAULT']):\n            if fltok:\n                cln_mrglst.append(len(cln_heads_r1)+1)\n                cln_heads_r1.extend([clnnam, ''])\n                cln_heads_r2.extend(['MVA', 'AMP'])\n\n        cln_heads_r1.extend(['THEVENIN IMPEDANCE (PU on 100 MVA and bus base KV)','', ''])\n        cln_heads_r2.extend"
  },
  {
    "id": "chunk_1397",
    "text": "bus base KV)','', ''])\n        cln_heads_r2.extend(['Positive Sequence', 'Negative Sequence', 'Zero Sequence'])\n\n        colheads = [cln_heads_r1, cln_heads_r2]\n\n        row = 7\n        cln = 1\n\n        sbase = psspy.sysmva()\n\n        for i in range(nfbus):\n            rowdata = []\n            fbus    = rlst.fltbus[i]\n            basekv  = bus_data[fbus]['basekv']\n            prefltv = bus_data[fbus]['prefltv']\n\n            rowdata.append(fbus)\n            rowdata.append(bus_data[fbus]['name'])\n"
  },
  {
    "id": "chunk_1398",
    "text": "           rowdata.append(bus_data[fbus]['name'])\n            rowdata.append(basekv)\n            rowdata.append(basekv*abs(prefltv))\n\n            if flt3ph:\n                cval = rlst.flt3ph[i].ia1   # Ifault=Ia1=Ia\n                crnt, mva = self._crnt_mva_mag(scfmt, scunit, cval, basekv, sbase)\n                rowdata.extend([mva, crnt])\n\n            if fltlg:\n                cval = rlst.fltlg[i].ia0    # Ifault=3*Ia0=Ia\n                crnt, mva = self._crnt_mva_mag(scfmt, scunit, cval, bas"
  },
  {
    "id": "chunk_1399",
    "text": " mva = self._crnt_mva_mag(scfmt, scunit, cval, basekv, sbase)\n                rowdata.extend([3*mva, 3*crnt])\n\n            if fltllg:\n                cval = rlst.fltllg[i].ia0   # Ifault=3*Ia0\n                crnt, mva = self._crnt_mva_mag(scfmt, scunit, cval, basekv, sbase)\n                rowdata.extend([3*mva, 3*crnt])\n\n            if fltll:\n                cval = rlst.fltll[i].ib   # Ifault=Ib\n                crnt, mva = self._crnt_mva_mag(scfmt, scunit, cval, basekv, sbase)\n                "
  },
  {
    "id": "chunk_1400",
    "text": "fmt, scunit, cval, basekv, sbase)\n                rowdata.extend([mva, crnt])\n\n            zpos  = rlst.thevzpu[i].z1\n            zneg  = rlst.thevzpu[i].z2\n            zzero = rlst.thevzpu[i].z0\n\n            s_zpos  = self._frmted_z(zpos)\n            s_zneg  = self._frmted_z(zneg)\n            s_zzero = self._frmted_z(zzero)\n\n            rowdata.extend([s_zpos, s_zneg, s_zzero])\n\n            brow,rcln = xlswbk.set_range(row,cln,rowdata)\n            row = brow + 1\n\n        xlswbk.font((6,3,brow,8"
  },
  {
    "id": "chunk_1401",
    "text": "   row = brow + 1\n\n        xlswbk.font((6,3,brow,8),numberFormat=\"0.00\")\n        xlswbk.autofit_columns((6,9,brow,rcln))\n        xlswbk.align((6,9,brow,rcln),'right')\n\n        # headings and column titles\n        xlswbk.set_cell((1,1),ttl,fontStyle=\"Bold\",fontSize=12, fontColor=\"red\")\n        xlswbk.merge((1,1,1,rcln))\n\n        xlswbk.set_cell((2,1),ttl_file,fontStyle=\"Bold\",fontSize=10, fontColor=\"red\")\n        xlswbk.merge((2,1,2,rcln))\n\n        xlswbk.set_cell((3,1),ttl_line1,fontStyle=\"Bold\""
  },
  {
    "id": "chunk_1402",
    "text": "  xlswbk.set_cell((3,1),ttl_line1,fontStyle=\"Bold\",fontSize=10, fontColor=\"red\")\n        xlswbk.merge((3,1,3,rcln))\n\n        xlswbk.set_cell((4,1),ttl_line2,fontStyle=\"Bold\",fontSize=10, fontColor=\"red\")\n        xlswbk.merge((4,1,4,rcln))\n\n        brow,rcln = xlswbk.set_range(5,1,colheads,fontSize=11, fontColor=\"blue\")\n\n        xlswbk.merge((5,1,5,2))\n        for cln in cln_mrglst:\n            xlswbk.merge((5,cln,5,cln+1))\n        xlswbk.merge((5,rcln-2,5,rcln))\n\n        xlswbk.align((1,1),'h_ce"
  },
  {
    "id": "chunk_1403",
    "text": ",rcln-2,5,rcln))\n\n        xlswbk.align((1,1),'h_center')\n        xlswbk.align_rows((1,1,6,1),'h_center')\n\n        if xlsfile: xlswbk.save(xlsfile)\n\n# ========================================================================================\ndef _get_exam_path():\n    import psspy\n    vrsn_pydir = os.path.dirname(psspy.__file__)\n    vrsn_rootdir, jnk = os.path.split(vrsn_pydir)\n    examdir = os.path.join(vrsn_rootdir, \"EXAMPLE\")\n    \n    return examdir\n\n# ============================================"
  },
  {
    "id": "chunk_1404",
    "text": "ir\n\n# ========================================================================================\ndef _get_outpath():\n    import psspy\n    \n    nam, mjr, mnr, pch, dt, stat = psspy.psseversion()\n    s_mjr = \"{}\".format(mjr)\n    s_mnr = \"{}\".format(mnr)\n    s_pch = \"{}\".format(pch)\n    vnam = \"v{}{}{}\".format(s_mjr.zfill(2), s_mnr.zfill(2), s_pch.zfill(2))\n    outnam = \"output_iecs_demo_{}\".format(vnam)\n    \n    outpath = os.path.join(os.getcwd(), outnam)\n    if not os.path.exists(outpath): os.maked"
  },
  {
    "id": "chunk_1405",
    "text": "tnam)\n    if not os.path.exists(outpath): os.makedirs(outpath)\n    \n    return outpath\n    \n# ========================================================================================\ndef _get_iec60909_network_files():\n    savfile = 'iec60909_testnetwork_50Hz.sav'\n    iecfile = 'iec60909_testnetwork.iec'\n    \n    if not os.path.exists(savfile):\n        examdir = _get_exam_path()\n        savfile = os.path.join(examdir, savfile)\n        iecfile = os.path.join(examdir, iecfile)\n        if not os.pat"
  },
  {
    "id": "chunk_1406",
    "text": ".path.join(examdir, iecfile)\n        if not os.path.exists(savfile):\n            msg = \" IEC 60909 Network case not found.\\n    {}\".format(savfile)\n            print(msg)\n            raise Exception(\" Case File not found\")\n\n    return savfile, iecfile\n\n# ========================================================================================\ndef run_iecs_4(**kwds):\n    import psspy\n    psspy.psseinit(buses=150000)\n\n    savfile, iecfile = _get_iec60909_network_files()\n\n    buses = [1,2,3,4,5,6,7,"
  },
  {
    "id": "chunk_1407",
    "text": "60909_network_files()\n\n    buses = [1,2,3,4,5,6,7,8]\n    sid, allbus = 3, 0\n\n    ierr = psspy.case(savfile)\n    ierr = fault_bsys(sid, buses=buses)\n\n    nam_unt = {0:'pu', 1:'amp'}\n    unt=1\n\n    rptfile = \"z_iec60909_testnetwork_iecs_4_{}_rpt{}_report.txt\".format(nam_unt[unt], kwds['rptop'])\n    outpath = _get_outpath()\n    rptfile = os.path.join(outpath, rptfile)\n\n    set_prg_rpt(rptfile=rptfile)\n\n    # set short circuit options\n    psspy.short_circuit_units(unt)          # 0=PU, 1=Physical\n  "
  },
  {
    "id": "chunk_1408",
    "text": "_circuit_units(unt)          # 0=PU, 1=Physical\n    psspy.short_circuit_z_units(unt)        # 0=PU, 1=Physical\n    psspy.short_circuit_coordinates(1)      # 0=rectangular, 1=polar\n    psspy.short_circuit_z_coordinates(0)    # 0=rectangular, 1=polar\n    psspy.short_circuit_warning(0)          # 0= disable, printing of of RESQ/TRSQ/solution warnings\n\n    kwds['iecfile'] = iecfile\n    iecsobj = IECS_DEMO()\n    iecsobj.run_iecs_api(sid, allbus, **kwds)\n\n    reset_prg_rpt()\n\n# ======================="
  },
  {
    "id": "chunk_1409",
    "text": "s)\n\n    reset_prg_rpt()\n\n# ========================================================================================\ndef run_iecs_currents_txtrpt(**kwds):\n    import psspy\n    psspy.psseinit(buses=150000)\n\n    savfile, iecfile = _get_iec60909_network_files()\n\n    buses = [1,2,3,4,5,6,7,8]\n    sid, allbus = 3, 0\n\n    nam_unt = {0:'pu', 1:'amp'}\n    unt=1\n\n    rptfile = \"z_iecs_currents_{}.txt\".format(nam_unt[unt])\n    outpath = _get_outpath()\n    rptfile = os.path.join(outpath, rptfile)\n\n    ierr "
  },
  {
    "id": "chunk_1410",
    "text": "ptfile = os.path.join(outpath, rptfile)\n\n    ierr = psspy.case(savfile)\n    ierr = fault_bsys(sid, buses=buses)\n\n    # set short circuit options\n    psspy.short_circuit_units(unt)          # 0=PU, 1=Physical\n    psspy.short_circuit_z_units(unt)        # 0=PU, 1=Physical\n    psspy.short_circuit_coordinates(1)      # 0=rectangular, 1=polar\n    psspy.short_circuit_z_coordinates(0)    # 0=rectangular, 1=polar\n    psspy.short_circuit_warning(0)          # 0= disable, printing of of RESQ/TRSQ/solution"
  },
  {
    "id": "chunk_1411",
    "text": "   # 0= disable, printing of of RESQ/TRSQ/solution warnings\n\n    kwds['iecfile'] = iecfile\n    iecsobj = IECS_DEMO()\n    rlst = iecsobj.run_iecs_currents(sid, allbus, **kwds)\n    iecsobj.report_iecs_currents(rlst, rptfile)\n\n# ========================================================================================\ndef run_iecs_currents_xls(**kwds):\n    import psspy\n    psspy.psseinit(buses=150000)\n\n    savfile, iecfile = _get_iec60909_network_files()\n\n    buses = [1,2,3,4,5,6,7,8]\n    sid, allbus"
  },
  {
    "id": "chunk_1412",
    "text": "s()\n\n    buses = [1,2,3,4,5,6,7,8]\n    sid, allbus = 3, 0\n\n    nam_unt = {0:'pu', 1:'amp'}\n    unt=1\n\n    xlsfile = \"z_iecs_currents_{}\".format(nam_unt[unt])\n    outpath = _get_outpath()\n    xlsfile = os.path.join(outpath, xlsfile)\n\n    ierr = psspy.case(savfile)\n    ierr = fault_bsys(sid, buses=buses)\n\n    # set short circuit options\n    psspy.short_circuit_units(unt)          # 0=PU, 1=Physical\n    psspy.short_circuit_z_units(unt)        # 0=PU, 1=Physical\n    psspy.short_circuit_coordinates(1"
  },
  {
    "id": "chunk_1413",
    "text": ", 1=Physical\n    psspy.short_circuit_coordinates(1)      # 0=rectangular, 1=polar\n    psspy.short_circuit_z_coordinates(0)    # 0=rectangular, 1=polar\n    psspy.short_circuit_warning(0)          # 0= disable, printing of of RESQ/TRSQ/solution warnings\n\n    kwds['iecfile'] = iecfile\n    iecsobj = IECS_DEMO()\n    rlst = iecsobj.run_iecs_currents(sid, allbus, **kwds)\n    iecsobj.excel_iecs_currents(rlst, xlsfile)\n\n# ==================================================================================="
  },
  {
    "id": "chunk_1414",
    "text": "=======================================================\ndef run_fault_summary_iecs(**kwds):\n    import psspy\n    psspy.psseinit(buses=150000)\n\n    savfile, iecfile = _get_iec60909_network_files()\n\n    buses = [1,2,3,4,5,6,7,8]\n    sid, allbus = 3, 0\n\n    nam_unt = {0:'pu', 1:'amp'}\n    unt=1\n\n    rptfile = \"z_iecs_fault_summary_{}.txt\".format(nam_unt[unt])\n    outpath = _get_outpath()\n    rptfile = os.path.join(outpath, rptfile)\n\n    ierr = psspy.case(savfile)\n    ierr = fault_bsys(sid, buses=bu"
  },
  {
    "id": "chunk_1415",
    "text": ".case(savfile)\n    ierr = fault_bsys(sid, buses=buses)\n\n    # set short circuit options\n    psspy.short_circuit_units(unt)          # 0=PU, 1=Physical\n    psspy.short_circuit_z_units(unt)        # 0=PU, 1=Physical\n    psspy.short_circuit_coordinates(1)      # 0=rectangular, 1=polar\n    psspy.short_circuit_z_coordinates(0)    # 0=rectangular, 1=polar\n    psspy.short_circuit_warning(0)          # 0= disable, printing of of RESQ/TRSQ/solution warnings\n\n##    kwds = {\n##        'flt3ph'   : 1, 'fltl"
  },
  {
    "id": "chunk_1416",
    "text": "gs\n\n##    kwds = {\n##        'flt3ph'   : 1, 'fltlg'    : 1, 'fltllg'   : 1, 'fltll'    : 1,\n##        'rptop'    : 1, 'rptlvl'   : 0, 'fltloc'   : 0, 'linout'   : 0,\n##        'linend'   : 0, 'tpunty'   : 0, 'lnchrg'   : 1, 'shntop'   : 1,\n##        'dcload'   : 0, 'zcorec'   : 0, 'cfactor'  : 0, 'loadop'   : 0,\n##        'genxop'   : 0, 'brktime'  : 0.1, 'ucfactor' : 1.0 }\n\n    kwds['iecfile'] = iecfile\n    iecsobj = IECS_DEMO()\n    fltobj = iecsobj.run_fault_summary(sid, allbus, **kwds)\n    f"
  },
  {
    "id": "chunk_1417",
    "text": "csobj.run_fault_summary(sid, allbus, **kwds)\n    fltobj.text_report(rptfile)\n\n# ========================================================================================\n# IEC 60909 Test Network - Compare PSSE Results  \ndef run_iec60909_test_network():\n    # Results output of following run_iecs_4(..)\n    # match to those in Table 12 and Table 13 of IEC 60909-4 2001.\n    run_iecs_4(flt3ph=1, fltlg=1, fltllg=1, fltll=1, rptop=1)\n    run_iecs_currents_txtrpt(flt3ph=1, fltlg=1, fltllg=1, fltll=1, rpt"
  },
  {
    "id": "chunk_1418",
    "text": "s_txtrpt(flt3ph=1, fltlg=1, fltllg=1, fltll=1, rptop=-1)\n    run_fault_summary_iecs(flt3ph=1, fltlg=1, fltllg=0, fltll=1, rptop=-1, linout=1, linend=1)\n    \n# ========================================================================================\ndef _temp():\n    # Run either of these functions under  __main__ to see how they work.\n    run_iecs_4(flt3ph=1, fltlg=1, fltllg=1, fltll=1, rptop=1)\n\n    run_iecs_currents_txtrpt(flt3ph=1, fltlg=1, fltllg=1, fltll=1, rptop=1)\n    run_iecs_currents_xls("
  },
  {
    "id": "chunk_1419",
    "text": "lg=1, fltll=1, rptop=1)\n    run_iecs_currents_xls(flt3ph=1, fltlg=1, fltllg=1, fltll=1)\n\n    run_fault_summary_iecs(flt3ph=1, fltlg=1, fltllg=1, fltll=1, rptop=1)\n    run_fault_summary_iecs(flt3ph=1, fltlg=1, fltllg=0, fltll=1, rptop=0, linout=1, linend=1)\n\n    run_iec60909_test_network()\n\n# ========================================================================================\nif __name__=='__main__':\n    pass\n#[iecs_demo.py]   Fault Calculations using IECS\n# =================================="
  },
  {
    "id": "chunk_1420",
    "text": "ns using IECS\n# =====================================================================================================\n'''There are three different ways to calculate faults using IECS.\n1) Using activity IECS (psspy.iecs_4)\n   Runs all types of faults, creates text reports, but no access to results from Python script.\n\n2) Using Python module arrbox.iecs.iecs_currents\n   Runs all types of faults, creates text reports and returns results in python object that can be\n   accessed from Python script.\n "
  },
  {
    "id": "chunk_1421",
    "text": "ject that can be\n   accessed from Python script.\n   The returned python object\n       a) contain both phase and sequence fault currents.\n       b) contain faults currents for bus faults only.\n       c) does not contain faults currents for linout and linend faults.\n\n3) Using Python module arrbox.fault.FAULT_SUMMARY\n   Runs all types of faults, creates text reports and returns results in python object that can be\n   accessed from Python script.\n   The returned python object\n       a) contain only "
  },
  {
    "id": "chunk_1422",
    "text": "The returned python object\n       a) contain only total fault currents for faults calculated.\n       b) contain faults currents for bus, linout and linend faults.\n\nThis is an example file showing how to run IECS fault calculations using either of these methods.\n\n---------------------------------------------------------------------------------\nHow to use this file?\n\nA) As showed in __main__ (end of this file), enable PSSE version specific environment, as an example:\n    import psseXX\n    [Here XX"
  },
  {
    "id": "chunk_1423",
    "text": "ent, as an example:\n    import psseXX\n    [Here XX is PSSE major version number.]\n\nB) This file contain following functions that uses IEC 60909 Test Network file run IECS calculations.\n    run_iecs_4(..)\n    run_iecs_currents_txtrpt(..)\n    run_iecs_currents_xls(..)\n    run_fault_summary_iecs(..)\n\n    Run either of these functions under  __main__ to see how they work.\n\nC) Create similar functions for the network case and faults you want to run.\n\n'''\n# ============================================"
  },
  {
    "id": "chunk_1424",
    "text": "'''\n# ========================================================================================\n#\n\"\"\"\nUse any of these keywords to run psspy.iecs or arrbox.iecs.iecs_currents or arrbox.fault.FAULT_SUMMARY.\nKeyword   Default   Description\n                    # STATUS array\nflt3ph   = 0        # 1 0=>omit, 1=>include\nfltlg    = 0        # 2 0=>omit, 1=>include\nfltllg   = 0        # 3 0=>omit, 1=>include\nfltll    = 0        # 4 0=>omit, 1=>include\nrptop    = 1        # 5  -1=>no report, 0=>summary, "
  },
  {
    "id": "chunk_1425",
    "text": "top    = 1        # 5  -1=>no report, 0=>summary, 1=>total, 2=>contributions 3=>total+contributions\nrptlvl   = 0        # 6  number of contribution levels\nfltloc   = 0        # 7  0=>network, 1=>LV bus of power station unit,\n                    #    2=>AUX.XMER (connected to power station unit) LV bus\nlinout   = 0        # 8  0=>omit, 1=>include\nlinend   = 0        # 9  0=>omit, 1=>include\ntpunty   = 0        # 10 0=>N and phi unchanged, 1=>N=1 and phi=0, 2=>N=1 and phi unchanged,\n              "
  },
  {
    "id": "chunk_1426",
    "text": "nd phi=0, 2=>N=1 and phi unchanged,\n                    #    3=>N unchanged and phi=0\nlnchrg   = 1        # 11 0=>unchanged, 1=>0.0 in +/- sequences, 2=>0.0 in all sequences (line charging)\nshntop   = 1        # 12 0=>unchanged, 1=>0.0 in +/- sequences,\n                    #    2=>0.0 in all sequences (line, fixed, swicthed shunts, xmer magnetization)\ndcload   = 0        # 13 0=>blocked, 1=>represent as load (dc line and FACTS option)\nzcorec   = 0        # 14 0=>ignore, 1=>apply  (zero sequence "
  },
  {
    "id": "chunk_1427",
    "text": "0        # 14 0=>ignore, 1=>apply  (zero sequence transformer impedance correction option)\ncfactor  = 0        # 15 0=>Maximum fault current, 1=>Minimum fault current,\n                    #    2=>User specified, maximum current, 3=>User specified, minimum current\nloadop   = 0        # 16 0=>unchanged, 1=>0.0 in +/- sequences, 2=>0.0 in all sequences (load)\ngenxop   = 0        # 17 0=>X'' 1=>X', 2=>Xs\n                    # VALUES array\nbrktime  = 0.1      # 0.1 seconds, breaker contact parting ti"
  },
  {
    "id": "chunk_1428",
    "text": "0.1      # 0.1 seconds, breaker contact parting time\nucfactor = 1.0      # specified voltage factor c value (used when option cfactor= 2 or 3)\n                    # File args\niecfile   = ''\nfcdfile   = ''\nscfile    = 'nooutput'\n\"\"\"\n\n# ========================================================================================\n\nimport sys, os, time, math\n\nbsys_kwds = {'usekv':0, 'basekv':[0.0, 999.0], 'areas':[], 'buses':[],\n             'owners':[], 'zones':[]}\n\ndef fault_bsys(sid, **kwds):\n    impo"
  },
  {
    "id": "chunk_1429",
    "text": "'zones':[]}\n\ndef fault_bsys(sid, **kwds):\n    import psspy\n\n    if sid==0: return\n\n    actv_kwds = {}  # activity keywords\n    for k, v in bsys_kwds.items():\n        if k in kwds:\n            actv_kwds[k] = kwds[k]\n        else:\n            actv_kwds[k] = v\n\n    actv_kwds['sid']      = sid\n    actv_kwds['numarea']  = len(actv_kwds['areas'])\n    actv_kwds['numbus']   = len(actv_kwds['buses'])\n    actv_kwds['numowner'] = len(actv_kwds['owners'])\n    actv_kwds['numzone']  = len(actv_kwds['zones'])\n"
  },
  {
    "id": "chunk_1430",
    "text": "  actv_kwds['numzone']  = len(actv_kwds['zones'])\n\n    ierr = psspy.bsys(**actv_kwds)\n\n    return ierr\n\n# ========================================================================================\n\ndef set_prg_rpt(prgfile='', rptfile=''):\n    import psspy\n    psspy.lines_per_page_one_device(1,10000000)\n    if prgfile: psspy.progress_output(2,prgfile,[0,0])\n    if rptfile: psspy.report_output(2,rptfile,[0,0])\n\n# ======================================================================================="
  },
  {
    "id": "chunk_1431",
    "text": "===================================================\n\ndef reset_prg_rpt():\n    import psspy\n    psspy.lines_per_page_one_device(2,10000000)\n    psspy.progress_output(1,'',[0,0])\n    psspy.report_output(1,'',[0,0])\n\n# ========================================================================================\n\nclass IECS_DEMO:\n    \"\"\" Run PSSE IECS Calculations\"\"\"\n\n    def __init__(self):\n        import psspy\n        self.ierr = psspy.psseinit(buses=150000)\n\n    # -------------------------------------"
  },
  {
    "id": "chunk_1432",
    "text": "0000)\n\n    # ------------------------------------------------------------------------------------\n    def _frmted_z(self, cnum):\n        r=cnum.real\n        x=cnum.imag\n        csign='+j'\n        if x<0:\n            csign='-j'\n            x=abs(x)\n\n        if r==0:\n            rstr=''\n        else:\n            rstr=\"%9.6f\" % r\n\n        if x==0:\n            xstr=''\n            csign=''\n        else:\n            xstr=\"%9.6f\" % x\n\n        zstr = \"%(rstr)s%(csign)s%(xstr)s\" % vars()\n\n        return "
  },
  {
    "id": "chunk_1433",
    "text": "rstr)s%(csign)s%(xstr)s\" % vars()\n\n        return zstr\n\n    # ------------------------------------------------------------------------------------\n    def _frmted_z_xbyr(self, cnum):\n\n        zstr = self._frmted_z(cnum)\n\n        r=cnum.real\n        x=abs(cnum.imag)\n        if r==0:\n            xbyr=''\n        else:\n            xbyr=\"%9.6f\" % (x/r)\n\n        cstr=\"%(zstr)s, %(xbyr)s\" % vars()\n\n        return cstr\n\n    # ------------------------------------------------------------------------------"
  },
  {
    "id": "chunk_1434",
    "text": "--------------------------------------------------------\n\n    def _crnt_mag(self, fmt, cval):\n        if fmt=='rectangular':\n            return abs(cval)\n        else:\n            return cval.real\n\n    # ------------------------------------------------------------------------------------\n\n    def _crnt_mva_mag(self, scfmt, scunit, cval, basekv, sbase):\n        if scfmt=='rectangular':\n            if scunit=='pu':\n                baseamp = (1000.0*sbase)/(math.sqrt(3.0)*basekv)\n                cr"
  },
  {
    "id": "chunk_1435",
    "text": "*sbase)/(math.sqrt(3.0)*basekv)\n                crnt = cval*baseamp\n            else:\n                crnt = cval\n            crnt = abs(crnt)\n        else:\n            cval = cval.real\n            if scunit=='pu':\n                baseamp = (1000.0*sbase)/(math.sqrt(3.0)*basekv)\n                crnt = cval*baseamp\n            else:\n                crnt = cval\n\n        mva  = math.sqrt(3.0)*basekv*crnt/1000.0\n\n        return crnt, mva\n\n    # -------------------------------------------------------"
  },
  {
    "id": "chunk_1436",
    "text": "-------------------------------------------------------------------------------\n    def run_iecs_api(self, sid, allbus, **kwds):\n        import psspy\n        ierr = psspy.iecs_4(sid, allbus, **kwds)\n\n    # ------------------------------------------------------------------------------------\n    def run_iecs_currents(self, sid, allbus, **kwds):\n        import psspy, arrbox.iecs\n\n        rlst = arrbox.iecs.iecs_currents(sid, allbus, **kwds)\n\n        if rlst.ierr!=0:\n            raise Exception(\"arr"
  },
  {
    "id": "chunk_1437",
    "text": " if rlst.ierr!=0:\n            raise Exception(\"arrbox.iecs.iecs_currents error= {}\\n\".format(rlst.ierr))\n\n        return rlst\n\n    # ------------------------------------------------------------------------------------\n    def run_fault_summary(self, sid, allbus, **kwds):\n        import psspy, arrbox.fault\n\n        fltobj = arrbox.fault.FAULT_SUMMARY('IECS', sid, allbus, **kwds)\n\n        if fltobj.ierr!=0:\n            raise Exception(\"arrbox.fault.FAULT_SUMMARY error= {}\\n\".format(fltobj.ierr))\n\n"
  },
  {
    "id": "chunk_1438",
    "text": ".FAULT_SUMMARY error= {}\\n\".format(fltobj.ierr))\n\n        return fltobj\n\n    # ------------------------------------------------------------------------------------\n    def report_iecs_currents(self, rlst, rptfile=''):\n        import psspy\n\n        if rlst.ierr: return\n\n        if rptfile:\n            p, nx = os.path.split(rptfile)\n            n, x = os.path.splitext(nx)\n            if not x:\n                x = '.txt'\n                nx = n + x\n            if p:\n                rptfile = os.path"
  },
  {
    "id": "chunk_1439",
    "text": "           if p:\n                rptfile = os.path.join(p, nx)\n            else:\n                rptfile = os.path.join(os.getcwd(), nx)\n            rptfile_h = open(rptfile,'w')\n            report    = rptfile_h.write\n        else:\n            psspy.beginreport()\n            report = psspy.report\n\n        flt3ph = rlst.flt3ph\n        fltlg  = rlst.fltlg\n        fltllg = rlst.fltllg\n        fltll  = rlst.fltll\n\n        nfbus=len(rlst.fltbus)\n\n        txtlst = []\n        if not rptfile: txtlst.ap"
  },
  {
    "id": "chunk_1440",
    "text": "     txtlst = []\n        if not rptfile: txtlst.append('')\n\n        ttlstr=\"PSS(R)E IECS SHORT CIRCUIT CURRENTS\" + 10*' ' + time.ctime()\n        ln1str,ln2str=psspy.titldt()\n        maxlen=max(len(ttlstr),len(ln1str),len(ln2str))\n        txtlst.append(ttlstr.center(maxlen))\n        txtlst.append(ln1str.center(maxlen))\n        txtlst.append(ln2str.center(maxlen))\n        txtlst.append('')\n        txtall = \"\\n\".join(txtlst)\n        report(txtall)\n\n        scunit = rlst.scunit\n        scfmt  = rlst"
  },
  {
    "id": "chunk_1441",
    "text": "        scunit = rlst.scunit\n        scfmt  = rlst.scfmt\n\n        scunit_z = rlst.scunit_z\n        scfmt_z  = rlst.scfmt_z\n\n        if scunit == 'pu':\n            units = 'PU'\n        else:\n            units = 'AMP'\n        unitstr   = units.center(10)\n        clnhdr    = \"   BUS     \" + 6*unitstr\n\n        for i in range(nfbus):\n            txtlst = []\n            txtlst.append('')\n            txtlst.append(\"           <--ia1--> <--ia2--> <--ia0--> <--ia---> <--ib---> <--ic--->\")\n            txt"
  },
  {
    "id": "chunk_1442",
    "text": "-> <--ia---> <--ib---> <--ic--->\")\n            txtlst.append(clnhdr)\n            fbus   = rlst.fltbus[i]\n            if flt3ph:\n                ttxt   = \"%6d\" % fbus\n                spc    = '3PH'\n                ia1    = self._crnt_mag(scfmt,rlst.flt3ph[i].ia1)\n                ia2    = self._crnt_mag(scfmt,rlst.flt3ph[i].ia2)\n                ia0    = self._crnt_mag(scfmt,rlst.flt3ph[i].ia0)\n                ia     = self._crnt_mag(scfmt,rlst.flt3ph[i].ia)\n                ib     = self._crnt_mag("
  },
  {
    "id": "chunk_1443",
    "text": "ph[i].ia)\n                ib     = self._crnt_mag(scfmt,rlst.flt3ph[i].ib)\n                ic     = self._crnt_mag(scfmt,rlst.flt3ph[i].ic)\n                tmptxt = \"%(ttxt)s %(spc)s %(ia1)9.2f %(ia2)9.2f %(ia0)9.2f %(ia)9.2f %(ib)9.2f %(ic)9.2f\" % vars()\n                txtlst.append(tmptxt)\n\n            if fltlg:\n                if flt3ph:\n                    ttxt = 6*' '\n                else:\n                    ttxt = \"%6d\" % fbus\n                spc    = ' LG'\n                ia1    = self."
  },
  {
    "id": "chunk_1444",
    "text": "     spc    = ' LG'\n                ia1    = self._crnt_mag(scfmt,rlst.fltlg[i].ia1)\n                ia2    = self._crnt_mag(scfmt,rlst.fltlg[i].ia2)\n                ia0    = self._crnt_mag(scfmt,rlst.fltlg[i].ia0)\n                ia     = self._crnt_mag(scfmt,rlst.fltlg[i].ia)\n                ib     = self._crnt_mag(scfmt,rlst.fltlg[i].ib)\n                ic     = self._crnt_mag(scfmt,rlst.fltlg[i].ic)\n                tmptxt = \"%(ttxt)s %(spc)s %(ia1)9.2f %(ia2)9.2f %(ia0)9.2f %(ia)9.2f %(ib)9."
  },
  {
    "id": "chunk_1445",
    "text": "%(ia1)9.2f %(ia2)9.2f %(ia0)9.2f %(ia)9.2f %(ib)9.2f %(ic)9.2f\" % vars()\n                txtlst.append(tmptxt)\n\n            if fltllg:\n                if flt3ph or fltlg:\n                    ttxt = 6*' '\n                else:\n                    ttxt = \"%6d\" % fbus\n                spc    = 'LLG'\n                ia1    = self._crnt_mag(scfmt,rlst.fltllg[i].ia1)\n                ia2    = self._crnt_mag(scfmt,rlst.fltllg[i].ia2)\n                ia0    = self._crnt_mag(scfmt,rlst.fltllg[i].ia0)\n     "
  },
  {
    "id": "chunk_1446",
    "text": "  = self._crnt_mag(scfmt,rlst.fltllg[i].ia0)\n                ia     = self._crnt_mag(scfmt,rlst.fltllg[i].ia)\n                ib     = self._crnt_mag(scfmt,rlst.fltllg[i].ib)\n                ic     = self._crnt_mag(scfmt,rlst.fltllg[i].ic)\n                tmptxt = \"%(ttxt)s %(spc)s %(ia1)9.2f %(ia2)9.2f %(ia0)9.2f %(ia)9.2f %(ib)9.2f %(ic)9.2f\" % vars()\n                txtlst.append(tmptxt)\n\n            if fltll:\n                if flt3ph or fltlg or fltllg:\n                    ttxt = 6*' '\n    "
  },
  {
    "id": "chunk_1447",
    "text": "g or fltllg:\n                    ttxt = 6*' '\n                else:\n                    ttxt = \"%6d\" % fbus\n                spc     = ' LL'\n                ia1    = self._crnt_mag(scfmt,rlst.fltll[i].ia1)\n                ia2    = self._crnt_mag(scfmt,rlst.fltll[i].ia2)\n                ia0    = self._crnt_mag(scfmt,rlst.fltll[i].ia0)\n                ia     = self._crnt_mag(scfmt,rlst.fltll[i].ia)\n                ib     = self._crnt_mag(scfmt,rlst.fltll[i].ib)\n                ic     = self._crnt_m"
  },
  {
    "id": "chunk_1448",
    "text": "fltll[i].ib)\n                ic     = self._crnt_mag(scfmt,rlst.fltll[i].ic)\n                tmptxt = \"%(ttxt)s %(spc)s %(ia1)9.2f %(ia2)9.2f %(ia0)9.2f %(ia)9.2f %(ib)9.2f %(ic)9.2f\" % vars()\n                txtlst.append(tmptxt)\n\n            txtlst.append(\"\\nTHEVENIN IMPEDANCE (pu), X/R\")\n\n            z1str = self._frmted_z_xbyr(rlst.thevzpu[i].z1)\n            z1str =\"Z1: \" + z1str\n            if fltlg or fltllg or fltll:\n                z2str = self._frmted_z_xbyr(rlst.thevzpu[i].z2)\n        "
  },
  {
    "id": "chunk_1449",
    "text": "= self._frmted_z_xbyr(rlst.thevzpu[i].z2)\n                z2str =\"Z2: \" + z2str\n                z0str = self._frmted_z_xbyr(rlst.thevzpu[i].z0)\n                z0str =\"Z0: \" + z0str\n                tmptxt=\"%(z1str)s    %(z2str)s    %(z0str)s\" % vars()\n            else:\n                tmptxt=\"%(z1str)s\" % vars()\n            txtlst.append(tmptxt)\n\n            if scunit_z!='pu':\n                txtlst.append(\"\\nTHEVENIN IMPEDANCE (ohms), X/R\")\n                z1str = self._frmted_z_xbyr(rlst.thevz"
  },
  {
    "id": "chunk_1450",
    "text": "            z1str = self._frmted_z_xbyr(rlst.thevz[i].z1)\n                z1str =\"Z1: \" + z1str\n                if fltlg or fltllg or fltll:\n                    z2str = self._frmted_z_xbyr(rlst.thevz[i].z2)\n                    z2str =\"Z2: \" + z2str\n                    z0str = self._frmted_z_xbyr(rlst.thevz[i].z0)\n                    z0str =\"Z0: \" + z0str\n                    tmptxt=\"%(z1str)s    %(z2str)s    %(z0str)s\" % vars()\n                else:\n                    tmptxt=\"%(z1str)s\" % vars()"
  },
  {
    "id": "chunk_1451",
    "text": "e:\n                    tmptxt=\"%(z1str)s\" % vars()\n                txtlst.append(tmptxt)\n\n            tmptxt=110*'-'\n            txtlst.append(tmptxt)\n            txtlst.append('')\n\n            txtall = \"\\n\".join(txtlst)\n            report(txtall)\n\n        # Maximum Fault Currents\n        inam = ['ia1', 'ia2', 'ia0', 'ia', 'ib', 'ic']\n        unitstr   = units.center(11)\n        unitstr = ''\n        for each in ['ia1', 'ia2', 'ia0', ' ia', ' ib', ' ic']:\n            t = each+'('+units+')'\n      "
  },
  {
    "id": "chunk_1452",
    "text": " ' ic']:\n            t = each+'('+units+')'\n            t = ' ' + t.center(9) + ' '\n            unitstr += t\n\n        txtlst = []\n        txtlst.append('')\n\n        clnhdr    = \"   BUS  \" + unitstr + \"  Description\"\n        txtlst.append(\"BREAKER DUTY CURRENTS\")\n        txtlst.append(clnhdr)\n        txtall = \"\\n\".join(txtlst)\n        report(txtall)\n\n        for i in range(nfbus):\n            fbus   = rlst.fltbus[i]\n            ia1    = self._crnt_mag(scfmt,rlst.maxflt[i].ia1)\n            ia2    "
  },
  {
    "id": "chunk_1453",
    "text": "_mag(scfmt,rlst.maxflt[i].ia1)\n            ia2    = self._crnt_mag(scfmt,rlst.maxflt[i].ia2)\n            ia0    = self._crnt_mag(scfmt,rlst.maxflt[i].ia0)\n            ia     = self._crnt_mag(scfmt,rlst.maxflt[i].ia)\n            ib     = self._crnt_mag(scfmt,rlst.maxflt[i].ib)\n            ic     = self._crnt_mag(scfmt,rlst.maxflt[i].ic)\n            dsc    = rlst.maxfltdsc[i]\n            if rptfile: report('\\n')\n            tmptxt = \"%(fbus)6d   %(ia1)9.2f  %(ia2)9.2f  %(ia0)9.2f  %(ia)9.2f  %(ib)"
  },
  {
    "id": "chunk_1454",
    "text": "ia1)9.2f  %(ia2)9.2f  %(ia0)9.2f  %(ia)9.2f  %(ib)9.2f  %(ic)9.2f   %(dsc)s\" % vars()\n            report(tmptxt)\n\n        # ------------------------------------------------------------------------------------------------\n        if rptfile:\n            rptfile_h.close()\n            print('\\n Done .... IECS FAULT Report saved to file %s' % rptfile)\n\n    # ------------------------------------------------------------------------------------\n    def excel_iecs_currents(self, rlst, faults_applied, xl"
  },
  {
    "id": "chunk_1455",
    "text": "excel_iecs_currents(self, rlst, faults_applied, xlsfile=''):\n        import psspy\n        import excelpy\n\n        if rlst.ierr: return\n\n        # bus data\n        sid  = -1   # consider subsystem of all buses\n        flag = 1    # consider only in-service buses\n        ierr,(busnums,)   = psspy.abusint(sid,flag,['NUMBER'])\n        ierr,(busbasevs,) = psspy.abusreal(sid,flag,'BASE')\n        ierr,(busvlt,)    = psspy.abuscplx(sid,flag,'VOLTAGE') # pre-fault bus voltages in pu\n        ierr,(busname"
  },
  {
    "id": "chunk_1456",
    "text": "pre-fault bus voltages in pu\n        ierr,(busname,)   = psspy.abuschar(sid,flag,'NAME')\n\n        bus_data = {}\n        for bnum, bbasev, bvlt, bnam in zip(busnums,busbasevs,busvlt,busname):\n            bus_data[bnum] = {'prefltv': bvlt, 'basekv': bbasev, 'name': bnam}\n\n        flt3ph = rlst.flt3ph\n        fltlg  = rlst.fltlg\n        fltllg = rlst.fltllg\n        fltll  = rlst.fltll\n\n        scunit   = rlst.scunit\n        scfmt    = rlst.scfmt\n        scunit_z = rlst.scunit_z\n        scfmt_z  = r"
  },
  {
    "id": "chunk_1457",
    "text": "     scunit_z = rlst.scunit_z\n        scfmt_z  = rlst.scfmt_z\n\n        nfbus=len(rlst.fltbus)\n\n        xlswbk = excelpy.workbook(xlsfile)\n        xlswbk.show()\n\n        savfile, snpfile = psspy.sfiles()\n        line1, line2 = psspy.titldt()\n\n        ttl      = r\"PSSE Short Circuit Calculations Using IECS\"\n        ttl      = ttl + 5*' ' + time.ctime()\n        ttl_file = savfile\n        ttl_line1= line1.strip()\n        ttl_line2= line2.strip()\n\n        cln_mrglst = []\n        cln_heads_r1 = ['BUS'"
  },
  {
    "id": "chunk_1458",
    "text": "     cln_mrglst = []\n        cln_heads_r1 = ['BUS', '', 'BASE', 'PREFLT']\n        cln_heads_r2 = ['NUMBER', 'NAME', 'kV', 'kV']\n        for fltok, clnnam in zip([flt3ph, fltlg, fltllg, fltll],\n                                 ['3-PH FAULT', 'LG FAULT', 'LLG FAULT', 'LL FAULT']):\n            if fltok:\n                cln_mrglst.append(len(cln_heads_r1)+1)\n                cln_heads_r1.extend([clnnam, ''])\n                cln_heads_r2.extend(['MVA', 'AMP'])\n\n        cln_heads_r1.extend(['THEVENIN I"
  },
  {
    "id": "chunk_1459",
    "text": " 'AMP'])\n\n        cln_heads_r1.extend(['THEVENIN IMPEDANCE (PU on 100 MVA and bus base KV)','', ''])\n        cln_heads_r2.extend(['Positive Sequence', 'Negative Sequence', 'Zero Sequence'])\n\n        colheads = [cln_heads_r1, cln_heads_r2]\n\n        row = 7\n        cln = 1\n\n        sbase = psspy.sysmva()\n\n        for i in range(nfbus):\n            rowdata = []\n            fbus    = rlst.fltbus[i]\n            basekv  = bus_data[fbus]['basekv']\n            prefltv = bus_data[fbus]['prefltv']\n\n      "
  },
  {
    "id": "chunk_1460",
    "text": "       prefltv = bus_data[fbus]['prefltv']\n\n            rowdata.append(fbus)\n            rowdata.append(bus_data[fbus]['name'])\n            rowdata.append(basekv)\n            rowdata.append(basekv*abs(prefltv))\n\n            if flt3ph:\n                cval = rlst.flt3ph[i].ia1   # Ifault=Ia1=Ia\n                crnt, mva = self._crnt_mva_mag(scfmt, scunit, cval, basekv, sbase)\n                rowdata.extend([mva, crnt])\n\n            if fltlg:\n                cval = rlst.fltlg[i].ia0    # Ifault=3*"
  },
  {
    "id": "chunk_1461",
    "text": "           cval = rlst.fltlg[i].ia0    # Ifault=3*Ia0=Ia\n                crnt, mva = self._crnt_mva_mag(scfmt, scunit, cval, basekv, sbase)\n                rowdata.extend([3*mva, 3*crnt])\n\n            if fltllg:\n                cval = rlst.fltllg[i].ia0   # Ifault=3*Ia0\n                crnt, mva = self._crnt_mva_mag(scfmt, scunit, cval, basekv, sbase)\n                rowdata.extend([3*mva, 3*crnt])\n\n            if fltll:\n                cval = rlst.fltll[i].ib   # Ifault=Ib\n                crnt,"
  },
  {
    "id": "chunk_1462",
    "text": "st.fltll[i].ib   # Ifault=Ib\n                crnt, mva = self._crnt_mva_mag(scfmt, scunit, cval, basekv, sbase)\n                rowdata.extend([mva, crnt])\n\n            zpos  = rlst.thevzpu[i].z1\n            zneg  = rlst.thevzpu[i].z2\n            zzero = rlst.thevzpu[i].z0\n\n            s_zpos  = self._frmted_z(zpos)\n            s_zneg  = self._frmted_z(zneg)\n            s_zzero = self._frmted_z(zzero)\n\n            rowdata.extend([s_zpos, s_zneg, s_zzero])\n\n            brow,rcln = xlswbk.set_rang"
  },
  {
    "id": "chunk_1463",
    "text": "s_zzero])\n\n            brow,rcln = xlswbk.set_range(row,cln,rowdata)\n            row = brow + 1\n\n        xlswbk.font((6,3,brow,8),numberFormat=\"0.00\")\n        xlswbk.autofit_columns((6,9,brow,rcln))\n        xlswbk.align((6,9,brow,rcln),'right')\n\n        # headings and column titles\n        xlswbk.set_cell((1,1),ttl,fontStyle=\"Bold\",fontSize=12, fontColor=\"red\")\n        xlswbk.merge((1,1,1,rcln))\n\n        xlswbk.set_cell((2,1),ttl_file,fontStyle=\"Bold\",fontSize=10, fontColor=\"red\")\n        xlswbk"
  },
  {
    "id": "chunk_1464",
    "text": "Bold\",fontSize=10, fontColor=\"red\")\n        xlswbk.merge((2,1,2,rcln))\n\n        xlswbk.set_cell((3,1),ttl_line1,fontStyle=\"Bold\",fontSize=10, fontColor=\"red\")\n        xlswbk.merge((3,1,3,rcln))\n\n        xlswbk.set_cell((4,1),ttl_line2,fontStyle=\"Bold\",fontSize=10, fontColor=\"red\")\n        xlswbk.merge((4,1,4,rcln))\n\n        brow,rcln = xlswbk.set_range(5,1,colheads,fontSize=11, fontColor=\"blue\")\n\n        xlswbk.merge((5,1,5,2))\n        for cln in cln_mrglst:\n            xlswbk.merge((5,cln,5,cln"
  },
  {
    "id": "chunk_1465",
    "text": " cln_mrglst:\n            xlswbk.merge((5,cln,5,cln+1))\n        xlswbk.merge((5,rcln-2,5,rcln))\n\n        xlswbk.align((1,1),'h_center')\n        xlswbk.align_rows((1,1,6,1),'h_center')\n\n        if xlsfile: xlswbk.save(xlsfile)\n\n# ========================================================================================\ndef _get_exam_path():\n    import psspy\n    vrsn_pydir = os.path.dirname(psspy.__file__)\n    vrsn_rootdir, jnk = os.path.split(vrsn_pydir)\n    examdir = os.path.join(vrsn_rootdir, \"EXA"
  },
  {
    "id": "chunk_1466",
    "text": "dir)\n    examdir = os.path.join(vrsn_rootdir, \"EXAMPLE\")\n    \n    return examdir\n\n# ========================================================================================\ndef _get_outpath():\n    import psspy\n    \n    nam, mjr, mnr, pch, dt, stat = psspy.psseversion()\n    s_mjr = \"{}\".format(mjr)\n    s_mnr = \"{}\".format(mnr)\n    s_pch = \"{}\".format(pch)\n    vnam = \"v{}{}{}\".format(s_mjr.zfill(2), s_mnr.zfill(2), s_pch.zfill(2))\n    outnam = \"output_iecs_demo_{}\".format(vnam)\n    \n    outpath = "
  },
  {
    "id": "chunk_1467",
    "text": "put_iecs_demo_{}\".format(vnam)\n    \n    outpath = os.path.join(os.getcwd(), outnam)\n    if not os.path.exists(outpath): os.makedirs(outpath)\n    \n    return outpath\n    \n# ========================================================================================\ndef _get_iec60909_network_files():\n    savfile = 'iec60909_testnetwork_50Hz.sav'\n    iecfile = 'iec60909_testnetwork.iec'\n    \n    if not os.path.exists(savfile):\n        examdir = _get_exam_path()\n        savfile = os.path.join(examdir, s"
  },
  {
    "id": "chunk_1468",
    "text": "m_path()\n        savfile = os.path.join(examdir, savfile)\n        iecfile = os.path.join(examdir, iecfile)\n        if not os.path.exists(savfile):\n            msg = \" IEC 60909 Network case not found.\\n    {}\".format(savfile)\n            print(msg)\n            raise Exception(\" Case File not found\")\n\n    return savfile, iecfile\n\n# ========================================================================================\ndef run_iecs_4(**kwds):\n    import psspy\n    psspy.psseinit(buses=150000)\n\n   "
  },
  {
    "id": "chunk_1469",
    "text": "import psspy\n    psspy.psseinit(buses=150000)\n\n    savfile, iecfile = _get_iec60909_network_files()\n\n    buses = [1,2,3,4,5,6,7,8]\n    sid, allbus = 3, 0\n\n    ierr = psspy.case(savfile)\n    ierr = fault_bsys(sid, buses=buses)\n\n    nam_unt = {0:'pu', 1:'amp'}\n    unt=1\n\n    rptfile = \"z_iec60909_testnetwork_iecs_4_{}_rpt{}_report.txt\".format(nam_unt[unt], kwds['rptop'])\n    outpath = _get_outpath()\n    rptfile = os.path.join(outpath, rptfile)\n\n    set_prg_rpt(rptfile=rptfile)\n\n    # set short cir"
  },
  {
    "id": "chunk_1470",
    "text": " set_prg_rpt(rptfile=rptfile)\n\n    # set short circuit options\n    psspy.short_circuit_units(unt)          # 0=PU, 1=Physical\n    psspy.short_circuit_z_units(unt)        # 0=PU, 1=Physical\n    psspy.short_circuit_coordinates(1)      # 0=rectangular, 1=polar\n    psspy.short_circuit_z_coordinates(0)    # 0=rectangular, 1=polar\n    psspy.short_circuit_warning(0)          # 0= disable, printing of of RESQ/TRSQ/solution warnings\n\n    kwds['iecfile'] = iecfile\n    iecsobj = IECS_DEMO()\n    iecsobj.run"
  },
  {
    "id": "chunk_1471",
    "text": " iecfile\n    iecsobj = IECS_DEMO()\n    iecsobj.run_iecs_api(sid, allbus, **kwds)\n\n    reset_prg_rpt()\n\n# ========================================================================================\ndef run_iecs_currents_txtrpt(**kwds):\n    import psspy\n    psspy.psseinit(buses=150000)\n\n    savfile, iecfile = _get_iec60909_network_files()\n\n    buses = [1,2,3,4,5,6,7,8]\n    sid, allbus = 3, 0\n\n    nam_unt = {0:'pu', 1:'amp'}\n    unt=1\n\n    rptfile = \"z_iecs_currents_{}.txt\".format(nam_unt[unt])\n    ou"
  },
  {
    "id": "chunk_1472",
    "text": "_iecs_currents_{}.txt\".format(nam_unt[unt])\n    outpath = _get_outpath()\n    rptfile = os.path.join(outpath, rptfile)\n\n    ierr = psspy.case(savfile)\n    ierr = fault_bsys(sid, buses=buses)\n\n    # set short circuit options\n    psspy.short_circuit_units(unt)          # 0=PU, 1=Physical\n    psspy.short_circuit_z_units(unt)        # 0=PU, 1=Physical\n    psspy.short_circuit_coordinates(1)      # 0=rectangular, 1=polar\n    psspy.short_circuit_z_coordinates(0)    # 0=rectangular, 1=polar\n    psspy.sho"
  },
  {
    "id": "chunk_1473",
    "text": "nates(0)    # 0=rectangular, 1=polar\n    psspy.short_circuit_warning(0)          # 0= disable, printing of of RESQ/TRSQ/solution warnings\n\n    kwds['iecfile'] = iecfile\n    iecsobj = IECS_DEMO()\n    rlst = iecsobj.run_iecs_currents(sid, allbus, **kwds)\n    iecsobj.report_iecs_currents(rlst, rptfile)\n\n# ========================================================================================\ndef run_iecs_currents_xls(**kwds):\n    import psspy\n    psspy.psseinit(buses=150000)\n\n    savfile, iecfile "
  },
  {
    "id": "chunk_1474",
    "text": "sspy.psseinit(buses=150000)\n\n    savfile, iecfile = _get_iec60909_network_files()\n\n    buses = [1,2,3,4,5,6,7,8]\n    sid, allbus = 3, 0\n\n    nam_unt = {0:'pu', 1:'amp'}\n    unt=1\n\n    xlsfile = \"z_iecs_currents_{}\".format(nam_unt[unt])\n    outpath = _get_outpath()\n    xlsfile = os.path.join(outpath, xlsfile)\n\n    ierr = psspy.case(savfile)\n    ierr = fault_bsys(sid, buses=buses)\n\n    # set short circuit options\n    psspy.short_circuit_units(unt)          # 0=PU, 1=Physical\n    psspy.short_circui"
  },
  {
    "id": "chunk_1475",
    "text": "         # 0=PU, 1=Physical\n    psspy.short_circuit_z_units(unt)        # 0=PU, 1=Physical\n    psspy.short_circuit_coordinates(1)      # 0=rectangular, 1=polar\n    psspy.short_circuit_z_coordinates(0)    # 0=rectangular, 1=polar\n    psspy.short_circuit_warning(0)          # 0= disable, printing of of RESQ/TRSQ/solution warnings\n\n    kwds['iecfile'] = iecfile\n    iecsobj = IECS_DEMO()\n    rlst = iecsobj.run_iecs_currents(sid, allbus, **kwds)\n    iecsobj.excel_iecs_currents(rlst, xlsfile)\n\n# ====="
  },
  {
    "id": "chunk_1476",
    "text": "ecsobj.excel_iecs_currents(rlst, xlsfile)\n\n# ========================================================================================\ndef run_fault_summary_iecs(**kwds):\n    import psspy\n    psspy.psseinit(buses=150000)\n\n    savfile, iecfile = _get_iec60909_network_files()\n\n    buses = [1,2,3,4,5,6,7,8]\n    sid, allbus = 3, 0\n\n    nam_unt = {0:'pu', 1:'amp'}\n    unt=1\n\n    rptfile = \"z_iecs_fault_summary_{}.txt\".format(nam_unt[unt])\n    outpath = _get_outpath()\n    rptfile = os.path.join(outpath"
  },
  {
    "id": "chunk_1477",
    "text": " _get_outpath()\n    rptfile = os.path.join(outpath, rptfile)\n\n    ierr = psspy.case(savfile)\n    ierr = fault_bsys(sid, buses=buses)\n\n    # set short circuit options\n    psspy.short_circuit_units(unt)          # 0=PU, 1=Physical\n    psspy.short_circuit_z_units(unt)        # 0=PU, 1=Physical\n    psspy.short_circuit_coordinates(1)      # 0=rectangular, 1=polar\n    psspy.short_circuit_z_coordinates(0)    # 0=rectangular, 1=polar\n    psspy.short_circuit_warning(0)          # 0= disable, printing of "
  },
  {
    "id": "chunk_1478",
    "text": "uit_warning(0)          # 0= disable, printing of of RESQ/TRSQ/solution warnings\n\n##    kwds = {\n##        'flt3ph'   : 1, 'fltlg'    : 1, 'fltllg'   : 1, 'fltll'    : 1,\n##        'rptop'    : 1, 'rptlvl'   : 0, 'fltloc'   : 0, 'linout'   : 0,\n##        'linend'   : 0, 'tpunty'   : 0, 'lnchrg'   : 1, 'shntop'   : 1,\n##        'dcload'   : 0, 'zcorec'   : 0, 'cfactor'  : 0, 'loadop'   : 0,\n##        'genxop'   : 0, 'brktime'  : 0.1, 'ucfactor' : 1.0 }\n\n    kwds['iecfile'] = iecfile\n    iecsobj ="
  },
  {
    "id": "chunk_1479",
    "text": "1.0 }\n\n    kwds['iecfile'] = iecfile\n    iecsobj = IECS_DEMO()\n    fltobj = iecsobj.run_fault_summary(sid, allbus, **kwds)\n    fltobj.text_report(rptfile)\n\n# ========================================================================================\n# IEC 60909 Test Network - Compare PSSE Results  \ndef run_iec60909_test_network():\n    # Results output of following run_iecs_4(..)\n    # match to those in Table 12 and Table 13 of IEC 60909-4 2001.\n    run_iecs_4(flt3ph=1, fltlg=1, fltllg=1, fltll=1, r"
  },
  {
    "id": "chunk_1480",
    "text": "run_iecs_4(flt3ph=1, fltlg=1, fltllg=1, fltll=1, rptop=1)\n    run_iecs_currents_txtrpt(flt3ph=1, fltlg=1, fltllg=1, fltll=1, rptop=-1)\n    run_fault_summary_iecs(flt3ph=1, fltlg=1, fltllg=0, fltll=1, rptop=-1, linout=1, linend=1)\n    \n# ========================================================================================\ndef _temp():\n    # Run either of these functions under  __main__ to see how they work.\n    run_iecs_4(flt3ph=1, fltlg=1, fltllg=1, fltll=1, rptop=1)\n\n    run_iecs_currents_tx"
  },
  {
    "id": "chunk_1481",
    "text": "llg=1, fltll=1, rptop=1)\n\n    run_iecs_currents_txtrpt(flt3ph=1, fltlg=1, fltllg=1, fltll=1, rptop=1)\n    run_iecs_currents_xls(flt3ph=1, fltlg=1, fltllg=1, fltll=1)\n\n    run_fault_summary_iecs(flt3ph=1, fltlg=1, fltllg=1, fltll=1, rptop=1)\n    run_fault_summary_iecs(flt3ph=1, fltlg=1, fltllg=0, fltll=1, rptop=0, linout=1, linend=1)\n\n    run_iec60909_test_network()\n\n# ========================================================================================\nif __name__=='__main__':\n    pass\n#[iecs"
  },
  {
    "id": "chunk_1482",
    "text": "=========\nif __name__=='__main__':\n    pass\n#[iecs_report.py]    Get IEC fault currents in arrays and create custom report\n# =====================================================================================================\n'''\nThis is an example file showing how to use \"iecs_currents\" function from pssarrays module.\n\nIECS_CURRENTS function returns IEC 60909 standard fault currents for each faulted bus and\neach type of fault applied. They are:\n    ia1   = Positive Sequence Current\n    ia2   ="
  },
  {
    "id": "chunk_1483",
    "text": "\n    ia1   = Positive Sequence Current\n    ia2   = Negative Sequence Current\n    ia0   = Zero Sequence Current\n    ia    = Phase A current\n    ib    = Phase B current\n    ic    = Phase C current\n    ipb   = peak Current - Method B, ip(B)\n    ipc   = peak Current - Method C, ip(C)\n    idc   = DC component of asymmetrical breaking current, idc\n    ibsym = symmetrical breaking current (r.m.s.), ib(sym)\n    ibuns = asymmetrical breaking current (r.m.s.), ib(uns)\n\nThe APIs used in this program are pa"
  },
  {
    "id": "chunk_1484",
    "text": "s.), ib(uns)\n\nThe APIs used in this program are part of python \"pssarrays\" module.\n\n---------------------------------------------------------------------------------\nHow to use this file?\n\nAs showed in __main__ (end of this file)\n- Enable PSSE version specific environment, as an example:\n    import psse35\n\n- call funtion\n    run_iecs_report()\n\n    You may want to change inputs specified in this function.\n    run_iecs_report(savfile, iecfile, fltbuses, rptfile)\n    Defaults:\n        savfile  = 'i"
  },
  {
    "id": "chunk_1485",
    "text": "uses, rptfile)\n    Defaults:\n        savfile  = 'iec60909_testnetwork_50Hz.sav'\n        iecfile  = 'iec60909_testnetwork.iec'\n        fltbuses = [1,2,3,4,5,6,7,8]\n        rptfile  = 'iecs_report_iec60909_testnetwork_50Hz.txt'\n                   When this script is called from PSSE's Example Folder,\n                   report is created in subfolder 'Output_Pyscript'\n'''\n\n# =====================================================================================================\n\nimport os, time\n\n# ==="
  },
  {
    "id": "chunk_1486",
    "text": "==========================\n\nimport os, time\n\n# =====================================================================================================\n\ndef encode_complex_number_xbyr(cnum):\n    r=cnum.real\n    x=cnum.imag\n    csign='+j'\n    if x<0:\n        csign='-j'\n        x=abs(x)\n\n    if r==0:\n        rstr=''\n        xbyr=''\n    else:\n        rstr=\"%9.6f\" % r\n        xbyr=\"%9.6f\" % (x/r)\n\n    if x==0:\n        xstr=''\n        csign=''\n    else:\n        xstr=\"%9.6f\" % x\n\n    cstr=\"%(rstr)s%(csig"
  },
  {
    "id": "chunk_1487",
    "text": "        xstr=\"%9.6f\" % x\n\n    cstr=\"%(rstr)s%(csign)s%(xstr)s, %(xbyr)s\" % vars()\n\n    return cstr\n\n# =====================================================================================================\n\ndef current_magnitude(fmt,cmplxvalue):\n    if fmt == 'rectangular':\n        return abs(cmplxvalue)\n    else:\n        return cmplxvalue.real\n\n# =====================================================================================================\n\ndef create_report(units,fmt,fltbuses,flt3ph,fltlg"
  },
  {
    "id": "chunk_1488",
    "text": "\ndef create_report(units,fmt,fltbuses,flt3ph,fltlg,fltllg,fltll,linout,linend,tpunty,\n                  lnchrg,shntop,dcload,zcorec,optnftrc,loadop,genxop,brktime,vfactorc,\n                  savfile,iecfile,fcdfile,scfile,rptfile,rprtyp,rprlvl):\n\n    import psspy, arrbox.iecs\n\n    # open case\n    if savfile: psspy.case(savfile)\n\n    # set sc units and format\n    psspy.short_circuit_units(units)\n    psspy.short_circuit_coordinates(fmt)\n\n    sid = 3\n    if fltbuses:\n        psspy.bsys(sid,0,[0.0,0"
  },
  {
    "id": "chunk_1489",
    "text": "3\n    if fltbuses:\n        psspy.bsys(sid,0,[0.0,0.0],0,[],len(fltbuses),fltbuses,0,[],0,[])\n        busall = 0\n    else:\n        busall = 1\n\n    # call pssarrays routine\n    rlst=arrbox.iecs.iecs_currents(sid=sid, all=busall, flt3ph=flt3ph, fltlg=fltlg, fltllg=fltllg,\n            fltll=fltll, linout=linout, linend=linend, tpunty=tpunty, lnchrg=lnchrg,\n            shntop=shntop, dcload=dcload, zcorec= zcorec, optnftrc=optnftrc, loadop=loadop,\n            genxop=genxop, brktime=brktime, vfactorc="
  },
  {
    "id": "chunk_1490",
    "text": "         genxop=genxop, brktime=brktime, vfactorc=vfactorc,\n            iecfile=iecfile, fcdfile=fcdfile, scfile=scfile, rprtyp=rprtyp, rprlvl=rprlvl)\n    if rlst.ierr!=0:\n        raise Exception(\"arrbox.iecs.iecs_currents error= %d\\n\" % rlst.ierr)\n\n    if rptfile:\n        p, nx = os.path.split(rptfile)\n        n, x = os.path.splitext(nx)\n        if not x:\n            x = '.txt'\n            nx = n + x\n        if p:\n            rptfile = os.path.join(p, nx)\n        else:\n            rptfile = os."
  },
  {
    "id": "chunk_1491",
    "text": "oin(p, nx)\n        else:\n            rptfile = os.path.join(os.getcwd(), nx)\n        rptfile_h = open(rptfile,'w')\n        report    = rptfile_h.write\n    else:\n        psspy.beginreport()\n        report = psspy.report\n\n    nfbus=len(rlst.fltbus)\n\n    ttlstr=\"PSS(R)E IEC 60909 SHORT CIRCUIT CURRENTS\" + 10*' ' + time.ctime()\n    ln1str,ln2str=psspy.titldt()\n    maxlen=max(len(ttlstr),len(ln1str),len(ln2str))\n    report(ttlstr.center(maxlen))\n    report(\"\\n\")\n    report(ln1str.center(maxlen))\n    "
  },
  {
    "id": "chunk_1492",
    "text": "eport(\"\\n\")\n    report(ln1str.center(maxlen))\n    report(\"\\n\")\n    report(ln2str.center(maxlen))\n    report(\"\\n\\n\")\n\n    scunit = rlst.scunit\n    scfmt  = rlst.scfmt\n    if scunit == 'pu':\n        units = 'PU'\n    else:\n        units = 'AMP'\n    unitstr   = units.center(10)\n    clnhdr    = \"   BUS     \" + 6*unitstr + \"\\n\"\n\n    for i in range(nfbus):\n        report(\"           <-i''k--> <-ip(B)-> <-ip(C)-> <--idc--> <ib(sym)> <ib(uns)>\\n\")\n        report(clnhdr)\n        fbus   = rlst.fltbus[i]\n  "
  },
  {
    "id": "chunk_1493",
    "text": " report(clnhdr)\n        fbus   = rlst.fltbus[i]\n        if flt3ph:\n            ttxt   = \"%6d\" % fbus\n            spc    = '3PH'\n            ia1    = current_magnitude(scfmt,rlst.flt3ph[i].ia1)\n            ia2    = current_magnitude(scfmt,rlst.flt3ph[i].ia2)\n            ia0    = current_magnitude(scfmt,rlst.flt3ph[i].ia0)\n            ia     = current_magnitude(scfmt,rlst.flt3ph[i].ia)\n            ib     = current_magnitude(scfmt,rlst.flt3ph[i].ib)\n            ic     = current_magnitude(scfmt,rlst"
  },
  {
    "id": "chunk_1494",
    "text": "\n            ic     = current_magnitude(scfmt,rlst.flt3ph[i].ic)\n            ipb    = current_magnitude(scfmt,rlst.flt3ph[i].ipb)\n            ipc    = current_magnitude(scfmt,rlst.flt3ph[i].ipc)\n            idc    = current_magnitude(scfmt,rlst.flt3ph[i].idc)\n            ibsym  = current_magnitude(scfmt,rlst.flt3ph[i].ibsym)\n            ibuns  = current_magnitude(scfmt,rlst.flt3ph[i].ibuns)\n            tmptxt = \"%(ttxt)s %(spc)s %(ia1)9.2f %(ipb)9.2f %(ipc)9.2f %(idc)9.2f %(ibsym)9.2f %(ibuns)9."
  },
  {
    "id": "chunk_1495",
    "text": "9.2f %(ipc)9.2f %(idc)9.2f %(ibsym)9.2f %(ibuns)9.2f \\n\" % vars()\n            report(tmptxt)\n\n        if fltlg:\n            if flt3ph:\n                ttxt = 6*' '\n            else:\n                ttxt = \"%6d\" % fbus\n            spc    = ' LG'\n            ia1    = current_magnitude(scfmt,rlst.fltlg[i].ia1)\n            ia2    = current_magnitude(scfmt,rlst.fltlg[i].ia2)\n            ia0    = current_magnitude(scfmt,3*rlst.fltlg[i].ia0)\n            ia     = current_magnitude(scfmt,rlst.fltlg[i].ia"
  },
  {
    "id": "chunk_1496",
    "text": " ia     = current_magnitude(scfmt,rlst.fltlg[i].ia)\n            ib     = current_magnitude(scfmt,rlst.fltlg[i].ib)\n            ic     = current_magnitude(scfmt,rlst.fltlg[i].ic)\n            ipb    = current_magnitude(scfmt,rlst.fltlg[i].ipb)\n            ipc    = current_magnitude(scfmt,rlst.fltlg[i].ipc)\n            idc    = current_magnitude(scfmt,rlst.fltlg[i].idc)\n            ibsym  = current_magnitude(scfmt,rlst.fltlg[i].ibsym)\n            ibuns  = current_magnitude(scfmt,rlst.fltlg[i].ibuns"
  },
  {
    "id": "chunk_1497",
    "text": "uns  = current_magnitude(scfmt,rlst.fltlg[i].ibuns)\n            tmptxt = \"%(ttxt)s %(spc)s %(ia0)9.2f %(ipb)9.2f %(ipc)9.2f %(idc)9.2f %(ibsym)9.2f %(ibuns)9.2f \\n\" % vars()\n            report(tmptxt)\n\n        if fltllg:\n            if flt3ph or fltlg:\n                ttxt = 6*' '\n            else:\n                ttxt = \"%6d\" % fbus\n            spc    = 'LLG'\n            ia1    = current_magnitude(scfmt,rlst.fltllg[i].ia1)\n            ia2    = current_magnitude(scfmt,rlst.fltllg[i].ia2)\n       "
  },
  {
    "id": "chunk_1498",
    "text": "urrent_magnitude(scfmt,rlst.fltllg[i].ia2)\n            ia0    = current_magnitude(scfmt,3*rlst.fltllg[i].ia0)\n            ia     = current_magnitude(scfmt,rlst.fltllg[i].ia)\n            ib     = current_magnitude(scfmt,rlst.fltllg[i].ib)\n            ic     = current_magnitude(scfmt,rlst.fltllg[i].ic)\n            ipb    = current_magnitude(scfmt,rlst.fltllg[i].ipb)\n            ipc    = current_magnitude(scfmt,rlst.fltllg[i].ipc)\n            idc    = current_magnitude(scfmt,rlst.fltllg[i].idc)\n   "
  },
  {
    "id": "chunk_1499",
    "text": " = current_magnitude(scfmt,rlst.fltllg[i].idc)\n            ibsym  = current_magnitude(scfmt,rlst.fltllg[i].ibsym)\n            ibuns  = current_magnitude(scfmt,rlst.fltllg[i].ibuns)\n            tmptxt = \"%(ttxt)s %(spc)s %(ia0)9.2f %(ipb)9.2f %(ipc)9.2f %(idc)9.2f %(ibsym)9.2f %(ibuns)9.2f \\n\" % vars()\n            report(tmptxt)\n\n        if fltll:\n            if flt3ph or fltlg or fltllg:\n                ttxt = 6*' '\n            else:\n                ttxt = \"%6d\" % fbus\n            spc     = ' LL"
  },
  {
    "id": "chunk_1500",
    "text": "    ttxt = \"%6d\" % fbus\n            spc     = ' LL'\n            ia1    = current_magnitude(scfmt,rlst.fltll[i].ia1)\n            ia2    = current_magnitude(scfmt,rlst.fltll[i].ia2)\n            ia0    = current_magnitude(scfmt,rlst.fltll[i].ia0)\n            ia     = current_magnitude(scfmt,rlst.fltll[i].ia)\n            ib     = current_magnitude(scfmt,rlst.fltll[i].ib)\n            ic     = current_magnitude(scfmt,rlst.fltll[i].ic)\n            ipb    = current_magnitude(scfmt,rlst.fltll[i].ipb)\n   "
  },
  {
    "id": "chunk_1501",
    "text": "  = current_magnitude(scfmt,rlst.fltll[i].ipb)\n            ipc    = current_magnitude(scfmt,rlst.fltll[i].ipc)\n            idc    = current_magnitude(scfmt,rlst.fltll[i].idc)\n            ibsym  = current_magnitude(scfmt,rlst.fltll[i].ibsym)\n            ibuns  = current_magnitude(scfmt,rlst.fltll[i].ibuns)\n            tmptxt = \"%(ttxt)s %(spc)s %(ib)9.2f %(ipb)9.2f %(ipc)9.2f %(idc)9.2f %(ibsym)9.2f %(ibuns)9.2f \\n\" % vars()\n            report(tmptxt)\n\n        report(\"\\nTHEVENIN IMPEDANCE (pu), X"
  },
  {
    "id": "chunk_1502",
    "text": "txt)\n\n        report(\"\\nTHEVENIN IMPEDANCE (pu), X/R\\n\")\n        z1str = encode_complex_number_xbyr(rlst.thevzpu[i].z1)\n        z1str =\"Z1: \" + z1str\n        if fltlg or fltllg or fltll:\n            z2str = encode_complex_number_xbyr(rlst.thevzpu[i].z2)\n            z2str =\"Z2: \" + z2str\n            z0str = encode_complex_number_xbyr(rlst.thevzpu[i].z0)\n            z0str =\"Z0: \" + z0str\n            tmptxt=\"%(z1str)s    %(z2str)s    %(z0str)s\\n\" % vars()\n        else:\n            tmptxt=\"%(z1str)s"
  },
  {
    "id": "chunk_1503",
    "text": "vars()\n        else:\n            tmptxt=\"%(z1str)s\\n\" % vars()\n        report(tmptxt)\n\n        if scunit != 'pu':\n            report(\"\\nTHEVENIN IMPEDANCE (ohms), X/R\\n\")\n            z1str = encode_complex_number_xbyr(rlst.thevz[i].z1)\n            z1str =\"Z1: \" + z1str\n            if fltlg or fltllg or fltll:\n                z2str = encode_complex_number_xbyr(rlst.thevz[i].z2)\n                z2str =\"Z2: \" + z2str\n                z0str = encode_complex_number_xbyr(rlst.thevz[i].z0)\n             "
  },
  {
    "id": "chunk_1504",
    "text": "omplex_number_xbyr(rlst.thevz[i].z0)\n                z0str =\"Z0: \" + z0str\n                tmptxt=\"%(z1str)s    %(z2str)s    %(z0str)s\\n\" % vars()\n            else:\n                tmptxt=\"%(z1str)s\\n\" % vars()\n            report(tmptxt)\n\n        tmptxt=110*'-'\n        report(tmptxt)\n        report(\"\\n\")\n\n    # Maximum Fault Currents\n    inam = ['ia1', 'ia2', 'ia0', 'ia', 'ib', 'ic']\n    unitstr   = units.center(11)\n    unitstr = ''\n    for each in ['ia1', 'ia2', 'ia0', ' ia', ' ib', ' ic']:\n   "
  },
  {
    "id": "chunk_1505",
    "text": "in ['ia1', 'ia2', 'ia0', ' ia', ' ib', ' ic']:\n        t = each+'('+units+')'\n        t = ' ' + t.center(9) + ' '\n        unitstr += t\n\n    clnhdr    = \"   BUS  \" + unitstr + \"  Description\\n\"\n    report(\"\\nBREAKER DUTY CURRENTS\\n\")\n    report(clnhdr)\n    for i in range(nfbus):\n        fbus   = rlst.fltbus[i]\n        ia1    = current_magnitude(scfmt,rlst.maxflt[i].ia1)\n        ia2    = current_magnitude(scfmt,rlst.maxflt[i].ia2)\n        ia0    = current_magnitude(scfmt,rlst.maxflt[i].ia0)\n      "
  },
  {
    "id": "chunk_1506",
    "text": "current_magnitude(scfmt,rlst.maxflt[i].ia0)\n        ia     = current_magnitude(scfmt,rlst.maxflt[i].ia)\n        ib     = current_magnitude(scfmt,rlst.maxflt[i].ib)\n        ic     = current_magnitude(scfmt,rlst.maxflt[i].ic)\n        dsc    = rlst.maxfltdsc[i]\n        tmptxt = \"%(fbus)6d   %(ia1)9.2f  %(ia2)9.2f  %(ia0)9.2f  %(ia)9.2f  %(ib)9.2f  %(ic)9.2f   %(dsc)s\\n\" % vars()\n        report(tmptxt)\n\n    # -------------------------------------------------------------------------------------------"
  },
  {
    "id": "chunk_1507",
    "text": "-------------------------------------------------------\n    if rptfile:\n        rptfile_h.close()\n        print('\\n Done .... IECS FAULT Report saved to file %s' % rptfile)\n    else:\n        print('\\n Done .... IECS FAULT Report created in Report window.')\n\n# =====================================================================================================\n\ndef check_psse_example_folder(rptfile):\n    # if called from PSSE's Example Folder, create report in subfolder 'Output_Pyscript'\n    rptp"
  },
  {
    "id": "chunk_1508",
    "text": "ate report in subfolder 'Output_Pyscript'\n    rptpath, rptfnam = os.path.split(rptfile)\n    if not rptpath:\n        rptpath = os.getcwd()\n        cwd = rptpath.lower()\n        i = cwd.find('pti')\n        j = cwd.find('psse')\n        k = cwd.find('example')\n        if i>0 and j>i and k>j:     # called from Example folder\n            outdir = os.path.join(os.getcwd(), 'Output_Pyscript')\n            if not os.path.exists(outdir): os.mkdir(outdir)\n        else:\n            outdir = os.getcwd()\n     "
  },
  {
    "id": "chunk_1509",
    "text": "      else:\n            outdir = os.getcwd()\n        rptfile  = os.path.join(outdir, rptfnam)\n\n    return rptfile\n\n# =====================================================================================================\n\ndef run_iecs_report(savfile='iec60909_testnetwork_50Hz.sav', iecfile='iec60909_testnetwork.iec',\n                    fltbuses=[1,2,3,4,5,6,7,8], rptfile='iecs_report_iec60909_testnetwork_50Hz.txt'):\n\n    import psspy\n\n    psspy.psseinit()\n\n    # Inputs, change as required\n\n    un"
  },
  {
    "id": "chunk_1510",
    "text": "seinit()\n\n    # Inputs, change as required\n\n    units    = 1       # 0=per unit,    1=physical\n    fmt      = 0       # 0=rectangular, 1=polar coordinates\n\n    flt3ph   = 1       #\n    fltlg    = 1       #\n    fltllg   = 1       #\n    fltll    = 1       #\n    linout   = 0       #\n    linend   = 0       #\n    tpunty   = 0       #\n    lnchrg   = 1       #\n    shntop   = 1       #\n    dcload   = 0       #\n    zcorec   = 0       #\n    optnftrc = 0       #\n    loadop   = 1       #\n    genxop   = 0   "
  },
  {
    "id": "chunk_1511",
    "text": "    #\n    loadop   = 1       #\n    genxop   = 0       # 0=X\", 1=X', 2=Xs (generator reactance)\n\n    brktime  = 0.1     # 0.1 seconds\n    vfactorc = 1.0     #\n\n    rptfile  = check_psse_example_folder(rptfile)\n\n    fcdfile  = \"\"\n    scfile   = \"\"\n\n    rprtyp   = -1      # no report\n    rprlvl   = 0       # number of contribution levels\n\n    create_report(units,fmt,fltbuses,flt3ph,fltlg,fltllg,fltll,linout,linend,tpunty,\n                  lnchrg,shntop,dcload,zcorec,optnftrc,loadop,genxop,brktime,"
  },
  {
    "id": "chunk_1512",
    "text": "ntop,dcload,zcorec,optnftrc,loadop,genxop,brktime,vfactorc,\n                  savfile,iecfile,fcdfile,scfile,rptfile,rprtyp,rprlvl)\n\n# ====================================================================================================\nif __name__ == '__main__':\n\n    import psse35\n    run_iecs_report()\n\n# ====================================================================================================\n#[nlevel_buses.py]   Get N level buses from Home Bus\n# ====================================="
  },
  {
    "id": "chunk_1513",
    "text": "m Home Bus\n# =====================================================================================================\n'''This script returns a dictionary of N level buses from Home (starting) Bus.\nThe next level bus is found from its branch and transformer connections [and not its electrical length].\n\n---------------------------------------------------------------------------------\nHow to use this file?\n    Refer \"test_me()\" function.\n'''\n\n# ========================================================="
  },
  {
    "id": "chunk_1514",
    "text": "=================================================================================\n\ndef get_nlevel_buses(homebus, nlevels):\n    \"\"\"\n    Python Syntax:\n        lvl_busdict = get_nlevel_buses(savfile, homebus, nlevels)\n\n    Arguments:\n        homebus(integer) : Home (starting) bus number to start finding next buses\n        nlevels(integer) : Number of levels of buses from Home Bus\n    \"\"\"\n    import psspy\n    psspy.psseinit()\n\n    lvl_list = [n+1 for n in range(nlevels)]\n\n    lvl_busdict = {}\n    l"
  },
  {
    "id": "chunk_1515",
    "text": "r n in range(nlevels)]\n\n    lvl_busdict = {}\n    lvl_busdict[0] = [homebus]\n\n    do_buslist = [homebus]\n    done_busdict = {}\n\n    for lvl in lvl_list:\n        if not do_buslist: break\n        tmp_busdict = {}\n\n        # Search for branches and two winding transformers\n        for ibus in do_buslist:\n            ierr = psspy.inibrn(ibus, single=2)\n            #print(\"0 inibrn: ierr={}, ibus={}\".format(ierr, ibus))\n            if ierr == 0:\n                while True:\n                    ierr,jbu"
  },
  {
    "id": "chunk_1516",
    "text": "          while True:\n                    ierr,jbus,ickt = psspy.nxtbrn(ibus)\n                    #print(\"1 nxtbrn: ierr={}, jbus={}\".format(ierr, jbus))\n                    if ierr: break\n                    tmp_busdict[jbus] = 1\n\n        # Search for three winding transformers\n        for ibus in do_buslist:\n            ierr = psspy.inibrn(ibus, single=2)\n            if ierr == 0:\n                while True:\n                    ierr,jbus,kbus,ickt = psspy.nxtbrn3(ibus)\n                    #pri"
  },
  {
    "id": "chunk_1517",
    "text": "ckt = psspy.nxtbrn3(ibus)\n                    #print(\"2 nxtbrn3: ierr={}, jbus={}, kbus={}\".format(ierr, jbus, kbus))\n                    if ierr: break\n                    tmp_busdict[jbus] = 1\n                    if (kbus>0): tmp_busdict[kbus] = 1\n\n        tmp_buslist = list(tmp_busdict.keys())\n        tmp_buslist.sort()\n\n        for ibus in do_buslist:\n            done_busdict[ibus] = 1\n\n        do_buslist = []\n        for ibus in tmp_buslist:\n            if ibus not in done_busdict:\n        "
  },
  {
    "id": "chunk_1518",
    "text": "\n            if ibus not in done_busdict:\n                do_buslist.append(ibus)\n\n        lvl_busdict[lvl] = do_buslist[:]\n\n    # all done\n    return lvl_busdict\n\n# ========================================================================================\ndef test_me():\n    import psse3502\n    import psspy\n    psspy.psseinit()\n    savfile = \"sample.sav\"\n    psspy.case(savfile)\n    lvl_busdict = get_nlevel_buses(151, 3)\n    #lvl_busdict = get_nlevel_buses(206, 10)\n    #lvl_busdict = get_nlevel_bus"
  },
  {
    "id": "chunk_1519",
    "text": "l_buses(206, 10)\n    #lvl_busdict = get_nlevel_buses(101, 10)\n    print(\"N Level Buses\")\n    for lvl, buslist in lvl_busdict.items():\n        print(\"Level={}, Buses={}\".format(lvl, buslist))\n\n# ========================================================================================\n\nif __name__==\"__main__\":\n    pass\n# Generated on TUE, JUN 08 2004  11:37\npsspy.case(r\"\"\"savnw.sav\"\"\")\npsspy.opendiagfile(r\"\"\"savnw.sld\"\"\")\n#[otdffactors_excel.py]  OTDF FACTORS Exported to Excel Spreadsheet\n# ======="
  },
  {
    "id": "chunk_1520",
    "text": "DF FACTORS Exported to Excel Spreadsheet\n# ====================================================================================================\n'''\nThis is an example file showing how to use DFAX_PP object's method \"otdf_factors\" from\nPSSARRAYS module to export OTDF factors to excel spreadsheet.\n\nYou need to have Win32 extensions for Python installed.\n(http://sourceforge.net/projects/pywin32)\n\n---------------------------------------------------------------------------------\nHow to use this file?"
  },
  {
    "id": "chunk_1521",
    "text": "----------------------------\nHow to use this file?\n\nAs showed in __main__ (end of this file)\n- Enable PSSE version specific environment, as an example:\n    import psse35\n\n- call funtion\n    otdf_excel(savfile, dfxfile, outpath, show)\n    or\n    otdf_excel()  <-- savnw.sav and savnw.dfx must exist in working folder.\n'''\n# ----------------------------------------------------------------------------------------------------\n\nimport sys, os\n\n# ---------------------------------------------------------"
  },
  {
    "id": "chunk_1522",
    "text": "----------------------------------------------------------------------------------------------\n\ndef get_output_dir(outpath):\n    # if called from PSSE's Example Folder, create report in subfolder 'Output_Pyscript'\n\n    if outpath:\n        outdir = outpath\n        if not os.path.exists(outdir): os.mkdir(outdir)\n    else:\n        outdir = os.getcwd()\n        cwd = outdir.lower()\n        i = cwd.find('pti')\n        j = cwd.find('psse')\n        k = cwd.find('example')\n        if i>0 and j>i and k>j:"
  },
  {
    "id": "chunk_1523",
    "text": "wd.find('example')\n        if i>0 and j>i and k>j:     # called from Example folder\n            outdir = os.path.join(outdir, 'Output_Pyscript')\n            if not os.path.exists(outdir): os.mkdir(outdir)\n\n    return outdir\n\n# -----------------------------------------------------------------------------------------------------\n\ndef get_output_filename(outpath, fnam):\n\n    p, nx = os.path.split(fnam)\n    if p:\n        retvfile = fnam\n    else:\n        outdir = get_output_dir(outpath)\n        retv"
  },
  {
    "id": "chunk_1524",
    "text": "     outdir = get_output_dir(outpath)\n        retvfile = os.path.join(outdir, fnam)\n\n    return retvfile\n\n# ----------------------------------------------------------------------------------------------------\n\ndef otdf_excel(savfile='savnw.sav', dfxfile='savnw.dfx', outpath=None, show=True):\n\n    import psspy, arrbox.dfax_pp\n\n    import excelpy\n\n    if not os.path.exists(savfile):\n        print(\"\\n SAV file '%s' not found.\" % savfile)\n        return\n\n    if not os.path.exists(dfxfile):\n        p"
  },
  {
    "id": "chunk_1525",
    "text": "urn\n\n    if not os.path.exists(dfxfile):\n        print(\"\\n DFAX file '%s' not found.\" % dfxfile)\n        return\n\n    p, nx = os.path.split(dfxfile)\n    n, x  = os.path.splitext(nx)\n    xlfile = get_output_filename(outpath, 'otdffactors_'+n)\n\n    psspy.psseinit()\n\n    psspy.case(savfile)\n\n    dfxobj = arrbox.dfax_pp.DFAX_PP(dfxfile)\n\n    otdfobj = dfxobj.otdf_factors()\n    if otdfobj.ierr != 0: return\n\n    otdfxls = excelpy.workbook(xlfile, 'OTDF FACTORS', overwritesheet=True)\n    if show: otdfxl"
  },
  {
    "id": "chunk_1526",
    "text": "FACTORS', overwritesheet=True)\n    if show: otdfxls.show()\n    otdfxls.show_alerts(0) # do not show pop-up alerts\n\n    otdfxls.page_format(orientation=\"landscape\",left=1.0,right=1.0,\n                       top=0.5,bottom=0.5,header=0.25,footer=0.25)\n    otdfxls.page_footer(left='page number of page total', right='date, time')\n    otdfxls.page_header(center='file name:sheet name')\n    otdfxls.font_sheet()\n\n    # Report Title\n    col = 1\n    row = 1\n    tmplst = ([\"OTDF Factors Report\"],[dfxfile])"
  },
  {
    "id": "chunk_1527",
    "text": "1\n    tmplst = ([\"OTDF Factors Report\"],[dfxfile])\n    bottomRow,rightCol = otdfxls.set_range(row,col,tmplst)\n    otdfxls.font((1,1),fontColor='red',fontSize=14)\n    otdfxls.font_color((2,1),'blue')\n\n    row = bottomRow + 1\n\n    tmplst = [\n        otdfobj.casetitle.line1,                                       #\n        otdfobj.casetitle.line2,                                       #\n        ''\n        'Saved Case file              = %s' % otdfobj.file.sav,         #\n        'DFAX file           "
  },
  {
    "id": "chunk_1528",
    "text": ".file.sav,         #\n        'DFAX file                    = %s' % otdfobj.file.dfx,         #\n        'Subsystem file               = %s' % otdfobj.file.sub,         #\n        'Monitored Element file       = %s' % otdfobj.file.mon,         #\n        'Contingency Description file = %s' % otdfobj.file.con,         #\n        ]\n\n    bottomRow,rightCol = otdfxls.set_range(row,col,tmplst,transpose=True)\n    row = bottomRow + 2 # one blank row\n\n    txt = \"'*** OTDF Contingency Description ***\"\n    otd"
  },
  {
    "id": "chunk_1529",
    "text": " = \"'*** OTDF Contingency Description ***\"\n    otdfxls.set_cell((row,col),txt,fontStyle=\"Bold\",fontSize=12, fontColor=\"red\")\n    row = row + 1\n\n    tmplst=[]\n    for i in range(otdfobj.size.ncase):\n        lbl  = otdfobj.colabel[i]\n        desc = otdfobj.codesc[i]\n        tmplst.append([lbl,desc])\n    bottomRow,rightCol = otdfxls.set_range(row,col,tmplst)\n    otdfxls.align((row,col,bottomRow,col),'right')\n    otdfxls.font_color((row,col,bottomRow,col),'dgreen')\n\n    row = bottomRow + 2 # one bla"
  },
  {
    "id": "chunk_1530",
    "text": ",col),'dgreen')\n\n    row = bottomRow + 2 # one blank row\n\n    txt = \"'*** OTDF Factors ***\"\n    otdfxls.set_cell((row,col),txt,fontStyle=\"Bold\",fontSize=12, fontColor=\"red\")\n    row = row + 1\n\n    tmplst=['<---------- Monitored Branch/Interface ------------->']\n    for each in otdfobj.colabel:\n        tmplst.append(each.strip())\n    bottomRow,rightCol = otdfxls.set_range(row,col,tmplst)\n    otdfxls.align((row,col,bottomRow,rightCol),'right')\n    otdfxls.font_color((row,col,bottomRow,rightCol),'b"
  },
  {
    "id": "chunk_1531",
    "text": "otdfxls.font_color((row,col,bottomRow,rightCol),'blue')\n\n    row = bottomRow + 1\n\n    tmplst=[]\n    for i in range(otdfobj.size.nmline+otdfobj.size.ninter):\n        tmplst.append([otdfobj.melement[i].strip()])\n    bottomRow,rightCol = otdfxls.set_range(row,col,tmplst)\n    otdfxls.align((row,col,bottomRow,col),'right')\n    otdfxls.font_color((row,col,bottomRow,col),'dgreen')\n\n    col = rightCol + 1\n    bottomRow,rightCol = otdfxls.set_range(row,col,otdfobj.factor,transpose=True,numberFormat='0.00"
  },
  {
    "id": "chunk_1532",
    "text": "l,otdfobj.factor,transpose=True,numberFormat='0.0000')\n\n    otdfxls.width((1,1),53)\n    otdfxls.width((1,2,1,rightCol),12)\n\n    # ------------------------------------------------------------------------------------------------\n    # Save the workbook and close the Excel application\n    xlfile = otdfxls.save(xlfile)\n\n    if not show:\n        otdfxls.close()\n        txt = '\\n OTDF Factors saved to file %s\\n' % xlfile\n        sys.stdout.write(txt)\n\n# ================================================"
  },
  {
    "id": "chunk_1533",
    "text": "# ====================================================================================================\n# ====================================================================================================\nif __name__ == '__main__':\n\n    import psse35\n    otdf_excel()\n    # OR\n    #otdf_excel(savfile, dfxfile, outpath, show)\n\n\n# ====================================================================================================\n#[otdffactors_report.py]  OTDF FACTORS REPORT\n# ===================="
  },
  {
    "id": "chunk_1534",
    "text": "rt.py]  OTDF FACTORS REPORT\n# ====================================================================================================\n'''\nThis is an example file showing how to use DFAX_PP object's method \"otdf_factors\" from\nPSSARRAYS module to generate OTDF factors report.\n\n---------------------------------------------------------------------------------\nHow to use this file?\n\nAs showed in __main__ (end of this file)\n- Enable PSSE version specific environment, as an example:\n    import psse35\n\n- c"
  },
  {
    "id": "chunk_1535",
    "text": "environment, as an example:\n    import psse35\n\n- call funtion\n    otdf_report(savfile, dfxfile, outpath, show)\n    or\n    otdf_report()  <-- savnw.sav and savnw.dfx must exist in working folder.\n'''\n\n# ----------------------------------------------------------------------------------------------------\n\nimport sys, os, time\n\n# -----------------------------------------------------------------------------------------------------\n\ndef get_output_dir(outpath):\n    # if called from PSSE's Example Fold"
  },
  {
    "id": "chunk_1536",
    "text": "outpath):\n    # if called from PSSE's Example Folder, create report in subfolder 'Output_Pyscript'\n\n    if outpath:\n        outdir = outpath\n        if not os.path.exists(outdir): os.mkdir(outdir)\n    else:\n        outdir = os.getcwd()\n        cwd = outdir.lower()\n        i = cwd.find('pti')\n        j = cwd.find('psse')\n        k = cwd.find('example')\n        if i>0 and j>i and k>j:     # called from Example folder\n            outdir = os.path.join(outdir, 'Output_Pyscript')\n            if not o"
  },
  {
    "id": "chunk_1537",
    "text": "in(outdir, 'Output_Pyscript')\n            if not os.path.exists(outdir): os.mkdir(outdir)\n\n    return outdir\n\n# -----------------------------------------------------------------------------------------------------\n\ndef get_output_filename(outpath, fnam):\n\n    p, nx = os.path.split(fnam)\n    if p:\n        retvfile = fnam\n    else:\n        outdir = get_output_dir(outpath)\n        retvfile = os.path.join(outdir, fnam)\n\n    return retvfile\n\n# ---------------------------------------------------------"
  },
  {
    "id": "chunk_1538",
    "text": "---------------------------------------------------------------------------------------------\n\ndef otdf_report(savfile='savnw.sav', dfxfile='savnw.dfx', outpath=None):\n\n    import psspy, arrbox.dfax_pp\n\n    if not os.path.exists(savfile):\n        print(\"\\n SAV file '%s' not found.\" % savfile)\n        return\n\n    if not os.path.exists(dfxfile):\n        print(\"\\n DFAX file '%s' not found.\" % dfxfile)\n        return\n\n    p, nx = os.path.split(dfxfile)\n    n, x  = os.path.splitext(nx)\n    rptfile = "
  },
  {
    "id": "chunk_1539",
    "text": "e)\n    n, x  = os.path.splitext(nx)\n    rptfile = get_output_filename(outpath, 'otdffactors_'+n+'.txt')\n\n    psspy.psseinit()\n\n    psspy.case(savfile)\n\n    dfxobj = arrbox.dfax_pp.DFAX_PP(dfxfile)\n    otdfobj = dfxobj.otdf_factors()\n    if otdfobj.ierr != 0: return\n\n    rptfile_h = open(rptfile,'w')\n    report    = rptfile_h.write\n\n    # (0) Report title\n    ttl_hline = '*' + 46* ' *' + '\\n\\n'\n    ttl       = 30*' ' + \"OTDF Factors Report\" + \"\\n\"\n    ttl_file  = 30*' ' + otdfobj.file.dfx + \"\\n\"\n"
  },
  {
    "id": "chunk_1540",
    "text": "\n    ttl_file  = 30*' ' + otdfobj.file.dfx + \"\\n\"\n    ttl_time  = 30*' ' + time.ctime() + \"\\n\\n\"\n    report(ttl_hline)\n    report(ttl)\n    report(ttl_file)\n    report(ttl_time)\n    report(ttl_hline)\n\n    report('%s\\n' % otdfobj.casetitle.line1)\n    report('%s\\n' % otdfobj.casetitle.line2)\n    report('\\n')\n\n    report('Saved Case file              = %s\\n' % otdfobj.file.sav)\n    report('DFAX file                    = %s\\n' % otdfobj.file.dfx)\n    report('Subsystem file               = %s\\n' % otd"
  },
  {
    "id": "chunk_1541",
    "text": "report('Subsystem file               = %s\\n' % otdfobj.file.sub)\n    report('Monitored Element file       = %s\\n' % otdfobj.file.mon)\n    report('Contingency Description file = %s\\n' % otdfobj.file.con)\n    report('\\n')\n\n    report('*** OTDF Contingency Description ***\\n')\n    for i in range(otdfobj.size.ncase):\n        lbl  = otdfobj.colabel[i]\n        desc = otdfobj.codesc[i]\n        report(\"  %(lbl)12s  %(desc)s\\n\" %vars())\n\n    report(\"\\n\")\n    report('*** OTDF Factors ***\\n')\n    report('  "
  },
  {
    "id": "chunk_1542",
    "text": "   report('*** OTDF Factors ***\\n')\n    report('  <---------- Monitored Branch/Interface ------------->  ')\n    for each in otdfobj.colabel:\n        report(\"%12s  \" %each.strip())\n    report(\"\\n\")\n    for i in range(otdfobj.size.nmline+otdfobj.size.ninter):\n        report(\"  %52s  \" % otdfobj.melement[i].strip())\n        for j in range(otdfobj.size.ncase):\n            report(\"%12.6f  \" % otdfobj.factor[j][i])\n        report(\"\\n\")\n\n    # -----------------------------------------------------------"
  },
  {
    "id": "chunk_1543",
    "text": "---------------------------------------------------------------------------------------\n    rptfile_h.close()\n    txt = '\\n OTDF Factors saved to file %s\\n' % rptfile\n    sys.stdout.write(txt)\n\n# ====================================================================================================\n# ====================================================================================================\nif __name__ == '__main__':\n\n    import psse35\n    otdf_report()\n    # OR\n    #otdf_report(savfile, d"
  },
  {
    "id": "chunk_1544",
    "text": "otdf_report()\n    # OR\n    #otdf_report(savfile, dfxfile, outpath)\n\n# ====================================================================================================\n# [preparer_transfomers_iec_data.py] 04/08/2009 Preparer Two and Three Winding Transformers IEC Data\n# ==================================================================================================\n'''\nIn some PSSE Saved Cases, especially some old sav files, all transformer data is provided on\nSystem MVA base (SBASE). When "
  },
  {
    "id": "chunk_1545",
    "text": "data is provided on\nSystem MVA base (SBASE). When this network data is to be used to calculate fault currents\naccording to \"IEC 60909\" standard, in order to calculate correct IEC impedance correction factors,\nnameplate transformer winding MVA data is required.\n\nThis file is used to:\n(1) Change working case to update transformers winding MVA derived from RATE A or B or C, and\n    when winding MVA is 100 MVA and impedance data I/O code (CZ) is System MVA Base.\n    Refer function: change_winding_mv"
  },
  {
    "id": "chunk_1546",
    "text": "em MVA Base.\n    Refer function: change_winding_mva(rating='')\n    In some Saved case files, nameplate winding MVA data is stored as one of the ratings (RATE A, B, C),\n    then this files can be used to change transformer winding MVA with selected Rating. \n\n(2) Create transformers IEC data file.\n    Refer function: create_iecdata(wdgmva='',rptfile='')\n    Create a text file with all transformer branches and then use this file to provide\n    nameplate transformer winding MVA as part of transforme"
  },
  {
    "id": "chunk_1547",
    "text": "late transformer winding MVA as part of transformer nameplate IEC data records.\n    \n---------------------------------------------------------------------------------\nFunctions:\n\n(1) change_winding_mva(rating='')\n    Change all Transformers Winding MVA to a MVA value derived from RATE A or B or C.\n\n(2) create_iecdata(wdgmva='',rptfile='')\n    Create IEC data file for all Transformers Winding MVA.\n    Each IEC data record for a transformer has following format.\n    IBUS, JBUS, KBUS, CKT, SBASE1-2"
  },
  {
    "id": "chunk_1548",
    "text": "lowing format.\n    IBUS, JBUS, KBUS, CKT, SBASE1-2, SBASE2-3, SBASE3-1\n\n    Transformers IEC data records created here need to put in complete IEC data file.\n        Refer POM Volume 1, API IECS for format of IEC data file.\n        \n    This function creates output file depending on the wndmva input provided.\n    (1) If wndmva is not provided, it creates records in the following format.\n    IBUS, JBUS, KBUS, CKT\n    Then users would modify this file and manually input SBASE1-2, SBASE2-3, SBASE3-"
  },
  {
    "id": "chunk_1549",
    "text": "ile and manually input SBASE1-2, SBASE2-3, SBASE3-1 values.\n\n    (2) If wndmva=\"SBASE\", it creates records in the following format.\n    IBUS, JBUS, KBUS, CKT, SBASE1-2, SBASE2-3, SBASE3-1\n    Then users would modify this file and manually update SBASE1-2, SBASE2-3, SBASE3-1 values.\n\n    (3) If wndmva=\"RATEA\" or \"RATEB\" or \"RATEC\", it creates records in the following format.\n    IBUS, JBUS, KBUS, CKT, SBASE1-2, SBASE2-3, SBASE3-1\n    where SBASE1-2 = min(Winding 1 Selected Rating, Winding 2 Selec"
  },
  {
    "id": "chunk_1550",
    "text": "2 = min(Winding 1 Selected Rating, Winding 2 Selected Rating)\n          SBASE2-3 = min(Winding 2 Selected Rating, Winding 3 Selected Rating)\n          SBASE3-1 = min(Winding 3 Selected Rating, Winding 1 Selected Rating)\n          If any of the winding MVA is zero, it is ignored.\n    Users could modify this file and manually update SBASE1-2, SBASE2-3, SBASE3-1 values.\n\n---------------------------------------------------------------------------------\nHow to use this file?\n\n(1) Open the Saved Case "
  },
  {
    "id": "chunk_1551",
    "text": "--\nHow to use this file?\n\n(1) Open the Saved Case using PSS(R)E GUI\n\n(2) Without PROMPT for inputing arguments:\n    Call follwoing functions from CLI or another Python automation file:\n    change_winding_mva(rating)\n    or\n    create_iecdata(wndmva, rptfile)\n\n(3) With PROMPTS for inputing arguments:\n    Call follwoing functions from CLI or another Python automation file:\n    dochng()\n    or\n    docreate()\n'''\n\nimport psspy, os\n\n\n# ================================================================="
  },
  {
    "id": "chunk_1552",
    "text": "============================================================================\n\ndef _splitstring_commaspace(tmpstr):\n    '''Split string first at comma and then by space. Example:\n    Input  tmpstr = a1       a2,  ,a4 a5 ,,,a8,a9\n    Output strlst = ['a1', 'a2', ' ', 'a4', 'a5', ' ', ' ', 'a8', 'a9']\n    '''\n    strlst = []\n    commalst = tmpstr.split(',')\n    for each in commalst:\n        eachlst = each.split()\n        if eachlst:\n            strlst.extend(eachlst)\n        else:\n            strls"
  },
  {
    "id": "chunk_1553",
    "text": "st.extend(eachlst)\n        else:\n            strlst.extend(' ')\n\n    return strlst\n\n# ===========================================================================================\n\ndef _check_wdgmva(instr):\n    '''check for valid wdgmva string.'''\n\n    if type(instr) != str: instr = str(instr)\n    instr0 = instr\n    \n    instr = instr.strip().lower()\n    if not instr:\n        retv = ''\n    elif instr =='ratea':\n        retv = \"RATEA\"\n    elif instr =='rateb':\n        retv = \"RATEB\"\n    elif instr "
  },
  {
    "id": "chunk_1554",
    "text": " =='rateb':\n        retv = \"RATEB\"\n    elif instr =='ratec':\n        retv = \"RATEC\"\n    elif instr =='sbase':\n        retv = \"SBASE\"\n    else:\n        print(' Input value \"%s\" not recognized.\\n' % str(instr0))\n        retv = ''\n\n    return retv\n\n# ===========================================================================================\n\ndef _min_rate(r1,r2):\n    if not r1:\n        retv = r2\n    elif not r2:\n        retv = r1\n    else:\n        retv = min(r1,r2)\n\n    return retv\n\n# ============="
  },
  {
    "id": "chunk_1555",
    "text": "etv = min(r1,r2)\n\n    return retv\n\n# ===========================================================================================\n\ndef _get_xmer_data(wdgmva=''):\n\n    '''\n    wdgmva = 0 or ''    # return just transfomrer buses and ckt id\n           = 'sbase'    # return transfomrer buses, ckt id with winding MVA as SBASE\n           \n           = 'ratea'    # return transfomrer buses, ckt id with winding MVA derived from\n           = 'rateb'    # winding rating A or B or C\n           = 'ratec'    "
  },
  {
    "id": "chunk_1556",
    "text": "inding rating A or B or C\n           = 'ratec'    # Example: sbase1-2 = min(winding 1 Rate A, winding 2 Rate A)\n    '''\n    \n    sid   = -1       # all buses\n    owner = 1        # ignored\n    ties  = 1        # ignored\n\n    # Get Two Winding Transformer Specified Rating\n    flag  = 2        # =1 in-service transformers, =2 all\n    entry = 1        # each branch once only\n\n    ierr, tmplist1 = psspy.atrnint (sid, owner, ties, flag, entry, string=['FROMNUMBER','TONUMBER'])\n    ierr, tmplist2 = ps"
  },
  {
    "id": "chunk_1557",
    "text": "['FROMNUMBER','TONUMBER'])\n    ierr, tmplist2 = psspy.atrnchar(sid, owner, ties, flag, entry, string=['ID'])\n    if wdgmva:\n        if wdgmva == \"SBASE\":\n            strval = \"SBASE1\"\n        else:\n            strval = wdgmva\n        ierr, tmplist3 = psspy.atrnreal(sid, owner, ties, flag, entry, string=[strval])\n\n    two_wdg_xmers = {}\n    for i in range(len(tmplist1[0])):\n        busi  = tmplist1[0][i]\n        busj  = tmplist1[1][i]\n        cktid = tmplist2[0][i]\n        if wdgmva:\n            "
  },
  {
    "id": "chunk_1558",
    "text": "d = tmplist2[0][i]\n        if wdgmva:\n            val = tmplist3[0][i]\n        else:\n            val = ''\n        two_wdg_xmers[(busi,busj,cktid)] = {'sbase12':val}\n\n    # Three Winding Transformer Specified Rating\n    flag  = 3        # =2 all windings of in-service transformers\n                     # =3 all transformers\n    entry = 2        # transformer name order, don't make this 1, following assignments (ratea_w1 etc.)\n                     # need to be done differently when entry = 1\n\n    i"
  },
  {
    "id": "chunk_1559",
    "text": " need to be done differently when entry = 1\n\n    ierr, tmplist1 = psspy.awndint (sid, owner, ties, flag, entry, string=['WIND1NUMBER','WIND2NUMBER','WIND3NUMBER'])\n    ierr, tmplist2 = psspy.awndchar(sid, owner, ties, flag, entry, string=['ID'])\n    if wdgmva:\n        ierr, tmplist3 = psspy.awndreal(sid, owner, ties, flag, entry, string=[wdgmva])\n\n    three_wdg_xmers = {}\n    nwdgs = len(tmplist1[0])\n    for i in range(0,nwdgs,3):\n        busi     = tmplist1[0][i]\n        busj     = tmplist1[1]["
  },
  {
    "id": "chunk_1560",
    "text": "  = tmplist1[0][i]\n        busj     = tmplist1[1][i]\n        busk     = tmplist1[2][i]\n        cktid    = tmplist2[0][i]\n        if wdgmva == 'SBASE':\n            val1 = tmplist3[0][i]\n            val2 = tmplist3[0][i+1]\n            val3 = tmplist3[0][i+2]\n        elif wdgmva in ['RATEA', 'RATEB', 'RATEC']:\n            ratea_w1 = tmplist3[0][i]\n            ratea_w2 = tmplist3[0][i+1]\n            ratea_w3 = tmplist3[0][i+2]\n            val1 = _min_rate(ratea_w1,ratea_w2)\n            val2 = _min_r"
  },
  {
    "id": "chunk_1561",
    "text": "_rate(ratea_w1,ratea_w2)\n            val2 = _min_rate(ratea_w2,ratea_w3)\n            val3 = _min_rate(ratea_w3,ratea_w1)\n        else:\n            val1 = ''\n            val2 = ''\n            val3 = ''\n            \n        three_wdg_xmers[(busi,busj,busk,cktid)] = {'sbase12':val1, 'sbase23':val2, 'sbase31':val3}\n   \n    return two_wdg_xmers, three_wdg_xmers\n\n# ===========================================================================================\n\ndef change_winding_mva(rating=''):\n    '''Cha"
  },
  {
    "id": "chunk_1562",
    "text": "===\n\ndef change_winding_mva(rating=''):\n    '''Change all Transformers Winding MVA to a MVA value derived from RATE A or B or C.'''\n\n    wdgmva = _check_wdgmva(rating)\n    \n    if wdgmva not in ['RATEA', 'RATEB', 'RATEC']:\n        print(\" No need to update working case.\")\n        return\n    \n    two_wdg_xmers, three_wdg_xmers = _get_xmer_data(wdgmva)\n\n    lst2wdg = list(two_wdg_xmers.keys())\n    lst2wdg.sort()\n\n    lst3wdg = list(three_wdg_xmers.keys())\n    lst3wdg.sort()\n\n    for brn in lst2wdg"
  },
  {
    "id": "chunk_1563",
    "text": "keys())\n    lst3wdg.sort()\n\n    for brn in lst2wdg:\n        ibus = brn[0]\n        jbus = brn[1]\n        ckt  = brn[2]\n        sbase12 = two_wdg_xmers[brn]['sbase12']\n        ierr,realaro = psspy.two_winding_data(ibus, jbus, ckt, realari3=sbase12)\n\n    for brn in lst3wdg:\n        ibus = brn[0]\n        jbus = brn[1]\n        kbus = brn[2]    \n        ckt  = brn[3]\n        sbase12 = three_wdg_xmers[brn]['sbase12']\n        sbase23 = three_wdg_xmers[brn]['sbase23']\n        sbase31 = three_wdg_xmers[br"
  },
  {
    "id": "chunk_1564",
    "text": "n]['sbase23']\n        sbase31 = three_wdg_xmers[brn]['sbase31']    \n        ierr,realaro = psspy.three_wnd_impedance_data(ibus, jbus, kbus, ckt, realari7=sbase12,\n                                                      realari8=sbase23, realari9=sbase31)\n    \n# ===========================================================================================\n\ndef create_iecdata(wdgmva='',rptfile=''):\n    '''Create IEC data file for all Transformers Winding MVA.'''\n\n    wdgmva = _check_wdgmva(wdgmva)\n\n   "
  },
  {
    "id": "chunk_1565",
    "text": "g MVA.'''\n\n    wdgmva = _check_wdgmva(wdgmva)\n\n    two_wdg_xmers, three_wdg_xmers = _get_xmer_data(wdgmva)\n\n    if rptfile:     # open report file to write\n        p,nx = os.path.split(rptfile)\n        if not p: p = os.getcwd()\n        n,x = os.path.splitext(nx)\n        if not x or x.lower() != '.txt': x = '.txt'\n        nx = n + x\n        rptfile = os.path.join(p,nx)\n        rptfile_h = open(rptfile,'w')\n        report       = rptfile_h.write\n    else:           # send results to PSS(R)E report"
  },
  {
    "id": "chunk_1566",
    "text": "  else:           # send results to PSS(R)E report window\n        psspy.beginreport()\n        report = psspy.report\n\n    # printing\n    report('/  BUS I   BUS J   BUS K  CKT  SBASE1-2  SBASE2-3  SBASE3-1\\n')\n\n    # Two Winding Transformers\n    lst2wdg = list(two_wdg_xmers.keys())\n    lst2wdg.sort()\n    for brn in lst2wdg:\n        ibus = brn[0]\n        jbus = brn[1]\n        kbus = 0\n        ckt  = brn[2].strip()\n        sbase12 = two_wdg_xmers[brn]['sbase12']\n        if sbase12:\n            sbase"
  },
  {
    "id": "chunk_1567",
    "text": "]['sbase12']\n        if sbase12:\n            sbase12 = \"%8.2f\" % sbase12\n        else:\n            sbase12 = ''\n        report('%(ibus)8d  %(jbus)6d  %(kbus)6d  %(ckt)3s  %(sbase12)s\\n' % vars())\n\n    # Three Winding Transformers\n    lst3wdg = list(three_wdg_xmers.keys())\n    lst3wdg.sort()\n\n    for brn in lst3wdg:\n        ibus = brn[0]\n        jbus = brn[1]\n        kbus = brn[2]    \n        ckt  = brn[3].strip()\n        sbase12  = three_wdg_xmers[brn]['sbase12']\n        sbase23  = three_wdg_xme"
  },
  {
    "id": "chunk_1568",
    "text": "s[brn]['sbase12']\n        sbase23  = three_wdg_xmers[brn]['sbase23']\n        sbase31  = three_wdg_xmers[brn]['sbase31']    \n        if sbase12:\n            sbase12 = \"%8.2f\" % sbase12\n            sbase23 = \"%8.2f\" % sbase23\n            sbase31 = \"%8.2f\" % sbase31\n        else:\n            sbase12 = ''\n            sbase23 = ''\n            sbase31 = ''\n\n        report('%(ibus)8d  %(jbus)6d  %(kbus)6d  %(ckt)3s  %(sbase12)s  %(sbase23)s  %(sbase31)s\\n' % vars())\n\n    if rptfile:\n        print(\" Tra"
  },
  {
    "id": "chunk_1569",
    "text": "\\n' % vars())\n\n    if rptfile:\n        print(\" Transformers IEC Data records saved in file %s.\" % rptfile)\n\n# ====================================================================================================\n\ndef dochng():\n    psspy.prompt(\"PROVIDE RATING TO SELECT:\\n\\n\\\n        - TYPE ratea for RATE A or\\n\\\n        - TYPE rateb for RATE B or\\n\\\n        - TYPE ratec for RATE C\")\n    \n    ierr, rating = psspy.userin()\n\n    change_winding_mva(rating)\n    \n# ====================================="
  },
  {
    "id": "chunk_1570",
    "text": "ting)\n    \n# ====================================================================================================\n\ndef docreate():\n    psspy.prompt(\"PROVIDE WINDING MVA selection string and IEC DATA output text file name:\\n\\n\\\n        - ALLOWED WINDING MVA selection string\\n\\\n             sbase, ratea, rateb, ratec or ''(empty string) \\n\")\n    psspy.prompt(\"        - OPTIONAL OUTPUT text file name (when not provided, output created in PSS(R)E report window)\\n\")\n    psspy.prompt(\"TYPE inputs sepa"
  },
  {
    "id": "chunk_1571",
    "text": "ort window)\\n\")\n    psspy.prompt(\"TYPE inputs separated either by comma or space.\")\n    \n    ierr, instr = psspy.userin()\n    wndmva  = ''\n    rptfile = ''\n\n    if instr:\n        instrlst = _splitstring_commaspace(instr)\n        wndmva = instrlst[0]\n        try:\n            rptfile = instrlst[1]\n        except:\n            pass\n\n    create_iecdata(wndmva, rptfile)\n    \n# ====================================================================================================\n\nif __name__ == '__main__"
  },
  {
    "id": "chunk_1572",
    "text": "========================\n\nif __name__ == '__main__':\n    #dochng()\n    docreate()\n\n# ====================================================================================================\n   \n\n# [preparer_transfomers_iec_data.py] 04/08/2009 Preparer Two and Three Winding Transformers IEC Data\n# ==================================================================================================\n'''\nIn some PSSE Saved Cases, especially some old sav files, all transformer data is provided on\nSystem MVA"
  },
  {
    "id": "chunk_1573",
    "text": "es, all transformer data is provided on\nSystem MVA base (SBASE). When this network data is to be used to calculate fault currents\naccording to \"IEC 60909\" standard, in order to calculate correct IEC impedance correction factors,\nnameplate transformer winding MVA data is required.\n\nThis file is used to:\n(1) Change working case to update transformers winding MVA derived from RATE A or B or C, and\n    when winding MVA is 100 MVA and impedance data I/O code (CZ) is System MVA Base.\n    Refer functio"
  },
  {
    "id": "chunk_1574",
    "text": "/O code (CZ) is System MVA Base.\n    Refer function: change_winding_mva(rating='')\n    In some Saved case files, nameplate winding MVA data is stored as one of the ratings (RATE A, B, C),\n    then this files can be used to change transformer winding MVA with selected Rating. \n\n(2) Create transformers IEC data file.\n    Refer function: create_iecdata(wdgmva='',rptfile='')\n    Create a text file with all transformer branches and then use this file to provide\n    nameplate transformer winding MVA a"
  },
  {
    "id": "chunk_1575",
    "text": "to provide\n    nameplate transformer winding MVA as part of transformer nameplate IEC data records.\n    \n---------------------------------------------------------------------------------\nFunctions:\n\n(1) change_winding_mva(rating='')\n    Change all Transformers Winding MVA to a MVA value derived from RATE A or B or C.\n\n(2) create_iecdata(wdgmva='',rptfile='')\n    Create IEC data file for all Transformers Winding MVA.\n    Each IEC data record for a transformer has following format.\n    IBUS, JBUS,"
  },
  {
    "id": "chunk_1576",
    "text": " transformer has following format.\n    IBUS, JBUS, KBUS, CKT, SBASE1-2, SBASE2-3, SBASE3-1\n\n    Transformers IEC data records created here need to put in complete IEC data file.\n        Refer POM Volume 1, API IECS for format of IEC data file.\n        \n    This function creates output file depending on the wndmva input provided.\n    (1) If wndmva is not provided, it creates records in the following format.\n    IBUS, JBUS, KBUS, CKT\n    Then users would modify this file and manually input SBASE1-"
  },
  {
    "id": "chunk_1577",
    "text": " would modify this file and manually input SBASE1-2, SBASE2-3, SBASE3-1 values.\n\n    (2) If wndmva=\"SBASE\", it creates records in the following format.\n    IBUS, JBUS, KBUS, CKT, SBASE1-2, SBASE2-3, SBASE3-1\n    Then users would modify this file and manually update SBASE1-2, SBASE2-3, SBASE3-1 values.\n\n    (3) If wndmva=\"RATEA\" or \"RATEB\" or \"RATEC\", it creates records in the following format.\n    IBUS, JBUS, KBUS, CKT, SBASE1-2, SBASE2-3, SBASE3-1\n    where SBASE1-2 = min(Winding 1 Selected Rat"
  },
  {
    "id": "chunk_1578",
    "text": "-1\n    where SBASE1-2 = min(Winding 1 Selected Rating, Winding 2 Selected Rating)\n          SBASE2-3 = min(Winding 2 Selected Rating, Winding 3 Selected Rating)\n          SBASE3-1 = min(Winding 3 Selected Rating, Winding 1 Selected Rating)\n          If any of the winding MVA is zero, it is ignored.\n    Users could modify this file and manually update SBASE1-2, SBASE2-3, SBASE3-1 values.\n\n---------------------------------------------------------------------------------\nHow to use this file?\n\n(1) "
  },
  {
    "id": "chunk_1579",
    "text": "----------------------\nHow to use this file?\n\n(1) Open the Saved Case using PSS(R)E GUI\n\n(2) Without PROMPT for inputing arguments:\n    Call follwoing functions from CLI or another Python automation file:\n    change_winding_mva(rating)\n    or\n    create_iecdata(wndmva, rptfile)\n\n(3) With PROMPTS for inputing arguments:\n    Call follwoing functions from CLI or another Python automation file:\n    dochng()\n    or\n    docreate()\n'''\n\nimport psspy, os\n\n\n# ============================================="
  },
  {
    "id": "chunk_1580",
    "text": "\n\n\n# ===========================================================================================\n\ndef _splitstring_commaspace(tmpstr):\n    '''Split string first at comma and then by space. Example:\n    Input  tmpstr = a1       a2,  ,a4 a5 ,,,a8,a9\n    Output strlst = ['a1', 'a2', ' ', 'a4', 'a5', ' ', ' ', 'a8', 'a9']\n    '''\n    strlst = []\n    commalst = tmpstr.split(',')\n    for each in commalst:\n        eachlst = each.split()\n        if eachlst:\n            strlst.extend(eachlst)\n        els"
  },
  {
    "id": "chunk_1581",
    "text": "st:\n            strlst.extend(eachlst)\n        else:\n            strlst.extend(' ')\n\n    return strlst\n\n# ===========================================================================================\n\ndef _check_wdgmva(instr):\n    '''check for valid wdgmva string.'''\n\n    if type(instr) != str: instr = str(instr)\n    instr0 = instr\n    \n    instr = instr.strip().lower()\n    if not instr:\n        retv = ''\n    elif instr =='ratea':\n        retv = \"RATEA\"\n    elif instr =='rateb':\n        retv = \"RA"
  },
  {
    "id": "chunk_1582",
    "text": "ATEA\"\n    elif instr =='rateb':\n        retv = \"RATEB\"\n    elif instr =='ratec':\n        retv = \"RATEC\"\n    elif instr =='sbase':\n        retv = \"SBASE\"\n    else:\n        print(' Input value \"%s\" not recognized.\\n' % str(instr0))\n        retv = ''\n\n    return retv\n\n# ===========================================================================================\n\ndef _min_rate(r1,r2):\n    if not r1:\n        retv = r2\n    elif not r2:\n        retv = r1\n    else:\n        retv = min(r1,r2)\n\n    return r"
  },
  {
    "id": "chunk_1583",
    "text": "\n    else:\n        retv = min(r1,r2)\n\n    return retv\n\n# ===========================================================================================\n\ndef _get_xmer_data(wdgmva=''):\n\n    '''\n    wdgmva = 0 or ''    # return just transfomrer buses and ckt id\n           = 'sbase'    # return transfomrer buses, ckt id with winding MVA as SBASE\n           \n           = 'ratea'    # return transfomrer buses, ckt id with winding MVA derived from\n           = 'rateb'    # winding rating A or B or C\n    "
  },
  {
    "id": "chunk_1584",
    "text": "    = 'rateb'    # winding rating A or B or C\n           = 'ratec'    # Example: sbase1-2 = min(winding 1 Rate A, winding 2 Rate A)\n    '''\n    \n    sid   = -1       # all buses\n    owner = 1        # ignored\n    ties  = 1        # ignored\n\n    # Get Two Winding Transformer Specified Rating\n    flag  = 2        # =1 in-service transformers, =2 all\n    entry = 1        # each branch once only\n\n    ierr, tmplist1 = psspy.atrnint (sid, owner, ties, flag, entry, string=['FROMNUMBER','TONUMBER'])\n   "
  },
  {
    "id": "chunk_1585",
    "text": "flag, entry, string=['FROMNUMBER','TONUMBER'])\n    ierr, tmplist2 = psspy.atrnchar(sid, owner, ties, flag, entry, string=['ID'])\n    if wdgmva:\n        if wdgmva == \"SBASE\":\n            strval = \"SBASE1\"\n        else:\n            strval = wdgmva\n        ierr, tmplist3 = psspy.atrnreal(sid, owner, ties, flag, entry, string=[strval])\n\n    two_wdg_xmers = {}\n    for i in range(len(tmplist1[0])):\n        busi  = tmplist1[0][i]\n        busj  = tmplist1[1][i]\n        cktid = tmplist2[0][i]\n        if "
  },
  {
    "id": "chunk_1586",
    "text": "1[1][i]\n        cktid = tmplist2[0][i]\n        if wdgmva:\n            val = tmplist3[0][i]\n        else:\n            val = ''\n        two_wdg_xmers[(busi,busj,cktid)] = {'sbase12':val}\n\n    # Three Winding Transformer Specified Rating\n    flag  = 3        # =2 all windings of in-service transformers\n                     # =3 all transformers\n    entry = 2        # transformer name order, don't make this 1, following assignments (ratea_w1 etc.)\n                     # need to be done differently w"
  },
  {
    "id": "chunk_1587",
    "text": "                   # need to be done differently when entry = 1\n\n    ierr, tmplist1 = psspy.awndint (sid, owner, ties, flag, entry, string=['WIND1NUMBER','WIND2NUMBER','WIND3NUMBER'])\n    ierr, tmplist2 = psspy.awndchar(sid, owner, ties, flag, entry, string=['ID'])\n    if wdgmva:\n        ierr, tmplist3 = psspy.awndreal(sid, owner, ties, flag, entry, string=[wdgmva])\n\n    three_wdg_xmers = {}\n    nwdgs = len(tmplist1[0])\n    for i in range(0,nwdgs,3):\n        busi     = tmplist1[0][i]\n        bus"
  },
  {
    "id": "chunk_1588",
    "text": ",3):\n        busi     = tmplist1[0][i]\n        busj     = tmplist1[1][i]\n        busk     = tmplist1[2][i]\n        cktid    = tmplist2[0][i]\n        if wdgmva == 'SBASE':\n            val1 = tmplist3[0][i]\n            val2 = tmplist3[0][i+1]\n            val3 = tmplist3[0][i+2]\n        elif wdgmva in ['RATEA', 'RATEB', 'RATEC']:\n            ratea_w1 = tmplist3[0][i]\n            ratea_w2 = tmplist3[0][i+1]\n            ratea_w3 = tmplist3[0][i+2]\n            val1 = _min_rate(ratea_w1,ratea_w2)\n     "
  },
  {
    "id": "chunk_1589",
    "text": "         val1 = _min_rate(ratea_w1,ratea_w2)\n            val2 = _min_rate(ratea_w2,ratea_w3)\n            val3 = _min_rate(ratea_w3,ratea_w1)\n        else:\n            val1 = ''\n            val2 = ''\n            val3 = ''\n            \n        three_wdg_xmers[(busi,busj,busk,cktid)] = {'sbase12':val1, 'sbase23':val2, 'sbase31':val3}\n   \n    return two_wdg_xmers, three_wdg_xmers\n\n# ===========================================================================================\n\ndef change_winding_mva(ra"
  },
  {
    "id": "chunk_1590",
    "text": "=======================\n\ndef change_winding_mva(rating=''):\n    '''Change all Transformers Winding MVA to a MVA value derived from RATE A or B or C.'''\n\n    wdgmva = _check_wdgmva(rating)\n    \n    if wdgmva not in ['RATEA', 'RATEB', 'RATEC']:\n        print(\" No need to update working case.\")\n        return\n    \n    two_wdg_xmers, three_wdg_xmers = _get_xmer_data(wdgmva)\n\n    lst2wdg = list(two_wdg_xmers.keys())\n    lst2wdg.sort()\n\n    lst3wdg = list(three_wdg_xmers.keys())\n    lst3wdg.sort()\n\n  "
  },
  {
    "id": "chunk_1591",
    "text": "ist(three_wdg_xmers.keys())\n    lst3wdg.sort()\n\n    for brn in lst2wdg:\n        ibus = brn[0]\n        jbus = brn[1]\n        ckt  = brn[2]\n        sbase12 = two_wdg_xmers[brn]['sbase12']\n        ierr,realaro = psspy.two_winding_data(ibus, jbus, ckt, realari3=sbase12)\n\n    for brn in lst3wdg:\n        ibus = brn[0]\n        jbus = brn[1]\n        kbus = brn[2]    \n        ckt  = brn[3]\n        sbase12 = three_wdg_xmers[brn]['sbase12']\n        sbase23 = three_wdg_xmers[brn]['sbase23']\n        sbase31 "
  },
  {
    "id": "chunk_1592",
    "text": "= three_wdg_xmers[brn]['sbase23']\n        sbase31 = three_wdg_xmers[brn]['sbase31']    \n        ierr,realaro = psspy.three_wnd_impedance_data(ibus, jbus, kbus, ckt, realari7=sbase12,\n                                                      realari8=sbase23, realari9=sbase31)\n    \n# ===========================================================================================\n\ndef create_iecdata(wdgmva='',rptfile=''):\n    '''Create IEC data file for all Transformers Winding MVA.'''\n\n    wdgmva = _check"
  },
  {
    "id": "chunk_1593",
    "text": " Transformers Winding MVA.'''\n\n    wdgmva = _check_wdgmva(wdgmva)\n\n    two_wdg_xmers, three_wdg_xmers = _get_xmer_data(wdgmva)\n\n    if rptfile:     # open report file to write\n        p,nx = os.path.split(rptfile)\n        if not p: p = os.getcwd()\n        n,x = os.path.splitext(nx)\n        if not x or x.lower() != '.txt': x = '.txt'\n        nx = n + x\n        rptfile = os.path.join(p,nx)\n        rptfile_h = open(rptfile,'w')\n        report       = rptfile_h.write\n    else:           # send resul"
  },
  {
    "id": "chunk_1594",
    "text": "= rptfile_h.write\n    else:           # send results to PSS(R)E report window\n        psspy.beginreport()\n        report = psspy.report\n\n    # printing\n    report('/  BUS I   BUS J   BUS K  CKT  SBASE1-2  SBASE2-3  SBASE3-1\\n')\n\n    # Two Winding Transformers\n    lst2wdg = list(two_wdg_xmers.keys())\n    lst2wdg.sort()\n    for brn in lst2wdg:\n        ibus = brn[0]\n        jbus = brn[1]\n        kbus = 0\n        ckt  = brn[2].strip()\n        sbase12 = two_wdg_xmers[brn]['sbase12']\n        if sbase1"
  },
  {
    "id": "chunk_1595",
    "text": " = two_wdg_xmers[brn]['sbase12']\n        if sbase12:\n            sbase12 = \"%8.2f\" % sbase12\n        else:\n            sbase12 = ''\n        report('%(ibus)8d  %(jbus)6d  %(kbus)6d  %(ckt)3s  %(sbase12)s\\n' % vars())\n\n    # Three Winding Transformers\n    lst3wdg = list(three_wdg_xmers.keys())\n    lst3wdg.sort()\n\n    for brn in lst3wdg:\n        ibus = brn[0]\n        jbus = brn[1]\n        kbus = brn[2]    \n        ckt  = brn[3].strip()\n        sbase12  = three_wdg_xmers[brn]['sbase12']\n        sbas"
  },
  {
    "id": "chunk_1596",
    "text": "12  = three_wdg_xmers[brn]['sbase12']\n        sbase23  = three_wdg_xmers[brn]['sbase23']\n        sbase31  = three_wdg_xmers[brn]['sbase31']    \n        if sbase12:\n            sbase12 = \"%8.2f\" % sbase12\n            sbase23 = \"%8.2f\" % sbase23\n            sbase31 = \"%8.2f\" % sbase31\n        else:\n            sbase12 = ''\n            sbase23 = ''\n            sbase31 = ''\n\n        report('%(ibus)8d  %(jbus)6d  %(kbus)6d  %(ckt)3s  %(sbase12)s  %(sbase23)s  %(sbase31)s\\n' % vars())\n\n    if rptfile:"
  },
  {
    "id": "chunk_1597",
    "text": "ase23)s  %(sbase31)s\\n' % vars())\n\n    if rptfile:\n        print(\" Transformers IEC Data records saved in file %s.\" % rptfile)\n\n# ====================================================================================================\n\ndef dochng():\n    psspy.prompt(\"PROVIDE RATING TO SELECT:\\n\\n\\\n        - TYPE ratea for RATE A or\\n\\\n        - TYPE rateb for RATE B or\\n\\\n        - TYPE ratec for RATE C\")\n    \n    ierr, rating = psspy.userin()\n\n    change_winding_mva(rating)\n    \n# ================="
  },
  {
    "id": "chunk_1598",
    "text": "hange_winding_mva(rating)\n    \n# ====================================================================================================\n\ndef docreate():\n    psspy.prompt(\"PROVIDE WINDING MVA selection string and IEC DATA output text file name:\\n\\n\\\n        - ALLOWED WINDING MVA selection string\\n\\\n             sbase, ratea, rateb, ratec or ''(empty string) \\n\")\n    psspy.prompt(\"        - OPTIONAL OUTPUT text file name (when not provided, output created in PSS(R)E report window)\\n\")\n    psspy.prom"
  },
  {
    "id": "chunk_1599",
    "text": "eated in PSS(R)E report window)\\n\")\n    psspy.prompt(\"TYPE inputs separated either by comma or space.\")\n    \n    ierr, instr = psspy.userin()\n    wndmva  = ''\n    rptfile = ''\n\n    if instr:\n        instrlst = _splitstring_commaspace(instr)\n        wndmva = instrlst[0]\n        try:\n            rptfile = instrlst[1]\n        except:\n            pass\n\n    create_iecdata(wndmva, rptfile)\n    \n# ====================================================================================================\n\nif _"
  },
  {
    "id": "chunk_1600",
    "text": "============================================\n\nif __name__ == '__main__':\n    #dochng()\n    docreate()\n\n# ====================================================================================================\n   \n# pssexcel_demo.py  Use of pssexcel to export ACCC, PV and QV\n# ====================================================================================================\n'''\nThis is an example file showing how to use Python module \"pssexcel\"\nto export ACCC, PV and QV solution results to excel s"
  },
  {
    "id": "chunk_1601",
    "text": "export ACCC, PV and QV solution results to excel spreadsheets.\n\nRefer help(pssexcel) for details.\n\n---------------------------------------------------------------------------------\nHow to use this file?\n\nAs showed in __main__ (end of this file)\n- Enable PSSE version specific environment, as an example, where XX could be 33 or 34:\n    import psseXX\n\n- call any of the function as below\n    accc()\n    accc(accfile='savnw.acc', show=True, cosep=True)\n\n    pv()\n    pv(pvfile='savnw.pv', show=True)\n\n "
  },
  {
    "id": "chunk_1602",
    "text": "\n\n    pv()\n    pv(pvfile='savnw.pv', show=True)\n\n    qv()\n    qv(qvfile='savnw.qv', show=True)\n\n---------------------------------------------------------------------------------\nAlternatively, use either of the following menu items.\n- from Start>Programs>PSSExx>Export Results to Excel OR\n- from Power Flow>Reports>Export Results to Excel\n\n'''\n# ====================================================================================================\nimport sys, os\n\ndef get_output_dir(outpath):\n    # if"
  },
  {
    "id": "chunk_1603",
    "text": "ort sys, os\n\ndef get_output_dir(outpath):\n    # if called from PSSE's Example Folder, create report in subfolder 'Output_Pyscript'\n\n    if outpath:\n        outdir = outpath\n        if not os.path.exists(outdir): os.mkdir(outdir)\n    else:\n        outdir = os.getcwd()\n        cwd = outdir.lower()\n        i = cwd.find('pti')\n        j = cwd.find('psse')\n        k = cwd.find('example')\n        if i>0 and j>i and k>j:     # called from Example folder\n            outdir = os.path.join(outdir, 'Output"
  },
  {
    "id": "chunk_1604",
    "text": "\n            outdir = os.path.join(outdir, 'Output_Pyscript')\n            if not os.path.exists(outdir): os.mkdir(outdir)\n\n    return outdir\n\n# ====================================================================================================\n\ndef get_output_filename(outpath, fnam):\n\n    p, nx = os.path.split(fnam)\n    if p:\n        retvfile = fnam\n    else:\n        outdir = get_output_dir(outpath)\n        retvfile = os.path.join(outdir, fnam)\n\n    return retvfile\n\n# =========================="
  },
  {
    "id": "chunk_1605",
    "text": "\n    return retvfile\n\n# ====================================================================================================\n\ndef accc(accfile='savnw.acc', outpath=None, show=True, cosep=True):\n    import pssexcel\n\n    if not os.path.exists(accfile):\n        prgmsg = \" Error: Input accfile '{0}' does not exist\".format(accfile)\n        print(prgmsg)\n        return\n\n    # Change these values as required.\n    string  = ['s','e','b','i','v','l','g','p','a']\n    colabel = [] #'base case', 'trip1nucle"
  },
  {
    "id": "chunk_1606",
    "text": "p','a']\n    colabel = [] #'base case', 'trip1nuclear', 'trip2nuclear']\n\n    p, nx = os.path.split(accfile)\n    n, x  = os.path.splitext(nx)\n\n    xlsfile = get_output_filename(outpath, 'pssexcel_demo_accc_' + n)\n\n    sheet = n + '_accc'\n    overwritesheet = True\n\n    baseflowvio = False\n    basevoltvio = False\n    flowlimit   = 0.0\n    flowchange  = 0.0\n    voltchange  = 0.0\n    branchanglediff = True\n    angdifmin=0.05\n\n    pssexcel.accc(accfile,string,colabel=colabel,xlsfile=xlsfile,sheet=sheet"
  },
  {
    "id": "chunk_1607",
    "text": "string,colabel=colabel,xlsfile=xlsfile,sheet=sheet,overwritesheet=overwritesheet,show=show,\n                  baseflowvio=baseflowvio, basevoltvio=basevoltvio, flowlimit=flowlimit,\n                  flowchange=flowchange, voltchange=voltchange, angdifmin=angdifmin, cosep=cosep, branchanglediff=branchanglediff)\n\n# ====================================================================================================\n\ndef pv(pvfile='savnw.pv', outpath=None, show=True):\n    import pssexcel\n\n    if not"
  },
  {
    "id": "chunk_1608",
    "text": "=None, show=True):\n    import pssexcel\n\n    if not os.path.exists(pvfile):\n        prgmsg = \" Error: Input pvfile '{0}' does not exist\".format(pvfile)\n        print(prgmsg)\n        return\n\n    # Change these values as required.\n    string  = ['s','v','m','g','l','b','i']\n    colabel = [] #'base case', 'trip1nuclear', 'trip2nuclear']\n\n    p, nx = os.path.split(pvfile)\n    n, x  = os.path.splitext(nx)\n\n    xlsfile = get_output_filename(outpath, 'pssexcel_demo_pv_' + n)\n\n    sheet = n + '_pv'\n    o"
  },
  {
    "id": "chunk_1609",
    "text": "sexcel_demo_pv_' + n)\n\n    sheet = n + '_pv'\n    overwritesheet = True\n\n    pssexcel.pv(pvfile,string,colabel=colabel,xlsfile=xlsfile,sheet=sheet,overwritesheet=overwritesheet,show=show)\n\n# ====================================================================================================\n\ndef qv(qvfile='savnw.qv', outpath=None, show=True):\n    import pssexcel\n\n    if not os.path.exists(qvfile):\n        prgmsg = \" Error: Input qvfile '{0}' does not exist\".format(qvfile)\n        print(prgmsg)\n  "
  },
  {
    "id": "chunk_1610",
    "text": "not exist\".format(qvfile)\n        print(prgmsg)\n        return\n\n    # Change these values as required.\n    string  = ['s','v','m','g']\n    colabel = [] #'base case', 'trip1nuclear', 'trip2nuclear']\n\n    p, nx = os.path.split(qvfile)\n    n, x  = os.path.splitext(nx)\n\n    xlsfile = get_output_filename(outpath, 'pssexcel_demo_qv_' + n)\n\n    sheet = n + '_qv'\n    overwritesheet = True\n\n    pssexcel.qv(qvfile,string,colabel=colabel,xlsfile=xlsfile,sheet=sheet,overwritesheet=overwritesheet,show=show)\n"
  },
  {
    "id": "chunk_1611",
    "text": "et=sheet,overwritesheet=overwritesheet,show=show)\n\n# ====================================================================================================\n# ====================================================================================================\nif __name__ == '__main__':\n    pass\n    # change XX to 33, 34 or 35.\n    #import psseXX\n\n    #accc(accfile)\n    #pv(pvfile)\n    #qv(qvfile)\n\n# ===================================================================================================="
  },
  {
    "id": "chunk_1612",
    "text": "==================================================\n\n\n# pv_export.py  Exporting PV Solution Results to Excel Spreadsheet\n# ====================================================================================================\n'''\nThis is an example file showing how to export PV solution results to excel spreadsheets.\n\nRefer help(arrbox.pv_pp) for details.\n\n---------------------------------------------------------------------------------\nHow to use this file?\n\nAs showed in __main__ (end of this file"
  },
  {
    "id": "chunk_1613",
    "text": "his file?\n\nAs showed in __main__ (end of this file)\n- Enable PSSE version specific environment, as an example:\n    import psse35\n\n- call any of the function as below\n    excel_report()\n    excel_report(pvfile='savnw.pv', show=True)\n\n    text_report()\n    text_report(pvfile='savnw.pv')\n\n---------------------------------------------------------------------------------\nAlternatively, use either of the following menu items.\n- from Start>Programs>PSSExx>Export Results to Excel OR\n- from Power Flow>Re"
  },
  {
    "id": "chunk_1614",
    "text": "xx>Export Results to Excel OR\n- from Power Flow>Reports>Export Results to Excel\n\n'''\n# ====================================================================================================\nimport sys, os\n\ndef get_output_dir(outpath):\n    # if called from PSSE's Example Folder, create report in subfolder 'Output_Pyscript'\n\n    if outpath:\n        outdir = outpath\n        if not os.path.exists(outdir): os.mkdir(outdir)\n    else:\n        outdir = os.getcwd()\n        cwd = outdir.lower()\n        i = "
  },
  {
    "id": "chunk_1615",
    "text": "getcwd()\n        cwd = outdir.lower()\n        i = cwd.find('pti')\n        j = cwd.find('psse')\n        k = cwd.find('example')\n        if i>0 and j>i and k>j:     # called from Example folder\n            outdir = os.path.join(outdir, 'Output_Pyscript')\n            if not os.path.exists(outdir): os.mkdir(outdir)\n\n    return outdir\n\n# ====================================================================================================\n\ndef get_output_filename(outpath, fnam):\n\n    p, nx = os.path.sp"
  },
  {
    "id": "chunk_1616",
    "text": "t_filename(outpath, fnam):\n\n    p, nx = os.path.split(fnam)\n    if p:\n        retvfile = fnam\n    else:\n        outdir = get_output_dir(outpath)\n        retvfile = os.path.join(outdir, fnam)\n\n    return retvfile\n\n# ====================================================================================================\n\ndef excel_report(pvfile='savnw.pv', outpath=None, show=True):\n    import pssexcel\n\n    if not os.path.exists(pvfile):\n        prgmsg = \" Error: Input pvfile '{0}' does not exist\".form"
  },
  {
    "id": "chunk_1617",
    "text": "= \" Error: Input pvfile '{0}' does not exist\".format(pvfile)\n        print(prgmsg)\n        return\n\n    # Change these values as required.\n    string  = ['s','v','m','g','l','b','i']\n    colabel = [] #['base case', 'trip1nuclear', 'trip2nuclear']\n\n    p, nx = os.path.split(pvfile)\n    n, x  = os.path.splitext(nx)\n\n    xlsfile = get_output_filename(outpath, 'pv_export_' + n)\n\n    sheet = n + '_pv'\n    overwritesheet = True\n\n    pssexcel.pv(pvfile,string,colabel=colabel,xlsfile=xlsfile,sheet=sheet,"
  },
  {
    "id": "chunk_1618",
    "text": "tring,colabel=colabel,xlsfile=xlsfile,sheet=sheet,overwritesheet=overwritesheet,show=show)\n\n# ====================================================================================================\n\ndef text_report(pvfile='savnw.pv', outpath=None):\n\n    import arrbox.pv_pp\n\n    if not os.path.exists(pvfile):\n        prgmsg = \" Error: Input pvfile '{0}' does not exist\".format(pvfile)\n        print(prgmsg)\n        return\n\n    pvobj = arrbox.pv_pp.PV_PP(pvfile)\n\n    p, nx = os.path.split(pvfile)\n    n"
  },
  {
    "id": "chunk_1619",
    "text": "P(pvfile)\n\n    p, nx = os.path.split(pvfile)\n    n, x  = os.path.splitext(nx)\n\n    smryfile = get_output_filename(outpath, 'pv_export_' + n +'_summary.txt')\n    solnfile = get_output_filename(outpath, 'pv_export_' + n +'_solution.txt')\n\n    ierr = pvobj.summary_report(smryfile)\n\n    ierr = pvobj.solution_report(colabels=None,rptfile=solnfile)\n\n# ====================================================================================================\n# ================================================="
  },
  {
    "id": "chunk_1620",
    "text": " ====================================================================================================\nif __name__ == '__main__':\n\n    import psse35\n\n    #excel_report()\n    #text_report()\n    #excel_report(pvfile='savnw.pv', show=True)\n    #text_report(pvfile='savnw.pv')\n\n# ====================================================================================================\n# qv_export.py  Exporting QV Solution Results to Excel Spreadsheet\n# ======================================================="
  },
  {
    "id": "chunk_1621",
    "text": "===============================================================================================\n'''\nThis is an example file showing how to export PV solution results to excel spreadsheets.\n\nRefer help(arrbox.qv_pp) for details.\n\n---------------------------------------------------------------------------------\nHow to use this file?\n\nAs showed in __main__ (end of this file)\n- Enable PSSE version specific environment, as an example:\n    import psse35\n\n- call any of the function as below\n    excel_r"
  },
  {
    "id": "chunk_1622",
    "text": "5\n\n- call any of the function as below\n    excel_report()\n    excel_report(qvfile='savnw.qv', show=True)\n\n    text_report()\n    text_report(qvfile='savnw.qv')\n\n---------------------------------------------------------------------------------\nAlternatively, use either of the following menu items.\n- from Start>Programs>PSSExx>Export Results to Excel OR\n- from Power Flow>Reports>Export Results to Excel\n\n'''\n# =========================================================================================="
  },
  {
    "id": "chunk_1623",
    "text": "============================================================\nimport sys, os\n\ndef get_output_dir(outpath):\n    # if called from PSSE's Example Folder, create report in subfolder 'Output_Pyscript'\n\n    if outpath:\n        outdir = outpath\n        if not os.path.exists(outdir): os.mkdir(outdir)\n    else:\n        outdir = os.getcwd()\n        cwd = outdir.lower()\n        i = cwd.find('pti')\n        j = cwd.find('psse')\n        k = cwd.find('example')\n        if i>0 and j>i and k>j:     # called from "
  },
  {
    "id": "chunk_1624",
    "text": "        if i>0 and j>i and k>j:     # called from Example folder\n            outdir = os.path.join(outdir, 'Output_Pyscript')\n            if not os.path.exists(outdir): os.mkdir(outdir)\n\n    return outdir\n\n# ====================================================================================================\n\ndef get_output_filename(outpath, fnam):\n\n    p, nx = os.path.split(fnam)\n    if p:\n        retvfile = fnam\n    else:\n        outdir = get_output_dir(outpath)\n        retvfile = os.path.join("
  },
  {
    "id": "chunk_1625",
    "text": "tput_dir(outpath)\n        retvfile = os.path.join(outdir, fnam)\n\n    return retvfile\n\n# ====================================================================================================\n\ndef excel_report(qvfile='savnw.qv', outpath=None, show=True):\n    import pssexcel\n\n    if not os.path.exists(qvfile):\n        prgmsg = \" Error: Input qvfile '{0}' does not exist\".format(qvfile)\n        print(prgmsg)\n        return\n\n    # Change these values as required.\n    string  = ['s','v','m','g']\n    col"
  },
  {
    "id": "chunk_1626",
    "text": " required.\n    string  = ['s','v','m','g']\n    colabel = [] #['base case', 'trip1nuclear', 'trip2nuclear']\n\n    p, nx = os.path.split(qvfile)\n    n, x  = os.path.splitext(nx)\n\n    xlsfile = get_output_filename(outpath, 'qv_export_' + n)\n\n    sheet = n + '_qv'\n    overwritesheet = True\n\n    pssexcel.qv(qvfile,string,colabel=colabel,xlsfile=xlsfile,sheet=sheet,overwritesheet=overwritesheet,show=show)\n\n# ==============================================================================================="
  },
  {
    "id": "chunk_1627",
    "text": "=======================================================\n\ndef text_report(qvfile='savnw.qv', outpath=None):\n\n    import arrbox.qv_pp\n\n    if not os.path.exists(qvfile):\n        prgmsg = \" Error: Input qvfile '{0}' does not exist\".format(qvfile)\n        print(prgmsg)\n        return\n\n    qvobj = arrbox.qv_pp.QV_PP(qvfile)\n\n    p, nx = os.path.split(qvfile)\n    n, x  = os.path.splitext(nx)\n\n    smryfile = get_output_filename(outpath, 'qv_export_' + n +'_summary.txt')\n    solnfile = get_output_filena"
  },
  {
    "id": "chunk_1628",
    "text": " +'_summary.txt')\n    solnfile = get_output_filename(outpath, 'qv_export_' + n +'_solution.txt')\n\n    ierr = qvobj.summary_report(smryfile)\n\n    ierr = qvobj.solution_report(colabels=None,rptfile=solnfile)\n\n# ====================================================================================================\n# ====================================================================================================\nif __name__ == '__main__':\n\n    import psse35\n\n    #excel_report()\n    #text_report()\n "
  },
  {
    "id": "chunk_1629",
    "text": "t psse35\n\n    #excel_report()\n    #text_report()\n    #excel_report(qvfile='savnw.qv', show=True)\n    #text_report(qvfile='savnw.qv')\n\n# ====================================================================================================\n'run_idle.py - This script starts up the IDLE interpreter (for Python 2.3).'\n\nimport sys\n\n# Import IDLE's PyShell and run its main()\nsys.argv=['','-n','-t','PSS/E-Python Shell'] #Arguments for IDLE\nimport idlelib.PyShell                       #Import the PyShell "
  },
  {
    "id": "chunk_1630",
    "text": "PyShell                       #Import the PyShell module\nidlelib.PyShell.main()                       #Start IDLE\n\n#[sample_add_substations.py]    Create sample_zils case with various Node Breaker Substation Configurations\n# =====================================================================================================\n'''This file shows example of adding one or more substation configurations.\nUses sample.raw and sample.seq files.\n\nThis example uses substations data [latitude, longitude, R"
  },
  {
    "id": "chunk_1631",
    "text": "mple uses substations data [latitude, longitude, RG] from sample_fv4.gic, but applies\ndifferent Substation Configurations.\n'''\nss_config = {\n    1: 'SB',        #'Single Bus',\n    2: 'RB',        #'Ring Bus',\n    3: 'DBDB',      #'Double Bus double breaker',\n    4: 'BH',        #'Breaker and a half',\n    5: 'DBSB',      #'Double Bus Single breaker',\n    6: 'MBTB',      #'Main Bus Transfer Bus',\n    }\n\nsub_dict = {\n     1: {'name': 'NILE',        'lat': 34.6135,  'long': -86.67371,  'rg':0.11, 'c"
  },
  {
    "id": "chunk_1632",
    "text": "'lat': 34.6135,  'long': -86.67371,  'rg':0.11, 'config':3, 'buses': [101, 102, 151, 201, 211      ]},\n     2: {'name': 'YANGTZE',     'lat': 32.5104,  'long': -86.3658 ,  'rg':0.12, 'config':6, 'buses': [152, 153, 3006, 3021, 3022   ]},\n     3: {'name': 'ARKANSAS',    'lat': 32.1551,  'long': -83.6794 ,  'rg':0.13, 'config':4, 'buses': [154, 9154                    ]},\n     4: {'name': 'COLORADO',    'lat': 33.7051,  'long': -84.6634 ,  'rg':0.15, 'config':5, 'buses': [202, 203, 70202          "
  },
  {
    "id": "chunk_1633",
    "text": "5, 'config':5, 'buses': [202, 203, 70202              ]},\n     5: {'name': 'MISSISSIPPI', 'lat': 33.3773,  'long': -82.6188 ,  'rg':0.16, 'config':5, 'buses': [204, 205, 206, 208, 215, 9204]},\n     6: {'name': 'VOLGA',       'lat': 34.2522,  'long': -82.8363 ,  'rg':0.17, 'config':1, 'buses': [209, 217, 218                ]},\n     7: {'name': 'YUKON',       'lat': 33.5956,  'long': -88.798  ,  'rg':0.18, 'config':4, 'buses': [3001, 3002, 3011, 93002      ]},\n     8: {'name': 'BRAHMAPUTRA', 'lat'"
  },
  {
    "id": "chunk_1634",
    "text": "002      ]},\n     8: {'name': 'BRAHMAPUTRA', 'lat': 31.9123,  'long': -88.3123 ,  'rg':0.19, 'config':4, 'buses': [3004, 3005, 703005           ]},\n     9: {'name': 'INDUS',       'lat': 31.0133,  'long': -82.0133 ,  'rg':0.2 , 'config':6, 'buses': [3008, 3010, 3012, 3018       ]},\n    10: {'name': 'DANUBE',      'lat': 32.0143,  'long': -82.5143 ,  'rg':0.21, 'config':4, 'buses': [155                          ]},\n    11: {'name': 'ALLEGHENY',   'lat': 35.2153,  'long': -86.0153 ,  'rg':0.22, 'c"
  },
  {
    "id": "chunk_1635",
    "text": "'lat': 35.2153,  'long': -86.0153 ,  'rg':0.22, 'config':2, 'buses': [207                          ]},\n    12: {'name': 'GANGES',      'lat': 33.5163,  'long': -81.0163 ,  'rg':0.23, 'config':2, 'buses': [212                          ]},\n    13: {'name': 'OXUS',        'lat': 35.0173,  'long': -82.0173 ,  'rg':0.24, 'config':1, 'buses': [214                          ]},\n    14: {'name': 'SALWEEN',     'lat': 34.7183,  'long': -81.0183 ,  'rg':0.25, 'config':1, 'buses': [216                      "
  },
  {
    "id": "chunk_1636",
    "text": "5, 'config':1, 'buses': [216                          ]},\n    15: {'name': 'HEILONG',     'lat': 35.0193,  'long': -84.0193 ,  'rg':0.26, 'config':3, 'buses': [213                          ]},\n    16: {'name': 'ZAIRE',       'lat': 35.003 ,  'long': -87.5203 ,  'rg':0.27, 'config':4, 'buses': [3003, 703003                 ]},\n    17: {'name': 'ZAMBEZI',     'lat': 31.4213,  'long': -85.7213 ,  'rg':0.28, 'config':3, 'buses': [3007                         ]},\n    18: {'name': 'PILCOMAYO',   'lat'"
  },
  {
    "id": "chunk_1637",
    "text": "         ]},\n    18: {'name': 'PILCOMAYO',   'lat': 31.4223,  'long': -81.0223 ,  'rg':0.29, 'config':2, 'buses': [3009                         ]},\n    }\n\nrawfnam           = r\"sample.raw\"\nseqfnam           = r\"sample.seq\"\nrawoutfnam        = r\"sample\"\nrawoutfnam_nb     = r\"sample_nb\"\nrawoutfnam_nb_sec = r\"sample_nb_sec\"\nprgfnam           = r\"sample_nb_progress.txt\"\n\nimport os\n\n# ==================================================================================================\ndef solve_pf():\n  "
  },
  {
    "id": "chunk_1638",
    "text": "===============================\ndef solve_pf():\n    import psspy\n    pf_options = [1,0,0,1,1,0,99,0]\n    psspy.fdns(pf_options)\n    psspy.fdns(pf_options)\n    ival = psspy.solved()\n    return ival\n\ndef save_case(rawfile, seqfile, savfnam, outpath):\n    import psspy\n    psspy.read(0, rawfile)\n    psspy.resq(seqfile)\n    ival = solve_pf()\n    if ival==0:\n        savfile = \"{}.sav\".format(savfnam)\n        savfile = os.path.join(outpath, savfile)\n        psspy.save(savfile)\n\n# ======================"
  },
  {
    "id": "chunk_1639",
    "text": "     psspy.save(savfile)\n\n# ==================================================================================================\n\ndef run(datapath=None, outpath=None):\n    import psspy\n\n    if datapath is None:        # use Example folder\n        psspy_dir = os.path.dirname(psspy.__file__)\n        psse_dir, jnk = os.path.split(psspy_dir)\n        datapath = os.path.join(psse_dir, 'Example')\n\n    rawfile = os.path.join(datapath, rawfnam)\n    seqfile = os.path.join(datapath, seqfnam)\n\n    if not os.p"
  },
  {
    "id": "chunk_1640",
    "text": "= os.path.join(datapath, seqfnam)\n\n    if not os.path.exists(rawfile):\n        msg = \"\\n Error- RAW file not found, terminated:\\n    {}\".format(rawfile)\n        print(msg)\n        return\n\n    if not os.path.exists(seqfile):\n        msg = \"\\n Error- SEQ file not found, terminated:\\n    {}\".format(seqfile)\n        print(msg)\n        return\n\n    if outpath is None:\n        outpath = os.path.dirname(__file__)\n        outpath = os.path.join(outpath, 'output_sample_nb')\n    if not os.path.exists(outpa"
  },
  {
    "id": "chunk_1641",
    "text": "output_sample_nb')\n    if not os.path.exists(outpath): os.makedirs(outpath)\n\n    psspy.psseinit()\n\n    prgfile = os.path.join(outpath, prgfnam)\n\n    psspy.progress_output(2,prgfile,[0,0])\n\n    _i = psspy.getdefaultint()\n    _f = psspy.getdefaultreal()\n    _s = psspy.getdefaultchar()\n\n    psspy.read(0, rawfile)\n    psspy.resq(seqfile)\n\n    ival_raw = solve_pf()\n    if ival_raw>0:\n        msg = \"\\n Error - Power flow non converged. RAW file:\\n    {}\".format(rawfile)\n        print(msg)\n        retu"
  },
  {
    "id": "chunk_1642",
    "text": "}\".format(rawfile)\n        print(msg)\n        return\n\n    sslst = list(sub_dict.keys())\n    sslst.sort()\n\n    for ss in sslst:\n        vdict = sub_dict[ss]\n        name  = sub_dict[ss]['name']\n        lat   = sub_dict[ss]['lat']\n        lon   = sub_dict[ss]['long']\n        rg    = sub_dict[ss]['rg']\n        config= sub_dict[ss]['config']\n        buses = sub_dict[ss]['buses']\n\n        s_ss = \"{:{fill}2d}\".format(ss, fill='0')\n        s_config = ss_config[config]\n\n        ss_name  = \"SS{}_{}_TYP_{"
  },
  {
    "id": "chunk_1643",
    "text": "_config[config]\n\n        ss_name  = \"SS{}_{}_TYP_{}_{}\".format(s_ss, name, config, s_config)\n\n        for b in buses:\n            psspy.station_build_config(b,ss,_s,config)\n\n        psspy.station_data(ss, [lat, lon, rg], ss_name)\n\n    # Update/Change Node and Switching Device Names\n    sid = -1\n    flag = 1\n    ierr, (ss_num_lst, node_lst) = psspy.anodeint(sid, flag, ['STATION', 'NODE'])\n    ierr, (ss_nam_lst,) = psspy.anodechar(sid, flag, ['STATIONNAME'])\n\n    for ss,node,nam in zip(ss_num_lst,"
  },
  {
    "id": "chunk_1644",
    "text": "IONNAME'])\n\n    for ss,node,nam in zip(ss_num_lst, node_lst, ss_nam_lst):\n        nlst = nam.strip().split('_')\n        newlst = ['SS', nlst[1], 'NODE', str(node)]\n        newnam = '_'.join(newlst)\n        psspy.station_node_chng(ss,node,[_i,_i],newnam)\n\n    ierr, (swd_ss_lst, fromnode_lst, tonode_lst) = psspy.astaswdevint(sid, flag, ['STATION','FROMNODE', 'TONODE'])\n    ierr, (swd_ss_nam_lst, swd_id_lst) = psspy.astaswdevchar(sid, flag, ['STATIONNAME','ID'])\n\n    for ss,fm,to,nam,iid in zip(swd"
  },
  {
    "id": "chunk_1645",
    "text": "NNAME','ID'])\n\n    for ss,fm,to,nam,iid in zip(swd_ss_lst, fromnode_lst, tonode_lst, swd_ss_nam_lst, swd_id_lst):\n        nlst = nam.strip().split('_')\n        newlst = ['SS', nlst[1], 'SWD', str(fm), str(to), iid]\n        newnam = '_'.join(newlst)\n        psspy.station_swd_chng(ss,fm,to,iid,[_i,_i,_i],[_f,0.0,_f,0.0],newnam)\n\n    # --------------------------------------------------\n    # Save un-solved raw file\n##    rawfileout = \"{}_pf_no.raw\".format(rawoutfnam_nb)\n##    rawfileout = os.path.j"
  },
  {
    "id": "chunk_1646",
    "text": "format(rawoutfnam_nb)\n##    rawfileout = os.path.join(outpath, rawfileout)\n##    psspy.rawd_2(0,1,[1,1,1,0,0,0,0],0,rawfileout)\n\n    # --------------------------------------------------\n    # Solve power flow and save raw file\n    ival_raw_nb = solve_pf()\n    psspy.case_title_data(r'PSS(R)E SAMPLE CASE - ALL RECORD GROUPS WITH SEQ DATA',\n                          r'CONTAINS NODE BREAKERS BUT NO SUBSTN SECTIONS, NO ZILS')\n    rawfileout_nb = \"{}.raw\".format(rawoutfnam_nb)\n    rawfileout_nb = os.p"
  },
  {
    "id": "chunk_1647",
    "text": "aw\".format(rawoutfnam_nb)\n    rawfileout_nb = os.path.join(outpath, rawfileout_nb)\n    psspy.rawd_2(0,1,[1,1,1,0,0,0,0],0,rawfileout_nb)\n\n    seqfileout_nb = \"{}.seq\".format(rawoutfnam_nb)\n    seqfileout_nb = os.path.join(outpath, seqfileout_nb)\n    psspy.rwsq_2(0,1,[1,1,1,0,0],0,seqfileout_nb)\n\n    if ival_raw_nb>0:\n        msg = \"\\n Error - Power flow non converged after adding substations, SAV file not created.\"\n        print(msg)\n\n    # --------------------------------------------------\n    "
  },
  {
    "id": "chunk_1648",
    "text": "---------------------------------------------\n    # Create substation sections\n    psspy.station_swd_chng(3, 1, 4, '1', [0,_i,_i], [_f,_f,_f,_f], _s)\n    psspy.station_swd_chng(3, 2,10, '1', [0,_i,_i], [_f,_f,_f,_f], _s)\n    psspy.station_swd_chng(3, 1, 8, '1', [0,_i,_i], [_f,_f,_f,_f], _s)\n    psspy.station_swd_chng(3, 2,14, '1', [0,_i,_i], [_f,_f,_f,_f], _s)\n    psspy.station_swd_chng(8, 7, 9, '1', [0,_i,_i], [_f,_f,_f,_f], _s)\n    psspy.station_swd_chng(8, 8,14, '1', [0,_i,_i], [_f,_f,_f,_f],"
  },
  {
    "id": "chunk_1649",
    "text": "n_swd_chng(8, 8,14, '1', [0,_i,_i], [_f,_f,_f,_f], _s)\n\n    # --------------------------------------------------\n    # Solve power flow and save raw file\n    ival_raw_nb_sec = solve_pf()\n    psspy.case_title_data(r'PSS(R)E SAMPLE CASE - ALL RECORD GROUPS WITH SEQ DATA',\n                          r'CONTAINS NODE BREAKER AND SUBSTN SECTIONS, NO ZILS')\n    rawfileout_nb_sec = \"{}.raw\".format(rawoutfnam_nb_sec)\n    rawfileout_nb_sec = os.path.join(outpath, rawfileout_nb_sec)\n    psspy.rawd_2(0,1,[1,"
  },
  {
    "id": "chunk_1650",
    "text": "tpath, rawfileout_nb_sec)\n    psspy.rawd_2(0,1,[1,1,1,0,0,0,0],0,rawfileout_nb_sec)\n\n    seqfileout_nb_sec = \"{}.seq\".format(rawoutfnam_nb_sec)\n    seqfileout_nb_sec = os.path.join(outpath, seqfileout_nb_sec)\n    psspy.rwsq_2(0,1,[1,1,1,0,0],0,seqfileout_nb_sec)\n\n    if ival_raw_nb_sec>0:\n        msg = \"\\n Error - Power flow non converged after adding substation sections, SAV file not created.\"\n        print(msg)\n        return\n\n    # --------------------------------------------------\n    # Crea"
  },
  {
    "id": "chunk_1651",
    "text": "---------------------------------------\n    # Create .sav files\n    if not os.path.exists(seqfile):\n        msg = \"\\n Error- SEQ sile not found:\\n    {}\".format(seqfile)\n        print(msg)\n        return\n\n    # base case\n    save_case(rawfile, seqfile, rawoutfnam, outpath)\n\n    # base+NB case\n    save_case(rawfileout_nb, seqfileout_nb, rawoutfnam_nb, outpath)\n\n    # base+NB+sections case\n    save_case(rawfileout_nb_sec, seqfileout_nb_sec, rawoutfnam_nb_sec, outpath)\n\n    # ----------------------"
  },
  {
    "id": "chunk_1652",
    "text": "nam_nb_sec, outpath)\n\n    # --------------------------------------------------\n    # all done\n\n    psspy.progress_output(1,\"\",[0,0])\n\n    msg = \"\\n Progress saved in file: {}\".format(prgfile)\n    print(msg)\n\n# ==================================================================================================\ndef test1():\n    # Run from outside of PSSE GUI.\n    # Use input sample RAW/SEQ files from specified folder [datapath].\n    # Create output RAW/SEQ files in specified folder [outpath].\n    im"
  },
  {
    "id": "chunk_1653",
    "text": "AW/SEQ files in specified folder [outpath].\n    import psse35\n    datapath = os.getcwd()\n    outpath  = os.getcwd()\n    run(datapath=datapath, outpath=outpath)\n\n# --------------------------------------------------\ndef test2():\n    # Run from inside of PSSE GUI.\n    # Use input sample RAW/SEQ files from specified folder [datapath].\n    # Create output RAW/SEQ files in specified folder [outpath].\n    import psse35\n    datapath = os.getcwd()\n    outpath  = os.getcwd()\n    run(datapath=datapath, out"
  },
  {
    "id": "chunk_1654",
    "text": "path  = os.getcwd()\n    run(datapath=datapath, outpath=outpath)\n\n# --------------------------------------------------\ndef test3():\n    # Run from inside of PSSE GUI.\n    # Use input sample RAW/SEQ files from Example folder.\n    # Create output RAW/SEQ files in folder Example/output_sample_nb.\n    run()\n\n# ==================================================================================================\nif __name__=='__main__':\n    pass\n#[sample_zils_add_substations.py]    Create sample case with"
  },
  {
    "id": "chunk_1655",
    "text": "ils_add_substations.py]    Create sample case with various Node Breaker Substation Configurations\n# =====================================================================================================\n'''This file shows example of adding one or more substation configurations.\nUses sample_zils.raw and sample_zils.seq files.\n\nThis example uses substations data [latitude, longitude, RG] from sample_zils_fv4.gic, but applies\ndifferent Substation Configurations.\n'''\nss_config = {\n    1: 'SB',       "
  },
  {
    "id": "chunk_1656",
    "text": "figurations.\n'''\nss_config = {\n    1: 'SB',        #'Single Bus',\n    2: 'RB',        #'Ring Bus',\n    3: 'DBDB',      #'Double Bus double breaker',\n    4: 'BH',        #'Breaker and a half',\n    5: 'DBSB',      #'Double Bus Single breaker',\n    6: 'MBTB',      #'Main Bus Transfer Bus',\n    }\n\nsub_dict = {\n     1: {'name': 'NILE',        'lat': 34.6135,  'long': -86.67371,  'rg':0.11, 'config':3, 'buses': [101, 102, 151, 201, 211, 80102, 80151 ]},\n     2: {'name': 'YANGTZE',     'lat': 32.5104, "
  },
  {
    "id": "chunk_1657",
    "text": ",\n     2: {'name': 'YANGTZE',     'lat': 32.5104,  'long': -86.3658 ,  'rg':0.12, 'config':6, 'buses': [152, 153, 3006, 3021, 3022, 803022    ]},\n     3: {'name': 'ARKANSAS',    'lat': 32.1551,  'long': -83.6794 ,  'rg':0.13, 'config':4, 'buses': [154, 9154, 809154                     ]},\n     4: {'name': 'COLORADO',    'lat': 33.7051,  'long': -84.6634 ,  'rg':0.15, 'config':5, 'buses': [202, 203, 70202, 80203                ]},\n     5: {'name': 'MISSISSIPPI', 'lat': 33.3773,  'long': -82.6188 "
  },
  {
    "id": "chunk_1658",
    "text": " 'MISSISSIPPI', 'lat': 33.3773,  'long': -82.6188 ,  'rg':0.16, 'config':5, 'buses': [204, 205, 206, 208, 215, 9204         ]},\n     6: {'name': 'VOLGA',       'lat': 34.2522,  'long': -82.8363 ,  'rg':0.17, 'config':1, 'buses': [209, 217, 218                         ]},\n     7: {'name': 'YUKON',       'lat': 33.5956,  'long': -88.798  ,  'rg':0.18, 'config':4, 'buses': [3001, 3002, 3011, 93002, 803002       ]},\n     8: {'name': 'BRAHMAPUTRA', 'lat': 31.9123,  'long': -88.3123 ,  'rg':0.19, 'con"
  },
  {
    "id": "chunk_1659",
    "text": "at': 31.9123,  'long': -88.3123 ,  'rg':0.19, 'config':4, 'buses': [3004, 3005, 703005                    ]},\n     9: {'name': 'INDUS',       'lat': 31.0133,  'long': -82.0133 ,  'rg':0.2 , 'config':6, 'buses': [3008, 3010, 3012, 3018, 803008, 803010, 803018]},\n    10: {'name': 'DANUBE',      'lat': 32.0143,  'long': -82.5143 ,  'rg':0.21, 'config':4, 'buses': [155                                   ]},\n    11: {'name': 'ALLEGHENY',   'lat': 35.2153,  'long': -86.0153 ,  'rg':0.22, 'config':2, 'b"
  },
  {
    "id": "chunk_1660",
    "text": "53,  'long': -86.0153 ,  'rg':0.22, 'config':2, 'buses': [207                                   ]},\n    12: {'name': 'GANGES',      'lat': 33.5163,  'long': -81.0163 ,  'rg':0.23, 'config':2, 'buses': [212, 80212                            ]},\n    13: {'name': 'OXUS',        'lat': 35.0173,  'long': -82.0173 ,  'rg':0.24, 'config':1, 'buses': [214                                   ]},\n    14: {'name': 'SALWEEN',     'lat': 34.7183,  'long': -81.0183 ,  'rg':0.25, 'config':1, 'buses': [216       "
  },
  {
    "id": "chunk_1661",
    "text": "183 ,  'rg':0.25, 'config':1, 'buses': [216                                   ]},\n    15: {'name': 'HEILONG',     'lat': 35.0193,  'long': -84.0193 ,  'rg':0.26, 'config':3, 'buses': [213                                   ]},\n    16: {'name': 'ZAIRE',       'lat': 35.003 ,  'long': -87.5203 ,  'rg':0.27, 'config':4, 'buses': [3003, 703003                          ]},\n    17: {'name': 'ZAMBEZI',     'lat': 31.4213,  'long': -85.7213 ,  'rg':0.28, 'config':3, 'buses': [3007                        "
  },
  {
    "id": "chunk_1662",
    "text": "'config':3, 'buses': [3007                                  ]},\n    18: {'name': 'PILCOMAYO',   'lat': 31.4223,  'long': -81.0223 ,  'rg':0.29, 'config':2, 'buses': [3009                                  ]},\n    19: {'name': 'DC2TERM',     'lat': 31.7104,  'long': -84.5694 ,  'rg':0.30, 'config':1, 'buses': [301, 80301                            ]},\n    20: {'name': 'DCMTERM',     'lat': 33.9163,  'long': -81.9163 ,  'rg':0.31, 'config':1, 'buses': [401, 402, 80402                       ]},\n    "
  },
  {
    "id": "chunk_1663",
    "text": "': [401, 402, 80402                       ]},\n    }\n\nrawfnam           = r\"sample_zils.raw\"\nseqfnam           = r\"sample_zils.seq\"\nrawoutfnam        = r\"sample_zils\"\nrawoutfnam_nb     = r\"sample_zils_nb\"\nrawoutfnam_nb_sec = r\"sample_zils_nb_sec\"\nprgfnam           = r\"sample_zils_nb_progress.txt\"\n\nimport os\n\n# ==================================================================================================\ndef solve_pf():\n    import psspy\n    pf_options = [1,0,0,1,1,0,99,0]\n    psspy.fdns(pf_opt"
  },
  {
    "id": "chunk_1664",
    "text": "options = [1,0,0,1,1,0,99,0]\n    psspy.fdns(pf_options)\n    psspy.fdns(pf_options)\n    ival = psspy.solved()\n    return ival\n\ndef save_case(rawfile, seqfile, savfnam, outpath):\n    import psspy\n    psspy.read(0, rawfile)\n    psspy.resq(seqfile)\n    ival = solve_pf()\n    if ival==0:\n        savfile = \"{}.sav\".format(savfnam)\n        savfile = os.path.join(outpath, savfile)\n        psspy.save(savfile)\n\n# =============================================================================================="
  },
  {
    "id": "chunk_1665",
    "text": "======================================================\n\ndef run(datapath=None, outpath=None):\n    import psspy\n\n    if datapath is None:        # use Example folder\n        psspy_dir = os.path.dirname(psspy.__file__)\n        psse_dir, jnk = os.path.split(psspy_dir)\n        datapath = os.path.join(psse_dir, 'Example')\n\n    rawfile = os.path.join(datapath, rawfnam)\n    seqfile = os.path.join(datapath, seqfnam)\n\n    if not os.path.exists(rawfile):\n        msg = \"\\n Error- RAW file not found, termin"
  },
  {
    "id": "chunk_1666",
    "text": "       msg = \"\\n Error- RAW file not found, terminated:\\n    {}\".format(rawfile)\n        print(msg)\n        return\n\n    if not os.path.exists(seqfile):\n        msg = \"\\n Error- SEQ file not found, terminated:\\n    {}\".format(seqfile)\n        print(msg)\n        return\n\n    if outpath is None:\n        outpath = os.path.dirname(__file__)\n        outpath = os.path.join(outpath, 'output_sample_nb')\n    if not os.path.exists(outpath): os.makedirs(outpath)\n\n    psspy.psseinit()\n\n    prgfile = os.path.j"
  },
  {
    "id": "chunk_1667",
    "text": "th)\n\n    psspy.psseinit()\n\n    prgfile = os.path.join(outpath, prgfnam)\n\n    psspy.progress_output(2,prgfile,[0,0])\n\n    _i = psspy.getdefaultint()\n    _f = psspy.getdefaultreal()\n    _s = psspy.getdefaultchar()\n\n    psspy.read(0, rawfile)\n    psspy.resq(seqfile)\n\n    ival_raw = solve_pf()\n    if ival_raw>0:\n        msg = \"\\n Error - Power flow non converged. RAW file:\\n    {}\".format(rawfile)\n        print(msg)\n        return\n\n    sslst = list(sub_dict.keys())\n    sslst.sort()\n\n    for ss in ss"
  },
  {
    "id": "chunk_1668",
    "text": "ub_dict.keys())\n    sslst.sort()\n\n    for ss in sslst:\n        vdict = sub_dict[ss]\n        name  = sub_dict[ss]['name']\n        lat   = sub_dict[ss]['lat']\n        lon   = sub_dict[ss]['long']\n        rg    = sub_dict[ss]['rg']\n        config= sub_dict[ss]['config']\n        buses = sub_dict[ss]['buses']\n\n        s_ss = \"{:{fill}2d}\".format(ss, fill='0')\n        s_config = ss_config[config]\n\n        ss_name  = \"SS{}_{}_TYP_{}_{}\".format(s_ss, name, config, s_config)\n\n        for b in buses:\n    "
  },
  {
    "id": "chunk_1669",
    "text": "e, config, s_config)\n\n        for b in buses:\n            psspy.station_build_config(b,ss,_s,config)\n\n        psspy.station_data(ss, [lat, lon, rg], ss_name)\n\n    # Update/Change Node and Switching Device Names\n    sid = -1\n    flag = 1\n    ierr, (ss_num_lst, node_lst) = psspy.anodeint(sid, flag, ['STATION', 'NODE'])\n    ierr, (ss_nam_lst,) = psspy.anodechar(sid, flag, ['STATIONNAME'])\n\n    for ss,node,nam in zip(ss_num_lst, node_lst, ss_nam_lst):\n        nlst = nam.strip().split('_')\n        ne"
  },
  {
    "id": "chunk_1670",
    "text": ":\n        nlst = nam.strip().split('_')\n        newlst = ['SS', nlst[1], 'NODE', str(node)]\n        newnam = '_'.join(newlst)\n        psspy.station_node_chng(ss,node,[_i,_i],newnam)\n\n    ierr, (swd_ss_lst, fromnode_lst, tonode_lst) = psspy.astaswdevint(sid, flag, ['STATION','FROMNODE', 'TONODE'])\n    ierr, (swd_ss_nam_lst, swd_id_lst) = psspy.astaswdevchar(sid, flag, ['STATIONNAME','ID'])\n\n    for ss,fm,to,nam,iid in zip(swd_ss_lst, fromnode_lst, tonode_lst, swd_ss_nam_lst, swd_id_lst):\n        "
  },
  {
    "id": "chunk_1671",
    "text": " tonode_lst, swd_ss_nam_lst, swd_id_lst):\n        nlst = nam.strip().split('_')\n        newlst = ['SS', nlst[1], 'SWD', str(fm), str(to), iid]\n        newnam = '_'.join(newlst)\n        psspy.station_swd_chng(ss,fm,to,iid,[_i,_i,_i],[_f,0.0,_f,0.0],newnam)\n\n    # --------------------------------------------------\n    # Save un-solved raw file\n##    rawfileout = \"{}_pf_no.raw\".format(rawoutfnam_nb)\n##    rawfileout = os.path.join(outpath, rawfileout)\n##    psspy.rawd_2(0,1,[1,1,1,0,0,0,0],0,rawfil"
  },
  {
    "id": "chunk_1672",
    "text": "t)\n##    psspy.rawd_2(0,1,[1,1,1,0,0,0,0],0,rawfileout)\n\n    # --------------------------------------------------\n    # Solve power flow and save raw file\n    ival_raw_nb = solve_pf()\n    psspy.case_title_data(r'PSS(R)E SAMPLE CASE - ALL RECORD GROUPS WITH SEQ DATA',\n                          r'CONTAINS NODE BREAKERS BUT NO SUBSTN SECTIONS, CONTAINS ZILS')\n    rawfileout_nb = \"{}.raw\".format(rawoutfnam_nb)\n    rawfileout_nb = os.path.join(outpath, rawfileout_nb)\n    psspy.rawd_2(0,1,[1,1,1,0,0,0"
  },
  {
    "id": "chunk_1673",
    "text": ", rawfileout_nb)\n    psspy.rawd_2(0,1,[1,1,1,0,0,0,0],0,rawfileout_nb)\n\n    seqfileout_nb = \"{}.seq\".format(rawoutfnam_nb)\n    seqfileout_nb = os.path.join(outpath, seqfileout_nb)\n    psspy.rwsq_2(0,1,[1,1,1,0,0],0,seqfileout_nb)\n\n    if ival_raw_nb>0:\n        msg = \"\\n Error - Power flow non converged after adding substations, SAV file not created.\"\n        print(msg)\n\n    # --------------------------------------------------\n    # Create substation sections\n    psspy.station_swd_chng(3, 1, 4, '"
  },
  {
    "id": "chunk_1674",
    "text": "ion sections\n    psspy.station_swd_chng(3, 1, 4, '1', [0,_i,_i], [_f,_f,_f,_f], _s)\n    psspy.station_swd_chng(3, 2,10, '1', [0,_i,_i], [_f,_f,_f,_f], _s)\n    psspy.station_swd_chng(3, 1, 8, '1', [0,_i,_i], [_f,_f,_f,_f], _s)\n    psspy.station_swd_chng(3, 2,14, '1', [0,_i,_i], [_f,_f,_f,_f], _s)\n    psspy.station_swd_chng(8, 7, 9, '1', [0,_i,_i], [_f,_f,_f,_f], _s)\n    psspy.station_swd_chng(8, 8,14, '1', [0,_i,_i], [_f,_f,_f,_f], _s)\n\n    # --------------------------------------------------\n   "
  },
  {
    "id": "chunk_1675",
    "text": "----------------------------------------------\n    # Solve power flow and save raw file\n    ival_raw_nb_sec = solve_pf()\n    psspy.case_title_data(r'PSS(R)E SAMPLE CASE - ALL RECORD GROUPS WITH SEQ DATA',\n                          r'CONTAINS NODE BREAKER AND SUBSTN SECTIONS, CONTAINS ZILS')\n    rawfileout_nb_sec = \"{}.raw\".format(rawoutfnam_nb_sec)\n    rawfileout_nb_sec = os.path.join(outpath, rawfileout_nb_sec)\n    psspy.rawd_2(0,1,[1,1,1,0,0,0,0],0,rawfileout_nb_sec)\n\n    seqfileout_nb_sec = \""
  },
  {
    "id": "chunk_1676",
    "text": "0],0,rawfileout_nb_sec)\n\n    seqfileout_nb_sec = \"{}.seq\".format(rawoutfnam_nb_sec)\n    seqfileout_nb_sec = os.path.join(outpath, seqfileout_nb_sec)\n    psspy.rwsq_2(0,1,[1,1,1,0,0],0,seqfileout_nb_sec)\n\n    if ival_raw_nb_sec>0:\n        msg = \"\\n Error - Power flow non converged after adding substation sections, SAV file not created.\"\n        print(msg)\n        return\n\n    # --------------------------------------------------\n    # Create .sav files\n    if not os.path.exists(seqfile):\n        ms"
  },
  {
    "id": "chunk_1677",
    "text": "les\n    if not os.path.exists(seqfile):\n        msg = \"\\n Error- SEQ sile not found:\\n    {}\".format(seqfile)\n        print(msg)\n        return\n\n    # base case\n    save_case(rawfile, seqfile, rawoutfnam, outpath)\n\n    # base+NB case\n    save_case(rawfileout_nb, seqfileout_nb, rawoutfnam_nb, outpath)\n\n    # base+NB+sections case\n    save_case(rawfileout_nb_sec, seqfileout_nb_sec, rawoutfnam_nb_sec, outpath)\n\n    # --------------------------------------------------\n    # all done\n    psspy.progre"
  },
  {
    "id": "chunk_1678",
    "text": "------------------\n    # all done\n    psspy.progress_output(1,\"\",[0,0])\n\n    msg = \"\\n Progress saved in file: {}\".format(prgfile)\n    print(msg)\n\n# ==================================================================================================\ndef test1():\n    # Run from outside of PSSE GUI.\n    # Use input sample RAW/SEQ files from specified folder [datapath].\n    # Create output RAW/SEQ files in specified folder [outpath].\n    import psse35\n    datapath = os.getcwd()\n    outpath  = os.getc"
  },
  {
    "id": "chunk_1679",
    "text": "\n    datapath = os.getcwd()\n    outpath  = os.getcwd()\n    run(datapath=datapath, outpath=outpath)\n\n# --------------------------------------------------\ndef test2():\n    # Run from inside of PSSE GUI.\n    # Use input sample RAW/SEQ files from specified folder [datapath].\n    # Create output RAW/SEQ files in specified folder [outpath].\n    import psse35\n    datapath = os.getcwd()\n    outpath  = os.getcwd()\n    run(datapath=datapath, outpath=outpath)\n\n# --------------------------------------------"
  },
  {
    "id": "chunk_1680",
    "text": "h)\n\n# --------------------------------------------------\ndef test3():\n    # Run from inside of PSSE GUI.\n    # Use input sample RAW/SEQ files from Example folder.\n    # Create output RAW/SEQ files in folder Example/output_sample_nb.\n    run()\n\n# ==================================================================================================\nif __name__=='__main__':\n    pass\n#[sensitivity_factors.py]  Sensitivity Analysis Report and Accesing them in Python Script\n# ============================="
  },
  {
    "id": "chunk_1681",
    "text": "m in Python Script\n# ====================================================================================================\n'''Sensitivity Factors of a branch flow to MW power at generator and load buses:\nThis is an example file showing how to generate sensitivity factors report or\naccess those factor values in Python script.\n\n# ----------------------------------------------------------------------------------------------------\n\nHow to use this file?\n\nAs showed in __main__ (end of this file)\n- Ena"
  },
  {
    "id": "chunk_1682",
    "text": "e?\n\nAs showed in __main__ (end of this file)\n- Enable PSSE version specific environment, as an example:\n    import psse35\n\n- call any of the function as below\n    run_demo()  OR\n    run_demo(savfile='savnw.sav', dfxfile='savnw.dfx', outpath=None)\n    You could modify various inputs in run)demo() as desired.\n'''\n\n# ====================================================================================================\nimport sys, os\n\ndef get_output_dir(outpath):\n    # if called from PSSE's Example Fo"
  },
  {
    "id": "chunk_1683",
    "text": "r(outpath):\n    # if called from PSSE's Example Folder, create report in subfolder 'Output_Pyscript'\n\n    if outpath:\n        outdir = outpath\n        if not os.path.exists(outdir): os.mkdir(outdir)\n    else:\n        outdir = os.getcwd()\n        cwd = outdir.lower()\n        i = cwd.find('pti')\n        j = cwd.find('psse')\n        k = cwd.find('example')\n        if i>0 and j>i and k>j:     # called from Example folder\n            outdir = os.path.join(outdir, 'Output_Pyscript')\n            if not"
  },
  {
    "id": "chunk_1684",
    "text": "join(outdir, 'Output_Pyscript')\n            if not os.path.exists(outdir): os.mkdir(outdir)\n\n    return outdir\n\n# ====================================================================================================\n\ndef get_output_filename(outpath, fnam):\n\n    p, nx = os.path.split(fnam)\n    if p:\n        retvfile = fnam\n    else:\n        outdir = get_output_dir(outpath)\n        retvfile = os.path.join(outdir, fnam)\n\n    return retvfile\n\n# ========================================================"
  },
  {
    "id": "chunk_1685",
    "text": "==============================================================================================\n\ndef create_report(ibus,jbus,mainsys,dfxfile,kbus,ckt,netmod,brnflowtyp,transfertyp,oppsystyp,dispmod,toln,oppsys,rptfile):\n    # Create Report\n    import arrbox.sensitivity_flow_to_mw\n\n    flow2mw = arrbox.sensitivity_flow_to_mw()\n\n    ierr = flow2mw.sensitivity_flow_to_mw_report(ibus,jbus,mainsys,dfxfile,kbus=0,ckt='1',netmod='dc',brnflowtyp='mw',\n        transfertyp='import',oppsystyp='slack bus',di"
  },
  {
    "id": "chunk_1686",
    "text": "     transfertyp='import',oppsystyp='slack bus',dispmod=1,toln=None,oppsys='',rptfile=rptfile)\n\n# ====================================================================================================\n\ndef demo_access(ibus,jbus,mainsys,dfxfile,kbus,ckt,netmod,brnflowtyp,transfertyp,oppsystyp,dispmod,toln,oppsys):\n    # Access factor results in Python script\n    import arrbox.sensitivity_flow_to_mw\n\n    flow2mw = arrbox.sensitivity_flow_to_mw()\n\n    robj = flow2mw.sensitivity_flow_to_mw(ibus,jbus,m"
  },
  {
    "id": "chunk_1687",
    "text": " robj = flow2mw.sensitivity_flow_to_mw(ibus,jbus,mainsys,dfxfile,kbus=0,ckt='1',netmod='dc',brnflowtyp='mw',\n        transfertyp='import',oppsystyp='slack bus',dispmod=1,toln=None,oppsys='')\n\n    print(\"\\n Returned dictionary object as is:\")\n    print(robj)\n    print('\\n')\n\n    print(\"  Getting 'ngenbuses' value by different ways:\")\n    print(\"     robj.ngenbuses    = {0:d}\".format(robj.ngenbuses))\n    print(\"     robj.ngenBuses    = {0:d}\".format(robj.ngenBuses))\n    print(\"     robj['ngenbuses"
  },
  {
    "id": "chunk_1688",
    "text": "t(robj.ngenBuses))\n    print(\"     robj['ngenbuses'] = {0:d}\".format(robj['ngenbuses']))\n    print(\"     robj['NGENbuses'] = {0:d}\".format(robj['NGENbuses']))\n    print('\\n')\n\n    print(\"  Bus names for which generator factors are calculated:\")\n    print(list(robj.genvalues.keys()))\n    print('\\n')\n\n    print(\"  Generator factors:\")\n    for bus, vdict in list(robj.genvalues.items()):\n        tdct = {'bus':bus, 'pmax':vdict.pmax, 'pmin':vdict.pmin, 'pgen':vdict.pgen, 'sftr':vdict.factor}\n        "
  },
  {
    "id": "chunk_1689",
    "text": ", 'pgen':vdict.pgen, 'sftr':vdict.factor}\n        print(\"{bus:s}  {pmax:8.2f}  {pmin:8.2f} {pgen:8.2f}  {sftr:8.5f}\".format(**tdct))\n\n# ====================================================================================================\n\ndef run_demo(savfile='savnw.sav', dfxfile='savnw.dfx', outpath=None):\n    import psspy\n\n    ibus        = 151\n    jbus        = 152\n    kbus        = 0\n    ckt         = '1'\n    mainsys     = 'STUDY'\n    netmod      = 'dc'\n    brnflowtyp  = 'mw'\n    transfertyp "
  },
  {
    "id": "chunk_1690",
    "text": "    = 'dc'\n    brnflowtyp  = 'mw'\n    transfertyp = 'import'\n    oppsystyp   = 'slack bus'\n    dispmod     = 1\n    toln        = None\n    oppsys      = ''\n\n    if not os.path.exists(savfile):\n        prgmsg = \" Error: Input savfile '{0}' does not exist\".format(savfile)\n        print(prgmsg)\n        return\n\n    if not os.path.exists(dfxfile):\n        prgmsg = \" Error: Input dfxfile '{0}' does not exist\".format(dfxfile)\n        print(prgmsg)\n        return\n\n    p, nx = os.path.split(dfxfile)\n    n"
  },
  {
    "id": "chunk_1691",
    "text": "  return\n\n    p, nx = os.path.split(dfxfile)\n    n, x = os.path.splitext(nx)\n\n    rptfile = get_output_filename(outpath, 'sensitivity_factors_' + n +'_report.txt')\n\n    psspy.psseinit()\n\n    psspy.case(savfile)\n\n    create_report(ibus,jbus,mainsys,dfxfile,kbus,ckt,netmod,brnflowtyp,transfertyp,oppsystyp,dispmod,toln,oppsys,rptfile)\n\n    demo_access(ibus,jbus,mainsys,dfxfile,kbus,ckt,netmod,brnflowtyp,transfertyp,oppsystyp,dispmod,toln,oppsys)\n\n# =================================================="
  },
  {
    "id": "chunk_1692",
    "text": "====================================================================================================\n# ====================================================================================================\n\nif __name__ == '__main__':\n\n    import psse35\n    run_demo()\n\n# ====================================================================================================\n# [\t]     04/23/20     Python Functions to emulate GRPG\n#\n#  * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *"
  },
  {
    "id": "chunk_1693",
    "text": " * * * * * * * * * * * * * * * * * * * * * * * * * *\n#  *                                                                     *\n#  *  THIS PROGRAM AND ITS DOCUMENTATION ARE TRADE SECRETS OF POWER      *\n#  *  TECHNOLOGIES, INC. (PTI).  THEY HAVE BEEN LEASED TO                *\n#  *                   client full name (clabr)                          *\n#  *  SUBJECT TO TERMS WHICH PROHIBIT clabr FROM DISCLOSING OR TRANS-    *\n#  *  FERRING THE PROGRAM OR ITS DOCUMENTATION, WHETHER IN ITS ORIGINAL "
  },
  {
    "id": "chunk_1694",
    "text": "RAM OR ITS DOCUMENTATION, WHETHER IN ITS ORIGINAL  *\n#  *  OR MODIFIED FORM, TO A THIRD PARTY, OR FROM USING THE PROGRAM FOR  *\n#  *  ANY PURPOSE OTHER THAN COMPUTATION RELATING TO clabr'S OWN SYSTEM. *\n#  *  ANY SUCH TRANSFER OR USE BY clabr OR ITS EMPLOYEES WILL CONSTI-    *\n#  *  TUTE A BREACH OF CONFIDENCE AND OF THE CONTRACT UNDER WHICH        *\n#  *  RIGHTS OF USE HAVE BEEN GRANTED.                                   *\n#  *                                                                    "
  },
  {
    "id": "chunk_1695",
    "text": "                                                   *\n#  * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\n'''The functions in this Python module return:\n    - formatted text which can be used to put annotation on slider diagrams.\n    - values which are used to generate formatted text above.\nExample: function 'area_summary' returns formatted text and\n         function 'area_summary_v' returns values used by 'area_summary'\n         i.e, functions with name ending with \"_v\" re"
  },
  {
    "id": "chunk_1696",
    "text": "      i.e, functions with name ending with \"_v\" return values\n'''\n\nimport psspy\n\n#========================================================================================\n\ndef area_summary_v(arnum):\n    '''Returns desired and net interchange, loads, generation and losses for\n    area 'arnum'.\npdes,pint,qint,pload,qload,pgen,qgen,ploss,qloss = pssgrpg.area_summary_v(arnum)\n'''\n    sid  = 3\n    flag = 2\n    ierr = psspy.asys(sid, flag, [arnum])\n    ierr, rdata = psspy.aareareal(sid,flag,\n        ["
  },
  {
    "id": "chunk_1697",
    "text": " ierr, rdata = psspy.aareareal(sid,flag,\n        ['PDES','PINT','QINT','PLOADLD','QLOADLD','PGEN','QGEN','PLOSS','QLOSS'])\n    psspy.asysdef(sid, 0)\n    if ierr==0:\n        (pdes,pint,qint,ploadld,qloadld,pgen,qgen,ploss,qloss) = rdata\n        if len(pdes)>0:\n           return pdes[0],pint[0],qint[0],ploadld[0],qloadld[0],pgen[0],qgen[0],ploss[0],qloss[0]\n    return None,None,None,None,None,None,None,None,None\n\ndef area_summary(arnum):\n    '''Returns formatted text showing desired and net interc"
  },
  {
    "id": "chunk_1698",
    "text": "urns formatted text showing desired and net interchange, loads, generation\n     and losses for area 'arnum'.\ntxt = pssgrpg.area_summary(arnum)\n'''\n    pdes,pint,qint,ploadld,qloadld,pgen,qgen,ploss,qloss = area_summary_v(arnum)\n    if pdes:\n        txt = '''Area %(arnum)d Summary:\n  Desired Interchange: %(pdes)9.2f MW\n  Net Interchange    : %(pint)9.2f MW, %(qint)9.2f MVAR\n  Area loads         : %(ploadld)9.2f MW, %(qloadld)9.2f MVAR\n  Area generation    : %(pgen)9.2f MW, %(qgen)9.2f MVAR\n  Area"
  },
  {
    "id": "chunk_1699",
    "text": "ation    : %(pgen)9.2f MW, %(qgen)9.2f MVAR\n  Area losses        : %(ploss)9.2f MW, %(qloss)9.2f MVAR''' % vars()\n    else:\n        txt = '''Area %(arnum)d Summary:\n  Desired Interchange: None\n  Net Interchange    : None\n  Area loads         : None\n  Area generation    : None\n  Area losses        : None''' % vars()\n    return txt\n\ndef area_interchange_net_v(arnum):\n    '''Returns desired and net interchange for area 'arnum'.\npdes,pint,qint = pssgrpg.area_interchange_net_v(arnum)\n'''\n    sid  = 3"
  },
  {
    "id": "chunk_1700",
    "text": "rpg.area_interchange_net_v(arnum)\n'''\n    sid  = 3\n    flag = 2\n    ierr = psspy.asys(sid, flag, [arnum])\n    ierr, rdata = psspy.aareareal(sid,flag,['PDES','PINT','QINT'])\n    psspy.asysdef(sid, 0)\n    if ierr==0:\n        (pdes,pint,qint) = rdata\n        if len(pdes)>0:\n           return pdes[0],pint[0],qint[0]\n    return None,None,None\n\ndef area_interchange_net(arnum):\n    '''Returns formatted text showing desired and net interchange for area 'arnum'.\ntxt = pssgrpg.area_interchange_net(arnum)\n"
  },
  {
    "id": "chunk_1701",
    "text": "arnum'.\ntxt = pssgrpg.area_interchange_net(arnum)\n'''\n    pdes,pint,qint = area_interchange_net_v(arnum)\n    if pdes:\n        txt = '''Area %(arnum)d Interchange:\n  Desired Interchange: %(pdes)9.2f MW\n  Net Interchange    : %(pint)9.2f MW, %(qint)9.2f MVAR''' % vars()\n    else:\n        txt = '''Area %(arnum)d Interchange:\n  Desired Interchange: None\n  Net Interchange    : None''' % vars()\n    return txt\n\ndef area_interchange_ij_v(iar,jar):\n    '''Returns interchange from area 'iar' to area 'jar'"
  },
  {
    "id": "chunk_1702",
    "text": "'Returns interchange from area 'iar' to area 'jar'.\np,q = pssgrpg.area_interchange_ij_v(iar,jar)\n'''\n    ierr, cmpval = psspy.aritoj(iar,jar)\n    if ierr==0:\n        return cmpval.real, cmpval.imag\n    return None,None\n\ndef area_interchange_ij(iar,jar):\n    '''Returns formatted text showing interchange from area 'iar' to area 'jar'.\ntxt = pssgrpg.area_interchange_ij(iar,jar)\n'''\n    pint,qint = area_interchange_ij_v(iar,jar)\n    if pint:\n        txt = '''Interchange from Area %(iar)d to Area %(j"
  },
  {
    "id": "chunk_1703",
    "text": "txt = '''Interchange from Area %(iar)d to Area %(jar)d: %(pint)9.2f MW, %(qint)9.2f MVAR''' % vars()\n    else:\n        txt = '''Interchange from Area %(iar)d to Area %(jar)d: None''' % vars()\n    return txt\n\n#========================================================================================\n\ndef zone_summary_v(znnum):\n    '''Returns net interchange, loads, generation and losses for zone 'znnum'.\npint,qint,pload,qload,pgen,qgen,ploss,qloss = pssgrpg.zone_summary_v(znnum)\n'''\n    sid  = 3\n  "
  },
  {
    "id": "chunk_1704",
    "text": " pssgrpg.zone_summary_v(znnum)\n'''\n    sid  = 3\n    flag = 2\n    ierr = psspy.zsys(sid, flag, [znnum])\n    ierr, rdata = psspy.azonereal(sid,flag,\n        ['PINT','QINT','PLOADLD','QLOADLD','PGEN','QGEN','PLOSS','QLOSS'])\n    psspy.zsysdef(sid, 0)\n    if ierr==0:\n        (pint,qint,ploadld,qloadld,pgen,qgen,ploss,qloss) = rdata\n        if len(pint)>0:\n           return pint[0],qint[0],ploadld[0],qloadld[0],pgen[0],qgen[0],ploss[0],qloss[0]\n    return None,None,None,None,None,None,None,None,None\n"
  },
  {
    "id": "chunk_1705",
    "text": "turn None,None,None,None,None,None,None,None,None\n\ndef zone_summary(znnum):\n    '''Returns formatted text showing net interchange, loads, generation and losses\n    for zone 'znnum'.\ntxt = pssgrpg.zone_summary(znnum)\n'''\n    pint,qint,ploadld,qloadld,pgen,qgen,ploss,qloss = zone_summary_v(znnum)\n    if pint:\n        txt = '''Zone %(znnum)d Summary:\n  Net Interchange : %(pint)9.2f MW, %(qint)9.2f MVAR\n  Zone loads      : %(ploadld)9.2f MW, %(qloadld)9.2f MVAR\n  Zone generation : %(pgen)9.2f MW, %("
  },
  {
    "id": "chunk_1706",
    "text": "d)9.2f MVAR\n  Zone generation : %(pgen)9.2f MW, %(qgen)9.2f MVAR\n  Zone losses     : %(ploss)9.2f MW, %(qloss)9.2f MVAR''' % vars()\n    else:\n        txt = '''Zone %(znnum)d Summary:\n  Net Interchange : None\n  Zone loads      : None\n  Zone generation : None\n  Zone losses     : None''' % vars()\n    return txt\n\ndef zone_interchange_ij_v(izn,jzn):\n    '''Returns interchange from zone 'izn' to zone 'jzn'.\np,q = pssgrpg.zone_interchange_ij_v(izn,jzn)\n'''\n    ierr, cmpval = psspy.znitoj(izn,jzn)\n    i"
  },
  {
    "id": "chunk_1707",
    "text": "'''\n    ierr, cmpval = psspy.znitoj(izn,jzn)\n    if ierr==0:\n        return cmpval.real, cmpval.imag\n    return None,None\n\ndef zone_interchange_ij(izn,jzn):\n    '''Returns formatted text showing interchange from zone 'izn' to zone 'jzn'.\ntxt = pssgrpg.zone_interchange_ij(izn,jzn)\n'''\n    pint,qint = zone_interchange_ij_v(izn,jzn)\n    if pint:\n        txt = '''Interchange from Zone %(izn)d to Area %(jzn)d: %(pint)9.2f MW, %(qint)9.2f MVAR''' % vars()\n    else:\n        txt = '''Interchange from Zo"
  },
  {
    "id": "chunk_1708",
    "text": "s()\n    else:\n        txt = '''Interchange from Zone %(izn)d to Zone %(jzn)d: None''' % vars()\n    return txt\n\n#========================================================================================\n\ndef system_summary_v():\n    '''Returns working case loads, generation and losses.\npload,qload,pgen,qgen,ploss,qloss = pssgrpg.system_summary_v()\n'''\n    ierr, syslod = psspy.systot('LOAD')\n    ierr, sysgen = psspy.systot('GEN')\n    ierr, syslos = psspy.systot('LOSS')\n    return syslod.real, syslod"
  },
  {
    "id": "chunk_1709",
    "text": "sspy.systot('LOSS')\n    return syslod.real, syslod.imag, sysgen.real, sysgen.imag, syslos.real, syslos.imag\n\ndef system_summary():\n    '''Returns formatted text showing working case loads, generation and losses.\ntxt = pssgrpg.system_summary()\n'''\n    pload,qload,pgen,qgen,ploss,qloss = system_summary_v()\n    txt = '''Case Summary:\n  Total loads      : %(pload)9.2f MW, %(qload)9.2f MVAR\n  Total generation : %(pgen)9.2f MW, %(qgen)9.2f MVAR\n  Total losses     : %(ploss)9.2f MW, %(qloss)9.2f MVAR''"
  },
  {
    "id": "chunk_1710",
    "text": " losses     : %(ploss)9.2f MW, %(qloss)9.2f MVAR''' % vars()\n    return txt\n\n#========================================================================================\n#[wecclf_demo.py]  Demo for running WECCLF Converter from Python Scripts\n# ====================================================================================================\n'''\nWECCLF converter is used to convert PSLF Power Flow (.epc) and Sequence (.seq) Data\nto PSSE Power Flow (.raw) and Sequence (.seq) Data.\n\nAdditionally it "
  },
  {
    "id": "chunk_1711",
    "text": "(.raw) and Sequence (.seq) Data.\n\nAdditionally it also compares PSSE and PSLF Power Flow Solutions.\n\nWECCLF converter can be run from its own GUI:\n>>> import wecclf_gui\n>>> wecclf_gui.main()\n\nThis scripts shows different ways to run WECCLF Converter from Python Scripts.\n'''\n\nimport os, sys\n\n# ====================================================================================================\n\ndef run_wecclf(pslf_version, pslf_epcfile, psse_version, workdir=os.getcwd(), testnum=2):\n\n    import nd"
  },
  {
    "id": "chunk_1712",
    "text": "n, workdir=os.getcwd(), testnum=2):\n\n    import ndppslf\n\n    if not os.path.exists(pslf_epcfile):\n        msgtxt = \" EPC file does not exist, WECCLF converter not run.\\n    {}\".format(pslf_epcfile)\n        print(msgtxt)\n        return\n\n    p, nx = os.path.split(pslf_epcfile)\n    nam, ext  = os.path.splitext(nx)\n\n    outdir = 'wecclf_demo_output_v{}'.format(psse_version)\n    workdir = os.path.join(workdir, outdir)\n    if not os.path.exists(workdir): os.makedirs(workdir)\n\n    rawfnam  = \"{}_v{}.ra"
  },
  {
    "id": "chunk_1713",
    "text": "): os.makedirs(workdir)\n\n    rawfnam  = \"{}_v{}.raw\".format(nam, psse_version)\n    rawfile  = os.path.join(workdir, rawfnam)\n\n    prgsplit = False\n    prgfull  = True\n\n    if testnum==1:\n        #(1) Convert and compare power flow solutions using all default options\n        ndppslf.pslf2psse(pslf_version, pslf_epcfile, psse_version,\n            psse_rawfile=rawfile, ratea=1, rateb=2, ratec=3,\n            workdir=workdir, prgsplit=prgsplit, prgfull=prgfull)\n\n    elif testnum==2:\n        #(2) Conv"
  },
  {
    "id": "chunk_1714",
    "text": "l=prgfull)\n\n    elif testnum==2:\n        #(2) Convert only\n        ndppslf.pslf2psse(pslf_version, pslf_epcfile, psse_version,\n            psse_rawfile=rawfile, do_psse_pfsoln=False,\n            workdir=workdir, compare_pfsoln=False, prgfull=prgfull, prgsplit=prgsplit)\n\n    elif testnum==3:\n        #(3) Convert and compare power flow solutions using options from epcfile and options as specified\n        ndppslf.pslf2psse(pslf_version, pslf_epcfile, psse_version,\n            psse_rawfile=rawfile,\n"
  },
  {
    "id": "chunk_1715",
    "text": ", psse_version,\n            psse_rawfile=rawfile,\n            workdir=workdir, prgsplit=prgsplit, prgfull=prgfull,\n            pfmethod='RSOL', use_epcoptns=False, itmxn=100, flat=0, varlmt=99, nondiv=0,\n            rsol_pfmethod='FDNS', rsol_solnfail=0, rsol_mismatch=500.0, rsol_varband=5.0,\n            compare_pfsoln=True, show_ntop=-1, toler_vpu=-0.001,\n            toler_pgen=-1.0, toler_qgen=-1.0, toler_bact=-0.01, toler_pitf=-1.0, toler_qitf=-1.0)\n\n    elif testnum==4:\n        #(4) Convert "
  },
  {
    "id": "chunk_1716",
    "text": "=-1.0)\n\n    elif testnum==4:\n        #(4) Convert and compare power flow solutions using options as specified\n        ndppslf.pslf2psse(pslf_version, pslf_epcfile, psse_version,\n            psse_rawfile=rawfile, psse_autofile='',\n            workdir=workdir, prgsplit=prgsplit, prgfull=prgfull,\n            pfmethod='RSOL', use_epcoptns=False, itmxn=100, toln=0.1, thrshz=0.0001, tap=0,\n            area=0, phshft=0, dctap=1, swsh=1,flat=0, varlmt=99, nondiv=0,\n            rsol_pfmethod='FDNS', rsol"
  },
  {
    "id": "chunk_1717",
    "text": ", nondiv=0,\n            rsol_pfmethod='FDNS', rsol_solnfail=0, rsol_mismatch=500.0, rsol_varband=5.0,\n            compare_pfsoln=True, show_ntop=100, toler_vpu=0.02, toler_pgen=1.0,\n            toler_qgen=-1.0, toler_bact=0.01, toler_pitf=1.0, toler_qitf=-1.0)\n\n# ====================================================================================================\n\ndef _run_how():\n    pass\n##    # EPC file version=18\n##    epcfile18 = r\"sample18.epc\"\n##    run_wecclf(18, epcfile18, psse_version=34"
  },
  {
    "id": "chunk_1718",
    "text": "c\"\n##    run_wecclf(18, epcfile18, psse_version=34, workdir=os.getcwd(), testnum=3)\n##\n##    # EPC file version=19\n##    epcfile19 = r\"sample19.epc\"\n##    run_wecclf(19, epcfile19, psse_version=34, workdir=os.getcwd(), testnum=3)\n##\n##    # EPC file version=21\n##    epcfile21 = r\"sample21.epc\"\n##    run_wecclf(21, epcfile21, psse_version=34, workdir=os.getcwd(), testnum=3)\n\n# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\nif __name__ == '__ma"
  },
  {
    "id": "chunk_1719",
    "text": ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>\nif __name__ == '__main__':\n    pass\n    # Here \"import psse34\" or \"import psse35\" as appropriate.\n    # Then run required test. See _run_how() above for reference.\n#[wordpy_demo.py]  Demo for using functions from wordpy module\n# ====================================================================================================\n'''\n'wordpy' module provides Pythonic Interface to Miscrosoft Word.\nThis module has functions to create new or update existing Microsoft Wor"
  },
  {
    "id": "chunk_1720",
    "text": "ons to create new or update existing Microsoft Word document by:\n- adding text into Word document\n- inserting pictures/plots into Word document\n\nThis is an example file showing how to use various functions available in wordpy module.\n\n---------------------------------------------------------------------------------\nHow to use this file?\n\nAs showed in __main__ (end of this file)\n- Enable PSSE version specific environment, as an example:\n    import psse35\n\n- call any of the function as below\n    r"
  },
  {
    "id": "chunk_1721",
    "text": " psse35\n\n- call any of the function as below\n    run()  OR\n    run(pssplt_eps_files, pict_files, docfile, outpath, show)\n    You could modify various inputs in run)demo() as desired.\n\n'''\n\n# ====================================================================================================\nimport sys, os\n\ndef get_output_dir(outpath):\n    # if called from PSSE's Example Folder, create report in subfolder 'Output_Pyscript'\n\n    if outpath:\n        outdir = outpath\n        if not os.path.exists(ou"
  },
  {
    "id": "chunk_1722",
    "text": " outdir = outpath\n        if not os.path.exists(outdir): os.mkdir(outdir)\n    else:\n        outdir = os.getcwd()\n        cwd = outdir.lower()\n        i = cwd.find('pti')\n        j = cwd.find('psse')\n        k = cwd.find('example')\n        if i>0 and j>i and k>j:     # called from Example folder\n            outdir = os.path.join(outdir, 'Output_Pyscript')\n            if not os.path.exists(outdir): os.mkdir(outdir)\n\n    return outdir\n\n# ============================================================="
  },
  {
    "id": "chunk_1723",
    "text": "=========================================================================================\n\ndef get_output_filename(outpath, fnam):\n\n    p, nx = os.path.split(fnam)\n    if p:\n        retvfile = fnam\n    else:\n        outdir = get_output_dir(outpath)\n        retvfile = os.path.join(outdir, fnam)\n\n    return retvfile\n\n# ====================================================================================================\n\ndef run(pssplt_eps_files=[], pict_files=[], docfile='', outpath=None, show=True"
  },
  {
    "id": "chunk_1724",
    "text": "pict_files=[], docfile='', outpath=None, show=True):\n    \"\"\"\nInputs:\npssplt_eps_files --> List of Multi-page 'eps' plot files created by PSSPLT\npict_files       --> List of any word compatible picture files (.eps, .wmf, .png, .bmp etc.)\ndocfile          --> Word file name\noutpath          --> Outpath where Word file created/saved\nShow             --> = True, Show Word\n                     = False, Create and Save Word file but do not show\n\"\"\"\n    import wordpy\n\n    pssplt_eps_files_lst = []\n    "
  },
  {
    "id": "chunk_1725",
    "text": " import wordpy\n\n    pssplt_eps_files_lst = []\n    for fnam in pssplt_eps_files:\n        if not os.path.exists(fnam): continue\n        pssplt_eps_files_lst.append(fnam)\n\n    pict_files_lst   = []\n    pict_caption_lst = []\n    for fnam in pict_files:\n        if not os.path.exists(fnam): continue\n        p, nx = os.path.split(fnam)\n        caption, x = os.path.splitext(nx)\n        pict_files_lst.append(fnam)\n        pict_caption_lst.append(caption)\n\n    if  docfile:\n        p, nx = os.path.split(do"
  },
  {
    "id": "chunk_1726",
    "text": "\n    if  docfile:\n        p, nx = os.path.split(docfile)\n        docfnam, x = os.path.splitext(nx)\n    else:\n        docfnam = r'wordpy_demo_created'\n        p = outpath\n\n    # doc file\n    docfile = get_output_filename(p, docfnam)\n\n    docoverwrite = True\n\n    # Picture Insert Options (see help(wordpy) for explaination)\n    align      = 'center'\n    captionpos = 'below'\n    height     = None\n    width      = None\n    rotate     = None\n\n    # ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^"
  },
  {
    "id": "chunk_1727",
    "text": "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n    # Put-it-together\n    wdobj = wordpy.workdoc(docfile=docfile, overwrite=docoverwrite)\n    if show:\n        wdobj.show()\n\n    wdobj.page_format(orientation=\"portrait\",left=0.75,right=0.75,top=0.5,bottom=0.5,\n                      header=0.25,footer=0.25)\n\n    wdobj.add_styled_para('Use of Python and Word','Title')\n\n    txt = \"This file is produced by Python script, by inserting picture files into word "
  },
  {
    "id": "chunk_1728",
    "text": "thon script, by inserting picture files into word document. \\\n    It uses python module 'wordpy'.\\n\\n\\\n    This module is mainly created to add plot files (.eps, .png, .wmf etc.) \\\n    created by PSSPLT/PSSPLOT to existing or new Word files.\\n\\n\\\n    Use PSSPLT to create .eps files, and PSSPLOT to create .wmf files. Then use \\\n    'wordpy' module to create Word document from those files.\\n\\n\\\n    How to use it?\\n\\n\\\n    Use 'workdoc' function to create Miscrosoft Word object and use 'add_picture"
  },
  {
    "id": "chunk_1729",
    "text": "create Miscrosoft Word object and use 'add_picture(...)' or \\\n    'add_pictures(...)' methods to insert pictures into the doc file.\\n\\n\"\n    wdobj.add_text(txt)\n\n    txt = \"\"\"Use either of the following to create Word object:\n    (1) When file does not exist, create new file.\n        wdobj = wordpy.workdoc()\n    (2) When file exists, do not remove the content and add data at the end.\n        wdobj = wordpy.workdoc(r\"c:\\working dir\\ex1.doc\", overwrite=False)\n    (3) When file exists, remove the c"
  },
  {
    "id": "chunk_1730",
    "text": "rite=False)\n    (3) When file exists, remove the content and create new file.\n        wdobj = wordpy.workdoc(r\"c:\\working dir\\ex1.doc\", overwrite=True)\n    \"\"\"\n    wdobj.add_text(txt)\n\n\n    if pssplt_eps_files_lst:\n        wdobj.insert_page_break()\n        wdobj.add_styled_para('Inserting multi-page PSSPLT EPS Files - add_pssplt_eps(...)','Heading 1')\n        for fnam in pssplt_eps_files_lst:\n            wdobj.add_pssplt_eps(fnam, captionlst=True, align=align, captionpos=captionpos,\n            "
  },
  {
    "id": "chunk_1731",
    "text": ", align=align, captionpos=captionpos,\n                                 height=height, width=width, rotate=rotate)\n            wdobj.insert_page_break()\n\n    if pict_files_lst:\n        wdobj.add_styled_para('Inserting One Picture File - add_picture(...)','Heading 1')\n        wdobj.add_picture(pictfile=pict_files_lst[0], caption=pict_caption_lst[0], align=align,\n                          captionpos=captionpos, height=None, width=None, rotate=0.0)\n        wdobj.insert_page_break()\n\n    if pict_file"
  },
  {
    "id": "chunk_1732",
    "text": "       wdobj.insert_page_break()\n\n    if pict_files_lst:\n        wdobj.add_styled_para('Inserting Many Picture Files - add_pictures(...)','Heading 1')\n        wdobj.add_pictures(pictfilelst=pict_files_lst, captionlst=pict_caption_lst, align=align,\n                           captionpos=captionpos, height=height, width=width, rotate=0.0)\n\n    wdobj.save()\n\n    if not show:\n        txt = \"\\n Word file created:\\n     {0}\".format(wdobj.DOCFNAM)\n        wdobj.close()\n        print(txt)\n\n# ============"
  },
  {
    "id": "chunk_1733",
    "text": "  wdobj.close()\n        print(txt)\n\n# ====================================================================================================\n# ====================================================================================================\n\nif __name__ == '__main__':\n\n    import psse35\n    run()\n\n# ====================================================================================================\n\n\n# Blocks of code to run (0 - Do no run ; 1 - Run)\nGUI_CASES = 1\nGUI_STUDY = 0\nGUI_REPORTS = 0\nG"
  },
  {
    "id": "chunk_1734",
    "text": "Run)\nGUI_CASES = 1\nGUI_STUDY = 0\nGUI_REPORTS = 0\nGUI_CAPACITY = 0\nGUI_DELTA = 0\nGUI_SLIM = 0\nGUI_MATCH = 0\n# Set thresholds to eliminate redundant contingencies and consolidate reports\n# * Disable this feature by setting Threshold = 0\n# [0] Report name (do not change)\n# [1] Report number (do not change)\n# [2] Thermal threshold is in decimal percent\n#     Voltage threshold is in decimal pu\n#     Convergence threshold should be 0 (do not change)\n#     Capacity threshold is in decimal percent and a"
  },
  {
    "id": "chunk_1735",
    "text": "    Capacity threshold is in decimal percent and assumes 50 MVA minimum element rating\nFS_REPORT = []\nFS_REPORT.append([\"THERMAL\",1,0.05])\nFS_REPORT.append([\"VOLTAGE\",2,0.01])\nFS_REPORT.append([\"CONVERGENCE\",4,0])\nFS_REPORT.append([\"CAPACITY\",6,0.05])\nFS_REPORT.append([\"DELTA\",0,0.05])\n# Clean mode (0 - Leave miscellaneous files in place ; 1 - Delete miscellaneous files)\nFS_CLEAN = 1\n# Contingencies to run (0 - Do not run contingency ; 1 - Run contingency)\nP1 = 1\nP2_1 = 1\nP2 = 0\nP3 = 1 # ERCOT2\n"
  },
  {
    "id": "chunk_1736",
    "text": "ntingency)\nP1 = 1\nP2_1 = 1\nP2 = 0\nP3 = 1 # ERCOT2\nP4 = 0\nP5 = 0\nP6 = 0\nP7 = 1 # ERCOT1\nERCOT3 = 1\nEE = 0\nSPECIAL = 0\n# Maximum number of contingency events in a single file\nFS_CONSPLIT = 57\n# Number of CPUs to use for parallel processing\nFS_CPU = 6\n# Post-contingency thermal loading threshold, in percent\nFS_LOADING = 90\n# Post-contingency rating (1 - Rate A ; 2 - Rate B ; 3 - Rate C)\nFS_RATE = 1\n# Post-contingency voltage limit (1 - Normal limit ; 2 - Emergency limit)\nFS_LIMIT = 2\n# Exclude elem"
  },
  {
    "id": "chunk_1737",
    "text": "; 2 - Emergency limit)\nFS_LIMIT = 2\n# Exclude elements with pre-contingency (base case) voltage violations (0 - Do not exclude ; 1 - Exclude)\nFS_EXCLUDE = 0\n# Post-contingency tap adjustment (0 - Lock taps ; 1 - Stepping ; 2 - Direct)\nFS_TAP = 0\n# Post-contingency shunt control (0 - Lock all ; 1 - Enable all ; 2 - Enable continuous and disable discrete)\nFS_SHUNT = 1\n# Post-contingency adjust PSTs (0 - Do not adjust ; 1 - Adjust)\nFS_PST = 0\n# Mismatch tolerance\nFS_TOL = 1.0\n# File paths\nFPATH_SAV"
  },
  {
    "id": "chunk_1738",
    "text": "atch tolerance\nFS_TOL = 1.0\n# File paths\nFPATH_SAV = \"CASES\\\\SAV\\\\\"\nFPATH_RAW = \"CASES\\\\RAW\\\\\"\nFPATH_RCSV = \"CASES\\\\CSV\\\\\"\nFPATH_RCON = \"CASES\\\\CONFILES\\\\\"\nFPATH_CON = \"CONFILES\\\\\"\nFPATH_ACC = \"PSSE\\\\ACC\\\\\"\nFPATH_PDEV = \"PSSE\\\\PDEV\\\\\"\nFPATH_DFX = \"PSSE\\\\DFX\\\\\"\nFPATH_TXT = \"REPORTS\\\\TXT\\\\\"\nFPATH_CSV = \"REPORTS\\\\CSV\\\\\"\n\n# Import libraries\nimport os, sys, time, re, string, shutil\nfrom datetime import datetime\nfrom glob import glob\nimport importlib\nimport multiprocessing\nimport functools\nimport tkin"
  },
  {
    "id": "chunk_1739",
    "text": "mport multiprocessing\nimport functools\nimport tkinter as tk\nfrom tkinter import scrolledtext\n\n# Import PSS/E library and initialize PSS/E\nos.path.abspath(sys.argv[0])\nsys.path.append(r\"C:\\Program Files\\PTI\\PSSE35\\35.6\\PSSPY311\")\nos.environ['PATH'] += \";\" + r\"C:\\Program Files\\PTI\\PSSE35\\35.6\\PSSPY311\"\nimport psse3506 as psse35\nimport psspy\nimport pssarrays\nimport redirect\nredirect.psse2py()\nierr = psspy.psseinit(0)\n\n##### Main function\n# (0) Setup GUI\n# (1) Case I/O\n# (2) Run study and create .tx"
  },
  {
    "id": "chunk_1740",
    "text": " GUI\n# (1) Case I/O\n# (2) Run study and create .txt reports\n# (3) Create .csv reports\n# (4) Create .csv capacity reports\n# (5) Consolidate and trim .csv reports\n# (6) Add bus and branch information to .csv reports\ndef main():\n    m_gui()\n    if GUI_STUDY == 1:\n        m_study()\n    if GUI_REPORTS == 1:\n        m_reports()\n    if GUI_CAPACITY == 1 or GUI_DELTA == 1:\n        # Run both\n        if GUI_CAPACITY == 1 and GUI_DELTA == 1:\n            m_capacity(0)\n        # Run capacity report only\n   "
  },
  {
    "id": "chunk_1741",
    "text": "capacity(0)\n        # Run capacity report only\n        elif GUI_CAPACITY == 1:\n            m_capacity(1)\n        # Run delta report only\n        elif GUI_DELTA == 1:\n            m_capacity(-1)\n        # (0,0) condition does not exist\n    if GUI_DELTA == 1:\n        m_delta()\n    if GUI_SLIM == 1:\n        m_slim()\n    if GUI_MATCH == 1:\n        m_match()\n\n\n##### GUI\ndef m_gui():\n    global GUI_CASES, GUI_STUDY, GUI_REPORTS, GUI_CAPACITY, GUI_DELTA, GUI_SLIM, GUI_MATCH\n    global P1, P2_1, P2, P3, "
  },
  {
    "id": "chunk_1742",
    "text": " GUI_SLIM, GUI_MATCH\n    global P1, P2_1, P2, P3, P4, P5, P6, P7, ERCOT3, EE, SPECIAL\n    global FS_CPU, FS_LOADING, FS_EXCLUDE, FS_TAP, FS_SHUNT\n    global FS_REPORT\n    root = tk.Tk()\n    root.winfo_toplevel().title(\"FastStudy\")\n    # Variables to interface the GUI and code\n    GUI_CASES = tk.IntVar(value=GUI_CASES)\n    GUI_STUDY = tk.IntVar(value=GUI_STUDY)\n    GUI_REPORTS = tk.IntVar(value=GUI_REPORTS)\n    GUI_CAPACITY = tk.IntVar(value=GUI_CAPACITY)\n    GUI_DELTA = tk.IntVar(value=GUI_DELTA"
  },
  {
    "id": "chunk_1743",
    "text": "APACITY)\n    GUI_DELTA = tk.IntVar(value=GUI_DELTA)\n    GUI_SLIM = tk.IntVar(value=GUI_SLIM)\n    GUI_MATCH = tk.IntVar(value=GUI_MATCH)\n    #\n    P1 = tk.IntVar(value=P1)\n    P2_1 = tk.IntVar(value=P2_1)\n    P2 = tk.IntVar(value=P2)\n    P3 = tk.IntVar(value=P3)\n    P4 = tk.IntVar(value=P4)\n    P5 = tk.IntVar(value=P5)\n    P6 = tk.IntVar(value=P6)\n    P7 = tk.IntVar(value=P7)\n    ERCOT3 = tk.IntVar(value=ERCOT3)\n    EE = tk.IntVar(value=EE)\n    SPECIAL = tk.IntVar(value=SPECIAL)\n    #\n    FS_CPU "
  },
  {
    "id": "chunk_1744",
    "text": "ECIAL = tk.IntVar(value=SPECIAL)\n    #\n    FS_CPU = tk.IntVar(value=FS_CPU)\n    FS_LOADING = tk.DoubleVar(value=FS_LOADING)\n    FS_EXCLUDE = tk.IntVar(value=FS_EXCLUDE)\n    FS_TAP = tk.IntVar(value=FS_TAP)\n    FS_SHUNT = tk.IntVar(value=FS_SHUNT)\n    #\n    FS_REPORT_THERMAL = tk.DoubleVar(value=FS_REPORT[0][2])\n    FS_REPORT_VOLTAGE = tk.DoubleVar(value=FS_REPORT[1][2])\n    FS_REPORT_CAPACITY = tk.DoubleVar(value=FS_REPORT[3][2])\n    FS_REPORT_DELTA = tk.DoubleVar(value=FS_REPORT[4][2])\n    # m_"
  },
  {
    "id": "chunk_1745",
    "text": "LTA = tk.DoubleVar(value=FS_REPORT[4][2])\n    # m_cases()\n    # tk.Checkbutton(root,text=\"Convert .sav case files to .raw and .csv case files\",variable=GUI_CASES).grid(row=1,column=1,sticky=\"W\")\n    tk.Button(root,text=\"Click this button to create case .csv and .con files\",command=m_gui_cases,height=2,width=40,bg=\"white\",fg=\"blue\").grid(row=1,column=1,pady=(20,20))\n    # m_study\n    tk.Checkbutton(root,text=\"Create .acc study files and .txt report files\",variable=GUI_STUDY).grid(row=2,column=1,s"
  },
  {
    "id": "chunk_1746",
    "text": "t files\",variable=GUI_STUDY).grid(row=2,column=1,sticky=\"W\")\n    tk.Checkbutton(root,text=\"P1 / P2.1 / P7 / ERCOT 1\",variable=P1).grid(row=3,column=1,sticky=\"W\",padx=(20,0))\n    # tk.Checkbutton(root,text=\"* P2.1\",variable=P2_1).grid(row=4,column=1,sticky=\"W\",padx=(20,0))\n    # tk.Checkbutton(root,text=\"* P7 / ERCOT 1\",variable=P7).grid(row=5,column=1,sticky=\"W\",padx=(20,0))\n    tk.Checkbutton(root,text=\"P3 / ERCOT 2\",variable=P3).grid(row=6,column=1,sticky=\"W\",padx=(20,0))\n    tk.Checkbutton(ro"
  },
  {
    "id": "chunk_1747",
    "text": "mn=1,sticky=\"W\",padx=(20,0))\n    tk.Checkbutton(root,text=\"ERCOT 3\",variable=ERCOT3).grid(row=7,column=1,sticky=\"W\",padx=(20,0))\n    tk.Checkbutton(root,text=\"\\u2217 P2 / P4 / P5 / EE\",variable=P2).grid(row=8,column=1,sticky=\"W\",padx=(20,0))\n    # tk.Checkbutton(root,text=\"* P4\",variable=P4).grid(row=9,column=1,sticky=\"W\",padx=(20,0))\n    # tk.Checkbutton(root,text=\"* P5\",variable=P5).grid(row=10,column=1,sticky=\"W\",padx=(20,0))\n    # tk.Checkbutton(root,text=\"* EE\",variable=EE).grid(row=11,colu"
  },
  {
    "id": "chunk_1748",
    "text": "ton(root,text=\"* EE\",variable=EE).grid(row=11,column=1,sticky=\"W\",padx=(20,0))\n    tk.Checkbutton(root,text=\"\\u2217 P6\",variable=P6).grid(row=12,column=1,sticky=\"W\",padx=(20,0))\n    tk.Checkbutton(root,text=\"\\u2217 SPECIAL\",variable=SPECIAL).grid(row=13,column=1,sticky=\"W\",padx=(20,0))\n    tk.Entry(root,textvariable=FS_CPU,width=6).grid(row=14,column=1,sticky=\"W\",padx=(25,0))\n    tk.Label(root,text=\"Number of CPUs to use for parallel processing (integer)\").grid(row=14,column=1,sticky=\"W\",padx=(6"
  },
  {
    "id": "chunk_1749",
    "text": "integer)\").grid(row=14,column=1,sticky=\"W\",padx=(69,0))\n    tk.Checkbutton(root,text=\"Exclude elements with base case voltage violations\",variable=FS_EXCLUDE).grid(row=15,column=1,sticky=\"W\",padx=(20,0))\n    tk.Checkbutton(root,text=\"Enable transformer taps\",variable=FS_TAP).grid(row=16,column=1,sticky=\"W\",padx=(20,0))\n    tk.Checkbutton(root,text=\"Enable switch shunts\",variable=FS_SHUNT).grid(row=17,column=1,sticky=\"W\",padx=(20,0))\n    tk.Entry(root,textvariable=FS_LOADING,width=6).grid(row=18,"
  },
  {
    "id": "chunk_1750",
    "text": "root,textvariable=FS_LOADING,width=6).grid(row=18,column=1,sticky=\"W\",padx=(25,0))\n    tk.Label(root,text=\"Post-contingency thermal loading threshold (percent)\").grid(row=18,column=1,sticky=\"W\",padx=(69,5))\n    # Report\n    tk.Checkbutton(root,text=\"Convert .txt report files to .csv report files\",variable=GUI_REPORTS).grid(row=19,column=1,sticky=\"W\")    \n    # Capacity\n    tk.Checkbutton(root,text=\"Create .csv capacity report files using .acc study files\",variable=GUI_CAPACITY).grid(row=20,colum"
  },
  {
    "id": "chunk_1751",
    "text": "dy files\",variable=GUI_CAPACITY).grid(row=20,column=1,sticky=\"W\",padx=(20,0))\n    tk.Checkbutton(root,text=\"Create .csv delta report files using .acc study files\",variable=GUI_DELTA).grid(row=21,column=1,sticky=\"W\",padx=(20,0))\n    # Slim\n    tk.Checkbutton(root,text=\"Combine .csv report files and eliminate redundant violations\",variable=GUI_SLIM).grid(row=22,column=1,sticky=\"W\")\n    tk.Entry(root,textvariable=FS_REPORT_THERMAL,width=6).grid(row=23,column=1,sticky=\"W\",padx=(25,0))\n    tk.Label(r"
  },
  {
    "id": "chunk_1752",
    "text": "23,column=1,sticky=\"W\",padx=(25,0))\n    tk.Label(root,text=\"Thermal redudancy threshold (decimal percent)\").grid(row=23,column=1,sticky=\"W\",padx=(69,0))\n    tk.Entry(root,textvariable=FS_REPORT_VOLTAGE,width=6).grid(row=24,column=1,sticky=\"W\",padx=(25,0))\n    tk.Label(root,text=\"Voltage redudancy threshold (pu)\").grid(row=24,column=1,sticky=\"W\",padx=(69,0))\n    tk.Entry(root,textvariable=FS_REPORT_CAPACITY,width=6).grid(row=25,column=1,sticky=\"W\",padx=(25,0))\n    tk.Label(root,text=\"Capacity red"
  },
  {
    "id": "chunk_1753",
    "text": ",padx=(25,0))\n    tk.Label(root,text=\"Capacity redudancy threshold (decimal percent)\").grid(row=25,column=1,sticky=\"W\",padx=(69,0))\n    tk.Entry(root,textvariable=FS_REPORT_DELTA,width=6).grid(row=26,column=1,sticky=\"W\",padx=(25,0))\n    tk.Label(root,text=\"Delta redudancy threshold (decimal percent)\").grid(row=26,column=1,sticky=\"W\",padx=(69,0))\n    # Match\n    tk.Checkbutton(root,text=\"Add case data to combined .csv report files\",variable=GUI_MATCH).grid(row=27,column=1,sticky=\"W\")\n    # I/O\n  "
  },
  {
    "id": "chunk_1754",
    "text": "TCH).grid(row=27,column=1,sticky=\"W\")\n    # I/O\n    def GUI_IO():\n        global GUI_CASES, GUI_STUDY, GUI_REPORTS, GUI_CAPACITY, GUI_DELTA, GUI_SLIM, GUI_MATCH\n        global P1, P2_1, P2, P3, P4, P5, P6, P7, ERCOT3, EE, SPECIAL\n        global FS_CPU, FS_LOADING, FS_EXCLUDE, FS_TAP, FS_SHUNT\n        global FS_REPORT\n        GUI_CASES = GUI_CASES.get()\n        GUI_STUDY = GUI_STUDY.get()\n        GUI_REPORTS = GUI_REPORTS.get()\n        GUI_CAPACITY = GUI_CAPACITY.get()\n        GUI_DELTA = GUI_DEL"
  },
  {
    "id": "chunk_1755",
    "text": "Y = GUI_CAPACITY.get()\n        GUI_DELTA = GUI_DELTA.get()\n        GUI_SLIM = GUI_SLIM.get()\n        GUI_MATCH = GUI_MATCH.get()\n        #\n        P1 = P1.get()\n        P2_1 = P1 # P2_1.get()\n        P2 = P2.get()\n        P3 = P3.get()\n        P4 = P2 # P4.get()\n        P5 = P2 # P5.get()\n        P6 = P6.get()\n        P7 = P1 # P7.get()\n        ERCOT3 = ERCOT3.get()\n        EE = P2 # EE.get()\n        SPECIAL = SPECIAL.get()\n        #\n        FS_CPU = int(FS_CPU.get())\n        FS_LOADING = float("
  },
  {
    "id": "chunk_1756",
    "text": "PU = int(FS_CPU.get())\n        FS_LOADING = float(FS_LOADING.get())\n        FS_EXCLUDE = FS_EXCLUDE.get()\n        FS_TAP = FS_TAP.get()\n        FS_SHUNT = FS_SHUNT.get()\n        #\n        FS_REPORT[0][2] = float(FS_REPORT_THERMAL.get())\n        FS_REPORT[1][2] = float(FS_REPORT_VOLTAGE.get())\n        FS_REPORT[3][2] = float(FS_REPORT_CAPACITY.get())\n        FS_REPORT[4][2] = float(FS_REPORT_DELTA.get())\n        #\n        root.destroy()\n    # Button\n    tk.Button(root,text=\"Click this button to r"
  },
  {
    "id": "chunk_1757",
    "text": "on\n    tk.Button(root,text=\"Click this button to run the script\",command=GUI_IO,height=2,width=30,bg=\"white\").grid(row=28,column=1,pady=(20,20))\n    tk.Button(root,text=\"Click this button to delete files\",command=m_gui_kill,height=2,width=30,bg=\"white\",fg=\"red\").grid(row=29,column=1,pady=(0,20))\n    # Close\n    root.mainloop()\n\n\ndef m_gui_cases():\n    m_cases()\n    print(\"Created case files!\")\n\ndef m_gui_kill():\n    # Folders\n    rs = []\n    rs.append([FPATH_RAW,\"raw\",\"orange\",0])\n    rs.append("
  },
  {
    "id": "chunk_1758",
    "text": "ppend([FPATH_RAW,\"raw\",\"orange\",0])\n    rs.append([FPATH_RCSV,\"csv\",\"orange\",0])\n    rs.append([FPATH_ACC,\"acc\",\"red\",0])\n    rs.append([FPATH_PDEV,\"pdev\",\"red\",1])\n    rs.append([FPATH_DFX,\"dfx\",\"red\",1])\n    rs.append([FPATH_CSV,\"csv\",\"purple\",0])\n    rs.append([FPATH_CSV + \"CAPACITY\\\\\",\"csv\",\"purple\",0])\n    rs.append([FPATH_CSV + \"CONTINGENCY\\\\\",\"csv\",\"purple\",1])\n    rs.append([FPATH_CSV + \"CONVERGENCE\\\\\",\"csv\",\"purple\",1])\n    rs.append([FPATH_CSV + \"DELTA\\\\\",\"csv\",\"purple\",1])\n    rs.appe"
  },
  {
    "id": "chunk_1759",
    "text": "ATH_CSV + \"DELTA\\\\\",\"csv\",\"purple\",1])\n    rs.append([FPATH_CSV + \"LOAD\\\\\",\"csv\",\"purple\",1])\n    rs.append([FPATH_CSV + \"THERMAL\\\\\",\"csv\",\"purple\",1])\n    rs.append([FPATH_CSV + \"VOLTAGE\\\\\",\"csv\",\"purple\",1])\n    # Window 1\n    root = tk.Tk()\n    root.winfo_toplevel().title(\"Delete\")\n    GUI_RS = [tk.IntVar(root,value=r[3]) for r in rs]\n    for i, r in enumerate(rs):\n        tk.Checkbutton(root,text=r[0]+\"*.\"+r[1],fg=r[2],variable=GUI_RS[i],font=\"TkFixedFont\").grid(row=i+1,column=1,sticky=\"W\")\n"
  },
  {
    "id": "chunk_1760",
    "text": "=\"TkFixedFont\").grid(row=i+1,column=1,sticky=\"W\")\n    # Kill list\n    def m_gui_kill_confirm(rs):\n        # Get value from GUI\n        for i, r in enumerate(rs):\n            rs[i][2] = GUI_RS[i].get()\n        # Update list\n        # [^\\\\\\\\]* is any character excluding \"\\\"\n        rs = [r[0].replace(\"\\\\\",\"\\\\\\\\\").replace(\"*\",\"[^\\\\\\\\]*\") + \"[^\\\\\\\\]*\" + \"\\.\" + r[1] for r in rs if r[2] == 1]\n        # Get list of filenames\n        fnames = set()\n        for fpath, dirs, files in os.walk(\".\"):\n       "
  },
  {
    "id": "chunk_1761",
    "text": "   for fpath, dirs, files in os.walk(\".\"):\n            for fname in files:\n                fnames.add(os.path.join(fpath.replace(\".\\\\\",\"\"),fname))\n        fnames = list(fnames)\n        fnames.sort()\n        # Workaround \"\\\\\" usage in re\n        fnames = [fname.replace(\"\\\\\",\"/\") for fname in fnames]\n        # Filter list of filenames\n        fnames_filter = set()\n        for r in rs:\n            # Workaround \"\\\\\" usage in re\n            fnames_filter.update(set(filter(re.compile(r.replace(\"\\\\\\\\\","
  },
  {
    "id": "chunk_1762",
    "text": "ter.update(set(filter(re.compile(r.replace(\"\\\\\\\\\",\"/\")).match,fnames)))\n        fnames = list(fnames_filter)\n        fnames.sort()\n        # Workaround \"\\\\\" usage in re\n        fnames = [fname.replace(\"/\",\"\\\\\") for fname in fnames]\n        # Kill Window 1\n        for widget in root.winfo_children():\n            widget.destroy()\n        # Window 2\n        st = scrolledtext.ScrolledText(root,wrap=tk.WORD,width=120,height=40,font=\"TkFixedFont\")\n        st.grid(row=1,column=1,pady=10,padx=10)\n      "
  },
  {
    "id": "chunk_1763",
    "text": "    st.grid(row=1,column=1,pady=10,padx=10)\n        st.configure(state =\"normal\")\n        for i, fname in enumerate(fnames):\n            st.insert(tk.INSERT,fname + \"\\n\")\n        st.configure(state =\"disabled\")\n        st.focus()\n        tk.Button(root,text=\"Click this button to delete these files\",command=functools.partial(m_kill,fnames),height=2,width=30,bg=\"white\").grid(row=2,column=1,pady=(0,10))\n    # Kill function\n    def m_kill(fnames):\n        for fname in fnames:\n            os.remove(f"
  },
  {
    "id": "chunk_1764",
    "text": "      for fname in fnames:\n            os.remove(fname)\n        root.destroy()\n    # Button\n    tk.Button(root,text=\"Click this button to generate delete list\",command=functools.partial(m_gui_kill_confirm,rs),height=2,width=30,bg=\"white\").grid(row=len(rs)+1,column=1,pady=(20,20))\n    # Close\n    root.mainloop()\n\n\n##### Case I/O\n# (1) Export .sav files in the FPATH_SAV folder to .raw files in the FPATH_RAW folder\n# (2) Convert .raw files in the FPATH_RAW folder to a set of .csv files in FPATH_CSV"
  },
  {
    "id": "chunk_1765",
    "text": "ATH_RAW folder to a set of .csv files in FPATH_CSV subfolders\n# (3) Combine .csv files in the FPATH_RCSV folder and subfolders\ndef m_cases():\n    # Export each .sav file to .raw file\n    fnames_sav = [os.path.basename(x) for x in glob(FPATH_SAV + \"*.sav\")]\n    for fname_sav in fnames_sav:\n        fname_raw = FPATH_RAW + fname_sav.replace(\".sav\",\".raw\")\n        psspy.case(FPATH_SAV + fname_sav)\n        psspy.rawd_2(0,1,[1,1,1,0,0,0,0],0,fname_raw)\n    # Clean up the FPATH_RCSV folder\n    nuke(FPA"
  },
  {
    "id": "chunk_1766",
    "text": "\n    # Clean up the FPATH_RCSV folder\n    nuke(FPATH_RCSV,0)\n    fpaths = [\"AREA\",\"BRANCH\",\"BUS\",\"FACTSDEVICE\",\"FIXEDSHUNT\",\"GENERATOR\",\"LINES\",\"LINES_MIRROR\",\"LOAD\",\"MULTI-SECTIONLINE\",\"OWNER\",\"SWITCHEDSHUNT\",\"SYSTEMSWITCHINGDEVICE\",\"TRANSFORMER2\",\"TRANSFORMER3\",\"ZONE\"]\n    for fpath in fpaths:\n        os.mkdir(FPATH_RCSV + fpath)\n    # Clean up the FPATH_RCON folder\n    fpaths = [\"P1_1\",\"P1_3\",\"P1_4\",\"P2_1\"]\n    for fpath in fpaths:\n        nuke(FPATH_RCON + fpath + \"\\\\\",1)\n        os.mkdir(FP"
  },
  {
    "id": "chunk_1767",
    "text": "e(FPATH_RCON + fpath + \"\\\\\",1)\n        os.mkdir(FPATH_RCON + fpath)\n    # Export each .raw file to a set of .csv files\n    fnames_raw = [os.path.basename(x) for x in glob(FPATH_RAW + \"*.raw\")]\n    for fname_raw in fnames_raw:\n        csv_case(FPATH_RAW + fname_raw)\n    # Export .csv files to .con files\n    fpaths = []\n    fpaths.append([\"GENERATOR\",\"P1_1\"])\n    fpaths.append([\"TRANSFORMER2\",\"P1_3\"])\n    fpaths.append([\"TRANSFORMER3\",\"P1_3\"])\n    fpaths.append([\"FIXEDSHUNT\",\"P1_4\"])\n    fpaths.ap"
  },
  {
    "id": "chunk_1768",
    "text": "fpaths.append([\"FIXEDSHUNT\",\"P1_4\"])\n    fpaths.append([\"SWITCHEDSHUNT\",\"P1_4\"])\n    fpaths.append([\"BRANCH\",\"P2_1\"])\n    for fpath in fpaths:\n        fpath_csv = FPATH_RCSV + fpath[0] + \"\\\\\"\n        fpath_con = FPATH_RCON + fpath[1] + \"\\\\\"\n        fnames_csv = [os.path.basename(x) for x in glob(fpath_csv + \"*.csv\")]\n        for fname_csv in fnames_csv:\n            fname_con = fpath_con + fname_csv.replace(\".csv\",\".con\")\n            csv_con(fpath_csv + fname_csv,fname_con,fpath[0])\n    # Combine"
  },
  {
    "id": "chunk_1769",
    "text": "_csv + fname_csv,fname_con,fpath[0])\n    # Combine cases\n    fpaths = glob(FPATH_RCSV + \"*\\\\\")\n    for fpath in fpaths:\n        fnames_csv = [os.path.basename(x) for x in glob(fpath + \"*.csv\")]\n        fnames_csv = [fpath + s for s in fnames_csv]\n        fname_dest = FPATH_RCSV + fpath.replace(FPATH_RCSV,\"\").replace(\"\\\\\",\"\") + \".csv\"\n        csv_combine(fnames_csv, fname_dest)\n    # Combine .con files\n    fnames = set()\n    for fpath, dirs, files in os.walk(FPATH_RCON):\n        for fname in file"
  },
  {
    "id": "chunk_1770",
    "text": " in os.walk(FPATH_RCON):\n        for fname in files:\n            fnames.add(os.path.join(fpath.replace(FPATH_RCON,\"\"),fname))\n    fnames = set(filter(re.compile(\".*\" + \"\\.con\").match,fnames))\n    con_scsfs(fnames,[\".*\" + \"\\\\\\\\\" + \".*\" + \"_P1.1\" + \".*\",\"P1_1\\\\\\\\\" + \".*\"],\"P1_1.con\",[],FS_CONSPLIT,[])\n    con_scsfs(fnames,[\".*\" + \"\\\\\\\\\" + \".*\" + \"_P1.2\" + \".*\",\"P2_1\\\\\\\\\" + \".*\"],\"P1_2.con\",[],FS_CONSPLIT,[])\n    con_scsfs(fnames,[\".*\" + \"\\\\\\\\\" + \".*\" + \"_P1.3\" + \".*\",\"P1_3\\\\\\\\\" + \".*\"],\"P1_3.con\","
  },
  {
    "id": "chunk_1771",
    "text": "*\" + \"_P1.3\" + \".*\",\"P1_3\\\\\\\\\" + \".*\"],\"P1_3.con\",[],FS_CONSPLIT,[])\n    con_scsfs(fnames,[\".*\" + \"\\\\\\\\\" + \".*\" + \"_P1.4\" + \".*\",\"P1_4\\\\\\\\\" + \".*\"],\"P1_4.con\",[],FS_CONSPLIT,[])\n    con_scsfs(fnames,[\".*\" + \"\\\\\\\\\" + \".*\" + \"P7\" + \".*\"],\"P7.con\",[],FS_CONSPLIT,[])\n    con_scsfs(fnames,[\".*\" + \"\\\\\\\\\" + \".*\" + \"_P[2,4,5]\" + \".*\"],\"P2_P4_P5.con\",[],0,[])\n    con_scsfs(fnames,[\".*\" + \"\\\\\\\\\" + \".*\" + \"_EE\" + \".*\"],\"EE.con\",[],0,[])\n    #con_scsfs(fnames,[\".*\" + \"\\\\\\\\\" + \"ERCOT3\" + \".*\"],\"ERCOT3.con\",["
  },
  {
    "id": "chunk_1772",
    "text": "s,[\".*\" + \"\\\\\\\\\" + \"ERCOT3\" + \".*\"],\"ERCOT3.con\",[],FS_CONSPLIT,[])\n    #con_scsfs(fnames,[\".*\" + \"\\\\\\\\\" + \"P3\" + \".*\"],\"P3.con\",[],FS_CONSPLIT,[])\n    fnames = [os.path.basename(x) for x in glob(FPATH_RCON + \"*.con\")]\n    con_scsfs(fnames,[\"P1_[2-9]\" + \".*\" + \".con\"],\"P6.con\",[\"DB_ID_\"],FS_CONSPLIT,[\"EHV\",\"HV\"])\n    con_scsfs(fnames,[\"P7\" + \".*\" + \".con\"],\"P6_PGRR98.con\",[],FS_CONSPLIT,[\"EHV\",\"HV\"])\n    #\n    con_scsfs(fnames,[\"P1_3\" + \".*\" + \".con\"],\"ERCOT3_EHV.con\",[\"DB_ID_\"],FS_CONSPLIT,[\"EH"
  },
  {
    "id": "chunk_1773",
    "text": "con\"],\"ERCOT3_EHV.con\",[\"DB_ID_\"],FS_CONSPLIT,[\"EHV\"])\n    con_scsfs(fnames,[\"P1_3\" + \".*\" + \".con\"],\"ERCOT3_HV.con\",[\"DB_ID_\"],FS_CONSPLIT,[\"HV\"])\n    # Combine .csv dictionary files\n    fnames = set()\n    for fpath, dirs, files in os.walk(FPATH_RCON):\n        for fname in files:\n            fnames.add(os.path.join(fpath.replace(FPATH_RCON,\"\"),fname))\n    fnames = set(filter(re.compile(\"P[1-2]_[1,3,4]\" + \"\\\\\\\\\" + \".*\" + \"\\.csv\").match,fnames))\n    fnames = [FPATH_RCON + fname for fname in fname"
  },
  {
    "id": "chunk_1774",
    "text": "   fnames = [FPATH_RCON + fname for fname in fnames]\n    csv_combine(fnames,FPATH_RCON + \"DICT_SINGLES_ONLY.csv\",True)\n    # Create unified dictionary file\n    fnames = [\"DICT_SINGLES_ONLY.csv\",\"DICT_SSWG_ONLY.csv\"]\n    fnames = [FPATH_RCON + fname for fname in fnames]\n    csv_combine(fnames,FPATH_RCON + \"DICT_ALL.csv\",True)\n    # Clean up the FPATH_RCSV folder\n    fpaths = [\"AREA\",\"BRANCH\",\"BUS\",\"FACTSDEVICE\",\"FIXEDSHUNT\",\"GENERATOR\",\"LINES\",\"LINES_MIRROR\",\"LOAD\",\"MULTI-SECTIONLINE\",\"OWNER\",\"SW"
  },
  {
    "id": "chunk_1775",
    "text": "NES_MIRROR\",\"LOAD\",\"MULTI-SECTIONLINE\",\"OWNER\",\"SWITCHEDSHUNT\",\"SYSTEMSWITCHINGDEVICE\",\"TRANSFORMER2\",\"TRANSFORMER3\",\"ZONE\"]\n    for fpath in fpaths:\n        nuke(FPATH_RCSV + fpath + \"\\\\\",1)\n    # Clean up the FPATH_RCON folder\n    fpaths = [\"P1_1\",\"P1_3\",\"P1_4\",\"P2_1\"]\n    for fpath in fpaths:\n        nuke(FPATH_RCON + fpath + \"\\\\\",1)\n    # Heavy\n    if True:\n        # BUS\n        fname_dest = FPATH_RCSV + \"HEAVY_BUS.csv\"\n        match_and_add(FPATH_RCSV + \"BUS.csv\", [0,5], FPATH_RCSV + \"AREA."
  },
  {
    "id": "chunk_1776",
    "text": "FPATH_RCSV + \"BUS.csv\", [0,5], FPATH_RCSV + \"AREA.csv\", [0,1], fname_dest)\n        match_and_add(fname_dest, [0,6], FPATH_RCSV + \"ZONE.csv\", [0,1], fname_dest)\n        match_and_add(fname_dest, [0,7], FPATH_RCSV + \"OWNER.csv\", [0,1], fname_dest)\n        # LOAD\n        fname_dest = FPATH_RCSV + \"HEAVY_LOAD.csv\"\n        match_and_add(FPATH_RCSV + \"LOAD.csv\", [0,4], FPATH_RCSV + \"AREA.csv\", [0,1], fname_dest)\n        match_and_add(fname_dest, [0,5], FPATH_RCSV + \"ZONE.csv\", [0,1], fname_dest)\n     "
  },
  {
    "id": "chunk_1777",
    "text": " FPATH_RCSV + \"ZONE.csv\", [0,1], fname_dest)\n        match_and_add(fname_dest, [0,12], FPATH_RCSV + \"OWNER.csv\", [0,1], fname_dest)\n        match_and_add(fname_dest, [0,1], FPATH_RCSV + \"HEAVY_BUS.csv\", [0,1], fname_dest)\n        # GENERATOR\n        fname_dest = FPATH_RCSV + \"HEAVY_GENERATOR.csv\"\n        match_and_add(FPATH_RCSV + \"GENERATOR.csv\", [0,1], FPATH_RCSV + \"HEAVY_BUS.csv\", [0,1], fname_dest)\n        match_and_add(fname_dest, [0,8], FPATH_RCSV + \"HEAVY_BUS.csv\", [0,1], fname_dest)\n    "
  },
  {
    "id": "chunk_1778",
    "text": "TH_RCSV + \"HEAVY_BUS.csv\", [0,1], fname_dest)\n        # FIXEDSHUNT\n        fname_dest = FPATH_RCSV + \"HEAVY_FIXEDSHUNT.csv\"\n        match_and_add(FPATH_RCSV + \"FIXEDSHUNT.csv\", [0,1], FPATH_RCSV + \"HEAVY_BUS.csv\", [0,1], fname_dest)\n        # SWITCHEDSHUNT\n        fname_dest = FPATH_RCSV + \"HEAVY_SWITCHEDSHUNT.csv\"\n        match_and_add(FPATH_RCSV + \"SWITCHEDSHUNT.csv\", [0,1], FPATH_RCSV + \"HEAVY_BUS.csv\", [0,1], fname_dest)\n        # BRANCH\n        fname_dest = FPATH_RCSV + \"HEAVY_BRANCH.csv\"\n "
  },
  {
    "id": "chunk_1779",
    "text": "    fname_dest = FPATH_RCSV + \"HEAVY_BRANCH.csv\"\n        match_and_add(FPATH_RCSV + \"BRANCH.csv\", [0,1], FPATH_RCSV + \"HEAVY_BUS.csv\", [0,1], fname_dest)\n        match_and_add(fname_dest, [0,2], FPATH_RCSV + \"HEAVY_BUS.csv\", [0,1], fname_dest)\n        match_and_add(fname_dest, [0,27], FPATH_RCSV + \"OWNER.csv\", [0,1], fname_dest)\n        match_and_add(fname_dest, [0,29], FPATH_RCSV + \"OWNER.csv\", [0,1], fname_dest)\n        match_and_add(fname_dest, [0,31], FPATH_RCSV + \"OWNER.csv\", [0,1], fname_d"
  },
  {
    "id": "chunk_1780",
    "text": ", [0,31], FPATH_RCSV + \"OWNER.csv\", [0,1], fname_dest)\n        match_and_add(fname_dest, [0,33], FPATH_RCSV + \"OWNER.csv\", [0,1], fname_dest)\n        # TRANSFORMER2\n        fname_dest = FPATH_RCSV + \"HEAVY_TRANSFORMER2.csv\"\n        match_and_add(FPATH_RCSV + \"TRANSFORMER2.csv\", [0,1], FPATH_RCSV + \"HEAVY_BUS.csv\", [0,1], fname_dest)\n        match_and_add(fname_dest, [0,2], FPATH_RCSV + \"HEAVY_BUS.csv\", [0,1], fname_dest)\n        match_and_add(fname_dest, [0,13], FPATH_RCSV + \"OWNER.csv\", [0,1], "
  },
  {
    "id": "chunk_1781",
    "text": "me_dest, [0,13], FPATH_RCSV + \"OWNER.csv\", [0,1], fname_dest)\n        match_and_add(fname_dest, [0,15], FPATH_RCSV + \"OWNER.csv\", [0,1], fname_dest)\n        match_and_add(fname_dest, [0,17], FPATH_RCSV + \"OWNER.csv\", [0,1], fname_dest)\n        match_and_add(fname_dest, [0,19], FPATH_RCSV + \"OWNER.csv\", [0,1], fname_dest)\n        # TRANSFORMER3\n        fname_dest = FPATH_RCSV + \"HEAVY_TRANSFORMER3.csv\"\n        match_and_add(FPATH_RCSV + \"TRANSFORMER3.csv\", [0,1], FPATH_RCSV + \"HEAVY_BUS.csv\", [0,"
  },
  {
    "id": "chunk_1782",
    "text": "ER3.csv\", [0,1], FPATH_RCSV + \"HEAVY_BUS.csv\", [0,1], fname_dest)\n        match_and_add(fname_dest, [0,2], FPATH_RCSV + \"HEAVY_BUS.csv\", [0,1], fname_dest)\n        match_and_add(fname_dest, [0,3], FPATH_RCSV + \"HEAVY_BUS.csv\", [0,1], fname_dest)\n        match_and_add(fname_dest, [0,13], FPATH_RCSV + \"OWNER.csv\", [0,1], fname_dest)\n        match_and_add(fname_dest, [0,15], FPATH_RCSV + \"OWNER.csv\", [0,1], fname_dest)\n        match_and_add(fname_dest, [0,17], FPATH_RCSV + \"OWNER.csv\", [0,1], fname"
  },
  {
    "id": "chunk_1783",
    "text": "st, [0,17], FPATH_RCSV + \"OWNER.csv\", [0,1], fname_dest)\n        match_and_add(fname_dest, [0,19], FPATH_RCSV + \"OWNER.csv\", [0,1], fname_dest)\n        # FACTSDEVICE\n        fname_dest = FPATH_RCSV + \"HEAVY_FACTSDEVICE.csv\"\n        match_and_add(FPATH_RCSV + \"FACTSDEVICE.csv\", [0,2], FPATH_RCSV + \"HEAVY_BUS.csv\", [0,1], fname_dest)\n        match_and_add(fname_dest, [0,3], FPATH_RCSV + \"HEAVY_BUS.csv\", [0,1], fname_dest)\n        match_and_add(fname_dest, [0,20], FPATH_RCSV + \"HEAVY_BUS.csv\", [0,1"
  },
  {
    "id": "chunk_1784",
    "text": "e_dest, [0,20], FPATH_RCSV + \"HEAVY_BUS.csv\", [0,1], fname_dest)\n        match_and_add(fname_dest, [0,16], FPATH_RCSV + \"OWNER.csv\", [0,1], fname_dest)\n        # SYSTEMSWITCHINGDEVICE\n        fname_dest = FPATH_RCSV + \"HEAVY_SYSTEMSWITCHINGDEVICE.csv\"\n        match_and_add(FPATH_RCSV + \"SYSTEMSWITCHINGDEVICE.csv\", [0,1], FPATH_RCSV + \"HEAVY_BUS.csv\", [0,1], fname_dest)\n        match_and_add(fname_dest, [0,2], FPATH_RCSV + \"HEAVY_BUS.csv\", [0,1], fname_dest)\n\n\n# Helper function to nuke a folder\nd"
  },
  {
    "id": "chunk_1785",
    "text": "fname_dest)\n\n\n# Helper function to nuke a folder\ndef nuke(fpath,delete_fpath=0):\n    if os.path.isdir(fpath):\n        for root, dirs, files in os.walk(fpath, topdown=False):\n            for fname in files:\n                os.remove(os.path.join(root,fname))\n            for sdir in dirs:\n                os.rmdir(os.path.join(root,sdir))\n        if delete_fpath == 1:\n            os.rmdir(fpath)\n\n# Helper function to search, combine, slim, filter, and split .con files\ndef con_scsfs(fnames, rs, fnam"
  },
  {
    "id": "chunk_1786",
    "text": "nd split .con files\ndef con_scsfs(fnames, rs, fname_dest, fs, n=100000, bes=[]):\n    if n == 0:\n        n = 100000\n    # Workaround \"\\\\\" usage in re\n    fnames = [fname.replace(\"\\\\\",\"/\") for fname in fnames]\n    # Search\n    fnames_con = set()\n    for r in rs:\n        # Workaround \"\\\\\" usage in re\n        fnames_con.update(set(filter(re.compile(r.replace(\"\\\\\\\\\",\"/\")).match,fnames)))\n    # Workaround \"\\\\\" usage in re\n    fnames_con = [fname_con.replace(\"/\",\"\\\\\") for fname_con in fnames_con]\n    #"
  },
  {
    "id": "chunk_1787",
    "text": "place(\"/\",\"\\\\\") for fname_con in fnames_con]\n    # Combine\n    fnames_con = [FPATH_RCON + fname_con for fname_con in fnames_con]\n    fnames_con.sort()\n    fname_dest = FPATH_RCON + fname_dest\n    con_combine(fnames_con,fname_dest)\n    # Slim\n    con_slim(fname_dest,FPATH_RCON + \"BUS_LIST.txt\",bes)\n    # Filter\n    for f in fs:\n        con_filter(fname_dest,f)\n    # Split\n    con_split(fname_dest,n)\n\n# Convert .csv file to .con file\ndef csv_con(fname_csv, fname_con, mode):\n    # Set the mode\n    "
  },
  {
    "id": "chunk_1788",
    "text": "ame_csv, fname_con, mode):\n    # Set the mode\n    if mode == \"GENERATOR\":\n        id_slugs = [\"UNIT \",\"(\",\")\"]\n        id_stops = [1,2]\n        cmd_slugs = [\"REMOVE UNIT \",\" FROM BUS \",\"\"]\n        cmd_stops = [2,1]\n        dict_slugs = [\"\",\"\"]\n        dict_stops = [1]\n        status = 16\n        nerc = \"P1.1\"\n    elif mode == \"TRANSFORMER2\":\n        id_slugs = [\"SINGLE \",\"-\",\"(\",\")\"]\n        id_stops = [1,2,4]\n        cmd_slugs = [\"OPEN BRANCH FROM BUS \",\" TO BUS \",\" CKT \",\"\"]\n        cmd_stops "
  },
  {
    "id": "chunk_1789",
    "text": "OM BUS \",\" TO BUS \",\" CKT \",\"\"]\n        cmd_stops = [1,2,4]\n        dict_slugs = [\"\",\" - \",\"\"]\n        dict_stops = [1,2]\n        status = 12\n        nerc = \"P1.3\"\n    elif mode == \"TRANSFORMER3\":\n        id_slugs = [\"SINGLE \",\"-\",\"-\",\"(\",\")\"]\n        id_stops = [1,2,3,4]\n        cmd_slugs = [\"OPEN BRANCH FROM BUS \",\" TO BUS \",\" TO BUS \",\" CKT \",\"\"]\n        cmd_stops = [1,2,3,4]\n        dict_slugs = [\"\",\" - \",\" - \",\"\"]\n        dict_stops = [1,2,3]\n        status = 12\n        nerc = \"P1.3\"\n    el"
  },
  {
    "id": "chunk_1790",
    "text": "]\n        status = 12\n        nerc = \"P1.3\"\n    elif mode == \"FIXEDSHUNT\":\n        id_slugs = [\"SHUNT \",\"(\",\")\"]\n        id_stops = [1,2]\n        cmd_slugs = [\"REMOVE SHUNT \",\" FROM BUS \",\"\"]\n        cmd_stops = [2,1]\n        dict_slugs = [\"\",\"\"]\n        dict_stops = [1]\n        status = 3\n        nerc = \"P1.4\"\n    elif mode == \"SWITCHEDSHUNT\":\n        id_slugs = [\"SHUNT \",\"(\",\")\"]\n        id_stops = [1,2]\n        cmd_slugs = [\"REMOVE SWSHUNT \",\" FROM BUS \",\"\"]\n        cmd_stops = [2,1]\n        "
  },
  {
    "id": "chunk_1791",
    "text": " FROM BUS \",\"\"]\n        cmd_stops = [2,1]\n        dict_slugs = [\"\",\"\"]\n        dict_stops = [1]\n        status = 5\n        nerc = \"P1.4\"\n    elif mode == \"BRANCH\":\n        id_slugs = [\"SINGLE \",\"-\",\"(\",\")\"]\n        id_stops = [1,2,3]\n        cmd_slugs = [\"OPEN BRANCH FROM BUS \",\" TO BUS \",\" CKT \",\"\"]\n        cmd_stops = [1,2,3]\n        dict_slugs = [\"\",\" - \",\"\"]\n        dict_stops = [1,2]\n        status = 24\n        nerc = \"P2.1\"\n    else:\n        return\n    # Read .csv file\n    with open(fname_"
  },
  {
    "id": "chunk_1792",
    "text": "  return\n    # Read .csv file\n    with open(fname_csv,\"r\") as f:\n        lines = f.readlines()\n    lines.pop(0)\n    # Dictionary\n    d = build_dict(fname_csv.replace(mode,\"BUS\"),[1])\n    for key, value in d.items():\n        d[key] = value.split(\",\")[2]\n    # Write contingency file\n    with open(fname_con,\"w\") as g:\n        with open(fname_con.replace(\".con\",\".csv\"),\"w\") as h:\n            # Dictionary header\n            h.write(\"CONTINGENCY,TYPE,SUBMITTER,DESCRIPTION\\n\")\n            for line in l"
  },
  {
    "id": "chunk_1793",
    "text": "UBMITTER,DESCRIPTION\\n\")\n            for line in lines:\n                s = line.replace(\"\\n\",\"\").split(\",\")\n                # Contingency name\n                con_id = id_slugs[0]\n                for i, id_stop in enumerate(id_stops):\n                    con_id = con_id + s[id_stop] + id_slugs[i+1]\n                # Contingency action\n                con_cmd = cmd_slugs[0]\n                for i, cmd_stop in enumerate(cmd_stops):\n                    con_cmd = con_cmd + s[cmd_stop] + cmd_slugs[i+"
  },
  {
    "id": "chunk_1794",
    "text": "    con_cmd = con_cmd + s[cmd_stop] + cmd_slugs[i+1]\n                # Check if the element is closed and write contingency\n                if s[status] == \"1\":\n                    g.write(\"CONTINGENCY '\" + con_id + \"'\\n\")\n                    g.write(\"   \" + con_cmd + \"\\n\")\n                    g.write(\"END\\n\")\n                # Dictionary\n                con_dict = dict_slugs[0]\n                for i, dict_stop in enumerate(dict_stops):\n                    con_dict = con_dict + d[s[dict_stop]] +"
  },
  {
    "id": "chunk_1795",
    "text": "           con_dict = con_dict + d[s[dict_stop]] + dict_slugs[i+1]\n                con_dict = con_dict + \" (\"\n                for i, cmd_stop in enumerate(cmd_stops):\n                    con_dict = con_dict + s[cmd_stop] + \"-\"\n                con_dict = con_dict[:-1] + \")\"\n                # Write dictionary\n                h.write(con_id + \",\" + nerc + \",SINGLE,\" + con_dict + \"\\n\")\n            # Terminate file\n            g.write(\"END\")\n\n# Convert .raw file to .csv file\ndef csv_case(fname_raw):\n"
  },
  {
    "id": "chunk_1796",
    "text": "t .raw file to .csv file\ndef csv_case(fname_raw):\n    with open(fname_raw,\"r\") as f:\n        lines = f.readlines()\n    # Strip file\n    lines = [line_snip(line,\"'\",\",\") for line in lines] # Fix commas inside quotes\n    lines = [line.replace(\"'\",\"\") for line in lines]\n    lines = [line.replace(\" \",\"\") for line in lines]\n    lines = [line for line in lines if line[0:2] != \"@!\"]\n    # Case name\n    a = fname_raw.rfind(\"\\\\\") + 1\n    b = fname_raw.rfind(\".\")\n    case_name = fname_raw[a:b]\n    # Bug t"
  },
  {
    "id": "chunk_1797",
    "text": "nd(\".\")\n    case_name = fname_raw[a:b]\n    # Bug to help generate paths and names\n    fname_bug = FPATH_RCSV + \"BUG\\\\\" + fname_raw.replace(FPATH_RAW,\"\").replace(\".raw\",\"_BUG.csv\")\n    # Headers for each section of the .raw file\n    sections = [\"AREA\",\"BRANCH\",\"BUS\",\"FACTSDEVICE\",\"FIXEDSHUNT\",\"GENERATOR\",\"LOAD\",\"MULTI-SECTIONLINE\",\"OWNER\",\"SWITCHEDSHUNT\",\"SYSTEMSWITCHINGDEVICE\",\"ZONE\"]\n    headers = [\"AREA,ISW,PDES,PTOL,NAME\\n\"]\n    headers.append(\"FR,TO,CKT,R,X,B,NAME,RATE_1,RATE_2,RATE_3,RATE_4"
  },
  {
    "id": "chunk_1798",
    "text": "(\"FR,TO,CKT,R,X,B,NAME,RATE_1,RATE_2,RATE_3,RATE_4,RATE_5,RATE_6,RATE_7,RATE_8,RATE_9,RATE_10,RATE_11,RATE_12,GI,BI,GJ,BJ,STATUS,MET,LEN,O1,F1,O2,F2,O3,F3,O4,F4\\n\")\n    headers.append(\"BUS,NAME,KV,IDE,AREA,ZONE,OWNER,VM,VA,NVHI,NVLO,EVHI,EVLO\\n\")\n    headers.append(\"NAME,FR,TO,MODE,PDES,QDES,VSET,SHMX,TRMX,VTMN,VTMX,VSMX,IMX,LINX,RMPCT,OWNER,SET1,SET2,VSREF,FCREG,NREG,MNAME\\n\")\n    headers.append(\"BUS,ID,STATUS,GL,BL\\n\")\n    headers.append(\"BUS,ID,PG,QG,QT,QB,VS,IREG,NREG,MBASE,ZR,ZX,RT,XT,GTAP,"
  },
  {
    "id": "chunk_1799",
    "text": "D,PG,QG,QT,QB,VS,IREG,NREG,MBASE,ZR,ZX,RT,XT,GTAP,STATUS,RMPCT,PT,PB,BASLOD,O1,F1,O2,F2,O3,F3,O4,F4,WMOD,WPF\\n\")\n    headers.append(\"BUS,ID,STATUS,AREA,ZONE,PL,QL,IP,IQ,YP,YQ,OWNER,SCALE,INTRPT,DGENP,DGENQ,DGENF,TYPE\\n\")\n    headers.append(\"FR,TO,ID,MET,DUM1,DUM2,DUM3,DUM4,DUM5,DUM6,DUM7,DUM8,DUM9\\n\")\n    headers.append(\"OWNER,NAME\\n\")\n    headers.append(\"BUS,ID,MODSW,ADJM,STATUS,VSWHI,VSWLO,SWREM,NREG,RMPCT,RMIDNT,BINIT,S1,N1,B1,S2,N2,B2,S3,N3,B3,S4,N4,B4,S5,N5,B5,S6,N6,B6,S7,N7,B7,S8,N8,B8\\n\")"
  },
  {
    "id": "chunk_1800",
    "text": "3,S4,N4,B4,S5,N5,B5,S6,N6,B6,S7,N7,B7,S8,N8,B8\\n\")\n    headers.append(\"FR,TO,CKT,X,RATE_1,RATE_2,RATE_3,RATE_4,RATE_5,RATE_6,RATE_7,RATE_8,RATE_9,RATE_10,RATE_11,RATE_12,STATUS,NSTATUS,MET,STYPE,NAME\\n\")\n    headers.append(\"ZONE,NAME\\n\")\n    # Parse the .raw file\n    # Formats for .raw files and .csv files are the same\n    for i, section in enumerate(sections):\n        fname_csv = fname_bug.replace(\"BUG\",section)\n        g = open(fname_csv,\"w\")\n        g.write(\"CASE,\" + headers[i])\n        # Eac"
  },
  {
    "id": "chunk_1801",
    "text": "       g.write(\"CASE,\" + headers[i])\n        # Each section begins and ends with a similar cardinal\n        wlines = txt_trim(lines, \"BEGIN\" + section + \"DATA\", \"ENDOF\" + section + \"DATA\")\n        # Append the case name to the start of each line\n        wlines = [case_name + \",\" + wline for wline in wlines]\n        g.writelines(wlines)\n        g.close()\n    # Two-winding transformers\n    fname_csv = fname_bug.replace(\"BUG\",\"TRANSFORMER2\")\n    g2 = open(fname_csv,\"w\")\n    g2.write((\"CASE,FR,TO,TR"
  },
  {
    "id": "chunk_1802",
    "text": "= open(fname_csv,\"w\")\n    g2.write((\"CASE,FR,TO,TR,ID,CW,CZ,CM,MAG1,MAG2,METER,NAME,STATUS,O1,F1,O2,F2,O3,F3,O4,F4,VECGRP,R1_2,X1_2,SBASE1_2,\" +\n              \"WINDV1,NOMV1,ANG1,RATE_1,RATE_2,RATE_3,RATE_4,RATE_5,RATE_6,RATE_7,RATE_8,RATE_9,RATE_10,RATE_11,RATE_12,COD1,CONT1,NOD1,RMA1,RMI1,VMA1,VMI1,NTP1,TAB1,CR1,CX1,CNX1,WINDV2,NOMV2\\n\"))\n    # Three-winding transformers\n    fname_csv = fname_bug.replace(\"BUG\",\"TRANSFORMER3\")\n    g3 = open(fname_csv,\"w\")\n    g3.write((\"CASE,FR,TO,TR,ID,CW,CZ,CM"
  },
  {
    "id": "chunk_1803",
    "text": "_csv,\"w\")\n    g3.write((\"CASE,FR,TO,TR,ID,CW,CZ,CM,MAG1,MAG2,METER,NAME,STATUS,O1,F1,O2,F2,O3,F3,O4,F4,VECGRP,ZCOD,\" +\n              \"R1_2,X1_2,SBASE1_2,R2_3,X2_3,SBASE2_3,R3_1,X3_1,SBASE3_1,VMSTAR,ANSTAR,\" +\n              \"WINDV1,NOMV1,ANG1,RATE1_1,RATE1_2,RATE1_3,RATE1_4,RATE1_5,RATE1_6,RATE1_7,RATE1_8,RATE1_9,RATE1_10,RATE1_11,RATE1_12,COD1,CONT1,NOD1,RMA1,RMI1,VMA1,VMI1,NTP1,TAB1,CR1,CX1,CNXA1,\" +\n              \"WINDV2,NOMV2,ANG2,RATE2_1,RATE2_2,RATE2_3,RATE2_4,RATE2_5,RATE2_6,RATE2_7,RATE2_"
  },
  {
    "id": "chunk_1804",
    "text": "2_2,RATE2_3,RATE2_4,RATE2_5,RATE2_6,RATE2_7,RATE2_8,RATE2_9,RATE2_10,RATE2_11,RATE2_12,COD2,CONT2,NOD2,RMA2,RMI2,VMA2,VMI2,NTP2,TAB2,CR2,CX2,CNXA2,\" +\n              \"WINDV3,NOMV3,ANG3,RATE3_1,RATE3_2,RATE3_3,RATE3_4,RATE3_5,RATE3_6,RATE3_7,RATE3_8,RATE3_9,RATE3_10,RATE3_11,RATE3_12,COD3,CONT3,NOD3,RMA3,RMI3,VMA3,VMI3,NTP3,TAB3,CR3,CX3,CNXA3\\n\"))\n    # Parse the portion of the .raw file containing transformer data, which is split across multiple lines\n    i = 0\n    wlines = txt_trim(lines, \"BEGIN"
  },
  {
    "id": "chunk_1805",
    "text": "ines\n    i = 0\n    wlines = txt_trim(lines, \"BEGINTRANSFORMERDATA\", \"ENDOFTRANSFORMERDATA\")\n    wlines = [wline.replace(\"\\n\",\"\") for wline in wlines]\n    while i < len(wlines):\n        s = wlines[i].split(\",\")\n        # Two-winding transformers do not have a tertiary bus\n        if s[2] == \"0\":\n            g2.write(case_name + \",\" + wlines[i] + \",\" + wlines[i+1] + \",\" + wlines[i+2] + \",\" + wlines[i+3] + \"\\n\")\n            i = i + 4\n        # Three-winding transformers have a tertiary bus\n        "
  },
  {
    "id": "chunk_1806",
    "text": "-winding transformers have a tertiary bus\n        else:\n            g3.write(case_name + \",\" + wlines[i] + \",\" + wlines[i+1] + \",\" + wlines[i+2] + \",\" + wlines[i+3] + \",\" + wlines[i+4] + \"\\n\")\n            i = i + 5\n    g2.close()\n    g3.close()\n    # Pad out certain sections\n    sections = [\"BRANCH\",\"GENERATOR\",\"SWITCHEDSHUNT\"]\n    for section in sections:\n        fname_csv = fname_bug.replace(\"BUG\",section)\n        with open(fname_csv,\"r\") as f:\n            lines = f.readlines()\n        with op"
  },
  {
    "id": "chunk_1807",
    "text": "\n            lines = f.readlines()\n        with open(fname_csv,\"w\") as g:\n            g.write(lines.pop(0))\n            for line in lines:\n                s = line.replace(\"\\n\",\"\").split(\",\")\n                if section == \"BRANCH\":\n                    if len(s) == 29: s = s + [\"0\",\"1\",\"0\",\"1\",\"0\",\"1\"]\n                    if len(s) == 31: s = s + [\"0\",\"1\",\"0\",\"1\"]\n                    if len(s) == 33: s = s + [\"0\",\"1\"]\n                elif section == \"GENERATOR\":\n                    if len(s) == 2"
  },
  {
    "id": "chunk_1808",
    "text": "== \"GENERATOR\":\n                    if len(s) == 23: s = s + [\"0\",\"1\",\"0\",\"1\",\"0\",\"1\",\"\",\"\"]\n                    if len(s) == 25: s = s + [\"0\",\"1\",\"0\",\"1\",\"\",\"\"]\n                    if len(s) == 27: s = s + [\"0\",\"1\",\"\",\"\"]\n                    if len(s) == 29: s = s + [\"\",\"\"]\n                    if len(s) == 30: s = s + [\"\"]\n                elif section == \"SWITCHEDSHUNT\":\n                    if len(s) == 16: s = s + 21*[\"\"]\n                    if len(s) == 19: s = s + 18*[\"\"]\n                   "
  },
  {
    "id": "chunk_1809",
    "text": " len(s) == 19: s = s + 18*[\"\"]\n                    if len(s) == 22: s = s + 15*[\"\"]\n                    if len(s) == 25: s = s + 12*[\"\"]\n                    if len(s) == 28: s = s + 9*[\"\"]\n                    if len(s) == 31: s = s + 6*[\"\"]\n                    if len(s) == 34: s = s + 3*[\"\"]\n                g.write(\",\".join(s) + \"\\n\")\n    # Bus Name dictionary\n    dbusname = build_dict(fname_bug.replace(\"BUG\",\"BUS\"),[1])\n    for key, value in dbusname.items():\n        dbusname[key] = value.split"
  },
  {
    "id": "chunk_1810",
    "text": "sname.items():\n        dbusname[key] = value.split(\",\")[2]\n    # Bus kV dictionary\n    dbuskv = build_dict(fname_bug.replace(\"BUG\",\"BUS\"),[1])\n    for key, value in dbuskv.items():\n        dbuskv[key] = value.split(\",\")[3]\n    # Owner dictionary\n    downer = build_dict(fname_bug.replace(\"BUG\",\"OWNER\"),[1])\n    for key, value in downer.items():\n        downer[key] = value.split(\",\")[2]\n    # Lines include branches, two-winding transformers, and three-winding transformers\n    fname_csv = fname_bug"
  },
  {
    "id": "chunk_1811",
    "text": "ree-winding transformers\n    fname_csv = fname_bug.replace(\"BUG\",\"LINES\")\n    g = open(fname_csv,\"w\")\n    # Columns are hard-coded to each source csv file\n    g.write(\"CASE,TYPE,FR,TO,CKT,NAME,RATE_1,RATE_2,RATE_3,RATE_4,RATE_5,RATE_6,RATE_7,RATE_8,RATE_9,RATE_10,RATE_11,RATE_12,STATUS,LEN,O1,F1,O2,F2,O3,F3,O4,F4,BRANCH,KV\\n\")\n    # Branches\n    with open(fname_bug.replace(\"BUG\",\"BRANCH\"),\"r\") as f:\n        lines = f.readlines()\n        lines.pop(0)\n        for line in lines:\n            s = lin"
  },
  {
    "id": "chunk_1812",
    "text": "(0)\n        for line in lines:\n            s = line.replace(\"\\n\",\"\").split(\",\")\n            #\n            m1 = dbusname.get(s[1]) + \" > \" + dbusname.get(s[2]) + \" (\" + s[1] + \"-\" + s[2] + \"-\" + s[3] + \")\"\n            m2 = kvpretty(dbuskv.get(s[1]))\n            #\n            if len(s) == 29: s = s + [\"0\",\"1\",\"0\",\"1\",\"0\",\"1\"]\n            if len(s) == 31: s = s + [\"0\",\"1\",\"0\",\"1\"]\n            if len(s) == 33: s = s + [\"0\",\"1\"]\n            s1 = [s[i] for i in [1,2,3,7,8,9,10,11,12,13,14,15,16,17,18,"
  },
  {
    "id": "chunk_1813",
    "text": " for i in [1,2,3,7,8,9,10,11,12,13,14,15,16,17,18,19,24,26,27,28,29,30,31,32,33,34]]\n            g.write(s[0] + \",LINE,\" + \",\".join(s1) + \",\" + m1 + \",\" + m2 + \"\\n\")\n    # Two-winding transformers\n    with open(fname_bug.replace(\"BUG\",\"TRANSFORMER2\"),\"r\") as f:\n        lines = f.readlines()\n        lines.pop(0)\n        for line in lines:\n            s = line.replace(\"\\n\",\"\").split(\",\")\n            #\n            m2a = kvpretty(dbuskv.get(s[1]))\n            m2b = kvpretty(dbuskv.get(s[2]))\n       "
  },
  {
    "id": "chunk_1814",
    "text": "          m2b = kvpretty(dbuskv.get(s[2]))\n            if float(m2a) >= float(m2b):\n                m1 = dbusname.get(s[1]) + \" > \" + dbusname.get(s[2]) + \" (\" + s[1] + \"-\" + s[2] + \"-\" + s[4] + \")\"\n                m2 = m2a + \"/\" + m2b\n            else:\n                m1 = dbusname.get(s[2]) + \" > \" + dbusname.get(s[1]) + \" (\" + s[2] + \"-\" + s[1] + \"-\" + s[4] + \")\"\n                m2 = m2b + \"/\" + m2a\n            #\n            s1 = [s[i] for i in [1,2,4,11,28,29,30,31,32,33,34,35,36,37,38,39,12"
  },
  {
    "id": "chunk_1815",
    "text": "n [1,2,4,11,28,29,30,31,32,33,34,35,36,37,38,39,12]]\n            s2 = [s[i] for i in [13,14,15,16,17,18,19,20]]\n            g.write(s[0] + \",XFMR2,\" + \",\".join(s1) + \",0,\" + \",\".join(s2) + \",\" + m1 + \",\" + m2 + \"\\n\")\n    # Three-winding transformers\n    with open(fname_bug.replace(\"BUG\",\"TRANSFORMER3\"),\"r\") as f:\n        lines = f.readlines()\n        lines.pop(0)\n        for line in lines:\n            s = line.replace(\"\\n\",\"\").split(\",\")\n            #\n            m1 = [s[1],s[2],s[3]]\n          "
  },
  {
    "id": "chunk_1816",
    "text": "    #\n            m1 = [s[1],s[2],s[3]]\n            m2 = [kvpretty(dbuskv.get(m)) for m in m1]\n            m2float = [float(m) for m in m2]\n            m1 = [dbusname.get(m) for _ , m in sorted(zip(m2float,m1))]\n            m2 = [m for _ , m in sorted(zip(m2float,m2))]\n            #\n            m1 = m1[2] + \" > \" + m1[1] + \" (\" + s[1] + \"-\" + s[2] + \"-\" + s[3] + \"-\" + s[4]\n            m2 = m2[2] + \"/\" + m2[1]\n            #\n            kv = [s[1],s[2],s[3]]\n            kv = [kvpretty(dbuskv.get(m"
  },
  {
    "id": "chunk_1817",
    "text": "s[2],s[3]]\n            kv = [kvpretty(dbuskv.get(m)) for m in kv]\n            # Winding 1\n            s1 = [s[i] for i in [4,11,37,38,39,40,41,42,43,44,45,46,47,48,12]]\n            s2 = [s[i] for i in [13,14,15,16,17,18,19,20]]\n            g.write(s[0] + \",XFMR3,\" + s[1] + \",3WNDTR \" + s[11] + \",\" + \",\".join(s1) + \",0,\" + \",\".join(s2) + \",\" + m1 + \"w1),\" + m2 + \"#\" + kv[0] + \"\\n\")\n            # Winding 2\n            s1 = [s[i] for i in [4,11,64,65,66,67,68,69,70,71,72,73,74,75,12]]\n            s"
  },
  {
    "id": "chunk_1818",
    "text": "5,66,67,68,69,70,71,72,73,74,75,12]]\n            s2 = [s[i] for i in [13,14,15,16,17,18,19,20]]\n            g.write(s[0] + \",XFMR3,\" + s[2] + \",3WNDTR \" + s[11] + \",\" + \",\".join(s1) + \",0,\" + \",\".join(s2) + \",\" + m1 + \"w2),\" + m2 + \"#\" + kv[1] + \"\\n\")\n            # Winding 3\n            s1 = [s[i] for i in [4,11,91,92,93,94,95,96,97,98,99,100,101,102,12]]\n            s2 = [s[i] for i in [13,14,15,16,17,18,19,20]]\n            g.write(s[0] + \",XFMR3,\" + s[3] + \",3WNDTR \" + s[11] + \",\" + \",\".join(s"
  },
  {
    "id": "chunk_1819",
    "text": "3,\" + s[3] + \",3WNDTR \" + s[11] + \",\" + \",\".join(s1) + \",0,\" + \",\".join(s2) + \",\" + m1 + \"w3),\" + m2 + \"#\" + kv[2] + \"\\n\")\n    ## # Add owners\n    ## m3a = downer.get(s[27])\n    ## m3b = downer.get(s[29])\n    ## m3c = downer.get(s[31])\n    ## m3d = downer.get(s[33])\n    ## if r is None: r = d.get(k)\n    # Housekeeping\n    g.close()\n    # Lines in forward and reverse direction\n    fname_csv = fname_bug.replace(\"BUG\",\"LINES_MIRROR\")\n    g = open(fname_csv,\"w\")\n    # Branches\n    with open(fname_bu"
  },
  {
    "id": "chunk_1820",
    "text": "ame_csv,\"w\")\n    # Branches\n    with open(fname_bug.replace(\"BUG\",\"LINES\"),\"r\") as f:\n        lines = f.readlines()\n        # Header\n        line = lines.pop(0)\n        s = line.replace(\"\\n\",\"\").split(\",\")\n        s.insert(1,\"DIR\")\n        g.write(\",\".join(s) + \"\\n\")\n        # Body\n        for line in lines:\n            # Forward\n            s = line.replace(\"\\n\",\"\").split(\",\")\n            s.insert(1,\"F\")\n            g.write(\",\".join(s) + \"\\n\")\n            # Reverse\n            s = line.replace("
  },
  {
    "id": "chunk_1821",
    "text": "           # Reverse\n            s = line.replace(\"\\n\",\"\").split(\",\")\n            [s[2],s[3]] = [s[3],s[2]]\n            s.insert(1,\"R\")\n            g.write(\",\".join(s) + \"\\n\")\n    # Housekeeping\n    g.close()\n\n# Replace characters inside delimiters (e.g., commas inside string / quote marks)\ndef line_snip(line, delim_str, snip_str):\n    delim_str = delim_str[0]\n    snip_str = snip_str[0]\n    # Index of \"'\" characters\n    mn = [i for i, letter in enumerate(line) if letter == delim_str]\n    # \"m\" i"
  },
  {
    "id": "chunk_1822",
    "text": "numerate(line) if letter == delim_str]\n    # \"m\" is the start \"'\"\n    m = mn[0::2]\n    # \"n\" is the end \"'\"\n    n = mn[1::2]\n    # Catch unpaired \"'\"\n    if len(m) > len(n):\n        m = m[:-1]\n    # List of tuples\n    for mn in list(zip(m,n)):\n        line = line[:mn[0]] + line[mn[0]:mn[1]].replace(snip_str,\" \") + line[mn[1]:]\n    # Return line\n    return line\n\n# Parse list of strings using start (astr) and stop (bstr) flags (exclusive)\ndef txt_trim(lines, astr, bstr):\n    a = -1\n    b = -1\n    "
  },
  {
    "id": "chunk_1823",
    "text": "rim(lines, astr, bstr):\n    a = -1\n    b = -1\n    for i, line in enumerate(lines):\n        # Look for astr\n        if a < 0 and astr in line:\n            a = i + 1\n        # Look for bstr\n        elif a >= 0 and bstr in line:\n            b = i\n            break\n    # Start and stop flag not found\n    if a < 0 and b < 0:\n        return [\"\"]\n    # Stop flag not found\n    elif a >= 0 and b < 0:\n        return lines[a:]\n    # Start and stop flag found\n    elif a >= 0 and b >= 0:\n        return lines"
  },
  {
    "id": "chunk_1824",
    "text": "d\n    elif a >= 0 and b >= 0:\n        return lines[a:b]\n\n# Combine .csv files and export as a single .csv file\ndef csv_combine(fnames_csv, fname_dest, unique=False):\n    # Destination file\n    g = open(fname_dest,\"w\")\n    # No files to open\n    if len(fnames_csv) == 0:\n        g.close()\n        os.remove(fname_dest)\n        return\n    # Header\n    with open(fnames_csv[0],\"r\") as f:\n        g.write(f.readline())\n    # Contents\n    for fname_csv in fnames_csv:\n        with open(fname_csv,\"r\") as f"
  },
  {
    "id": "chunk_1825",
    "text": " fnames_csv:\n        with open(fname_csv,\"r\") as f:\n            f.readline()\n            for line in f:\n                g.write(line)\n    # Housekeeping\n    g.close()\n    # Uniques\n    if unique:\n        # Read\n        with open(fname_dest,\"r\") as f:\n            lines = f.readlines()\n        # Write\n        with open(fname_dest,\"w\") as g:\n            g.write(lines[0])\n            lines = list(set(lines[1:]))\n            lines.sort()\n            g.writelines(lines)\n\n# Combine .con files and expor"
  },
  {
    "id": "chunk_1826",
    "text": ".writelines(lines)\n\n# Combine .con files and export as a single .con file with unique contingencies\ndef con_combine(fnames_con, fname_dest):\n    # Dictionary with contingency definitions\n    d = {}\n    e = {}\n    # Parse each .con file and populate dictionary\n    fnames_con.sort()\n    for fname_con in fnames_con:\n        for kv in con_parse(fname_con):\n            # Key is the contingency command\n            key = kv[1]\n            # Value is the contingency name\n            value = kv[0]\n      "
  },
  {
    "id": "chunk_1827",
    "text": " contingency name\n            value = kv[0]\n            # Add to dictionary\n            if key not in d:\n                d[key] = value\n            elif d[key][0:6] == \"DB_ID_\":\n                d[key] = value\n            # Superset of all contingencies\n            if kv[0] not in e:\n                e[kv[0]] = kv[1]\n    # Write output .con file\n    with open(fname_dest,\"w\") as g:\n        # Header\n        for fname_con in fnames_con:\n            g.write(\"/* \" + fname_con.replace(FPATH_RCON,\"\").rep"
  },
  {
    "id": "chunk_1828",
    "text": "write(\"/* \" + fname_con.replace(FPATH_RCON,\"\").replace(\"\\\\\",\"/\") + \"\\n\")\n        g.write(\"\\n\")\n        # Content\n        lines = []\n        for key, value in d.items():\n            lines.append(\"CONTINGENCY '\" + value + \"'\\n\" + key + \"END\\n\")\n        # Uncomment next two lines to superset unique contingencies by ID\n        # for key, value in e.items():\n        #    lines.append(\"CONTINGENCY '\" + key + \"'\\n\" + value + \"END\\n\")\n        # Write\n        lines.sort()\n        g.writelines(lines)\n    "
  },
  {
    "id": "chunk_1829",
    "text": "     lines.sort()\n        g.writelines(lines)\n        g.write(\"END\")\n\n# Parse .con file into a string array\ndef con_parse(fname_con):\n    # Read\n    with open(fname_con,\"r\") as f:\n        lines = f.readlines()\n    # Clean\n    lines = [line.replace(\"\\n\",\"\") for line in lines]\n    lines = [line.split(\"/*\")[0] for line in lines]\n    lines = [line.strip() for line in lines]\n    lines = [line for line in lines if line != \"\"]\n    # Parse\n    conlines = []\n    conline = [\"\",\"\"]\n    for line in lines:\n "
  },
  {
    "id": "chunk_1830",
    "text": " []\n    conline = [\"\",\"\"]\n    for line in lines:\n        # Look for contingency name\n        if line[0:13] == \"CONTINGENCY '\":\n            conline[0] = line.replace(\"CONTINGENCY \",\"\").replace(\"'\",\"\")\n            continue\n        # Look for contingency end\n        if conline[0] != \"\" and line == \"END\":\n            if conline[1] != \"\":\n                conlines.append(conline)\n            conline = [\"\",\"\"]\n            continue\n        # Look for contingency actions\n        if conline[0] != \"\":\n    "
  },
  {
    "id": "chunk_1831",
    "text": "tingency actions\n        if conline[0] != \"\":\n            conline[1] = conline[1] + \"   \" + line + \"\\n\"\n    # Return\n    return conlines\n\n# Slim .con file to only include buses in a certain file\ndef con_slim(fname_con, fname_bus, bes=[]):\n    # Read bus list\n    with open(fname_bus,\"r\") as f:\n        bus_list = set([int(bus) for bus in f.readlines()])\n    # Read and parse\n    conlines = con_parse(fname_con)\n    # Bus kV dictionary\n    dbuskvfull = build_dict(FPATH_RCSV + \"BUS.csv\",[0,1])\n    dbu"
  },
  {
    "id": "chunk_1832",
    "text": "= build_dict(FPATH_RCSV + \"BUS.csv\",[0,1])\n    dbuskvfull.pop(0)\n    dbuskv = {}\n    for key, value in dbuskvfull.items():\n        dbuskvfull[key] = value.split(\",\")[3]\n    for key, value in dbuskvfull.items():\n        k = int(key.split(\",\")[1])\n        v = float(value)\n        if k not in dbuskv:\n            dbuskv[k] = v\n        elif v > dbuskv[k]:\n            dbuskv[k] = v\n    # Write\n    with open(fname_con,\"w\") as g:\n        for conline in conlines:\n            if True in [int(s.replace(\"BU"
  },
  {
    "id": "chunk_1833",
    "text": "onlines:\n            if True in [int(s.replace(\"BUS \",\"\")) in bus_list for s in re.findall(\"BUS [0-9]+\",conline[1])]:\n                # Include all contingencies with at least one BES element (i.e., bus number < 100000)\n                if len(bes) > 0:\n                    kv = set()\n                    for c in conline[1].split(\"\\n\")[:-1]:\n                        b = [int(s.replace(\"BUS \",\"\")) for s in re.findall(\"BUS [0-9]+\",c)]\n                        kv.add(kvclass(b, [dbuskv[i] if i in dbusk"
  },
  {
    "id": "chunk_1834",
    "text": "        kv.add(kvclass(b, [dbuskv[i] if i in dbuskv else 0 for i in b]))\n                    if len(kv.intersection(set(bes))) > 0:\n                        g.write(\"CONTINGENCY '\" + conline[0] + \"'\\n\" + conline[1] + \"END\\n\")\n                # Include all contingencies\n                else:\n                    g.write(\"CONTINGENCY '\" + conline[0] + \"'\\n\" + conline[1] + \"END\\n\")\n        g.write(\"END\")\n\n# Filter .con file to exclude contingencies containing string\ndef con_filter(fname_con, filter_s"
  },
  {
    "id": "chunk_1835",
    "text": "ntaining string\ndef con_filter(fname_con, filter_str):\n    # Do not look for the null string\n    if filter_str == \"\":\n        return\n    # Read and parse\n    conlines = con_parse(fname_con)\n    # Write\n    with open(fname_con,\"w\") as g:\n        for conline in conlines:\n            if filter_str not in conline[0]:\n                g.write(\"CONTINGENCY '\" + conline[0] + \"'\\n\" + conline[1] + \"END\\n\")\n        g.write(\"END\")\n\n# Split .con file into smaller chunks\ndef con_split(fname_con, n):\n    # Rea"
  },
  {
    "id": "chunk_1836",
    "text": "ller chunks\ndef con_split(fname_con, n):\n    # Read and parse\n    conlines = con_parse(fname_con)\n    # Minimum 10 contingencies in each file\n    n = max(n,10)\n    # Do not split small files\n    if len(conlines) <= 2*n:\n        return\n    # Counter\n    k = 1\n    while len(conlines) > 0:\n        # Chunk\n        if len(conlines) > 1.5*n:\n            lines = conlines[0:n]\n            del conlines[0:n]\n        else:\n            lines = conlines[0:]\n            del conlines[0:]\n        # Write chunk\n"
  },
  {
    "id": "chunk_1837",
    "text": "           del conlines[0:]\n        # Write chunk\n        with open(fname_con.replace(\".con\",\"__\" + format(k,\"04\") + \".con\"),\"w\") as g:\n            for line in lines:\n                g.write(\"CONTINGENCY '\" + line[0] + \"'\\n\" + line[1] + \"END\\n\")\n            g.write(\"END\")\n        # Increment counter\n        k = k + 1\n    # Delete original file\n    os.remove(fname_con)\n\n# Pretty print a voltage string\ndef kvpretty(kv):\n    kv = kv.rstrip(\"0\")\n    if kv[-1] == \".\":\n        return kv[:-1]\n    else:"
  },
  {
    "id": "chunk_1838",
    "text": "if kv[-1] == \".\":\n        return kv[:-1]\n    else:\n        return kv\n\n# Determine the voltage class of a branch based on the bus numbers\ndef kvclass(b, kv):\n    if len(b) != len(kv):\n        return \"\"\n    # Check for generator bus\n    if any([i >= 100000 and i < 200000 for i in b]):\n        return \"GEN\"\n    # Check for SODG bus\n    if any([i >= 700000 and i < 800000 for i in b]):\n        return \"SODG\"\n    #\n    if len(kv) == 1:\n        if kv[0] >= 300:\n            return \"EHV\"\n        elif kv[0]"
  },
  {
    "id": "chunk_1839",
    "text": "= 300:\n            return \"EHV\"\n        elif kv[0] >= 60:\n            return \"HV\"\n        else:\n            return \"LV\"\n    #\n    elif len(kv) == 2:\n        if max(kv) >= 300 and min(kv) >= 60:\n            return \"EHV\"\n        elif min(kv) >= 60:\n            return \"HV\"\n        else:\n            return \"LV\"\n    #\n    elif len(kv) == 3:\n        if sorted(kv)[2] >= 300 and sorted(kv)[1] >= 100:\n            return \"EHV\"\n        elif sorted(kv)[2] >= 60 and sorted(kv)[1] >= 60:\n            return \"H"
  },
  {
    "id": "chunk_1840",
    "text": " 60 and sorted(kv)[1] >= 60:\n            return \"HV\"\n        else:\n            return \"LV\"\n    #\n    else:\n        return \"\"\n    \n\n\n##### Run study and create .txt reports\n# (1) Get list of .sav files in FPATH_SAV folder\n# (2) Get list of .con files in FPATH_CON folder\n# (3) Match .sav and .con files according to contingency types\n# (4) Append each match to a list of \"ContingencyCalculation\" objects\n# (5) Create .acc file in FPATH_ACC folder for each \"ContingencyCalculation\" object in the list\n#"
  },
  {
    "id": "chunk_1841",
    "text": "each \"ContingencyCalculation\" object in the list\n# (6) Create .txt report in FPATH_TXT folder for each \"ContingencyCalculation\" object in the list\n# (7) Create .csv report in FPATH_CSV folder for each \"ContingencyCalculation\" object in the list\ndef m_study():\n    fnames_sav = [os.path.basename(x) for x in glob(FPATH_SAV + \"*.sav\")]\n    # fnames_con = [os.path.basename(x) for x in glob(FPATH_CON + \"*.con\")]\n    fname_sub = \"PSSE\\\\SUBSYSTEM.sub\"\n    fname_mon = \"PSSE\\\\MONITOR.mon\"\n    # Set of all"
  },
  {
    "id": "chunk_1842",
    "text": "  fname_mon = \"PSSE\\\\MONITOR.mon\"\n    # Set of all .con files in folder and subfolders\n    fnames = set()\n    for fpath, dirs, files in os.walk(FPATH_CON):\n        for fname in files:\n            fnames.add(os.path.join(fpath.replace(FPATH_CON,\"\"),fname))\n    fnames_con = set(filter(re.compile(\".*\" + \"\\.con\").match,fnames))\n    # Define combinations of .sav and .con files for N-1 and N-2 contingency calculations\n    # Sets are used to prevent the inclusion of duplicates\n    acc_set = set()\n    f"
  },
  {
    "id": "chunk_1843",
    "text": " inclusion of duplicates\n    acc_set = set()\n    for fname_sav in fnames_sav:\n        # Slug is the text before the third underscore\n        # [0:5] is the 6-character build, like \"20SSWG\" or \"20TSIP\"\n        # [6] is \"_\"\n        # [7:10] is the 4-digit year\n        # [11] is \"_\"\n        # [12:14] or [12:15] is the 3- or 4-character season, like \"MIN\" or \"HWLL\" or \"SUM1\"\n        slug = fname_sav\n        a = 0\n        b = slug.find(\"_\",12)\n        if b > 0 and a <= b:\n            slug = slug[a:b]"
  },
  {
    "id": "chunk_1844",
    "text": " if b > 0 and a <= b:\n            slug = slug[a:b]\n            # Slugs for \"SUM1\" and \"SUM2\" match contingency files for \"SUM1\" only\n            if slug[-1].isdigit():\n                slug = slug[:-1] + \"1\"\n        # Define contingencies by searching contingency filenames using regular expressions \n        s = set()\n        # N-1\n        if P1 == 1:\n            r1 = re.compile(slug + \".*\" + \"_P1\" + \".*\")\n            r2 = re.compile(\"P1\" + \".*\")\n            s.update(set(filter(r1.match,fnames_con"
  },
  {
    "id": "chunk_1845",
    "text": "           s.update(set(filter(r1.match,fnames_con)))\n            s.update(set(filter(r2.match,fnames_con)))\n        if P2_1 == 1:\n            r1 = re.compile(\"P2_1\" + \".*\")\n            s.update(set(filter(r1.match,fnames_con)))\n        if P2 == 1:\n            r1 = re.compile(slug + \".*\" + \"_P2\" + \".*\")\n            r2 = re.compile(\"P2\" + \".*\")\n            s.update(set(filter(r1.match,fnames_con)))\n            s.update(set(filter(r2.match,fnames_con)))\n        if P4 == 1:\n            r1 = re.comp"
  },
  {
    "id": "chunk_1846",
    "text": "on)))\n        if P4 == 1:\n            r1 = re.compile(slug + \".*\" + \"_P4\" + \".*\")\n            r2 = re.compile(\"P4\" + \".*\")\n            s.update(set(filter(r1.match,fnames_con)))\n            s.update(set(filter(r2.match,fnames_con)))\n        if P5 == 1:\n            r1 = re.compile(slug + \".*\" + \"_P5\" + \".*\")\n            r2 = re.compile(\"P5\" + \".*\")\n            s.update(set(filter(r1.match,fnames_con)))\n            s.update(set(filter(r2.match,fnames_con)))\n        if P7 == 1:\n            r1 = re."
  },
  {
    "id": "chunk_1847",
    "text": "es_con)))\n        if P7 == 1:\n            r1 = re.compile(slug + \".*\" + \"_P7\" + \".*\")\n            r2 = re.compile(\"P7\" + \".*\")\n            s.update(set(filter(r1.match,fnames_con)))\n            s.update(set(filter(r2.match,fnames_con)))\n        if EE == 1:\n            r1 = re.compile(slug + \".*\" + \"_EE\" + \".*\")\n            r2 = re.compile(\"EE\" + \".*\")\n            s.update(set(filter(r1.match,fnames_con)))\n            s.update(set(filter(r2.match,fnames_con)))\n        # Add N-0 and N-1 contingenc"
  },
  {
    "id": "chunk_1848",
    "text": "fnames_con)))\n        # Add N-0 and N-1 contingencies to list\n        for fname_con in s:\n            acc_set.add(fname_sav + \">\" + fname_con + \">\" + \"\")\n        # N-2\n        s1 = []\n        s2 = []\n        if P3 == 1:\n            t1_set = set()\n            t2_set = set()\n            # Contingency 1\n            r1 = re.compile(slug + \".*\" + \"_P1\" + \".*\")\n            r2 = re.compile(\"P1\" + \".*\")\n            r3 = re.compile(slug + \".*\" + \"_P7\" + \".*\")\n            r4 = re.compile(\"P7\" + \".*\")\n    "
  },
  {
    "id": "chunk_1849",
    "text": ".*\")\n            r4 = re.compile(\"P7\" + \".*\")\n            t1_set.update(set(filter(r1.match,fnames_con)))\n            t1_set.update(set(filter(r2.match,fnames_con)))\n            t1_set.update(set(filter(r3.match,fnames_con)))\n            t1_set.update(set(filter(r4.match,fnames_con)))\n            # Contingency 2\n            r1 = re.compile(\"P3\" + \".*\")\n            t2_set.update(set(filter(r1.match,fnames_con)))\n            # Add N-2 contingencies to list\n            for t1 in t1_set:\n           "
  },
  {
    "id": "chunk_1850",
    "text": " to list\n            for t1 in t1_set:\n                for t2 in t2_set:\n                    s1 = s1 + [t1]\n                    s2 = s2 + [t2]\n        if P6 == 1:\n            # Contingency 1\n            r1 = re.compile(\"P6\" + \".*\")\n            t1_list = list(filter(r1.match,fnames_con))\n            # Contingency 2\n            t2_list = t1_list\n            # Add N-2 contingencies to list\n            for i, t1 in enumerate(t1_list):\n                for j, t2 in enumerate(t2_list):\n                "
  },
  {
    "id": "chunk_1851",
    "text": " for j, t2 in enumerate(t2_list):\n                    if j >= i:\n                        s1 = s1 + [t1]\n                        s2 = s2 + [t2]\n        if ERCOT3 == 1:\n            t1_set = set()\n            t2_set = set()\n            # Contingency 1\n            r1 = re.compile(slug + \".*\" + \"_P1\" + \".*\")\n            r2 = re.compile(\"P1\" + \".*\")\n            r3 = re.compile(slug + \".*\" + \"_P7\" + \".*\")\n            r4 = re.compile(\"P7\" + \".*\")\n            t1_set.update(set(filter(r1.match,fnames_con)"
  },
  {
    "id": "chunk_1852",
    "text": "     t1_set.update(set(filter(r1.match,fnames_con)))\n            t1_set.update(set(filter(r2.match,fnames_con)))\n            t1_set.update(set(filter(r3.match,fnames_con)))\n            t1_set.update(set(filter(r4.match,fnames_con)))\n            # Contingency 2\n            r1 = re.compile(\".*\" + \"ERCOT3\" + \".*\")\n            t2_set.update(set(filter(r1.match,fnames_con)))\n            # Add N-2 contingencies to list\n            for t1 in t1_set:\n                for t2 in t2_set:\n                   "
  },
  {
    "id": "chunk_1853",
    "text": "             for t2 in t2_set:\n                    s1 = s1 + [t1]\n                    s2 = s2 + [t2]\n        # This section is a placeholder for custom contingency definitions\n        if SPECIAL == 1:\n            t1_set = set()\n            t2_set = set()\n            # Contingency 1\n            r1 = re.compile(slug + \".*\" + \"_P1\" + \".*\")\n            r2 = re.compile(\"P1\" + \".*\")\n            t1_set.update(set(filter(r1.match,fnames_con)))\n            t1_set.update(set(filter(r2.match,fnames_con)))\n"
  },
  {
    "id": "chunk_1854",
    "text": "  t1_set.update(set(filter(r2.match,fnames_con)))\n            # Contingency 2\n            r1 = re.compile(\"ECODEV\" + \"*.*\")\n            r2 = re.compile(slug + \".*\" + \"_P7\" + \".*\")\n            t2_set.update(set(filter(r1.match,fnames_con)))\n            t2_set.update(set(filter(r2.match,fnames_con)))\n            # Add N-2 contingencies to list\n            for t1 in t1_set:\n                for t2 in t2_set:\n                    s1 = s1 + [t1]\n                    s2 = s2 + [t2]\n        # Add N-1 cont"
  },
  {
    "id": "chunk_1855",
    "text": "             s2 = s2 + [t2]\n        # Add N-1 contingencies to list\n        for fname_con1 in set(s1):\n            acc_set.add(fname_sav + \">\" + fname_con1 + \">\" + \"\")\n        for fname_con2 in set(s2):\n            acc_set.add(fname_sav + \">\" + fname_con2 + \">\" + \"\")\n        # Add N-2 contingencies to list\n        for i, fname_con1 in enumerate(s1):\n            fname_con2 = s2[i]\n            acc_set.add(fname_sav + \">\" + fname_con1 + \">\" + fname_con2)\n\n    # Define ContingencyCalculation list\n  "
  },
  {
    "id": "chunk_1856",
    "text": "con2)\n\n    # Define ContingencyCalculation list\n    acc_list = []\n    # Slug to make each script run unique\n    time_slug = time.strftime(\"%Y_%b_%d_%H%M\").upper()\n    for line in acc_set:\n        s = line.split(\">\")\n        fname_sav = s[0]\n        fname_con1 = s[1]\n        fname_con2 = s[2]\n        fname_acc = fname_sav.replace(\".sav\", \"__\" + time_slug + \"_\" + format(len(acc_list) + 1, \"06\") + \".acc\")\n        acc = ContingencyCalculation(fname_sav, fname_con1, fname_con2, fname_acc)\n        acc"
  },
  {
    "id": "chunk_1857",
    "text": "av, fname_con1, fname_con2, fname_acc)\n        acc_list.append(acc)\n    # Hard code (if necessary)\n    # acc_list = []\n    # acc_list.append(ContingencyCalculation(\"SAV\",\"CON1\",\"CON2\",\"ACC\"))\n    \n    # Log which contingencies will be run\n    lines = []\n    for acc in acc_list:\n        lines.append(acc.fname_sav + \",\" + acc.fname_con1 + \",\" + acc.fname_con2 + \",\" + acc.fname_acc + \"\\n\")\n    with open(\"FastStudy_\" + time_slug + \".csv\",\"w\") as g:\n        g.write(\"SAV,CON1,CON2,ACC\\n\")\n        line"
  },
  {
    "id": "chunk_1858",
    "text": "       g.write(\"SAV,CON1,CON2,ACC\\n\")\n        lines.sort()\n        g.writelines(lines)\n    \n    # Run contingency analysis\n    p = multiprocessing.Pool(FS_CPU)\n    p.map(functools.partial(par_run_accc,fname_sub=fname_sub,fname_mon=fname_mon),iterable=acc_list)\n    p.close()\n\n# ContingencyCalculation encapsulates an AC Contingency Calculation in a single object\nclass ContingencyCalculation:\n    # Initialize ACCC object, which requires 1 .sav file and 1 or 2 .con files and 1 .acc output file\n    d"
  },
  {
    "id": "chunk_1859",
    "text": "and 1 or 2 .con files and 1 .acc output file\n    def __init__(self, fname_sav, fname_con1, fname_con2, fname_acc):\n        self.fname_sav = FPATH_SAV + fname_sav\n        self.fname_con1 = \"\"\n        self.fname_con2 = \"\"\n        if fname_con1 != \"\": self.fname_con1 = FPATH_CON + fname_con1\n        if fname_con2 != \"\": self.fname_con2 = FPATH_CON + fname_con2\n        self.fname_acc = FPATH_ACC + fname_acc\n        self.fname_pdev = FPATH_PDEV + fname_acc.replace(\".acc\",\".pdev\")\n        self.fname_d"
  },
  {
    "id": "chunk_1860",
    "text": "e_acc.replace(\".acc\",\".pdev\")\n        self.fname_dfx = FPATH_DFX + fname_acc.replace(\".acc\",\".dfx\")\n        self.fname_report = FPATH_TXT + fname_acc.replace(\".acc\",\".txt\")\n    \n    # Create .acc file\n    def run_accc(self, fname_sub, fname_mon):\n        # Open .sav file\n        psspy.case(self.fname_sav)\n        # Progress output file\n        psspy.lines_per_page_one_device(1,60)\n        psspy.progress_output(2,self.fname_pdev,[0,0])\n        # Construct a .dfx file (Distribution Factor Data Fil"
  },
  {
    "id": "chunk_1861",
    "text": "onstruct a .dfx file (Distribution Factor Data File)\n        psspy.dfax_2([1,1,0],fname_sub,fname_mon,self.fname_con1,self.fname_dfx)\n        # Solution engine is Full NR (0 - Fixed-slope decoupled NR ; 1 - Full NR)\n        # Post-contingency adjust DC taps is enabled (0 - Do not adjust ; 1 - Adjust)\n        # Contingency calculation for N-1\n        if self.fname_con2 == \"\":\n            psspy.accc_with_dsp_3(FS_TOL,[FS_TAP,0,FS_PST,1,FS_SHUNT,1,0,0,0,0,0],\"\",self.fname_dfx,self.fname_acc,\"\",\"\",\""
  },
  {
    "id": "chunk_1862",
    "text": ",0,0,0,0],\"\",self.fname_dfx,self.fname_acc,\"\",\"\",\"\")\n        # Contingency calculation for N-2\n        else:\n            #     n11_accc_2([FS_TAP,0,FS_PST,1,FS_SHUNT,0,1,0,FS_TAP,0,FS_PST,1,FS_SHUNT,0,0,0,1,1,1,1],[FS_TOL,100],\"\",self.fname_dfx,self.fname_acc,self.fname_con2,\"\",\"\")\n            psspy.n11_accc_3([FS_TAP,0,FS_PST,1,FS_SHUNT,0,1,0,FS_TAP,0,FS_PST,1,FS_SHUNT,0,0,0        ],[FS_TOL    ],\"\",self.fname_dfx,self.fname_acc,self.fname_con2,\"\",\"\")\n    \n    # Create .txt report file\n    def "
  },
  {
    "id": "chunk_1863",
    "text": "\"\",\"\")\n    \n    # Create .txt report file\n    def run_report(self):\n        psspy.lines_per_page_one_device(1,60)\n        psspy.report_output(2,self.fname_report,[0,0])\n        # Pre-contingency thermal rating is Rate A (1 - Rate A ; 2 - Rate B ; 3 - Rate C)\n        # Pre-contingency voltage limit is normal limit (1 - Normal limit ; 2 - Emergency limit)\n        # Post-contingency voltage limit is normal limit (1 - Normal limit ; 2 - Emergency limit)\n        # Voltage check is enabled (0 - Do not"
  },
  {
    "id": "chunk_1864",
    "text": "it)\n        # Voltage check is enabled (0 - Do not check ; 1 - Check)\n        #     accc_single_run_report_4([0,1,FS_RATE,    1,1,0,1,FS_EXCLUDE,FS_EXCLUDE,0,0,1],[0,0,0,0,6000],[0.5,5.0,FS_LOADING,0.1,0.0,0.0,99999.],self.fname_acc)\n        # 0.5 = Bus mismatch converged tolerance (MW or Mvar)\n        # 5.0 = System mismatch converged tolerance (MVA)\n        # FS_LOADING = Percent of flow rating used in overload report (%)\n        # 0.1 = Minimum contingency case flow change from base case valu"
  },
  {
    "id": "chunk_1865",
    "text": "m contingency case flow change from base case value (MVA)\n        # 0.0 = Minimum contingency case flow change from base case value (%)\n        # 0.001 = Minimum contingency case voltage change from base case value (pu)\n        # 99999 = Cutoff threshold for available capacity table (MVA)\n        psspy.accc_single_run_report_5([0,1,FS_RATE,1,1,1,1,0,1,FS_EXCLUDE,FS_EXCLUDE,0,0,1],[0,0,0,0,6000],[0.5,5.0,FS_LOADING,0.1,0.0,0.001,99999],self.fname_acc)\n        psspy.close_report()\n\n    # Create .c"
  },
  {
    "id": "chunk_1866",
    "text": "acc)\n        psspy.close_report()\n\n    # Create .csv capacity report file\n    def run_capacity(self):\n        capacity_report(self.fname_acc,1)\n\n    def nuke(self):\n        try:\n            os.remove(self.fname_acc)\n            os.remove(self.fname_dfx)\n        except:\n            pass\n\n# Run contingency calculations and output report files in parallel\ndef par_run_accc(acc, fname_sub, fname_mon):\n    acc.run_accc(fname_sub, fname_mon)\n    acc.run_report()\n    # Special for the screening study\n  "
  },
  {
    "id": "chunk_1867",
    "text": "_report()\n    # Special for the screening study\n    #acc.run_capacity()\n    #acc.nuke()\n\n\n#####  Create .csv reports\n# (1) Get list of .txt report files in FPATH_TXT folder\n# (2) Convert each .txt report file to a set of .csv report files in FPATH_CSV subfolders\ndef m_reports():\n    fnames_txt = [os.path.basename(x) for x in glob(FPATH_TXT + \"*.txt\")]\n    for fname_txt in fnames_txt:\n        csv_report(FPATH_TXT + fname_txt)\n\n# Convert a single .txt report files to a set of .csv report files in "
  },
  {
    "id": "chunk_1868",
    "text": "txt report files to a set of .csv report files in FPATH_CSV subfolders\ndef csv_report(fname_txt):\n    # Source file\n    f = open(fname_txt,\"r\")\n    # Case name\n    a = fname_txt.rfind(\"\\\\\") + 1\n    b = fname_txt.rfind(\"__\")\n    case_name = fname_txt[a:b]\n    # Read file line-by-line\n    flag = 0\n    for line in f:\n        # End of section\n        if flag > 0 and line in [\"\\n\", \"\\r\\n\"]:\n            flag = 0\n            g.close()\n        # Start of section\n        if flag == 0:\n            if \"-- "
  },
  {
    "id": "chunk_1869",
    "text": " section\n        if flag == 0:\n            if \"-- MONITORED BRANCH --\" in line:\n                flag = 1\n                report = \"THERMAL\"\n                header = \"CASE,FR,DIR_F,FR_NAME,FR_KV,TO,DIR_R,TO_NAME,TO_KV,ID,CONTINGENCY_1,CONTINGENCY_2,RATING,MW,MVAR,MVA,PERCENT\"\n            if \"MONITORED VOLTAGE REPORT:\" in line:\n                flag = 2\n                report = \"VOLTAGE\"\n                header = \"CASE,SYSTEM,TYPE,CONTINGENCY_1,CONTINGENCY_2,BUS,BUS_NAME,BUS_KV,V_CONT,V_INIT,V_MAX,V"
  },
  {
    "id": "chunk_1870",
    "text": "NGENCY_2,BUS,BUS_NAME,BUS_KV,V_CONT,V_INIT,V_MAX,V_MIN\"\n            if \"LOSS OF LOAD REPORT:\" in line:\n                flag = 3\n                report = \"LOAD\"\n                header = \"CASE,BUS,BUS_NAME,BUS_KV,CONTINGENCY_1,CONTINGENCY_2,LOAD_MW\"\n            if \"-- POST-CONTINGENCY SOLUTION --\" in line:\n                flag = 4\n                report = \"CONVERGENCE\"\n                header = \"CASE,CONTINGENCY_1,CONTINGENCY_2,TERMINATION_STATE,FLOW,SWD,VOLT,LOAD\"\n            if \"CONTINGENCY LEGEN"
  },
  {
    "id": "chunk_1871",
    "text": "W,SWD,VOLT,LOAD\"\n            if \"CONTINGENCY LEGEND:\" in line:\n                flag = 5\n                report = \"CONTINGENCY\"\n                header = \"CASE,CONTINGENCY,ACTION\"\n            if flag > 0:\n                fname_csv = fname_txt.replace(FPATH_TXT,FPATH_CSV + \"\\\\\" + report + \"\\\\\")\n                fname_csv = fname_csv.replace(\".txt\",\".csv\")\n                g = open(fname_csv,\"w\")\n                g.write(header + \"\\n\")\n        # Parse\n        if flag > 0:\n            # \"BASE CASE\" cont"
  },
  {
    "id": "chunk_1872",
    "text": "       if flag > 0:\n            # \"BASE CASE\" contingency is \"\"\n            line = line.replace(\"BASE CASE\",\"         \")\n            # Replace any stray commas\n            line = line.replace(\",\",\" \")\n            # Thermal N-1\n            if flag == 1 and len(line) == 140:\n                if line[30:36] == \"3WNDTR\":\n                    wline = case_name + \",\" + csv_split(line,[6,5,12,6,24,0,0,6,3,33,0,9,9,9,9,8])\n                else:\n                    wline = case_name + \",\" + csv_split(line,"
  },
  {
    "id": "chunk_1873",
    "text": "         wline = case_name + \",\" + csv_split(line,[6,5,12,6,7,5,12,6,3,33,0,9,9,9,9,8])\n            # Thermal N-2\n            elif flag == 1 and len(line) == 173:\n                if line[30:36] == \"3WNDTR\":\n                    wline = case_name + \",\" + csv_split(line,[6,5,12,6,24,0,0,6,3,33,33,9,9,9,9,8])\n                else:\n                    wline = case_name + \",\" + csv_split(line,[6,5,12,6,7,5,12,6,3,33,33,9,9,9,9,8])\n            # Voltage N-1\n            elif flag == 2 and len(line) == 1"
  },
  {
    "id": "chunk_1874",
    "text": " N-1\n            elif flag == 2 and len(line) == 144:\n                wline = case_name + \",\" + csv_split(line,[33,12,33,0,10,13,6,9,9,9,9])\n                wline = wline.replace(\"'\",\"\")\n                wline = wline.replace(\"RANGE\",\"R\")\n                wline = wline.replace(\"DEVIATION\",\"D\")\n            # Voltage N-2\n            elif flag == 2 and len(line) == 156:\n                wline = case_name + \",\" + csv_split(line,[20,4,33,33,10,13,6,9,9,9,9])\n                wline = wline.replace(\"'\",\"\")"
  },
  {
    "id": "chunk_1875",
    "text": ",9])\n                wline = wline.replace(\"'\",\"\")\n                wline = wline.replace(\"RANGE\",\"R\")\n                wline = wline.replace(\"DEVIATION\",\"D\")\n            # Load N-1\n            elif flag == 3 and len(line) == 72:\n                wline = case_name + \",\" + csv_split(line,[10,13,7,33,0,8])\n            # Load N-2\n            elif flag == 3 and len(line) == 105:\n                wline = case_name + \",\" + csv_split(line,[10,13,7,33,33,8])\n            # Convergence N-1\n            elif fl"
  },
  {
    "id": "chunk_1876",
    "text": "\n            # Convergence N-1\n            elif flag == 4 and len(line) == 77:\n                wline = case_name + \",\" + csv_split(line,[32,0,20,6,6,6,6])\n                wline = wline.replace(\"--\",\"9999\")\n            # Convergence N-2\n            elif flag == 4 and len(line) == 110:\n                wline = case_name + \",\" + csv_split(line,[33,32,20,6,6,6,6])\n                wline = wline.replace(\"--\",\"9999\")\n            # Contingency\n            elif flag == 5 and len(line) > 34:\n              "
  },
  {
    "id": "chunk_1877",
    "text": " elif flag == 5 and len(line) > 34:\n                wline = case_name + \",\" + csv_split(line.replace(\":\",\" \"),[33,10000])\n                # Clean up bus notation\n                b = wline.find(\"]\")\n                while b > -1:\n                    a = max(b-6,0)\n                    wline = wline[0:a] + wline[b:]\n                    b = wline.find(\"]\",a+1)\n                wline = wline.replace(\"BUS\",\"\")\n                # Clean up extra spaces\n                while wline.find(\"  \") > -1:\n         "
  },
  {
    "id": "chunk_1878",
    "text": "            while wline.find(\"  \") > -1:\n                    wline = wline.replace(\"  \",\" \")\n                wline = wline.replace(\" ]\",\"]\")\n            else:\n                wline = \"\"\n            # Headers contain carrots\n            if \"<\" not in wline and \">\" not in wline and wline != \"\":\n                g.write(wline + \"\\n\")\n    # Housekeeping\n    f.close()\n    if flag > 0: g.close()\n\n# Insert commas at specified stops in a string\ndef csv_split(rline,stops):\n    s = stops\n    a = 0\n    for "
  },
  {
    "id": "chunk_1879",
    "text": "lit(rline,stops):\n    s = stops\n    a = 0\n    for i, stop in enumerate(stops):\n        b = a + max(0,stop)\n        s[i] = rline[a:b].strip().replace(\",\",\"\")\n        a = min(b,len(rline))\n    return \",\".join(s)\n\n\n##### Create .csv capacity reports\n# (1) Get list of .acc files in FPATH_ACC folder\n# (2) Create a .csv capacity & delta report file in the FPATH_CSV folder from each .acc file\ndef m_capacity(delta=0):\n    fnames_acc = [FPATH_ACC + os.path.basename(x) for x in glob(FPATH_ACC + \"*.acc\")]\n"
  },
  {
    "id": "chunk_1880",
    "text": "h.basename(x) for x in glob(FPATH_ACC + \"*.acc\")]\n    p = multiprocessing.Pool(FS_CPU)\n    p.map(functools.partial(capacity_report,delta=delta),iterable=fnames_acc)\n    p.close()\n    # for fname_acc in fnames_acc: capacity_report(fname_acc,delta)\n\n# Create .csv capacity report file\ndef capacity_report(fname_acc,delta=0):\n    # Hack\n    fname_capacity = FPATH_CSV + \"CAPACITY\" + \"\\\\\" + fname_acc.replace(FPATH_ACC,\"\").replace(\".acc\",\".csv\")\n    fname_delta = FPATH_CSV + \"DELTA\" + \"\\\\\" + fname_acc.r"
  },
  {
    "id": "chunk_1881",
    "text": "e_delta = FPATH_CSV + \"DELTA\" + \"\\\\\" + fname_acc.replace(FPATH_ACC,\"\").replace(\".acc\",\".csv\")\n    # Case name\n    a = fname_acc.rfind(\"\\\\\") + 1\n    b = fname_acc.rfind(\"__\")\n    case_name = fname_acc[a:b]\n    # Element and rating lists\n    melements = pssarrays.accc_summary(fname_acc).melement\n    for i, melement in enumerate(melements):\n        if melement[30:36] == \"3WNDTR\":\n            melements[i] = case_name + \",\" + csv_split(melement.replace(\",\",\" \"),[11,12,6,24,0,6,3])\n        else:\n     "
  },
  {
    "id": "chunk_1882",
    "text": "e(\",\",\" \"),[11,12,6,24,0,6,3])\n        else:\n            melements[i] = case_name + \",\" + csv_split(melement.replace(\",\",\" \"),[11,12,6,12,12,6,3])\n    # Ratings\n    ratea = pssarrays.accc_summary(fname_acc).rating.a\n    rateb = pssarrays.accc_summary(fname_acc).rating.b\n    ratec = pssarrays.accc_summary(fname_acc).rating.c\n    rates = [\"{:.1f},{:.1f},{:.1f}\".format(ratea[i],rateb[i],ratec[i]) for i, rate in enumerate(ratea)]\n    # Contingency labels\n    colabels = list(pssarrays.accc_summary(fn"
  },
  {
    "id": "chunk_1883",
    "text": "bels\n    colabels = list(pssarrays.accc_summary(fname_acc).colabel)\n    s1 = [\"BASE CASE\" for s in colabels if s == \"BASE CASE\"]\n    s2 = [s for s in colabels if s != \"BASE CASE\" and \":\" not in s]\n    s3 = [s for s in colabels if \":\" in s]\n    colabels = s1 + s2 + s3\n    # Generate report\n    with open(fname_capacity,\"w\") as g:\n        with open(fname_delta,\"w\") as h:\n            # Write header\n            if delta >= 0: g.write(\"CASE,FR,FR_NAME,FR_KV,TO,TO_NAME,TO_KV,ID,CONTINGENCY_1,CONTINGENC"
  },
  {
    "id": "chunk_1884",
    "text": "FR_KV,TO,TO_NAME,TO_KV,ID,CONTINGENCY_1,CONTINGENCY_2,FLOW,RATE_1,RATE_2,RATE_3,CONV_STATUS\\n\")\n            if delta <= 0: h.write(\"CASE,FR,FR_NAME,FR_KV,TO,TO_NAME,TO_KV,ID,CONTINGENCY_1,CONTINGENCY_2,FLOW,RATE_2,RATE_2,RATE_3,CONV_STATUS\\n\")\n            # Dictionary\n            d = {}\n            for colabel in colabels:\n                # Split contingency label\n                if colabel == \"BASE CASE\":\n                    c = [\"\",\"\"]\n                elif \":\" not in colabel:\n                 "
  },
  {
    "id": "chunk_1885",
    "text": "        elif \":\" not in colabel:\n                    c = [colabel,\"\"]\n                else:\n                    c = colabel.split(\":\")\n                # Check convergence status\n                if not hasattr(pssarrays.accc_solution(fname_acc,colabel),\"cnvflag\"):\n                    continue\n                cnvcond = pssarrays.accc_solution(fname_acc,colabel).cnvcond\n                if not pssarrays.accc_solution(fname_acc,colabel).cnvflag and not cnvcond == \"Iteration limit exceeded\":\n         "
  },
  {
    "id": "chunk_1886",
    "text": "t cnvcond == \"Iteration limit exceeded\":\n                    # Pull line loadings in iterated solutions\n                    for i, melement in enumerate(melements):\n                        # \"Singular Jacobian or 0.0 voltage\"\n                        # \"Blown up\"\n                        if delta >= 0: g.write(melement + \",\" + c[0] + \",\" + c[1] + \",-9999,\" + rates[i] + \",\" + cnvcond + \"\\n\")\n                        if delta <= 0: h.write(melement + \",\" + c[0] + \",\" + c[1] + \",-9999,\" + rates[i] + \""
  },
  {
    "id": "chunk_1887",
    "text": "\",\" + c[0] + \",\" + c[1] + \",-9999,\" + rates[i] + \",\" + cnvcond + \"\\n\")\n                    continue\n                # Monitored element flows\n                mvaflows = pssarrays.accc_solution(fname_acc,colabel).mvaflow\n                mvaflows = [abs(mvaflow) for mvaflow in mvaflows]\n                # Add monitored element flows to dictionary\n                for i, mvaflow in enumerate(mvaflows):\n                    keys = []\n                    keys = keys + [melements[i] + \",\"]\n              "
  },
  {
    "id": "chunk_1888",
    "text": " keys = keys + [melements[i] + \",\"]\n                    keys = keys + [melements[i] + \",\" + c[0]]\n                    keys = keys + [melements[i] + \",\" + c[1]]\n                    # Flags set to False mean an equivalent contingency violation already exists\n                    flags = [True for key in keys]\n                    # Do not add key-value pair if existing value is within 2 percent or 0.5 MVA\n                    for j, key in enumerate(keys):\n                        if key in d and all("
  },
  {
    "id": "chunk_1889",
    "text": "eys):\n                        if key in d and all(flags):\n                            if mvaflow < (d[key] + 0.02*ratea[i]) or mvaflow < (d[key] + 0.5):\n                                flags[j] = False\n                    # Write element and flow to the capacity report\n                    if all(flags):\n                        if delta >= 0: g.write(melements[i] + \",\" + c[0] + \",\" + c[1] + \",\" + \"{:.2f}\".format(mvaflow) + \",\" + rates[i] + \",\" + cnvcond + \"\\n\")\n                        # Add N-0 o"
  },
  {
    "id": "chunk_1890",
    "text": "nvcond + \"\\n\")\n                        # Add N-0 or N-1 to dictionary\n                        if c[1] == \"\":\n                            d[melements[i] + \",\" + c[0]] = mvaflow\n                    # Write element and flow to the delta report\n                    if delta <= 0: h.write(melements[i] + \",\" + c[0] + \",\" + c[1] + \",\" + \"{:.2f}\".format(mvaflow) + \",\" + rates[i] + \",\" + cnvcond + \"\\n\")\n    # Housekeeping\n    if delta < 0: os.remove(fname_capacity)\n    if delta > 0: os.remove(fname_delta)"
  },
  {
    "id": "chunk_1891",
    "text": "capacity)\n    if delta > 0: os.remove(fname_delta)\n\n\n##### Create .csv delta reports\n# (0) Run m_capacity() with delta <= 0 before running this function to populate the DELTA folder\n# (1) Create a .csv capacity report file in the DELTA folder for each branch\n# (2) For each .csv branch capacity report file, pack with corresponding N-0 and N-1 loadings, as applicable, for each loading\n# (3) For each .csv branch capacity report file, slim the overloads report\ndef m_delta():\n    # Create a .csv capa"
  },
  {
    "id": "chunk_1892",
    "text": "ads report\ndef m_delta():\n    # Create a .csv capacity report file in the FPATH_DELTA folder from each .acc file, using the m_capacity() function\n    fnames_csv = [FPATH_CSV + \"DELTA\" + \"\\\\\" + os.path.basename(x) for x in glob(FPATH_CSV + \"DELTA\" + \"\\\\\" + \"*.csv\")]\n    #\n    fnames_acc = [FPATH_ACC + os.path.basename(x) for x in glob(FPATH_ACC + \"*.acc\")]\n    fnames_csv = [FPATH_CSV + \"DELTA\" + \"\\\\\" + fname_acc.replace(FPATH_ACC,\"\").replace(\".acc\",\".csv\") for fname_acc in fnames_acc]\n    # Get l"
  },
  {
    "id": "chunk_1893",
    "text": "\",\".csv\") for fname_acc in fnames_acc]\n    # Get list of branch names\n    d = {}\n    # Create a .csv capacity report file in the FPATH_DELTA folder for each branch\n    for i, fname_csv in enumerate(fnames_csv):\n        print(time.strftime(\"%Y-%m-%d %H:%M:%S\") + \" : \" + '{:5d}'.format(i+1) + \" / \" + str(len(fnames_csv)) + \" : \" + fname_csv.replace(FPATH_CSV + \"DELTA\" + \"\\\\\",\"\"))\n        with open(fname_csv,\"r\") as f:\n            header = f.readline() # Skip header\n            for line in f:\n     "
  },
  {
    "id": "chunk_1894",
    "text": "e() # Skip header\n            for line in f:\n                s = line.split(\",\")\n                # Key is the branch name\n                # !! This feature will break if branch names are not unique\n                # Value is the file pointer\n                key = \",\".join([s[c] for c in [1,2,4,5,7]])\n                # File does not exist\n                if key not in d:\n                    # print(\"+ \" + key)\n                    fname_dest = FPATH_CSV + \"DELTA\" + \"\\\\\" + key.replace(\",\",\"#\").repl"
  },
  {
    "id": "chunk_1895",
    "text": "H_CSV + \"DELTA\" + \"\\\\\" + key.replace(\",\",\"#\").replace(\" \",\"\") + \".csv\"\n                    d[key] = open(fname_dest,\"w\")\n                    d[key].write(header)\n                d[key].write(line)\n    # Housekeeping\n    for key, value in d.items():\n        d[key].close()\n    # Delete the old files\n    for fname_csv in fnames_csv:\n        os.remove(fname_csv)\n    # os.remove(FPATH_CSV + \"DELTA\" + \"\\\\\" + \"10076#CATCLAW1_5#10077#CATCLAW2_5#BT.csv\")\n    # os.remove(FPATH_CSV + \"DELTA\" + \"\\\\\" + \"1007"
  },
  {
    "id": "chunk_1896",
    "text": "    # os.remove(FPATH_CSV + \"DELTA\" + \"\\\\\" + \"10076#CATCLAW2_5#10077#CATCLAW1_5#BT.csv\")\n    # Process the new files\n    fnames_csv = [FPATH_CSV + \"DELTA\" + \"\\\\\" + os.path.basename(x) for x in glob(FPATH_CSV + \"DELTA\" + \"\\\\\" + \"*.csv\")]\n    p = multiprocessing.Pool(4)\n    p.map(functools.partial(m_delta_pack),iterable=fnames_csv)\n    p.map(functools.partial(m_delta_slim,threshold=FS_REPORT[4][2],dv=1.5),iterable=fnames_csv)\n    p.close()\n\n\n# Pack .csv delta report with N-0 and N-1 loadings\ndef m"
  },
  {
    "id": "chunk_1897",
    "text": " .csv delta report with N-0 and N-1 loadings\ndef m_delta_pack(fname_csv):\n    # Read file\n    with open(fname_csv,\"r\") as f:\n        lines = f.readlines()\n    # Key index\n    cols = [0]\n    # Contingency 1 index\n    c1 = 8\n    # Contingency 2 index\n    c2 = 9\n    # Flow index\n    v = 10\n    # Pack and write\n    with open(fname_csv,\"w\") as g:\n        # Header\n        line = lines.pop(0)\n        s = line.replace(\"\\n\",\"\").split(\",\")\n        s.insert(v,\"FLOW_N1B\")\n        s.insert(v,\"FLOW_N1A\")\n    "
  },
  {
    "id": "chunk_1898",
    "text": "(v,\"FLOW_N1B\")\n        s.insert(v,\"FLOW_N1A\")\n        s.insert(v,\"FLOW_N0\")\n        s.insert(c1,\"GROUP\")\n        g.write(\",\".join(s) + \"\\n\")\n        # Convert lines to set\n        lines = set(lines)\n        # Initialize contingency dictionary\n        d = {}\n        # N-0\n        for line in lines:\n            if contingency_count(line, c1, c2) == 0:\n                s = line.replace(\"\\n\",\"\").split(\",\")\n                # Add all N-0 key-value pairs\n                key = s[0] + \",\"\n                "
  },
  {
    "id": "chunk_1899",
    "text": "\n                key = s[0] + \",\"\n                if key not in d:\n                    d[key] = s[v]\n                # Write line\n                s.insert(v,\"\")\n                s.insert(v,\"\")\n                s.insert(v,\"\")\n                s.insert(c1,\"N-0\")\n                g.write(\",\".join(s) + \"\\n\")\n        # N-1\n        for line in lines:\n            if contingency_count(line, c1, c2) == 1:\n                s = line.replace(\"\\n\",\"\").split(\",\")\n                # Add all N-1 key-value pairs\n     "
  },
  {
    "id": "chunk_1900",
    "text": "               # Add all N-1 key-value pairs\n                key = s[0] + \",\" + s[c1]\n                if key not in d:\n                    d[key] = s[v]\n                # Write line\n                s.insert(v,\"\")\n                s.insert(v,\"\")\n                s.insert(v,d[s[0]+\",\"])\n                s.insert(c1,\"N-1\")\n                g.write(\",\".join(s) + \"\\n\")\n        # N-2\n        for line in lines:\n            if contingency_count(line, c1, c2) == 2:\n                s = line.replace(\"\\n\",\"\").s"
  },
  {
    "id": "chunk_1901",
    "text": " == 2:\n                s = line.replace(\"\\n\",\"\").split(\",\")\n                # Ensure that contingencies are in alphabetical order\n                if s[c1] > s[c2]:\n                    s[c1], s[c2] = s[c2], s[c1]\n                # Special code for ERCOT 2 and ERCOT 3 contingencies\n                if s[c1][0:2] == \"E2\" or s[c1][0:2] == \"E3\":\n                    s[c1], s[c2] = s[c2], s[c1]\n                # Write line\n                s.insert(v,d[s[0]+\",\"+s[c2]])\n                s.insert(v,d[s[0]+\""
  },
  {
    "id": "chunk_1902",
    "text": "0]+\",\"+s[c2]])\n                s.insert(v,d[s[0]+\",\"+s[c1]])\n                s.insert(v,d[s[0]+\",\"])\n                s.insert(c1,\"N-2\")\n                g.write(\",\".join(s) + \"\\n\")\n\n\n# Slim .csv delta report\ndef m_delta_slim(fname_csv,threshold=0.05,dv=1.5):\n    # Read file\n    with open(fname_csv,\"r\") as f:\n        lines = f.readlines()\n    # Slim and write\n    with open(fname_csv,\"w\") as g:\n        # Header\n        g.write(lines.pop(0).replace(\"\\n\",\",SCORE\\n\"))\n        # Key index\n        cols "
  },
  {
    "id": "chunk_1903",
    "text": "\\n\",\",SCORE\\n\"))\n        # Key index\n        cols = [9,10] # [0,9,10] for TSIP or single-case processing because s[0] is the case name\n        # Build dictionary & count the number of cases\n        d = {}\n        cases = set()\n        for line in lines:\n            s = line.replace(\"\\n\",\"\").split(\",\")\n            key = \",\".join([s[i] for i in cols])\n            # Create empty key-value pair if it does not exist\n            if key not in d:\n                d[key] = set()\n            # Key is Firs"
  },
  {
    "id": "chunk_1904",
    "text": "          d[key] = set()\n            # Key is First Contingency + Second Contingency\n            # Value is a set with all the lines with that First Contingency + Second Contingency\n            d[key].add(line.replace(\"\\n\",\"\"))\n            # Unique case names only\n            cases.add(s[0])\n        # Test 1 : At least one entry must be non-equal to the N-0 or N-1 violation\n        rkeys = set(d.keys())\n        for key, value in d.items():\n            for line in value:\n                s = line."
  },
  {
    "id": "chunk_1905",
    "text": "      for line in value:\n                s = line.split(\",\")\n                # N-0\n                if s[8] == \"N-0\":\n                    rkeys.remove(key)\n                    break\n                # N-1 and N-2\n                else:\n                    # N-1\n                    if s[8] == \"N-1\":\n                        v0 = float(s[11])\n                    # N-2\n                    else:\n                        v0 = max([float(v) for v in s[11:14]])\n                    # Any element with a zero "
  },
  {
    "id": "chunk_1906",
    "text": "]])\n                    # Any element with a zero rating is ignored\n                    if float(s[15]) <= 0:\n                        break\n                    # Test 1\n                    v0 = v0 / float(s[15])\n                    v = float(s[14]) / float(s[15])\n                    if v > (v0 + threshold) or v < 0:\n                        rkeys.remove(key)\n                        break\n        # Delete values that did not pass Test 1\n        for rkey in rkeys:\n            d.pop(rkey)\n        # "
  },
  {
    "id": "chunk_1907",
    "text": " rkey in rkeys:\n            d.pop(rkey)\n        # Test 2 : Maximum & minimum overloads to include overloads and large changes in flow\n        score = {}\n        for key, value in d.items():\n            score[key] = False\n            if len(value) == 0:\n                continue\n            # Need to copy because assign (\"=\") does not make a copy of the object\n            c = cases.copy()\n            v = set()\n            for line in value:\n                s = line.split(\",\")\n                # N-0"
  },
  {
    "id": "chunk_1908",
    "text": "         s = line.split(\",\")\n                # N-0\n                if s[8] == \"N-0\":\n                    break\n                # N-1 and N-2\n                else:\n                    # Set of cases not in value\n                    if s[0] in c:\n                        c.remove(s[0])\n                    # Array of values\n                    v.add(float(s[14])/float(s[15]))\n            # N-0\n            if len(v) == 0:\n                score[key] = \"A\"\n            # One case\n            elif len(v)"
  },
  {
    "id": "chunk_1909",
    "text": "\"A\"\n            # One case\n            elif len(v) == 1:\n                score[key] = \"B\"\n            # Negative (non-converged)\n            elif min(v) < 0:\n                score[key] = \"C\"\n            # Score = Max Flow + dv * (Max Flow - Min Flow)\n            else:\n                f = max(v) + dv*(max(v)-min(v))\n                if f > 0.99:\n                    score[key] = \"F99\"\n                elif f > 0.9:\n                    score[key] = \"F90\"\n                elif f > 0.8:\n                "
  },
  {
    "id": "chunk_1910",
    "text": "90\"\n                elif f > 0.8:\n                    score[key] = \"F80\"\n                elif f > 0.7:\n                    score[key] = \"F70\"\n                elif f > 0.6:\n                    score[key] = \"F60\"\n                elif f > 0.5:\n                    score[key] = \"F50\"\n                else:\n                    score[key] = \"F00\"\n                # Missing cases gets a different designator\n                if len(c) > 0:\n                    score[key] = score[key].replace(\"F\",\"D\")\n       "
  },
  {
    "id": "chunk_1911",
    "text": "  score[key] = score[key].replace(\"F\",\"D\")\n        # Write each key-value to the output file\n        lines = []\n        for key, value in d.items():\n            if len(value) > 0:\n                for line in value:\n                    lines.append(line + \",\" + score[key] + \"\\n\")\n        lines.sort()\n        g.writelines(lines)\n\n\n##### Consolidate and trim .csv reports\n# (1) Get list of unique case names in FPATH_TXT folder\n# (2) For each report type and unique case name, create a single .csv rep"
  },
  {
    "id": "chunk_1912",
    "text": "ype and unique case name, create a single .csv report file in the corresponding FPATH_CSV subfolder\n# (3) For each report type, create a consolidated .csv report file in FPATH_CSV folder\ndef m_slim():\n    for report in FS_REPORT:\n        # Special behavior for the delta report\n        if report[0] == \"DELTA\":\n            fnames_csv = [FPATH_CSV + \"DELTA\" + \"\\\\\" + os.path.basename(x) for x in glob(FPATH_CSV + \"DELTA\" + \"\\\\\" + \"*.csv\")]\n            csv_combine(fnames_csv, FPATH_CSV + report[0] + \""
  },
  {
    "id": "chunk_1913",
    "text": " csv_combine(fnames_csv, FPATH_CSV + report[0] + \".csv\")\n            continue\n        # Get unique case names\n        slugs = [os.path.basename(x) for x in glob(FPATH_CSV + report[0] + \"\\\\\" + \"*.csv\")]\n        slugs = [slug[0:slug.rfind(\"__\")] for slug in slugs]\n        slugs = list(set(slugs))\n        # Slim reports group according to their slug\n        for slug in slugs:\n            fname_dest = FPATH_CSV + report[0] + \"\\\\\" + slug + \".csv\"\n            if os.path.exists(fname_dest): os.remove(f"
  },
  {
    "id": "chunk_1914",
    "text": "        if os.path.exists(fname_dest): os.remove(fname_dest)\n            fnames_csv = [os.path.basename(x) for x in glob(FPATH_CSV + report[0] + \"\\\\\" + slug + \"__*.csv\")]\n            fnames_csv = [FPATH_CSV + report[0] + \"\\\\\" + s for s in fnames_csv]\n            if report[2] == 0:\n                csv_combine(fnames_csv, fname_dest)\n            else:\n                csv_slim(fnames_csv, fname_dest, report[1], report[2])\n            # Remove lines from the convergence report containing certain tex"
  },
  {
    "id": "chunk_1915",
    "text": "from the convergence report containing certain text\n            if report[1] == 4:\n                txt_slim(fname_dest, \"Met convergence to\")\n                # txt_slim(fname_dest, \"Iteration limit ex\")\n        # Consolidate all reports into a single .csv report file\n        fnames_csv = [FPATH_CSV + report[0] + \"\\\\\" + slug + \".csv\" for slug in slugs]\n        csv_combine(fnames_csv, FPATH_CSV + report[0] + \".csv\")\n        # Nuke slugs\n        for fname_csv in fnames_csv:\n            os.remove(fn"
  },
  {
    "id": "chunk_1916",
    "text": " fname_csv in fnames_csv:\n            os.remove(fname_csv)\n        \n\n# Combine and slim .csv thermal reports\ndef csv_slim(fnames_csv, fname_dest, mode, threshold):\n    # Thermal report indexes\n    if mode == 1:\n        # Key index\n        cols = [0,1,2,3,4,5,6,7,8,9]\n        # Contingency 1 index\n        c1 = 10\n        # Contingency 2 index\n        c2 = 11\n        # Thermal index\n        v = [15]\n    # Voltage report indexes\n    elif mode == 2:\n        # Voltage index\n        cols = [0,2,5,6,7,"
  },
  {
    "id": "chunk_1917",
    "text": "        # Voltage index\n        cols = [0,2,5,6,7,9,10,11]\n        # Contingency 1 index\n        c1 = 3\n        # Contingency 2 index\n        c2 = 4\n        # Voltage value index\n        v = [8]\n    # Capacity report indexes\n    elif mode == 6:\n        # Key index\n        cols = [0,1,2,3,4,5,6,7]\n        # Contingency 1 index\n        c1 = 8\n        # Contingency 2 index\n        c2 = 9\n        # Flow and rating index\n        v = [10,11]\n    # Capacity report proxy indexes\n    # elif mode == 6.1:\n"
  },
  {
    "id": "chunk_1918",
    "text": "city report proxy indexes\n    # elif mode == 6.1:\n    #   # Key index\n    #   cols = [0,1,2,3,4,5,6,7]\n    #   # Contingency 1 index\n    #   c1 = 15\n    #   # Contingency 2 index\n    #   c2 = 16\n    #   # Flow and rating index\n    #   v = [10,11]\n    else:\n        # Combine reports and quit\n        csv_combine(fnames_csv, fname_dest)\n        return\n    # Open destination file\n    g = open(fname_dest,\"w\")\n    # No files to open\n    if len(fnames_csv) == 0:\n        g.close()\n        return\n    # W"
  },
  {
    "id": "chunk_1919",
    "text": "sv) == 0:\n        g.close()\n        return\n    # Write header from first .csv file\n    with open(fnames_csv[0],\"r\") as f:\n        g.write(f.readline())\n    # Initialize contingency dictionary\n    d = {}\n    # N-0\n    for fname_csv in fnames_csv:\n        print(time.strftime(\"%Y-%m-%d %H:%M:%S\") + \" : N-0 : \" + fname_csv)\n        with open(fname_csv,\"r\") as f:\n            for line in f:\n                if contingency_count(line, c1, c2) == 0:\n                    s = line.replace(\"\\n\",\"\").split(\",\""
  },
  {
    "id": "chunk_1920",
    "text": "               s = line.replace(\"\\n\",\"\").split(\",\")\n                    k = \",\".join([s[i] for i in cols])\n                    # Add all N-0 key-value pairs\n                    key = k + \",,\"\n                    if key not in d:\n                        d[key] = line.replace(\"\\n\",\"\")\n    # N-1\n    for fname_csv in fnames_csv:\n        print(time.strftime(\"%Y-%m-%d %H:%M:%S\") + \" : N-1 : \" + fname_csv)\n        with open(fname_csv,\"r\") as f:\n            for line in f:\n                if contingency_"
  },
  {
    "id": "chunk_1921",
    "text": "    for line in f:\n                if contingency_count(line, c1, c2) == 1:\n                    s = line.replace(\"\\n\",\"\").split(\",\")\n                    k = \",\".join([s[i] for i in cols])\n                    # Keys to look for\n                    keys = []\n                    keys = keys + [k + \",,\"]\n                    keys = keys + [k + \",\" + s[c1] + \",\"]\n                    # Flags set to False mean an equivalent contingency violation already exists\n                    flags = [True for key i"
  },
  {
    "id": "chunk_1922",
    "text": "exists\n                    flags = [True for key in keys]\n                    # Do not add key-value pair if existing value is equal\n                    for i, key in enumerate(keys):\n                        if key in d and all(flags):\n                            if element_equal(d[key], line, v, mode, threshold):\n                                flags[i] = False\n                    if all(flags):\n                        d[keys[1]] = line.replace(\"\\n\",\"\")\n    # N-2\n    for fname_csv in fnames_csv"
  },
  {
    "id": "chunk_1923",
    "text": "\"\\n\",\"\")\n    # N-2\n    for fname_csv in fnames_csv:\n        print(time.strftime(\"%Y-%m-%d %H:%M:%S\") + \" : N-2 : \" + fname_csv)\n        with open(fname_csv,\"r\") as f:\n            f.readline() # Skip header\n            for line in f:\n                if contingency_count(line, c1, c2) == 2:\n                    s = line.replace(\"\\n\",\"\").split(\",\")\n                    k = \",\".join([s[i] for i in cols])\n                    # Keys to look for\n                    keys = []\n                    keys = ke"
  },
  {
    "id": "chunk_1924",
    "text": "           keys = []\n                    keys = keys + [k + \",,\"]\n                    keys = keys + [k + \",\" + s[c1] + \",\"]\n                    keys = keys + [k + \",\" + s[c2] + \",\"]\n                    keys = keys + [k + \",\" + s[c1] + \",\" + s[c2]]\n                    keys = keys + [k + \",\" + s[c2] + \",\" + s[c1]]\n                    # Flags set to False mean an equivalent contingency violation already exists\n                    flags = [True for key in keys]\n                    # Do not add key-v"
  },
  {
    "id": "chunk_1925",
    "text": "ey in keys]\n                    # Do not add key-value pair if existing value is equal\n                    for i, key in enumerate(keys):\n                        if key in d and all(flags):\n                            if element_equal(d[key], line, v, mode, threshold):\n                                flags[i] = False\n                    if all(flags):\n                        d[keys[3]] = line.replace(\"\\n\",\"\")\n    # Write output\n    lines = []\n    for key, value in d.items():\n        lines.append"
  },
  {
    "id": "chunk_1926",
    "text": " for key, value in d.items():\n        lines.append(value + \"\\n\")\n    lines.sort()\n    g.writelines(lines)\n    # Housekeeping\n    g.close()\n\n# Count the number of contingencies in a comma-separated report string (line)\ndef contingency_count(line, c1, c2):\n    s = line.split(\",\")\n    # Out-of-range\n    if c1 >= len(s) or c2 >= len(s) or c1 < 0 or c2 < 0:\n        return -1\n    # N-0\n    elif s[c1] == \"\" and s[c2] == \"\":\n        return 0\n    # N-1\n    elif s[c2] == \"\":\n        return 1\n    # N-2\n   "
  },
  {
    "id": "chunk_1927",
    "text": "  elif s[c2] == \"\":\n        return 1\n    # N-2\n    else:\n        return 2\n\n# Boolean T/F if value of Element 2 < Element 1 + Threshold\ndef element_equal(line1, line2, v, mode, threshold):\n    # DEBUG\n    if \"7170,L_BERGHE8_1Y,138.00,70170,P_BERGHE8_1_,138.00,1\" in line1:\n        return True\n    elif \"7170,L_BERGHE8_1Y,138.00,70170,P_BERGHE8_1_,138.00,1\" in line2:\n        return True\n    # DEBUG\n    s1 = line1.split(\",\")\n    s2 = line2.split(\",\")\n    # Numeric values for each line\n    if mode == "
  },
  {
    "id": "chunk_1928",
    "text": "    # Numeric values for each line\n    if mode == 1 or mode == 2:\n        v1 = float(s1[v[0]])\n        v2 = float(s2[v[0]])\n    elif int(mode) == 6:\n        v1 = float(s1[v[0]]) / float(s1[v[1]])\n        v2 = float(s2[v[0]]) / float(s2[v[1]])\n    # Thermal threshold (overloads) is in decimal percent\n    if mode == 1:\n        return (v2 < (1+threshold)*v1)\n    # Thermal threshold (capacity) is in decimal percent\n    elif int(mode) == 6:\n        return (v2 < (v1+threshold))\n    # Voltage threshold"
  },
  {
    "id": "chunk_1929",
    "text": "turn (v2 < (v1+threshold))\n    # Voltage threshold is in pu\n    elif mode == 2:\n        if v2 > 1:\n            # High voltage            \n            return (v2 < v1 + threshold)\n        else:\n            # Low voltage\n            return (v2 > v1 - threshold)\n    else:\n        return False\n\n# Delete lines containing a string from file\ndef txt_slim(fname, s):\n    fname_ext = fname[fname.rfind(\".\"):]\n    fname_temp = fname.replace(fname_ext, \"_TEMP\" + fname_ext)\n    f = open(fname,\"r\")\n    g = ope"
  },
  {
    "id": "chunk_1930",
    "text": "\" + fname_ext)\n    f = open(fname,\"r\")\n    g = open(fname_temp,\"w\")\n    for line in f:\n        if s not in line:\n            g.write(line)\n    f.close()\n    g.close()\n    # Overwrite old file with new file\n    shutil.move(fname_temp, fname)\n\n# Find and replace text\ndef txt_replace(fname, s):\n    fname_ext = fname[fname.rfind(\".\"):]\n    fname_temp = fname.replace(fname_ext, \"_TEMP\" + fname_ext)\n    f = open(fname,\"r\")\n    g = open(fname_temp,\"w\")\n    for line in f:\n        g.write(line.replace(s,"
  },
  {
    "id": "chunk_1931",
    "text": "    for line in f:\n        g.write(line.replace(s,\"\"))\n    f.close()\n    g.close()\n    # Overwrite old file with new file\n    shutil.move(fname_temp, fname)\n\n\n##### Add bus and branch information to .csv reports\n# (1) Match THERMAL.csv file in FPATH_CSV with LINES.csv file in FPATH_RCSV\n# (2) Match VOLTAGE.csv file in FPATH_CSV with BUS.csv file in FPATH RCSV\ndef m_match():\n    # Thermal\n    fname_csv = FPATH_CSV + \"THERMAL.csv\"\n    fname_dest = FPATH_CSV + \"THERMAL_MATCH.csv\"\n    if os.path.exi"
  },
  {
    "id": "chunk_1932",
    "text": "FPATH_CSV + \"THERMAL_MATCH.csv\"\n    if os.path.exists(fname_csv):\n        # Match thermal and line information\n        fname_dict = FPATH_RCSV + \"LINES_MIRROR.csv\"\n        match_and_add(fname_csv, [0,1,5,9], fname_dict, [0,3,4,5], fname_dest)\n        ## # Match thermal and owner information\n        ## fname_dict = FPATH_RCSV + \"OWNER.csv\"\n        ## match_and_add(fname_dest, [0,38], fname_dict, [0,1], fname_dest)\n        ## match_and_add(fname_dest, [0,40], fname_dict, [0,1], fname_dest)\n       "
  },
  {
    "id": "chunk_1933",
    "text": "st, [0,40], fname_dict, [0,1], fname_dest)\n        ## match_and_add(fname_dest, [0,42], fname_dict, [0,1], fname_dest)\n        ## match_and_add(fname_dest, [0,44], fname_dict, [0,1], fname_dest)\n        # Match thermal and contingency information\n        fname_dict = FPATH_CON + \"DICT_ALL.csv\"\n        match_and_add(fname_dest, [10], fname_dict, [0], fname_dest)\n        match_and_add(fname_dest, [11], fname_dict, [0], fname_dest)\n\n    # Voltage\n    fname_csv = FPATH_CSV + \"VOLTAGE.csv\"\n    fname_"
  },
  {
    "id": "chunk_1934",
    "text": "  fname_csv = FPATH_CSV + \"VOLTAGE.csv\"\n    fname_dest = FPATH_CSV + \"VOLTAGE_MATCH.csv\"\n    if os.path.exists(fname_csv):\n        # Match voltage and bus information\n        fname_dict = FPATH_RCSV + \"BUS.csv\"\n        match_and_add(fname_csv, [0,5], fname_dict, [0,1], fname_dest)\n        # Match voltage and area information\n        fname_dict = FPATH_RCSV + \"AREA.csv\"\n        match_and_add(fname_dest, [0,17], fname_dict, [0,1], fname_dest)\n        # Match voltage and zone information\n        fn"
  },
  {
    "id": "chunk_1935",
    "text": "   # Match voltage and zone information\n        fname_dict = FPATH_RCSV + \"ZONE.csv\"\n        match_and_add(fname_dest, [0,18], fname_dict, [0,1], fname_dest)\n        # Match voltage and owner information\n        fname_dict = FPATH_RCSV + \"OWNER.csv\"\n        match_and_add(fname_dest, [0,19], fname_dict, [0,1], fname_dest)\n        # Match voltage and contingency information\n        fname_dict = FPATH_CON + \"DICT_ALL.csv\"\n        match_and_add(fname_dest, [3], fname_dict, [0], fname_dest)\n        m"
  },
  {
    "id": "chunk_1936",
    "text": "_dest, [3], fname_dict, [0], fname_dest)\n        match_and_add(fname_dest, [4], fname_dict, [0], fname_dest)\n\n    # Convergence\n    fname_csv = FPATH_CSV + \"CONVERGENCE.csv\"\n    fname_dest = FPATH_CSV + \"CONVERGENCE_MATCH.csv\"\n    if os.path.exists(fname_csv):\n        # Match convergence and contingency information\n        fname_dict = FPATH_CON + \"DICT_ALL.csv\"\n        match_and_add(fname_csv, [1], fname_dict, [0], fname_dest)\n        match_and_add(fname_dest, [2], fname_dict, [0], fname_dest)\n"
  },
  {
    "id": "chunk_1937",
    "text": "add(fname_dest, [2], fname_dict, [0], fname_dest)\n\n    # Capacity Proxy\n    fname_csv = FPATH_CSV + \"CAPACITY.csv\"\n    if os.path.exists(fname_csv):\n        # Proxy Capacity Report\n        if os.stat(fname_csv).st_size > 1000000:\n            # Add proxy contingency types\n            fname_dest = FPATH_CSV + \"CAPACITY_PROXY.csv\"\n            capacity_proxy(fname_csv, fname_dest)\n            # Match capacity and line information\n            fname_csv = fname_dest\n        # Match capacity and line i"
  },
  {
    "id": "chunk_1938",
    "text": "v = fname_dest\n        # Match capacity and line information\n        fname_dest = FPATH_CSV + \"CAPACITY_MATCH.csv\"\n        fname_dict = FPATH_RCSV + \"LINES_MIRROR.csv\"\n        match_and_add(fname_csv, [0,1,4,7], fname_dict, [0,3,4,5], fname_dest)\n        ## # Match thermal and owner information\n        ## fname_dict = FPATH_RCSV + \"OWNER.csv\"\n        ## match_and_add(fname_dest, [0,35], fname_dict, [0,1], fname_dest)\n        ## match_and_add(fname_dest, [0,37], fname_dict, [0,1], fname_dest)\n   "
  },
  {
    "id": "chunk_1939",
    "text": "e_dest, [0,37], fname_dict, [0,1], fname_dest)\n        ## match_and_add(fname_dest, [0,39], fname_dict, [0,1], fname_dest)\n        ## match_and_add(fname_dest, [0,41], fname_dict, [0,1], fname_dest)\n        # Match thermal and contingency information\n        fname_dict = FPATH_CON + \"DICT_ALL.csv\"\n        match_and_add(fname_dest, [8], fname_dict, [0], fname_dest)\n        match_and_add(fname_dest, [9], fname_dict, [0], fname_dest)\n\n    # Delta\n    fname_csv = FPATH_CSV + \"DELTA.csv\"\n    fname_de"
  },
  {
    "id": "chunk_1940",
    "text": "  fname_csv = FPATH_CSV + \"DELTA.csv\"\n    fname_dest = FPATH_CSV + \"DELTA_MATCH.csv\"\n    if os.path.exists(fname_csv):\n        # Match thermal and line information\n        fname_dict = FPATH_RCSV + \"LINES_MIRROR.csv\"\n        match_and_add(fname_csv, [0,1,4,7], fname_dict, [0,3,4,5], fname_dest)\n        ## # Match thermal and owner information\n        ## fname_dict = FPATH_RCSV + \"OWNER.csv\"\n        ## match_and_add(fname_dest, [0,40], fname_dict, [0,1], fname_dest)\n        ## match_and_add(fname"
  },
  {
    "id": "chunk_1941",
    "text": " [0,1], fname_dest)\n        ## match_and_add(fname_dest, [0,42], fname_dict, [0,1], fname_dest)\n        ## match_and_add(fname_dest, [0,44], fname_dict, [0,1], fname_dest)\n        ## match_and_add(fname_dest, [0,46], fname_dict, [0,1], fname_dest)\n        # Match thermal and contingency information\n        fname_dict = FPATH_CON + \"DICT_ALL.csv\"\n        match_and_add(fname_dest, [9], fname_dict, [0], fname_dest)\n        match_and_add(fname_dest, [10], fname_dict, [0], fname_dest)\n\n# Add case inf"
  },
  {
    "id": "chunk_1942",
    "text": "[10], fname_dict, [0], fname_dest)\n\n# Add case information to report files\ndef match_and_add(fname_csv, k1, fname_dict, k2, fname_dest):\n    # Read report file\n    with open(fname_csv,\"r\") as f:\n        lines = [line.replace(\"\\n\",\"\") for line in f.readlines()]\n    # Create dictionary\n    d = build_dict(fname_dict, k2)\n    # Open output file\n    g = open(fname_dest,\"w\")\n    # Write header\n    g.write(lines.pop(0) + \",\" + d.get(0) + \"\\n\")\n    # Search dictionary\n    for line in lines:\n        s = "
  },
  {
    "id": "chunk_1943",
    "text": "rch dictionary\n    for line in lines:\n        s = line.split(\",\")\n        k = \",\".join([s[c] for c in k1])\n        r = d.get(k)\n        # Search for key without spaces\n        # Special consideration for 3-winding transformers\n        if r is None: r = d.get(k.replace(\" \",\"\").replace(\"3WNDTR\",\"3WNDTR \"))\n        # Special consideration for bus number sections (e.g., \"7150- 12\")\n        if r is None: r = d.get(k[:k.rfind(\"-\")])\n        # Blank if key is not found\n        if r is None: r = \",\".joi"
  },
  {
    "id": "chunk_1944",
    "text": "key is not found\n        if r is None: r = \",\".join([\"-\" for dummy in d.get(0).split(\",\")])\n        g.write(line + \",\" + r + \"\\n\")\n    g.close()\n\n# Build dictionary with key-value pairs defined by input columns\ndef build_dict(fname_csv, col):\n    # Open input file and strip newline characters\n    with open(fname_csv,\"r\") as f:\n        lines = [line.replace(\"\\n\",\"\") for line in f.readlines()]\n    # Empty dictionary\n    lines_dict = {}\n    # Header\n    lines_dict[0] = lines.pop(0)\n    # Construct "
  },
  {
    "id": "chunk_1945",
    "text": "\n    lines_dict[0] = lines.pop(0)\n    # Construct dictionary\n    for line in lines:\n        key = line.split(\",\")\n        key = [key[c] for c in col]\n        key = \",\".join(key)\n        lines_dict[key] = line\n    # Return\n    return lines_dict\n\n# Define contingency classes for capacity reports\ndef capacity_proxy(fname_csv, fname_dest):\n    f = open(fname_csv,\"r\")\n    g = open(fname_dest,\"w\")\n    # Header\n    g.write(f.readline())\n    # Dictionary\n    d = {}\n    cols = [0,1,2,3,4,5,6,7]\n    for l"
  },
  {
    "id": "chunk_1946",
    "text": "\n    d = {}\n    cols = [0,1,2,3,4,5,6,7]\n    for line in f:\n        s = line.replace(\"\\n\",\"\").split(\",\")\n        # Special consideration for bus number sections (e.g., \"7150- 12\")\n        if \"-\" in s[1]: s[1] = s[1][:s[1].rfind(\"-\")]\n        if \"-\" in s[4]: s[4] = s[4][:s[4].rfind(\"-\")]\n        key = \",\".join([s[i] for i in cols])\n        # Add that branch to the dictionary\n        if key not in d:\n            d[key] = []\n            print(time.strftime(\"%Y-%m-%d %H:%M:%S\") + \" : Capacity Report"
  },
  {
    "id": "chunk_1947",
    "text": "trftime(\"%Y-%m-%d %H:%M:%S\") + \" : Capacity Report : Added \" + key)\n        d[key].append(\",\".join(s) + \"\\n\")\n    # Housekeeping\n    f.close()\n    # Sort each value in the dictionary by flow\n    for key, value in d.items():\n        # Sort the value list in descending order\n        v = 10\n        v = [float(line.replace(\"\\n\",\"\").split(\",\")[v]) for line in value]\n        d[key] = [m for _ , m in sorted(zip(v,value),reverse=True)]\n    # Only include a specified number of each contingency type\n    f"
  },
  {
    "id": "chunk_1948",
    "text": " a specified number of each contingency type\n    for key, value in d.items():\n        # Create a new dictionary\n        # - Key is the contingency type\n        # - Value is the count & the maximum count\n        a = {}\n        a[\"BASE\"]   = [0,9999999999]\n        a[\"SINGLE\"] = [0,9999999999]\n        a[\"ERCOT3\"] = [0,20]\n        a[\"P3\"]     = [0,10]\n        a[\"P6\"]     = [0,5]\n        for line in value:\n            k = capacity_proxy_helper(line, 8, 9)\n            a[k][0] = a[k][0] + 1\n           "
  },
  {
    "id": "chunk_1949",
    "text": ", 9)\n            a[k][0] = a[k][0] + 1\n            if a[k][0] <= a[k][1]:\n                g.write(line)\n        # Reporting\n        print(time.strftime(\"%Y-%m-%d %H:%M:%S\") + \" : Capacity Report : Processed \" + key)\n    # Housekeeping\n    g.close()\n\n# Helper function\ndef capacity_proxy_helper(line, c1, c2):\n    # N-0\n    if contingency_count(line, c1, c2) == 0: return \"BASE\"\n    # N-1\n    if contingency_count(line, c1, c2) == 1: return \"SINGLE\"\n    # N-2\n    s = line.replace(\"\\n\",\"\").split(\",\")\n"
  },
  {
    "id": "chunk_1950",
    "text": "   # N-2\n    s = line.replace(\"\\n\",\"\").split(\",\")\n    s1 = s[c1]\n    s2 = s[c2]\n    p3set = {\n        \"P3_BAT_10908\",\"P3_BAT_11158\",\"P3_BAT_11163\",\"P3_BAT_11287\",\"P3_BAT_11359\",\"P3_BAT_11362\",\"P3_BAT_11387\",\"P3_BAT_11407\",\n        \"P3_BAT_13185\",\"P3_BAT_13278\",\"P3_BAT_13293\",\"P3_BAT_13294\",\"P3_BAT_13495\",\"P3_BAT_13526\",\"P3_BAT_13546\",\"P3_BAT_13548\",\n        \"P3_BAT_13549\",\"P3_BAT_13555\",\"P3_BAT_13556\",\"P3_BAT_13557\",\"P3_BAT_13558\",\"P3_BAT_13559\",\"P3_BAT_13560\",\"P3_BAT_13578\",\n        \"P3_BAT_136"
  },
  {
    "id": "chunk_1951",
    "text": "\"P3_BAT_13560\",\"P3_BAT_13578\",\n        \"P3_BAT_13615\",\"P3_BAT_13621\",\"P3_BAT_13622\",\"P3_BAT_13628\",\"P3_BAT_13633\",\"P3_BAT_13639\",\"P3_BAT_13640\",\"P3_BAT_13643\",\n        \"P3_BAT_15175\",\"P3_BAT_15213\",\"P3_BAT_15313\",\"P3_BAT_15319\",\"P3_BAT_15329\",\"P3_BAT_15338\",\"P3_BAT_15449\",\"P3_BAT_16098\",\n        \"P3_BAT_16296\",\"P3_BAT_16337\",\"P3_BAT_16338\",\"P3_BAT_16339\",\"P3_BAT_16340\",\"P3_BAT_16374\",\"P3_BAT_16380\",\"P3_BAT_16386\",\n        \"P3_BAT_16387\",\"P3_BAT_16404\",\"P3_BAT_16405\",\"P3_BAT_16406\",\"P3_BAT_16419\""
  },
  {
    "id": "chunk_1952",
    "text": "6404\",\"P3_BAT_16405\",\"P3_BAT_16406\",\"P3_BAT_16419\",\"P3_BAT_16420\",\"P3_BAT_16423\",\"P3_BAT_16428\",\n        \"P3_BAT_16433\",\"P3_BAT_17057\",\"P3_BAT_17058\",\"P3_BAT_17065\",\"P3_BAT_17066\",\"P3_BAT_17072\",\"P3_BAT_17087\",\"P3_BAT_17088\",\n        \"P3_BAT_17089\",\"P3_BAT_17107\",\"P3_BAT_17108\",\"P3_BAT_17137\",\"P3_BAT_17138\",\"P3_BAT_18095\",\"P3_BAT_18096\",\"P3_BAT_18103\",\n        \"P3_BAT_18327\",\"P3_BAT_18340\",\"P3_BAT_18351\",\"P3_BAT_18352\",\"P3_BAT_18362\",\"P3_BAT_18367\",\"P3_BAT_18378\",\"P3_BAT_18390\",\n        \"P3_COAL"
  },
  {
    "id": "chunk_1953",
    "text": "7\",\"P3_BAT_18378\",\"P3_BAT_18390\",\n        \"P3_COAL_COLETO\",\"P3_COAL_FPP_1\",\"P3_COAL_FPP_2\",\"P3_COAL_FPP_3\",\"P3_COAL_SANMIG\",\"P3_COAL_SCES\",\n        \"P3_COAL_SPRUCE_1\",\"P3_COAL_SPRUCE_2\",\"P3_COAL_STP_1\",\"P3_COAL_STP_2\",\"P3_COAL_TNP_1\",\"P3_COAL_TNP_2\",\n        \"P3_EXDS_ADEL\",\"P3_EXDS_ALIL\",\"P3_EXDS_ANSO\",\"P3_EXDS_ARGE\",\"P3_EXDS_AVIL\",\"P3_EXDS_BIRD\",\"P3_EXDS_BRAC\",\"P3_EXDS_BRDR\",\n        \"P3_EXDS_BRIG\",\"P3_EXDS_BSAM\",\"P3_EXDS_CACT\",\"P3_EXDS_CHIL\",\"P3_EXDS_CITF\",\"P3_EXDS_CSTA\",\"P3_EXDS_CUCH\",\"P3_EXD"
  },
  {
    "id": "chunk_1954",
    "text": "3_EXDS_CITF\",\"P3_EXDS_CSTA\",\"P3_EXDS_CUCH\",\"P3_EXDS_DOVE\",\n        \"P3_EXDS_GBRY\",\"P3_EXDS_GHOL\",\"P3_EXDS_GOLD\",\"P3_EXDS_GRYH\",\"P3_EXDS_GSLA\",\"P3_EXDS_HERM\",\"P3_EXDS_HFWF\",\"P3_EXDS_HNYC\",\n        \"P3_EXDS_HOYT\",\"P3_EXDS_INGO\",\"P3_EXDS_IRON\",\"P3_EXDS_LARK\",\"P3_EXDS_LAVA\",\"P3_EXDS_LIME\",\"P3_EXDS_LOMA\",\"P3_EXDS_LYNX\",\n        \"P3_EXDS_MATA\",\"P3_EXDS_MONT\",\"P3_EXDS_MRAN\",\"P3_EXDS_NFLL\",\"P3_EXDS_NORI\",\"P3_EXDS_PATR\",\"P3_EXDS_PICA\",\"P3_EXDS_PINT\",\n        \"P3_EXDS_RGDW\",\"P3_EXDS_RHOL\",\"P3_EXDS_ROCI\",\""
  },
  {
    "id": "chunk_1955",
    "text": "    \"P3_EXDS_RGDW\",\"P3_EXDS_RHOL\",\"P3_EXDS_ROCI\",\"P3_EXDS_SCHS\",\"P3_EXDS_SEVN\",\"P3_EXDS_SODA\",\"P3_EXDS_STLH\",\"P3_EXDS_STLI\",\n        \"P3_EXDS_STRG\",\"P3_EXDS_THRD\",\"P3_EXDS_TSEC\",\"P3_EXDS_YAUP\",\n        \"P3_GAS_ATKINS\",\"P3_GAS_AVR\",\"P3_GAS_BARNEY\",\"P3_GAS_BARNEY_1\",\"P3_GAS_BASTEN\",\"P3_GAS_BRAUNIG_1\",\"P3_GAS_BRAUNIG_2\",\"P3_GAS_BRAUNIG_3\",\n        \"P3_GAS_BRAUNIG_6\",\"P3_GAS_CALHOUN\",\"P3_GAS_DANSBY\",\"P3_GAS_DECKER\",\"P3_GAS_DUKE\",\"P3_GAS_ECEC\",\"P3_GAS_FERGUSON\",\"P3_GAS_FLCNS\",\n        \"P3_GAS_FRONTER"
  },
  {
    "id": "chunk_1956",
    "text": "_FERGUSON\",\"P3_GAS_FLCNS\",\n        \"P3_GAS_FRONTERA\",\"P3_GAS_GIDEON_1\",\"P3_GAS_GIDEON_2\",\"P3_GAS_GIDEON_3\",\"P3_GAS_GUADALUPE_1\",\"P3_GAS_GUADALUPE_2\",\n        \"P3_GAS_HAYSEN\",\"P3_GAS_LAREDO\",\"P3_GAS_LEON\",\"P3_GAS_LOSTPINES\",\"P3_GAS_MGSES\",\"P3_GAS_NEDIN\",\"P3_GAS_NUECES\",\"P3_GAS_OECCS_1\",\n        \"P3_GAS_OECCS_2\",\"P3_GAS_PB2SES\",\"P3_GAS_PEARSAL\",\"P3_GAS_QUAIL_1\",\"P3_GAS_QUAIL_2\",\"P3_GAS_RAYBURN\",\"P3_GAS_REDGATE\",\"P3_GAS_RIONOG\",\n        \"P3_GAS_SANDHILL\",\"P3_GAS_SANDHILL_5\",\"P3_GAS_SILAS\",\"P3_GAS_S"
  },
  {
    "id": "chunk_1957",
    "text": "HILL\",\"P3_GAS_SANDHILL_5\",\"P3_GAS_SILAS\",\"P3_GAS_SKY\",\"P3_GAS_SOMMERS_1\",\"P3_GAS_SOMMERS_2\",\"P3_GAS_TAMU\",\"P3_GAS_TEMPLE_1\",\n        \"P3_GAS_TEMPLE_2\",\"P3_GAS_TIMMERMAN\",\"P3_GAS_VICTCITY\",\"P3_GAS_VICTORIA\",\"P3_GAS_VICTPORT_1\",\"P3_GAS_VICTPORT_2\",\"P3_GAS_WINCHESTER\",\n        \"P3_SOL_11158\",\"P3_SOL_11163\",\"P3_SOL_11204\",\"P3_SOL_11209\",\"P3_SOL_11214\",\"P3_SOL_11226\",\"P3_SOL_11235\",\"P3_SOL_11277\",\n        \"P3_SOL_11287\",\"P3_SOL_11305\",\"P3_SOL_11311\",\"P3_SOL_11325\",\"P3_SOL_11365\",\"P3_SOL_11387\",\"P3_SO"
  },
  {
    "id": "chunk_1958",
    "text": "P3_SOL_11325\",\"P3_SOL_11365\",\"P3_SOL_11387\",\"P3_SOL_11392\",\"P3_SOL_11414\",\n        \"P3_SOL_12026\",\"P3_SOL_12039\",\"P3_SOL_13233\",\"P3_SOL_13243\",\"P3_SOL_13248\",\"P3_SOL_13273\",\"P3_SOL_13278\",\"P3_SOL_13283\",\n        \"P3_SOL_13288\",\"P3_SOL_13294\",\"P3_SOL_13334\",\"P3_SOL_13384\",\"P3_SOL_13409\",\"P3_SOL_13414\",\"P3_SOL_13424\",\"P3_SOL_13429\",\n        \"P3_SOL_13434\",\"P3_SOL_13444\",\"P3_SOL_13459\",\"P3_SOL_13470\",\"P3_SOL_13475\",\"P3_SOL_13480\",\"P3_SOL_13490\",\"P3_SOL_13495\",\n        \"P3_SOL_13501\",\"P3_SOL_13511\","
  },
  {
    "id": "chunk_1959",
    "text": "SOL_13495\",\n        \"P3_SOL_13501\",\"P3_SOL_13511\",\"P3_SOL_13518\",\"P3_SOL_13532\",\"P3_SOL_13550\",\"P3_SOL_13598\",\"P3_SOL_13610\",\"P3_SOL_13616\",\n        \"P3_SOL_13634\",\"P3_SOL_13644\",\"P3_SOL_15170\",\"P3_SOL_15175\",\"P3_SOL_15203\",\"P3_SOL_15213\",\"P3_SOL_15319\",\"P3_SOL_15329\",\n        \"P3_SOL_15338\",\"P3_SOL_15368\",\"P3_SOL_15373\",\"P3_SOL_15428\",\"P3_SOL_15449\",\"P3_SOL_16254\",\"P3_SOL_16279\",\"P3_SOL_16284\",\n        \"P3_SOL_16286\",\"P3_SOL_16302\",\"P3_SOL_16312\",\"P3_SOL_16317\",\"P3_SOL_16322\",\"P3_SOL_16332\",\"P3"
  },
  {
    "id": "chunk_1960",
    "text": "\",\"P3_SOL_16317\",\"P3_SOL_16322\",\"P3_SOL_16332\",\"P3_SOL_16352\",\"P3_SOL_16357\",\n        \"P3_SOL_16364\",\"P3_SOL_16369\",\"P3_SOL_16388\",\"P3_SOL_16393\",\"P3_SOL_16428\",\"P3_SOL_17020\",\"P3_SOL_17034\",\"P3_SOL_17038\",\n        \"P3_SOL_17052\",\"P3_SOL_17060\",\"P3_SOL_17067\",\"P3_SOL_17077\",\"P3_SOL_17082\",\"P3_SOL_17090\",\"P3_SOL_17095\",\"P3_SOL_17102\",\n        \"P3_SOL_17111\",\"P3_SOL_17116\",\"P3_SOL_17122\",\"P3_SOL_17127\",\"P3_SOL_17132\",\"P3_SOL_18075\",\"P3_SOL_18165\",\"P3_SOL_18168\",\n        \"P3_SOL_18173\",\"P3_SOL_1821"
  },
  {
    "id": "chunk_1961",
    "text": "P3_SOL_18168\",\n        \"P3_SOL_18173\",\"P3_SOL_18215\",\"P3_SOL_18225\",\"P3_SOL_18230\",\"P3_SOL_18250\",\"P3_SOL_18260\",\"P3_SOL_18282\",\"P3_SOL_18307\",\n        \"P3_SOL_18317\",\"P3_SOL_18322\",\"P3_SOL_18335\",\"P3_SOL_18340\",\"P3_SOL_18345\",\"P3_SOL_18352\",\"P3_SOL_18357\",\"P3_SOL_18362\",\n        \"P3_SOL_18368\",\"P3_SOL_18378\",\"P3_SOL_18385\",\"P3_SOL_78570\",\n        \"P3_WAT_AUSTIN\",\"P3_WAT_BUCHANAN\",\"P3_WAT_CANYON\",\"P3_WAT_INKS\",\"P3_WAT_MARBFA\",\"P3_WAT_MARSFO\",\"P3_WAT_WIRTZ\",\n        \"P3_WND_11138\",\"P3_WND_11298\","
  },
  {
    "id": "chunk_1962",
    "text": "WAT_WIRTZ\",\n        \"P3_WND_11138\",\"P3_WND_11298\",\"P3_WND_11409\",\"P3_WND_11421\",\"P3_WND_13012\",\"P3_WND_13033\",\"P3_WND_13043\",\"P3_WND_13053\",\n        \"P3_WND_13063\",\"P3_WND_13073\",\"P3_WND_13083\",\"P3_WND_13093\",\"P3_WND_13114\",\"P3_WND_13125\",\"P3_WND_13135\",\"P3_WND_13145\",\n        \"P3_WND_13155\",\"P3_WND_13165\",\"P3_WND_13175\",\"P3_WND_13185\",\"P3_WND_13195\",\"P3_WND_13211\",\"P3_WND_13216\",\"P3_WND_13221\",\n        \"P3_WND_13238\",\"P3_WND_13263\",\"P3_WND_13268\",\"P3_WND_13299\",\"P3_WND_13304\",\"P3_WND_13344\",\"P3"
  },
  {
    "id": "chunk_1963",
    "text": "\",\"P3_WND_13299\",\"P3_WND_13304\",\"P3_WND_13344\",\"P3_WND_13349\",\"P3_WND_13364\",\n        \"P3_WND_13379\",\"P3_WND_13399\",\"P3_WND_13404\",\"P3_WND_13449\",\"P3_WND_13454\",\"P3_WND_13465\",\"P3_WND_13485\",\"P3_WND_13561\",\n        \"P3_WND_13566\",\"P3_WND_13573\",\"P3_WND_13623\",\"P3_WND_13628\",\"P3_WND_15096\",\"P3_WND_15185\",\"P3_WND_15303\",\"P3_WND_16029\",\n        \"P3_WND_16039\",\"P3_WND_16049\",\"P3_WND_16059\",\"P3_WND_16069\",\"P3_WND_16074\",\"P3_WND_16083\",\"P3_WND_16088\",\"P3_WND_16098\",\n        \"P3_WND_16105\",\"P3_WND_1611"
  },
  {
    "id": "chunk_1964",
    "text": "P3_WND_16098\",\n        \"P3_WND_16105\",\"P3_WND_16110\",\"P3_WND_16120\",\"P3_WND_16125\",\"P3_WND_16145\",\"P3_WND_16150\",\"P3_WND_16155\",\"P3_WND_16160\",\n        \"P3_WND_16165\",\"P3_WND_16170\",\"P3_WND_16175\",\"P3_WND_16185\",\"P3_WND_16195\",\"P3_WND_16200\",\"P3_WND_16205\",\"P3_WND_16210\",\n        \"P3_WND_16215\",\"P3_WND_16220\",\"P3_WND_16225\",\"P3_WND_16230\",\"P3_WND_16245\",\"P3_WND_16249\",\"P3_WND_16269\",\"P3_WND_16274\",\n        \"P3_WND_16291\",\"P3_WND_16307\",\"P3_WND_16341\",\"P3_WND_16347\",\"P3_WND_16381\",\"P3_WND_16407\","
  },
  {
    "id": "chunk_1965",
    "text": "341\",\"P3_WND_16347\",\"P3_WND_16381\",\"P3_WND_16407\",\"P3_WND_17023\",\"P3_WND_17044\",\n        \"P3_WND_18005\",\"P3_WND_18015\",\"P3_WND_18025\",\"P3_WND_18035\",\"P3_WND_18045\",\"P3_WND_18055\",\"P3_WND_18065\",\"P3_WND_18075\",\n        \"P3_WND_18095\",\"P3_WND_18096\",\"P3_WND_18098\",\"P3_WND_18101\",\"P3_WND_18103\",\"P3_WND_18105\",\"P3_WND_18115\",\"P3_WND_18125\",\n        \"P3_WND_18135\",\"P3_WND_18145\",\"P3_WND_18155\",\"P3_WND_18175\",\"P3_WND_18185\",\"P3_WND_18190\",\"P3_WND_18195\",\"P3_WND_18200\",\n        \"P3_WND_18205\",\"P3_WND_1"
  },
  {
    "id": "chunk_1966",
    "text": "\",\"P3_WND_18200\",\n        \"P3_WND_18205\",\"P3_WND_18210\",\"P3_WND_18220\",\"P3_WND_18235\",\"P3_WND_18240\",\"P3_WND_18245\",\"P3_WND_18265\",\"P3_WND_18272\",\n        \"P3_WND_18277\",\"P3_WND_18278\",\"P3_WND_18297\",\"P3_WND_18302\",\"P3_WND_18312\"}\n    e3set = {\n        \"SINGLE 10049-10050-10051(1)\",\"SINGLE 10049-10050-10052(2)\",\"SINGLE 10053-10054-10055(1)\",\"SINGLE 10053-10054-10056(2)\",\n        \"SINGLE 10062-10063-10064(1)\",\"SINGLE 10062-10063-10065(2)\",\"SINGLE 1016-1027-18530(3H)\",\"SINGLE 1018-1019-18527(1)\",\n"
  },
  {
    "id": "chunk_1967",
    "text": "1016-1027-18530(3H)\",\"SINGLE 1018-1019-18527(1)\",\n        \"SINGLE 1018-1019-24996(2)\",\"SINGLE 1021-1023-24989(1)\",\"SINGLE 1022-1023-1014(1)\",\"SINGLE 1028-1027-18528(2)\",\n        \"SINGLE 1029-1027-18529(1)\",\"SINGLE 11010-1013-11007(2)\",\"SINGLE 11010-1013-11008(1)\",\"SINGLE 11084-11083-11075(2)\",\n        \"SINGLE 11084-11083-11085(1)\",\"SINGLE 11098-11097-11099(1)\",\"SINGLE 11098-11097-11109(2)\",\"SINGLE 11188-11189-11194(1)\",\n        \"SINGLE 11188-11189-11216(2)\",\"SINGLE 1125-1124-4000(1)\",\"SINGLE 113"
  },
  {
    "id": "chunk_1968",
    "text": "9-11216(2)\",\"SINGLE 1125-1124-4000(1)\",\"SINGLE 11387-11388-11386(2)\",\"SINGLE 11387-11388-11389(1)\",\n        \"SINGLE 11406-11407-18531(1)\",\"SINGLE 1185-1183-1186(3)\",\"SINGLE 1198-1196(1)\",\"SINGLE 126-33126(1)\",\n        \"SINGLE 131-130(1)\",\"SINGLE 1330-1329(1)\",\"SINGLE 133-132(1)\",\"SINGLE 1340-1339(1)\",\n        \"SINGLE 1340-1339(2)\",\"SINGLE 13429-13441-13440(2)\",\"SINGLE 13429-13442-13439(3)\",\"SINGLE 1626-1624(1)\",\n        \"SINGLE 1626-1624(2)\",\"SINGLE 1662-1661(1)\",\"SINGLE 18540-18541-24983(1)\",\"S"
  },
  {
    "id": "chunk_1969",
    "text": "GLE 1662-1661(1)\",\"SINGLE 18540-18541-24983(1)\",\"SINGLE 18540-18541-24984(2)\",\n        \"SINGLE 18544-18545-18546(1)\",\"SINGLE 18544-18545-18547(2)\",\"SINGLE 18548-18549-18550(1)\",\"SINGLE 18548-18549-18551(2)\",\n        \"SINGLE 23852-23875(1)\",\"SINGLE 23862-23873(1)\",\"SINGLE 32855-32856(1)\",\"SINGLE 32857-32865(1)\",\n        \"SINGLE 32864-32862(1)\",\"SINGLE 32870-32882(1)\",\"SINGLE 32874-32896(1)\",\"SINGLE 32875-32897(1)\",\n        \"SINGLE 32875-32897(2)\",\"SINGLE 3363-3362-13364(1)\",\"SINGLE 3363-3362-3364"
  },
  {
    "id": "chunk_1970",
    "text": "\"SINGLE 3363-3362-13364(1)\",\"SINGLE 3363-3362-3364(1)\",\"SINGLE 3402-3410-13410(1)\",\n        \"SINGLE 3406-3407-13406(1)\",\"SINGLE 3409-3410-13402(1)\",\"SINGLE 3412-3420-13412(1)\",\"SINGLE 3412-3420-13420(1)\",\n        \"SINGLE 3414-13415-13414(1)\",\"SINGLE 3414-3415-3718(1)\",\"SINGLE 3422-3423-13423(1)\",\"SINGLE 3422-3423-13424(2)\",\n        \"SINGLE 3496-3493(1)\",\"SINGLE 3649-3658(1)\",\"SINGLE 3684-3683(1)\",\"SINGLE 3696-3666-24992(2)\",\n        \"SINGLE 3696-3666-3660(1)\",\"SINGLE 3699-3640-3745(1)\",\"SINGLE 3"
  },
  {
    "id": "chunk_1971",
    "text": "3666-3660(1)\",\"SINGLE 3699-3640-3745(1)\",\"SINGLE 3699-3640-3746(1)\",\"SINGLE 3717-3713-3715(1)\",\n        \"SINGLE 3717-3714-3716(1)\",\"SINGLE 3751-3750-3752(1)\",\"SINGLE 38150-38143-38147(1)\",\"SINGLE 38150-38143-38148(2)\",\n        \"SINGLE 38150-38143-38149(3)\",\"SINGLE 38320-38310(1)\",\"SINGLE 38420-38430(1)\",\"SINGLE 40000-40010-49005(A1)\",\n        \"SINGLE 40000-40015-49008(A3)\",\"SINGLE 40005-40020-49006(2A)\",\"SINGLE 40005-40020-49007(2B)\",\"SINGLE 40450-40460-49054(A1)\",\n        \"SINGLE 40700-40710-49"
  },
  {
    "id": "chunk_1972",
    "text": "0-40460-49054(A1)\",\n        \"SINGLE 40700-40710-49018(A1)\",\"SINGLE 40700-40716-49019(A2)\",\"SINGLE 40850-40855-49077(A1)\",\"SINGLE 40850-40855-49078(A2)\",\n        \"SINGLE 40850-40855-49079(A3)\",\"SINGLE 42530-42540-49036(A1)\",\"SINGLE 42530-42540-49037(A2)\",\"SINGLE 42530-42540-49038(A3)\",\n        \"SINGLE 44500-44510-49031(A1)\",\"SINGLE 44500-44510-49063(A3)\",\"SINGLE 44500-44510-49064(A2)\",\"SINGLE 45500-45510-49039(A1)\",\n        \"SINGLE 45500-45515-49071(A3)\",\"SINGLE 45600-45610-49061(A1)\",\"SINGLE 456"
  },
  {
    "id": "chunk_1973",
    "text": "71(A3)\",\"SINGLE 45600-45610-49061(A1)\",\"SINGLE 45600-45610-49083(A2)\",\"SINGLE 46020-46025-49060(A2)\",\n        \"SINGLE 46020-46025-49068(A1)\",\"SINGLE 5056-5053-5060(4)\",\"SINGLE 5056-5054-5059(3)\",\"SINGLE 5056-5055(2)\",\n        \"SINGLE 5056-5055-5057(1)\",\"SINGLE 5211-5208-5215(4)\",\"SINGLE 5211-5209-5214(3)\",\"SINGLE 5211-5210-5212(1)\",\n        \"SINGLE 5211-5210-5213(2)\",\"SINGLE 5231-5230(1)\",\"SINGLE 5231-5230(2)\",\"SINGLE 5231-5230(3)\",\n        \"SINGLE 5295-5294(1)\",\"SINGLE 5295-5294(2)\",\"SINGLE 537"
  },
  {
    "id": "chunk_1974",
    "text": "LE 5295-5294(1)\",\"SINGLE 5295-5294(2)\",\"SINGLE 5371-5368(1)\",\"SINGLE 5371-5368-5373(2)\",\n        \"SINGLE 5371-5369-5374(3)\",\"SINGLE 5371-5370-5375(4)\",\"SINGLE 5500-5502(1)\",\"SINGLE 5535-78104(1)\",\n        \"SINGLE 5536-78103(1)\",\"SINGLE 5544-5546(1)\",\"SINGLE 5582-5584(1)\",\"SINGLE 5709-5705-5706(1)\",\n        \"SINGLE 5715-5717(1)\",\"SINGLE 5725-5727(1)\",\"SINGLE 5729-5728(1)\",\"SINGLE 57668-57666(1)\",\n        \"SINGLE 5784-5780(1)\",\"SINGLE 5811-5813(1)\",\"SINGLE 5821-5819(1)\",\"SINGLE 5849-5851(1)\",\n    "
  },
  {
    "id": "chunk_1975",
    "text": ",\"SINGLE 5821-5819(1)\",\"SINGLE 5849-5851(1)\",\n        \"SINGLE 5871-78280(1)\",\"SINGLE 5883-5885(1)\",\"SINGLE 5901-5902-5908(2)\",\"SINGLE 5901-5902-5909(1)\",\n        \"SINGLE 60040-6216-60041(2)\",\"SINGLE 60040-6216-60043(1)\",\"SINGLE 60040-66216-60043(1)\",\"SINGLE 60359-60360(1)\",\n        \"SINGLE 60385-60384(P1)\",\"SINGLE 60404-60385(T1)\",\"SINGLE 60404-60385(T2)\",\"SINGLE 60410-6393(1)\",\n        \"SINGLE 60431-60432(1)\",\"SINGLE 60433-60412(1)\",\"SINGLE 60447-60448(1)\",\"SINGLE 61011-61010(1)\",\n        \"SING"
  },
  {
    "id": "chunk_1976",
    "text": "7-60448(1)\",\"SINGLE 61011-61010(1)\",\n        \"SINGLE 6201-6224(1)\",\"SINGLE 6225-6228(1)\",\"SINGLE 6235-6231(1)\",\"SINGLE 6235-6231(2)\",\n        \"SINGLE 6235-6232(1)\",\"SINGLE 6253-6255(1)\",\"SINGLE 6258-6260(1)\",\"SINGLE 6310-6309(1)\",\n        \"SINGLE 6353-6355(1)\",\"SINGLE 6359-6390(1)\",\"SINGLE 6363-6364(1)\",\"SINGLE 6363-6364(2)\",\n        \"SINGLE 6364-6365(1)\",\"SINGLE 6444-6442-60769(2)\",\"SINGLE 6444-6442-6295(1)\",\"SINGLE 6462-6464(1)\",\n        \"SINGLE 6468-6470(1)\",\"SINGLE 6478-6480(1)\",\"SINGLE 6550"
  },
  {
    "id": "chunk_1977",
    "text": "E 6468-6470(1)\",\"SINGLE 6478-6480(1)\",\"SINGLE 6550-6562(1)\",\"SINGLE 6556-76013(1)\",\n        \"SINGLE 6565-6564(1)\",\"SINGLE 6578-76579(1)\",\"SINGLE 6601-6598(1)\",\"SINGLE 6601-6598(2)\",\n        \"SINGLE 6613-6615(1)\",\"SINGLE 6628-6630(1)\",\"SINGLE 6636-6260(2)\",\"SINGLE 6653-6655(1)\",\n        \"SINGLE 6672-6680(1)\",\"SINGLE 6678-6680(2)\",\"SINGLE 70197-70198(1)\",\"SINGLE 7040-9328-9329(1)\",\n        \"SINGLE 7040-9328-9330(2)\",\"SINGLE 7042-7180-77180(3)\",\"SINGLE 7042-7180-7832(1)\",\"SINGLE 7042-7180-7834(2)\","
  },
  {
    "id": "chunk_1978",
    "text": "GLE 7042-7180-7832(1)\",\"SINGLE 7042-7180-7834(2)\",\n        \"SINGLE 7044-7178-77044(T3)\",\"SINGLE 7044-7178-7822(2)\",\"SINGLE 7046-7150-77154(5)\",\"SINGLE 7046-7152-77152(4)\",\n        \"SINGLE 70480-7148(1)\",\"SINGLE 70484-70493(1)\",\"SINGLE 70499-70498(1)\",\"SINGLE 7050-7680-77680(2)\",\n        \"SINGLE 7050-7680-77683(1)\",\"SINGLE 7057-7286-7853(2)\",\"SINGLE 7058-7289-77289(4)\",\"SINGLE 7058-7289-7838(3)\",\n        \"SINGLE 7074-77074(1)\",\"SINGLE 7093-7087(1)\",\"SINGLE 7119-7120(1)\",\"SINGLE 7121-7127(1)\",\n   "
  },
  {
    "id": "chunk_1979",
    "text": "\",\"SINGLE 7119-7120(1)\",\"SINGLE 7121-7127(1)\",\n        \"SINGLE 7130-7132(1)\",\"SINGLE 7191-7192(1)\",\"SINGLE 7216-7215-7217(3)\",\"SINGLE 7223-7224(1)\",\n        \"SINGLE 7248-7247(3)\",\"SINGLE 7257-7258(1)\",\"SINGLE 7269-7270(1)\",\"SINGLE 7315-7314(1)\",\n        \"SINGLE 7340-7336-77340(1)\",\"SINGLE 7340-7336-77341(2)\",\"SINGLE 7345-7346(1)\",\"SINGLE 7410-7751(1)\",\n        \"SINGLE 7415-7149(1)\",\"SINGLE 7439-7438(1)\",\"SINGLE 7439-7438(2)\",\"SINGLE 7587-7237(1)\",\n        \"SINGLE 7597-7595(1)\",\"SINGLE 76000-7659"
  },
  {
    "id": "chunk_1980",
    "text": ",\n        \"SINGLE 7597-7595(1)\",\"SINGLE 76000-76595-76998(1)\",\"SINGLE 76000-76595-76999(2)\",\"SINGLE 76009-76011-77280(2)\",\n        \"SINGLE 76009-76011-77281(1)\",\"SINGLE 7617-7621(2)\",\"SINGLE 7619-7613(1)\",\"SINGLE 7626-7245(1)\",\n        \"SINGLE 76389-7394(3)\",\"SINGLE 76389-7395(2)\",\"SINGLE 77306-7306-77308(1)\",\"SINGLE 77306-7306-77309(2)\",\n        \"SINGLE 7770-7170-7771(1)\",\"SINGLE 7770-7170-7772(2)\",\"SINGLE 78118-78106(1)\",\"SINGLE 78118-78106(2)\",\n        \"SINGLE 78190-7244(1)\",\"SINGLE 79500-796"
  },
  {
    "id": "chunk_1981",
    "text": ",\n        \"SINGLE 78190-7244(1)\",\"SINGLE 79500-79600-79598(1)\",\"SINGLE 79500-79600-79599(2)\",\"SINGLE 80119-8992(1)\",\n        \"SINGLE 80119-8992(2)\",\"SINGLE 80137-8966-80139(2)\",\"SINGLE 80137-8974-80140(3)\",\"SINGLE 80219-80221(1)\",\n        \"SINGLE 80219-80221(2)\",\"SINGLE 8044-8666(1)\",\"SINGLE 8100-8102(1)\",\"SINGLE 8119-8121(1)\",\n        \"SINGLE 8121-8123(1)\",\"SINGLE 8164-8162-8160(1)\",\"SINGLE 8164-8162-8181(2)\",\"SINGLE 8183-89450(1)\",\n        \"SINGLE 8184-8186(1)\",\"SINGLE 8231-8234(1)\",\"SINGLE 82"
  },
  {
    "id": "chunk_1982",
    "text": "GLE 8184-8186(1)\",\"SINGLE 8231-8234(1)\",\"SINGLE 8238-80081(1)\",\"SINGLE 8255-8257(2)\",\n        \"SINGLE 8280-8283(1)\",\"SINGLE 8289-8314(2)\",\"SINGLE 8310-8314(2)\",\"SINGLE 8317-8314-8328(1)\",\n        \"SINGLE 8318-8319-80148(2)\",\"SINGLE 8318-8319-8336(1)\",\"SINGLE 8327-8325(1)\",\"SINGLE 8377-8380(1)\",\n        \"SINGLE 8383-88381-8341(1)\",\"SINGLE 8383-88382(2)\",\"SINGLE 8397-8399(1)\",\"SINGLE 8416-8418(1)\",\n        \"SINGLE 8427-8430(1)\",\"SINGLE 8432-8434(1)\",\"SINGLE 8432-8434(2)\",\"SINGLE 8439-8441(1)\",\n   "
  },
  {
    "id": "chunk_1983",
    "text": "\",\"SINGLE 8432-8434(2)\",\"SINGLE 8439-8441(1)\",\n        \"SINGLE 8448-8452(1)\",\"SINGLE 8448-8452(2)\",\"SINGLE 8455-84521-8499(1)\",\"SINGLE 8455-84522-8502(2)\",\n        \"SINGLE 8468-8470(1)\",\"SINGLE 8469-8467(1)\",\"SINGLE 85000-85001(1)\",\"SINGLE 85007-85001(1)\",\n        \"SINGLE 8512-8514(1)\",\"SINGLE 8528-8859-89413(T1)\",\"SINGLE 8532-8380(2)\",\"SINGLE 8622-8962(1)\",\n        \"SINGLE 8659-8660(1)\",\"SINGLE 8659-8674(2)\",\"SINGLE 8797-8793(1)\",\"SINGLE 88337-8735(1)\",\n        \"SINGLE 88337-8735(2)\",\"SINGLE 89"
  },
  {
    "id": "chunk_1984",
    "text": "735(1)\",\n        \"SINGLE 88337-8735(2)\",\"SINGLE 8949-8951(1)\",\"SINGLE 8956-8961-89612(1)\",\"SINGLE 8956-8961-89616(1)\",\n        \"SINGLE 8960-8961(1)\",\"SINGLE 8997-8495(1)\",\"SINGLE 9044-9045-90001(1)\",\"SINGLE 9044-9045-90007(2)\",\n        \"SINGLE 9048-9071-90002(1)\",\"SINGLE 9048-9071-90003(2)\",\"SINGLE 9074-9075-77075(3)\",\"SINGLE 9074-9075-9078(1)\",\n        \"SINGLE 9074-9075-9081(2)\",\"SINGLE 9077-9080-90004(1)\",\"SINGLE 9118-9119-90005(1)\",\"SINGLE 9122-9125-90006(1)\",\n        \"SINGLE 9128-9129-9130(1"
  },
  {
    "id": "chunk_1985",
    "text": "2-9125-90006(1)\",\n        \"SINGLE 9128-9129-9130(1)\",\"SINGLE 975-32859-978(1)\"}\n    if s1 in e3set or s2 in e3set: return \"ERCOT3\"\n    if s1 in p3set or s2 in p3set: return \"P3\"\n    return \"P6\"\n\n# Delete columns from csv file\ndef csv_keep(fname, cols):\n    fname_ext = fname[fname.rfind(\".\"):]\n    fname_temp = fname.replace(fname_ext, \"_TEMP\" + fname_ext)\n    f = open(fname,\"r\")\n    g = open(fname_temp,\"w\")\n    for line in f:\n        s = line.replace(\"\\n\",\"\").split(\",\")\n        s = \",\".join([s[i]"
  },
  {
    "id": "chunk_1986",
    "text": "ace(\"\\n\",\"\").split(\",\")\n        s = \",\".join([s[i] for i in cols])\n        g.write(s + \"\\n\")\n    f.close()\n    g.close()\n    # Delete old (read) file\n    os.remove(fname)\n    # Rename new (write) file\n    os.rename(fname_temp, fname)\n\n\n# Main loop\nif __name__ == '__main__':\n    try:\n        main()\n    except KeyboardInterrupt:\n        pool.terminate()\n        cleanup()\n=========================================================\n\n\nimport sys\nimport os\nimport datetime\nimport csv\nimport math\n\n\n\"\"\"\nTh"
  },
  {
    "id": "chunk_1987",
    "text": "os\nimport datetime\nimport csv\nimport math\n\n\n\"\"\"\nThis block of code is used for initializing PSSE and running it from Python\n\"\"\"\n\"\"\"\nsys_paths = [r'C:\\Program Files\\PTI\\PSSE35\\35.3\\PSSPY39']\n\nenv_paths = [r'C:\\Program Files\\PTI\\PSSE35\\35.3\\PSSBIN', \n             r'C:\\Program Files\\PTI\\PSSE35\\35.3\\PSSLIB', \n             ]\nfor path in sys_paths:\n    sys.path.append(path)\nfor path in env_paths:\n    os.environ['PATH'] = os.environ['PATH'] + ';' +  path\nimport psse35\nimport psspy\nierr = psspy.psseinit"
  },
  {
    "id": "chunk_1988",
    "text": "h\nimport psse35\nimport psspy\nierr = psspy.psseinit()\n\"\"\"\n\ndef text2csv(mytextfile, myaccfiles):\n    \n    import os\n    import csv\n    \n    #++++++ Consider condensing triggers into one variable\n    nPTrigger = \"PTI INTERACTIVE POWER SYSTEM SIMULATOR\" \n    tTrigger = \"CONTINGENCY CASE MONITORED BRANCHES AND INTERFACES LOADED ABOVE\"\n    vHTrigger = \"CONTINGENCY CASE BUSES WITH VOLTAGE GREATER THAN\"\n    vLTrigger = \"CONTINGENCY CASE BUSES WITH VOLTAGE LESS THAN\"\n    vDTrigger1 = \"CONTINGENCY CASE B"
  },
  {
    "id": "chunk_1989",
    "text": "GE LESS THAN\"\n    vDTrigger1 = \"CONTINGENCY CASE BUSES WITH VOLTAGE RISE BEYOND\"\n    vDTrigger2 = \"CONTINGENCY CASE BUSES WITH VOLTAGE DROP BEYOND\"\n    NCTrigger = \"NON-CONVERGED CONTINGENCIES REPORT\"\n    AFTrigger = \"OUTPUT FILE:\"\n    emptydata1 = \"..............................................\"\n    emptydata2 = \"---------------\"\n    \n    #Text file results\n    AF = []\n    tResults = []\n    vResults = []\n    vDResults = []\n    ncResults = []\n    \n    #Final Results for writing to csv\n    finalT"
  },
  {
    "id": "chunk_1990",
    "text": " \n    #Final Results for writing to csv\n    finalT = []   \n    finalV = []\n    finalVD = []\n    finalNC = []\n    \n    #Read the whole text file\n    with open(mytextfile, 'r') as myfile:\n        wfile = myfile.readlines()\n    \n    #Create output files\n    fdir = os.path.dirname(myaccfiles[0])\n    tcsv = fdir + \"\\\\Thermal.csv\"\n    fex = True\n    count = 1\n    while fex:\n        if os.path.isfile(tcsv):\n            tcsv = fdir + \"\\\\Thermal_\" + str(count) + \".csv\"\n        else:\n            fex = Fal"
  },
  {
    "id": "chunk_1991",
    "text": "ount) + \".csv\"\n        else:\n            fex = False\n        count = count + 1\n    vdcsv = fdir + \"\\\\VoltageDev.csv\"\n    fex = True\n    count = 1\n    while fex:\n        if os.path.isfile(vdcsv):\n            vdcsv = fdir + \"\\\\VoltageDev_\" + str(count) + \".csv\"\n        else:\n            fex = False\n        count = count + 1\n    vcsv = fdir + \"\\\\Voltage.csv\"\n    fex = True\n    count = 1\n    while fex:\n        if os.path.isfile(vcsv):\n            vcsv = fdir + \"\\\\Voltage_\" + str(count) + \".csv\"\n    "
  },
  {
    "id": "chunk_1992",
    "text": "v = fdir + \"\\\\Voltage_\" + str(count) + \".csv\"\n        else:\n            fex = False\n        count = count + 1\n    ncsv = fdir + \"\\\\NonConv.csv\"\n    fex = True\n    count = 1\n    while fex:\n        if os.path.isfile(ncsv):\n            ncsv = fdir + \"\\\\NonConv_\" + str(count) + \".csv\"\n        else:\n            fex = False\n        count = count + 1\n    \n    #Read all accfiles for names and write title to final results\n    TTitle = [\"Contingency\", \"Branch\"]\n    VTitle = [\"Contingency\", \"Bus\"]\n    NCTi"
  },
  {
    "id": "chunk_1993",
    "text": "nch\"]\n    VTitle = [\"Contingency\", \"Bus\"]\n    NCTitle = [\"Contingency\",]\n    for a in myaccfiles:\n        TTitle.append(os.path.basename(a))\n        VTitle.append(os.path.basename(a))\n        NCTitle.append(os.path.basename(a))\n    \n    finalT.append(TTitle)\n    finalV.append(VTitle)\n    finalVD.append(VTitle)\n    finalNC.append(NCTitle)\n\n    dataFound = 0\n    count = 0\n    for l in wfile:\n        if nPTrigger in l:\n            dataFound = 0\n        else:\n            if dataFound:\n              "
  },
  {
    "id": "chunk_1994",
    "text": "    else:\n            if dataFound:\n                if dataFound == 1 and count == 9:\n                    if emptydata1 in l or emptydata2 in l:\n                        pass\n                    else:\n                        tResults.append(l)\n                elif dataFound == 2 and count == 8:\n                    if emptydata1 in l or emptydata2 in l:\n                        pass\n                    else:\n                        vResults.append(l)\n                elif dataFound == 3 and count =="
  },
  {
    "id": "chunk_1995",
    "text": ")\n                elif dataFound == 3 and count == 7:\n                    if emptydata1 in l or emptydata2 in l:\n                        pass\n                    else:\n                        vDResults.append(l)\n                elif dataFound == 4 and count == 9:\n                    if emptydata1 in l or emptydata2 in l:\n                        pass\n                    else:\n                        ncResults.append(l)\n                else:\n                    count = count + 1\n            else:\n"
  },
  {
    "id": "chunk_1996",
    "text": "              count = count + 1\n            else:\n                if AFTrigger in l:\n                    dud, filename = l.split(\": \")\n                    AF.append(filename)\n                elif tTrigger in l:\n                    dataFound = 1\n                    count = 1\n                elif vHTrigger in l or vLTrigger in l:\n                    dataFound = 2\n                    count = 1\n                elif vDTrigger1 in l or vDTrigger2 in l:\n                    dataFound = 3\n               "
  },
  {
    "id": "chunk_1997",
    "text": "\n                    dataFound = 3\n                    count = 1\n                elif NCTrigger in l:\n                    dataFound = 4\n                    count = 1\n                    \n    for r in range(0, len(tResults), 2):\n        newr1 = tResults[r].split(\"|\")\n        newr2 = tResults[r+1].split(\"|\")\n        line = newr1[0][0:26]+newr2[0][:-2]\n        cont = newr1[1].strip()+newr2[1].strip()\n        flows = newr1[2:]\n        result = [cont, line]\n        flows = map(str.strip,flows)\n      "
  },
  {
    "id": "chunk_1998",
    "text": " line]\n        flows = map(str.strip,flows)\n        flows = map(lambda each:each.replace(\"%\", \"\"), flows)\n        flows = list(flows)\n        result.extend(flows[:-1])\n        finalT.append(result)\n\n    for r in range(0, len(vResults)):\n        newr1 = vResults[r].split(\"|\")\n        bus = newr1[0][:-1]\n        cont = newr1[1].strip()\n        pus = newr1[2:]\n        result = [cont, bus]\n        pus = map(str.strip,pus)\n        pus = list(pus)\n        result.extend(pus[:-1])\n        finalV.append("
  },
  {
    "id": "chunk_1999",
    "text": "    result.extend(pus[:-1])\n        finalV.append(result)\n            \n    for r in range(0, len(vDResults)):\n        newr1 = vDResults[r].split(\"|\")\n        bus = newr1[0][:-1]\n        cont = newr1[1].strip()\n        pus = newr1[2:]\n        result = [cont, bus]\n        pus = map(str.strip,pus)\n        pus = list(pus)\n        result.extend(pus[:-1])\n        finalVD.append(result)\n\n    for n in range(0, len(ncResults)):\n        newn = ncResults[n].split(\"|\")\n        cont = newn[0].strip()\n       "
  },
  {
    "id": "chunk_2000",
    "text": ".split(\"|\")\n        cont = newn[0].strip()\n        ncds = newn[1:]\n        result = [cont, ]\n        ncds = map(str.strip, ncds)\n        ncds = list(ncds)\n        result.extend(ncds[:-1])\n        finalNC.append(result)\n                  \n    myfile = open(tcsv, 'w')\n    with myfile:\n        writer = csv.writer(myfile, lineterminator = '\\n')\n        writer.writerows(finalT)\n\n    myfile = open(vdcsv, 'w')\n    with myfile:\n        writer = csv.writer(myfile, lineterminator = '\\n')\n        writer.wr"
  },
  {
    "id": "chunk_2001",
    "text": "r(myfile, lineterminator = '\\n')\n        writer.writerows(finalVD)\n\n    myfile = open(vcsv, 'w')\n    with myfile:\n        writer = csv.writer(myfile, lineterminator = '\\n')\n        writer.writerows(finalV)\n        \n    myfile = open(ncsv, 'w')\n    with myfile:\n        writer = csv.writer(myfile, lineterminator = '\\n')\n        writer.writerows(finalNC)\n\n#Run this line if the program is being run\nif __name__ == \"__main__\":\n    myaccfiles = [\n    r\"C:\\Users\\noberski.LCRANT\\Documents\\Python\\GINR_Ste"
  },
  {
    "id": "chunk_2002",
    "text": "C:\\Users\\noberski.LCRANT\\Documents\\Python\\GINR_Steady_State\\20SSWG_2022_WIN2_U4_FINAL_10222021_P5.acc\",\n    r\"C:\\Users\\noberski.LCRANT\\Documents\\Python\\GINR_Steady_State\\21SSWG_2022_FAL2_U1_FINAL_10222021_P5.acc\",\n    r\"C:\\Users\\noberski.LCRANT\\Documents\\Python\\GINR_Steady_State\\21SSWG_2022_SUM1_U1_FINAL_10222021_P5.acc\"\n        ]\n\n    mytextfile = r\"C:\\Users\\noberski.LCRANT\\Documents\\Python\\GINR_Steady_State\\Results_6.txt\"\n    text2csv(mytextfile, myaccfiles)\n# -*- coding: utf-8 -*-\n\"\"\"\nThis co"
  },
  {
    "id": "chunk_2003",
    "text": "e, myaccfiles)\n# -*- coding: utf-8 -*-\n\"\"\"\nThis code combines two contingency files into one.  Most useful for making P3\nand P6 contingency files for steady state analysis \n\"\"\"\nfrom collections import OrderedDict\nimport ctgx \nimport os\n\ndef makecon(file1, file2):\n    \"\"\"\n    This module combines two contingency files into one\n    It uses the ctgx program to extract information from the contingency file\n    \"\"\"\n    #Create variable to store new contingencies\n    Nm2 = OrderedDict()\n    \n    #Read"
  },
  {
    "id": "chunk_2004",
    "text": "ntingencies\n    Nm2 = OrderedDict()\n    \n    #Read files and extract contingency data\n    contsf1 = ctgx.conextract(file1)\n    contsf2 = ctgx.conextract(file2)\n    \n    #Create keys to loop through\n    key1 = contsf1.keys()\n    key2 = contsf2.keys()\n    \n    #Loop through combining contingencies into one\n    for k1 in key1:\n        for k2 in key2:\n            newname = k1 + \"+\" + k2\n            newname.replace(\"DB_ID\", \"\")\n            Nm2Conts = list(contsf2[k2])\n            Nm2Conts.extend(cont"
  },
  {
    "id": "chunk_2005",
    "text": "list(contsf2[k2])\n            Nm2Conts.extend(contsf1[k1])\n            Nm2[newname] = Nm2Conts\n    \n    #Create output file\n    f1name = os.path.basename(file1)\n    f2name = os.path.basename(file2)\n    fdir = os.path.dirname(file1)\n    newfile = fdir +\"\\\\\" + f1name.strip(\".con\") + \"_\" + f2name\n    \n    with open(newfile, 'w') as newcon:\n        for cont, events in Nm2.items():\n            newcon.write(\"CONTINGENCY '\" + cont + \"'\\n\")\n            for e in events:\n                newcon.write(\"  \" "
  },
  {
    "id": "chunk_2006",
    "text": "or e in events:\n                newcon.write(\"  \" + e +\"\\n\")\n            newcon.write(\"END\\n\")\n        newcon.write(\"END\\n\")\n    \n    return newfile\n\n\nif __name__ == \"__main__\":\n    myfile1 = r\"C:\\Users\\NOBERSKI\\Documents\\Code_Development\\ContingencyWork\\test.con\"\n    myfile2 = r\"C:\\Users\\NOBERSKI\\Documents\\Code_Development\\ContingencyWork\\SUM_P1.con\"\n    \n    newfile = makecon(myfile1, myfile2)\n    \n    #These commented lines are for code testing\n    \"\"\"\n    for key, data in newfile.iteritems()"
  },
  {
    "id": "chunk_2007",
    "text": "g\n    \"\"\"\n    for key, data in newfile.iteritems():\n        print key\n        for d in data:\n            print d\n    \"\"\"\n\n\"\"\"\nThis file is for running consecutive ACCC with one contingency file input \n\"\"\"\n\n\"\"\"\nImport the necessary modules to be used in the code\n\"\"\"\nimport sys\nimport os\nimport time \n\n\"\"\"\nThis block of code is used for initializing PSSE and running it from Python\n\"\"\"\nsys_paths = [r'C:\\Program Files\\PTI\\PSSE35\\35.3\\PSSPY39']\n\nenv_paths = [r'C:\\Program Files\\PTI\\PSSE35\\35.3\\PSSBIN',"
  },
  {
    "id": "chunk_2008",
    "text": "ths = [r'C:\\Program Files\\PTI\\PSSE35\\35.3\\PSSBIN', \n             r'C:\\Program Files\\PTI\\PSSE35\\35.3\\PSSLIB', \n             ]\nfor path in sys_paths:\n    sys.path.append(path)\nfor path in env_paths:\n    os.environ['PATH'] = os.environ['PATH'] + ';' +  path\nimport psse35\nimport psspy\nimport wx\nierr = psspy.psseinit()\n\ndef grandperformance(cases, confile, monfile, subfile):\n    \"\"\"\n    This module performs creates necessary files, performs the dfax, performs the\n    ACCC run, and creats a report of "
  },
  {
    "id": "chunk_2009",
    "text": "performs the\n    ACCC run, and creats a report of the results\n    \"\"\"\n    import psspy\n    import CSV_Results_Rev1\n    conname = os.path.basename(confile).strip(\".con\")\n    \n    dfxfiles = []\n    for case in cases:\n        case = case.strip(\".sav\")\n        case = case + \"_\" + conname + \".dfx\"\n        dfxfiles.append(case)\n\n    accfiles = []\n    for case in cases:\n        case = case.strip(\".sav\")\n        case = case + \"_\" + conname + \".acc\"\n        accfiles.append(case)\n\n    rfile = os.path.dirn"
  },
  {
    "id": "chunk_2010",
    "text": "   accfiles.append(case)\n\n    rfile = os.path.dirname(case)\n    r1file = rfile + \"\\\\Results.txt\"\n    fex = True\n    count = 1\n    while fex:\n        if os.path.isfile(r1file):\n            r1file = rfile + \"\\\\Results_\" + str(count) + \".txt\"\n        else:\n            fex = False\n        count = count + 1\n\n    #+++ Make these options available in the GUI\n    #Option functions for ACCC\n    optacc = [\n        0, #Tap adjustments 0=disable 1=enable stepping 2=enable direct\n        0, #Interchange 0=di"
  },
  {
    "id": "chunk_2011",
    "text": "pping 2=enable direct\n        0, #Interchange 0=disable 1=enable tie flow only 2=enable tie and loads\n        0, #Phase shift 0=disable 1=enable\n        1, #dc tap 0=disable 1=enable\n        1, #switched shunt 0=disable 1=enable 2=enable continuous\n        1, #solution flag 0=FDNS 1=FNSL 2=optimized FDNS\n        0, #Non-divergent 0=disable 1=enable\n        0, #induction motor 0=stall 1=trip\n        0, #induction failure 0=treat contingency as non-converage 1=treak contingency as solved if it con"
  },
  {
    "id": "chunk_2012",
    "text": "-converage 1=treak contingency as solved if it converges\n        0, #dispatch mode 0=disable\n        0, #zip archive 0=do not write ZIP 1=write a ZIP\n    ]\n\n    #Option functions for DFAX\n    optdfax = [\n        1, #distribution factor flag\n        0, #calculate distribution factors\n        0, #out-of-service branch flag\n        ]\n\n    #Empty variable for use in functions where no input is needed\n    empty = \"\"\n\n    for case, dfxfile, accfile in zip(cases, dfxfiles, accfiles):\n        \"\"\"\n      "
  },
  {
    "id": "chunk_2013",
    "text": "zip(cases, dfxfiles, accfiles):\n        \"\"\"\n        Redirect outputs to a log file for later analysis\n        \"\"\"\n        #Create log file from case name\n        logfile = case.strip(\".sav\")\n        logfile = logfile + \"_\" + conname + \".log\"\n        psspy.alert_output(2, logfile, [0, 0])\n        psspy.progress_output(2, logfile, [0, 0])\n\n        \"\"\"\n        Perform DFAX and ACCC\n        \"\"\"\n        psspy.case(case)\n        #Change max interations - Has to be called after a case is loaded\n       "
  },
  {
    "id": "chunk_2014",
    "text": " - Has to be called after a case is loaded\n        #+++ Give the user the ability to change this\n        psspy.solution_parameters_4(intgar2=40)\n        psspy.dfax_2(optdfax, subfile, monfile, confile, dfxfile)\n        psspy.accc_with_dsp_3(0.5, optacc, empty, dfxfile, accfile, empty, empty, empty)\n\n    \"\"\"\n    Create report from ACCC runs using these options\n    \"\"\"\n    report_opt = [\n        1,  #Column headings 1=accfile name 0=casefile name\n        1,  #Base Case Rating set 1=RateA 2=RateB 3"
  },
  {
    "id": "chunk_2015",
    "text": "       1,  #Base Case Rating set 1=RateA 2=RateB 3=RateC\n        2,  #Contingency Case Rating 1=RateA 2=RateB 3=RateC\n        1,  #Base Case Voltage Limit 1=Normal 2=Emergency\n        2,  #Contingency case voltage limit 1=Normal 2=Emergency\n        0,  #Print Monitored Elements Summary 0=No 1=Yes\n        0,  #Print Missing Monioted Elements Report 0=No 1=Yes\n        0,  #Print missing monitored voltages 0 = No 1=Yes\n        0,  #Print Contingency Legend 0=No 1=Master 2=reduced 3=both master and "
  },
  {
    "id": "chunk_2016",
    "text": " Legend 0=No 1=Master 2=reduced 3=both master and reduced\n        0,  #Print missing contingencies 0=No 1=Yes\n        1,  #Print non-converged report 0=No 1=Yes\n        2,  #Print loading violation 0=no 1=base case and worst 2=base case and all violations 3=All\n        2,  #Print voltage vilation 0=no 1=basecase and worst 2=base case and all violations 3=All\n        1,  #Interface loading violations 0=exclude 1=check and report\n        1,  #Exclude monitored branches violations in base case from"
  },
  {
    "id": "chunk_2017",
    "text": "de monitored branches violations in base case from contingency report 0=no 1=yes\n        1   #Exclude monitored buses violations in base case from contingency report 0=no 1=yes\n        ]\n    report_vals = [\n        0.5,    #Bus mismatch converge tolerance\n        5.0,    #System mismatch converge tolerance\n        100,     #Percent flow for report violations\n        100,     #Percent flor for reporting violatinos for worst\n        0,      #Min contingency flow change from basecase for reporting\n"
  },
  {
    "id": "chunk_2018",
    "text": "ntingency flow change from basecase for reporting\n        0,      #Min contingency case percentloading increase from basecase for reporting\n        0       #Min contingency case voltage change for reporting\n        ]\n\n    psspy.lines_per_page_one_device(1,100000)\n    psspy.report_output(2, r1file, [0, 0])\n    psspy.accc_multiple_run_report_2(report_opt, report_vals , len(accfiles), accfiles)\n    \n    #Output results to .csv files\n    CSV_Results_Rev1.text2csv(r1file, accfiles)\n\nclass EasyPanel(w"
  },
  {
    "id": "chunk_2019",
    "text": "Rev1.text2csv(r1file, accfiles)\n\nclass EasyPanel(wx.Panel):\n    \"\"\"\n    This panel is placed on the window and contains all the GUI items\n    \"\"\"\n    def __init__(self, parent):\n        wx.Panel.__init__(self, parent)\n        \n        #Setup panel items\n        caseboxsize = (300,325)\n        pboxsize = (400, 150)\n        iboxsize = (200, 35)\n            \n        boxlabel = wx.StaticBox(self, label=\"Cases:\")\n        inputlabel = wx.StaticBox(self, label=\"Input Files:\")\n        progresslabel = wx"
  },
  {
    "id": "chunk_2020",
    "text": ", label=\"Input Files:\")\n        progresslabel = wx.StaticBox(self, label=\"Progress:\")\n        subst = wx.StaticText(self, label='  sub file:')\n        monst = wx.StaticText(self, label='  mon file:')\n        const = wx.StaticText(self, label='  N-1 file:')\n        conn1st = wx.StaticText(self, label='  1st N-1 file:')\n        conn2st = wx.StaticText(self, label='  2nd N-1 file:')\n        \n        self.casetxt = wx.TextCtrl(self, style=wx.TE_MULTILINE, size=caseboxsize)\n        self.subtxt = wx.T"
  },
  {
    "id": "chunk_2021",
    "text": "LINE, size=caseboxsize)\n        self.subtxt = wx.TextCtrl(self, size=iboxsize)\n        self.montxt = wx.TextCtrl(self, size=iboxsize)\n        self.contxt = wx.TextCtrl(self, size=iboxsize)\n        self.conn1txt = wx.TextCtrl(self, size=iboxsize)\n        self.conn2txt = wx.TextCtrl(self, size=iboxsize)\n        self.progresstext = wx.TextCtrl(self, value='Select Cases and input files', size=pboxsize)\n\n        self.casebtn = wx.Button(self, label='Select Cases')\n        self.subbtn = wx.Button(self"
  },
  {
    "id": "chunk_2022",
    "text": "elect Cases')\n        self.subbtn = wx.Button(self, label='...')\n        self.monbtn = wx.Button(self, label='...')\n        self.conbtn = wx.Button(self, label='...')\n        self.conn1btn = wx.Button(self, label='...')\n        self.conn2btn = wx.Button(self, label='...')\n        self.runbtn = wx.Button(self, label='Run')\n        self.cancelbtn = wx.Button(self, -1, label='Cancel')\n        self.optbtn = wx.Button(self, -1, label='Options')\n        self.helpbtn = wx.Button(self, -1, label=\"Help\")"
  },
  {
    "id": "chunk_2023",
    "text": "  self.helpbtn = wx.Button(self, -1, label=\"Help\")\n        \n        #Setup Fonts and Color\n        boxFont = wx.Font(14, wx.FONTFAMILY_DEFAULT, wx.FONTSTYLE_NORMAL, wx.FONTWEIGHT_NORMAL, False)\n        self.SetBackgroundColour((0, 39, 76))\n        self.casebtn.SetFont(boxFont)\n        self.subbtn.SetFont(boxFont)\n        self.monbtn.SetFont(boxFont)\n        self.conbtn.SetFont(boxFont)\n        self.conn1btn.SetFont(boxFont)\n        self.conn2btn.SetFont(boxFont)\n        self.runbtn.SetFont(boxFo"
  },
  {
    "id": "chunk_2024",
    "text": "SetFont(boxFont)\n        self.runbtn.SetFont(boxFont)\n        self.cancelbtn.SetFont(boxFont)\n        self.optbtn.SetFont(boxFont)\n        self.helpbtn.SetFont(boxFont)\n        subst.SetFont(boxFont)\n        monst.SetFont(boxFont)\n        const.SetFont(boxFont)\n        conn1st.SetFont(boxFont)\n        conn2st.SetFont(boxFont)\n        boxlabel.SetFont(boxFont)\n        boxlabel.SetForegroundColour((255, 255, 255))\n        inputlabel.SetFont(boxFont)\n        inputlabel.SetForegroundColour((255, 255"
  },
  {
    "id": "chunk_2025",
    "text": ")\n        inputlabel.SetForegroundColour((255, 255, 255))\n        progresslabel.SetFont(boxFont)\n        progresslabel.SetForegroundColour((255, 255, 255))\n        subst.SetForegroundColour((255, 255, 255))\n        monst.SetForegroundColour((255, 255, 255))\n        const.SetForegroundColour((255, 255, 255))\n        conn1st.SetForegroundColour((255, 255, 255))\n        conn2st.SetForegroundColour((255, 255, 255))\n        \n        #SetupSizer to make everything fit on the panel and to create\n      "
  },
  {
    "id": "chunk_2026",
    "text": "e everything fit on the panel and to create\n        #a panel that is the minimum size capable \n        self.caseboxsizer = wx.StaticBoxSizer(boxlabel, wx.VERTICAL)\n        self.casesizer = wx.BoxSizer(wx.VERTICAL)\n        self.casesizer.Add(self.casetxt, 0, wx.ALL|wx.CENTER, 2)\n        self.casesizer.Add(self.casebtn, 0, wx.ALL|wx.CENTER, 2)\n        self.caseboxsizer.Add(self.casesizer, 0, wx.ALL|wx.CENTER, 5)\n        self.inputfilesizer = wx.StaticBoxSizer(inputlabel, wx.VERTICAL)\n        self."
  },
  {
    "id": "chunk_2027",
    "text": "ticBoxSizer(inputlabel, wx.VERTICAL)\n        self.filesizer = wx.FlexGridSizer(5, 3, 5, 5)\n        self.filesizer.Add(subst, 0, border=5)\n        self.filesizer.Add(self.subtxt, 0, border=5)\n        self.filesizer.Add(self.subbtn, 0, border=5)\n        self.filesizer.Add(monst, 0, border=5)\n        self.filesizer.Add(self.montxt, border=5)\n        self.filesizer.Add(self.monbtn, border=5)\n        self.filesizer.Add(const, border=5)\n        self.filesizer.Add(self.contxt, border=5)\n        self.fi"
  },
  {
    "id": "chunk_2028",
    "text": "lesizer.Add(self.contxt, border=5)\n        self.filesizer.Add(self.conbtn, border=5)\n        self.filesizer.Add(conn1st, border=5)\n        self.filesizer.Add(self.conn1txt, border=5)\n        self.filesizer.Add(self.conn1btn, border=5)\n        self.filesizer.Add(conn2st, border=5)\n        self.filesizer.Add(self.conn2txt, border=5)\n        self.filesizer.Add(self.conn2btn, border=5)\n        self.inputfilesizer.Add(self.filesizer, 0, wx.ALL|wx.CENTER, 5)\n        self.progresssizer = wx.StaticBoxSi"
  },
  {
    "id": "chunk_2029",
    "text": "ER, 5)\n        self.progresssizer = wx.StaticBoxSizer(progresslabel, wx.VERTICAL)\n        self.progresssizer.Add(self.progresstext, 0, wx.ALL|wx.CENTER, 5)\n        self.analysissizer = wx.BoxSizer(wx.HORIZONTAL)\n        self.analysissizer.Add(self.runbtn, 0, wx.ALL, 5)\n        self.analysissizer.Add(self.optbtn, 0, wx.ALL, 5)\n        self.analysissizer.Add(self.cancelbtn, 0, wx.ALL, 5)\n        self.analysissizer.Add(self.helpbtn, 0, wx.ALL, 5)\n        self.rightsizer = wx.BoxSizer(wx.VERTICAL)\n "
  },
  {
    "id": "chunk_2030",
    "text": "      self.rightsizer = wx.BoxSizer(wx.VERTICAL)\n        self.rightsizer.Add(self.inputfilesizer, 0, wx.ALIGN_CENTER)\n        self.rightsizer.Add(self.progresssizer, 0, wx.ALIGN_CENTER)\n        self.rightsizer.Add(self.analysissizer, 0, wx.ALL|wx.ALIGN_CENTER, 10)\n        self.myboxsizer = wx.BoxSizer(wx.HORIZONTAL)\n        self.myboxsizer.Add(self.caseboxsizer)\n        self.myboxsizer.Add(self.rightsizer)\n        self.SetSizer(self.myboxsizer)\n \nclass EasyGuy(wx.Frame):\n    \"\"\"\n    This class c"
  },
  {
    "id": "chunk_2031",
    "text": "\nclass EasyGuy(wx.Frame):\n    \"\"\"\n    This class creates the window frame and creates all the events based on\n    user button presses to allow inputs\n    \"\"\"\n    def __init__(self):\n        wx.Frame.__init__(self, None, title='GINR Steady State')\n        self.panel = EasyPanel(self)\n        windowsizer = wx.BoxSizer(wx.VERTICAL)\n        windowsizer.Add(self.panel)\n        self.Fit()\n        self.SetSizer(windowsizer)\n        self.Fit()\n        self.Show()\n\n        #Create all the binding events "
  },
  {
    "id": "chunk_2032",
    "text": "lf.Show()\n\n        #Create all the binding events to the GUI buttons\n        self.panel.Bind(wx.EVT_BUTTON, self.CaseSelect, self.panel.casebtn)\n        self.panel.Bind(wx.EVT_BUTTON, self.MonSelect, self.panel.monbtn)\n        self.panel.Bind(wx.EVT_BUTTON, self.ConSelect, self.panel.conbtn)\n        self.panel.Bind(wx.EVT_BUTTON, self.Conn1Select, self.panel.conn1btn)\n        self.panel.Bind(wx.EVT_BUTTON, self.Conn2Select, self.panel.conn2btn)\n        self.panel.Bind(wx.EVT_BUTTON, self.SubSele"
  },
  {
    "id": "chunk_2033",
    "text": "       self.panel.Bind(wx.EVT_BUTTON, self.SubSelect, self.panel.subbtn)\n        self.panel.Bind(wx.EVT_BUTTON, self.Run, self.panel.runbtn)\n        self.panel.Bind(wx.EVT_BUTTON, self.Cancel, self.panel.cancelbtn)\n        self.panel.Bind(wx.EVT_BUTTON, self.Options, self.panel.optbtn)\n        self.panel.Bind(wx.EVT_BUTTON, self.Help, self.panel.helpbtn)\n        \n    def CaseSelect(self, event):\n        \"\"\"\n        This module allows the user to select the cases that they would like\n        to p"
  },
  {
    "id": "chunk_2034",
    "text": "select the cases that they would like\n        to perform a contingency analysis on\n        \"\"\"\n        \n        with wx.FileDialog(self, \"Open SAV file\", wildcard=\"SAV files (*.sav)|*.sav\", style=wx.FD_OPEN | wx.FD_FILE_MUST_EXIST | wx.FD_MULTIPLE) as fileDialog:\n            if fileDialog.ShowModal() == wx.ID_CANCEL:\n                return\n            self.cases = fileDialog.GetPaths()\n            caseout = \"\"\n            newcases = []\n            #The two for statements are needed for printing "
  },
  {
    "id": "chunk_2035",
    "text": "  #The two for statements are needed for printing the selected cases\n            #to the GUI and for maintaining order for reporting purposes\n            for case in self.cases:\n                newcases.append(str(case))\n            for case in newcases:\n                caseout = caseout + str(os.path.basename(case)) + \"\\n\"\n            self.panel.casetxt.SetValue(caseout)\n            self.cases = newcases\n\n    def MonSelect(self, event):\n        \"\"\"\n        This module allows the user to select "
  },
  {
    "id": "chunk_2036",
    "text": "\"\"\"\n        This module allows the user to select the .mon file\n        \"\"\"\n\n        with wx.FileDialog(self, \"Open MON file\", wildcard=\"MON files (*.mon)|*.mon\", style=wx.FD_OPEN | wx.FD_FILE_MUST_EXIST) as fileDialog:\n            if fileDialog.ShowModal() == wx.ID_CANCEL:\n                return\n            self.monfile = str(fileDialog.GetPath())\n            self.panel.montxt.SetValue(os.path.basename(self.monfile))\n\n    def SubSelect(self, event):\n        \"\"\"\n        This module allows the us"
  },
  {
    "id": "chunk_2037",
    "text": "nt):\n        \"\"\"\n        This module allows the user to select the .sub file\n        \"\"\"\n\n        with wx.FileDialog(self, \"Open SUB file\", wildcard=\"SUB files (*.sub)|*.sub\", style=wx.FD_OPEN | wx.FD_FILE_MUST_EXIST) as fileDialog:\n            if fileDialog.ShowModal() == wx.ID_CANCEL:\n                return\n            self.subfile = str(fileDialog.GetPath())\n            self.panel.subtxt.SetValue(os.path.basename(self.subfile))\n\n    def ConSelect(self, event):\n        \"\"\"\n        This module "
  },
  {
    "id": "chunk_2038",
    "text": "ect(self, event):\n        \"\"\"\n        This module allows the user to select the N-1 .con file\n        \"\"\"\n\n        with wx.FileDialog(self, \"Open CON file\", wildcard=\"CON files (*.con)|*.con\", style=wx.FD_OPEN | wx.FD_FILE_MUST_EXIST) as fileDialog:\n            if fileDialog.ShowModal() == wx.ID_CANCEL:\n                return\n            self.confile = str(fileDialog.GetPath())\n            self.panel.contxt.SetValue(os.path.basename(self.confile))\n    \n    def Conn1Select(self, event):\n        \""
  },
  {
    "id": "chunk_2039",
    "text": ")\n    \n    def Conn1Select(self, event):\n        \"\"\"\n        This module allows the user to select the first N-2 .con file\n        \"\"\"\n\n        with wx.FileDialog(self, \"Open CON file\", wildcard=\"CON files (*.con)|*.con\", style=wx.FD_OPEN | wx.FD_FILE_MUST_EXIST) as fileDialog:\n            if fileDialog.ShowModal() == wx.ID_CANCEL:\n                return\n            self.conn1file = str(fileDialog.GetPath())\n            self.panel.conn1txt.SetValue(os.path.basename(self.conn1file))\n            \n"
  },
  {
    "id": "chunk_2040",
    "text": "ue(os.path.basename(self.conn1file))\n            \n    def Conn2Select(self, event):\n        \"\"\"\n        This module allows the user to select the second N-2 .con file\n        \"\"\"\n\n        with wx.FileDialog(self, \"Open CON file\", wildcard=\"CON files (*.con)|*.con\", style=wx.FD_OPEN | wx.FD_FILE_MUST_EXIST) as fileDialog:\n            if fileDialog.ShowModal() == wx.ID_CANCEL:\n                return\n            self.conn2file = str(fileDialog.GetPath())\n            self.panel.conn2txt.SetValue(os."
  },
  {
    "id": "chunk_2041",
    "text": "th())\n            self.panel.conn2txt.SetValue(os.path.basename(self.conn2file))\n\n    def Run(self, event):\n        \"\"\"\n        This module allows the user to select the .mon file\n        \"\"\"\n        \n        self.panel.progresstext.SetValue(\"Performing N-1 Analysis. See .log files.\")\n        time.sleep(5)\n        grandperformance(self.cases, self.confile, self.monfile, self.subfile)\n        if hasattr(self, 'conn1file') & hasattr(self, 'conn2file'):\n            import CombineConts\n            N"
  },
  {
    "id": "chunk_2042",
    "text": "e'):\n            import CombineConts\n            Nm2Con = CombineConts.makecon(self.conn1file, self.conn2file)\n            grandperformance(self.cases, Nm2Con, self.monfile, self.subfile)\n        self.panel.progresstext.SetValue(\"Analysis Complete :) See CSV Files\")\n\n    def Cancel(self, event):\n        \"\"\"\n        This module closes the program\n        \"\"\"\n\n        sys.exit()\n\n    def Options(self, event):\n        \"\"\"\n        This module is a place holder for future revisions\n        \"\"\"\n      "
  },
  {
    "id": "chunk_2043",
    "text": "ace holder for future revisions\n        \"\"\"\n        self.panel.progresstext.SetValue(\"This Option is not available yet.\")\n\n    def Help(self, event):\n        \"\"\"\n        This module opens the help button\n        \"\"\"\n        os.startfile(r\"\\\\wins.lcra.org\\data\\BTC\\Shared\\data\\SA\\DVAR_Planning\\PYTHON_SCRIPTS\\GINR_Steady_State\\GINR Steady State Help Document.pdf\")\n        \napp = wx.App(False)\nframe = EasyGuy()\napp.MainLoop()  \n\n\n\n\n\n\n\n\nmyaccfiles = [\nr\"C:\\Users\\noberski.LCRANT\\Documents\\Python\\GINR_"
  },
  {
    "id": "chunk_2044",
    "text": "\nr\"C:\\Users\\noberski.LCRANT\\Documents\\Python\\GINR_Steady_State\\20SSWG_2022_WIN2_U4_FINAL_10222021_P5.acc\",\nr\"C:\\Users\\noberski.LCRANT\\Documents\\Python\\GINR_Steady_State\\21SSWG_2022_FAL2_U1_FINAL_10222021_P5.acc\",\nr\"C:\\Users\\noberski.LCRANT\\Documents\\Python\\GINR_Steady_State\\21SSWG_2022_SUM1_U1_FINAL_10222021_P5.acc\"\n    ]\n\nmytextfile = r\"C:\\Users\\noberski.LCRANT\\Documents\\Python\\GINR_Steady_State\\Results_6.txt\"\n\nfullresults = False\n\n#++++++ Consider condensing triggers into one variable\nnPTrigge"
  },
  {
    "id": "chunk_2045",
    "text": "der condensing triggers into one variable\nnPTrigger = \"PTI INTERACTIVE POWER SYSTEM SIMULATOR\" \ntTrigger = \"CONTINGENCY CASE MONITORED BRANCHES AND INTERFACES LOADED ABOVE\"\nvHTrigger = \"CONTINGENCY CASE BUSES WITH VOLTAGE GREATER THAN\"\nvLTrigger = \"CONTINGENCY CASE BUSES WITH VOLTAGE LESS THAN\"\nvDTrigger1 = \"CONTINGENCY CASE BUSES WITH VOLTAGE RISE BEYOND\"\nvDTrigger2 = \"CONTINGENCY CASE BUSES WITH VOLTAGE DROP BEYOND\"\nNCTrigger = \"NON-CONVERGED CONTINGENCIES REPORT\"\nAFTrigger = \"OUTPUT FILE:\"\nem"
  },
  {
    "id": "chunk_2046",
    "text": "ONTINGENCIES REPORT\"\nAFTrigger = \"OUTPUT FILE:\"\nemptydata1 = \"..............................................\"\nemptydata2 = \"---------------\"\n\n#Text file results\nAF = []\ntResults = []\nvResults = []\nvDResults = []\nncResults = []\n\n#Final Results for .acc search\nfinalT = []   \nfinalV = []\nfinalVD = []\nfinalNC = []\n\n#Variable to store and get data from ACCC files\nTacc = []\nVacc = []\nVDacc = []\nNCacc = []\n\nimport sys\nimport os\nimport datetime\nimport csv\nimport math\n\nprint(datetime.datetime.now().time("
  },
  {
    "id": "chunk_2047",
    "text": "v\nimport math\n\nprint(datetime.datetime.now().time())\n\n\"\"\"\nThis block of code is used for initializing PSSE and running it from Python\n\"\"\"\nsys_paths = [r'C:\\Program Files\\PTI\\PSSE35\\35.3\\PSSPY39']\n\nenv_paths = [r'C:\\Program Files\\PTI\\PSSE35\\35.3\\PSSBIN', \n             r'C:\\Program Files\\PTI\\PSSE35\\35.3\\PSSLIB', \n             ]\nfor path in sys_paths:\n    sys.path.append(path)\nfor path in env_paths:\n    os.environ['PATH'] = os.environ['PATH'] + ';' +  path\nimport psse35\nimport psspy\nierr = psspy.ps"
  },
  {
    "id": "chunk_2048",
    "text": "+  path\nimport psse35\nimport psspy\nierr = psspy.psseinit()\n\nimport pssarrays\n\ndef istransformer(branch):\n    v1 = branch[19:25]\n    v2 = branch[45:51]\n    if v1 == v2:\n        xfmr = False\n    else:\n        xfmr = True\n    \n    return xfmr, float(v1)\n\ndef checkflows(flows):\n    for f in flows:\n        if f == \"\":\n            return False\n    \n    return True\n\ndef checkvolt(volts):\n    for v in volts:\n        if v == \"\":\n            return False\n    \n    return True\n\ndef checknc(descs):\n    for d"
  },
  {
    "id": "chunk_2049",
    "text": "   \n    return True\n\ndef checknc(descs):\n    for d in descs:\n        if d == \"\":\n            return False\n    return True\n\ndef findconv(afiles, adfiles, contingency):\n    fullres = [contingency, ]\n    \n    for afile, adfile in zip(afiles, adfiles):\n        couts = pssarrays.accc_solution(afile, contingency, \"contingency\", 0.5, 5.0)\n        if couts:\n            fullres.append(couts.cnvcond)\n        else:\n            fullres.append(\"N/A\")\n            \n    return fullres\n\ndef findallbranches(afile"
  },
  {
    "id": "chunk_2050",
    "text": "    \n    return fullres\n\ndef findallbranches(afiles, adfiles, contingency, branch):\n    \n    xfmr, v = istransformer(branch)\n    fullres = [contingency, branch]\n    \n    for a, ad in zip(afiles, adfiles):\n        couts = pssarrays.accc_solution(a, contingency, \"contingency\", 0.5, 5.0)\n        if couts:\n            if couts.cnvflag:\n                if xfmr:\n                    try:\n                        bindex = ad.melement.index(branch)\n                    except:\n                        fullr"
  },
  {
    "id": "chunk_2051",
    "text": "             except:\n                        fullres.append(\"N/A\")\n                        bindex = -1\n                    if bindex >= 0:\n                        bflow = couts.mvaflow[bindex]\n                        brating = ad.rating.b[bindex]\n                        bperct = round((abs(bflow/brating))*100, 1)\n                        bperct = str(bperct)\n                        fullres.append(bperct)  \n                else:\n                    try:\n                        bindex = ad.melement"
  },
  {
    "id": "chunk_2052",
    "text": " try:\n                        bindex = ad.melement.index(branch)\n                    except:\n                        fullres.append(\"N/A\")\n                        bindex = -1\n                    if bindex >= 0:\n                        bflow = (couts.ampflow[bindex])/(math.sqrt(3)*(v/1000))\n                        brating = (ad.rating.b[bindex])/(math.sqrt(3)*(v/1000))\n                        bperct = round((abs(bflow/brating))*100, 1)\n                        bperct = str(bperct)\n                "
  },
  {
    "id": "chunk_2053",
    "text": "             bperct = str(bperct)\n                        fullres.append(bperct) \n            else:\n                fullres.append(\"NONCNV\")\n        else:\n            fullres.append(\"N/A\")\n    \n    \n    return fullres\n\ndef findallbuses(afiles, adfiles, contingency, bus):\n    \n    fullres = [contingency, bus]\n    \n    for a, ad in zip(afiles, adfiles):\n        couts = pssarrays.accc_solution(a, contingency, \"contingency\", 0.5, 5.0)\n        if couts:\n            if couts.cnvflag:\n                t"
  },
  {
    "id": "chunk_2054",
    "text": "s:\n            if couts.cnvflag:\n                try:\n                    bindex = ad.mvbuslabel.index(bus)\n                except:\n                    fullres.append(\"N/A\")\n                    bindex = -1\n                if bindex >= 0:\n                    bvpu = couts.volts[bindex]\n                    fullres.append(bvpu)                \n            else:\n                fullres.append(\"NONCNV\")\n        else:\n            fullres.append(\"N/A\")\n\n\n    return fullres\n\nwith open(mytextfile, 'r') as"
  },
  {
    "id": "chunk_2055",
    "text": "\n    return fullres\n\nwith open(mytextfile, 'r') as myfile:\n    wfile = myfile.readlines()\n\n#Read all accfiles once\nadfiles = []\nTTitle = [\"Contingency\", \"Branch\"]\nVTitle = [\"Contingency\", \"Bus\"]\nNCTitle = [\"Contingency\",]\nfor a in myaccfiles:\n    aouts = pssarrays.accc_summary(a)\n    adfiles.append(aouts)\n    TTitle.append(os.path.basename(a))\n    VTitle.append(os.path.basename(a))\n    NCTitle.append(os.path.basename(a))\n    \nfinalT.append(TTitle)\nfinalV.append(VTitle)\nfinalVD.append(VTitle)\nfin"
  },
  {
    "id": "chunk_2056",
    "text": ")\nfinalV.append(VTitle)\nfinalVD.append(VTitle)\nfinalNC.append(NCTitle)\n\n\ndataFound = 0\ncount = 0\nfor l in wfile:\n    if nPTrigger in l:\n        dataFound = 0\n    else:\n        if dataFound:\n            if dataFound == 1 and count == 9:\n                if emptydata1 in l or emptydata2 in l:\n                    pass\n                else:\n                    tResults.append(l)\n            elif dataFound == 2 and count == 8:\n                if emptydata1 in l or emptydata2 in l:\n                    "
  },
  {
    "id": "chunk_2057",
    "text": "ata1 in l or emptydata2 in l:\n                    pass\n                else:\n                    vResults.append(l)\n            elif dataFound == 3 and count == 7:\n                if emptydata1 in l or emptydata2 in l:\n                    pass\n                else:\n                    vDResults.append(l)\n            elif dataFound == 4 and count == 9:\n                if emptydata1 in l or emptydata2 in l:\n                    pass\n                else:\n                    ncResults.append(l)\n    "
  },
  {
    "id": "chunk_2058",
    "text": "else:\n                    ncResults.append(l)\n            else:\n                count = count + 1\n        else:\n            if AFTrigger in l:\n                dud, filename = l.split(\": \")\n                AF.append(filename)\n            elif tTrigger in l:\n                dataFound = 1\n                count = 1\n            elif vHTrigger in l or vLTrigger in l:\n                dataFound = 2\n                count = 1\n            elif vDTrigger1 in l or vDTrigger2 in l:\n                dataFound ="
  },
  {
    "id": "chunk_2059",
    "text": " l or vDTrigger2 in l:\n                dataFound = 3\n                count = 1\n            elif NCTrigger in l:\n                dataFound = 4\n                count = 1\n                \nfor r in range(0, len(tResults), 2):\n    newr1 = tResults[r].split(\"|\")\n    newr2 = tResults[r+1].split(\"|\")\n    line = newr1[0][0:26]+newr2[0][:-2]\n    cont = newr1[1].strip()+newr2[1].strip()\n    flows = newr1[2:]\n    result = [cont, line]\n    flows = map(str.strip,flows)\n    flows = map(lambda each:each.replace"
  },
  {
    "id": "chunk_2060",
    "text": "ip,flows)\n    flows = map(lambda each:each.replace(\"%\", \"\"), flows)\n    flows = list(flows)\n    result.extend(flows[:-1])\n    add = checkflows(flows[:-1])\n    if fullresults:\n        if add:\n            finalT.append(result)\n        else:\n            Tacc.append(result)\n    else:\n        finalT.append(result)\n\nfor r in range(0, len(vResults)):\n    newr1 = vResults[r].split(\"|\")\n    bus = newr1[0][:-1]\n    cont = newr1[1].strip()\n    pus = newr1[2:]\n    result = [cont, bus]\n    pus = map(str.stri"
  },
  {
    "id": "chunk_2061",
    "text": ":]\n    result = [cont, bus]\n    pus = map(str.strip,pus)\n    pus = list(pus)\n    result.extend(pus[:-1])\n    add = checkvolt(pus[:-1])\n    if fullresults:\n        if add:\n            finalV.append(result)\n        else:\n            Vacc.append(result)\n    else:\n        finalV.append(result)\n        \nfor r in range(0, len(vDResults)):\n    newr1 = vDResults[r].split(\"|\")\n    bus = newr1[0][:-1]\n    cont = newr1[1].strip()\n    pus = newr1[2:]\n    result = [cont, bus]\n    pus = map(str.strip,pus)\n   "
  },
  {
    "id": "chunk_2062",
    "text": "ult = [cont, bus]\n    pus = map(str.strip,pus)\n    pus = list(pus)\n    result.extend(pus[:-1])\n    add = checkvolt(pus[:-1])\n    if fullresults:\n        if add:\n            finalVD.append(result)\n        else:\n            VDacc.append(result)\n    else:\n        finalVD.append(result)\n\nfor n in range(0, len(ncResults)):\n    newn = ncResults[n].split(\"|\")\n    cont = newn[0].strip()\n    ncds = newn[1:]\n    result = [cont, ]\n    ncds = map(str.strip, ncds)\n    ncds = list(ncds)\n    result.extend(ncds"
  },
  {
    "id": "chunk_2063",
    "text": "ncds)\n    ncds = list(ncds)\n    result.extend(ncds[:-1])\n    add = checknc(ncds[:-1])\n    if fullresults:\n        if add:\n            finalNC.append(result)\n        else:\n            NCacc.append(result)\n    else:\n        finalNC.append(result)\n        \n\nfor i in Tacc:\n    result = findallbranches(myaccfiles, adfiles, i[0], i[1])\n    if result:\n        finalT.append(result)\n    else:\n        finalT.apend(i)\n    \nfor i in Vacc:\n    if \":\" in i[0]:\n        finalV.append(i)\n    else:\n        result"
  },
  {
    "id": "chunk_2064",
    "text": "\n        finalV.append(i)\n    else:\n        result = findallbuses(myaccfiles, adfiles, i[0], i[1])\n        finalV.append(result)\n\nfor i in VDacc:\n    if \":\" in i[0]:\n        finalVD.append(i)\n    else:\n        result = findallbuses(myaccfiles, adfiles, i[0], i[1])\n        finalVD.append(result)\n\nfor i in NCacc:\n    if \":\" in i[0]:\n        finalNC.append(i)\n    else:\n        results = findconv(myaccfiles, adfiles, i[0])\n        finalNC.append(results)\n        \ncsvfile = r\"C:\\Users\\noberski.LCRANT"
  },
  {
    "id": "chunk_2065",
    "text": "lts)\n        \ncsvfile = r\"C:\\Users\\noberski.LCRANT\\Documents\\Python\\GINR_Steady_State\\Thermal.csv\"\nmyfile = open(csvfile, 'w')\nwith myfile:\n    writer = csv.writer(myfile, lineterminator = '\\n')\n    writer.writerows(finalT)\n\ncsvfile = r\"C:\\Users\\noberski.LCRANT\\Documents\\Python\\GINR_Steady_State\\VoltageDev.csv\"\nmyfile = open(csvfile, 'w')\nwith myfile:\n    writer = csv.writer(myfile, lineterminator = '\\n')\n    writer.writerows(finalVD)\n\ncsvfile = r\"C:\\Users\\noberski.LCRANT\\Documents\\Python\\GINR_S"
  },
  {
    "id": "chunk_2066",
    "text": "r\"C:\\Users\\noberski.LCRANT\\Documents\\Python\\GINR_Steady_State\\Voltage.csv\"\nmyfile = open(csvfile, 'w')\nwith myfile:\n    writer = csv.writer(myfile, lineterminator = '\\n')\n    writer.writerows(finalV)\n    \ncsvfile = r\"C:\\Users\\noberski.LCRANT\\Documents\\Python\\GINR_Steady_State\\NonConv.csv\"\nmyfile = open(csvfile, 'w')\nwith myfile:\n    writer = csv.writer(myfile, lineterminator = '\\n')\n    writer.writerows(finalNC)\n\nprint(datetime.datetime.now().time())\n\n\n\"\"\"\nThis code extracts details from a conti"
  },
  {
    "id": "chunk_2067",
    "text": "e())\n\n\n\"\"\"\nThis code extracts details from a contingency file.  It does only data \nextraction and does not do anything but return the information in a list.\nOther code needs to be developed to do additional actions with the returned\nlist\n\nCreated by: Nicholas Oberski\n\"\"\"\n\nfrom collections import OrderedDict\n\ndef conextract(cfile):\n    \"\"\"\n    The module reads the contingency file line by line and extracts the \n    data to make an ordered list of contingencies\n    \"\"\"\n    \n    with open(cfile, 'r"
  },
  {
    "id": "chunk_2068",
    "text": "contingencies\n    \"\"\"\n    \n    with open(cfile, 'r') as myfile:\n        clist = myfile.readlines()\n    \n    #Create an ordered dictionary to store contingencies \n    myconts = OrderedDict()\n    \n    \"\"\"\n    fstate is used to determine where in teh contingecy search the program is\n    located\n    \n    fstate = 0 No contingency start definition found yet\n    fstate = 1 Found a contingency start definiton\n    \"\"\"\n    fstate = 0 #No contingency found yet\n    for l in clist:\n        l = l.strip()\n   "
  },
  {
    "id": "chunk_2069",
    "text": " yet\n    for l in clist:\n        l = l.strip()\n        if fstate == 0:\n            if l.startswith(\"CONTINGENCY\") | l.startswith(\"Contingency\") | l.startswith(\"Contingency\"):\n                fstate = 1 #Contingency found\n                conName = l.split(\"'\")[1] #Find just contingency name\n                myconts[conName] = [] #Create contingency definistion in dictionary \n            else:\n                pass #Line is just a comment line, go to the next line\n        elif fstate == 1:\n         "
  },
  {
    "id": "chunk_2070",
    "text": " the next line\n        elif fstate == 1:\n            if l.startswith(\"END\") | l.startswith(\"End\") | l.startswith(\"end\"):\n                fstate = 0 #End of contingency statement, start looking for the next one\n            else:\n                myconts[conName].append(l) #Add event to contingency definition \n    \n    return myconts\n\n#Run this line if the program is being run\nif __name__ == \"__main__\":\n    myfile = r\"C:\\Users\\NOBERSKI\\Documents\\Code_Development\\ContingencyWork\\SUM_P1.con\"\n    cond"
  },
  {
    "id": "chunk_2071",
    "text": "e_Development\\ContingencyWork\\SUM_P1.con\"\n    condict = conextract(myfile)\n    \n    #These commented lines are for code testing\n    \"\"\"\n    for key, data in condict.iteritems():\n        print key\n        for d in data:\n            print d\n    \"\"\"\n\n                \n'''\nUncomment the line \"input()\" if you want to keep python window open after the tests are complete  \n'''\ndef main(INIfn):\n    import os,sys        \n    py_ver = sys.version\n    if py_ver.startswith('3.7'):\n        tools_path = 'TOOLs"
  },
  {
    "id": "chunk_2072",
    "text": "ver.startswith('3.7'):\n        tools_path = 'TOOLs(py3.7)'\n    elif py_ver.startswith('3.8'):\n        tools_path = 'TOOLs(py3.8)'\n    elif py_ver.startswith('3.9'):\n        tools_path = 'TOOLs(py3.9)'\n    else:\n        print ('Python 3.7, or 3.8, or 3.9 is needed for DMView')\n        quit()   \n    sys.path.append(os.path.abspath(tools_path))    \n    from DMView_main import DMView_main \n    DMView_main(INIfn,tools_path)\n    #input(\"\\nPress any key to end the program\")\n    \nif __name__ == '__main_"
  },
  {
    "id": "chunk_2073",
    "text": " to end the program\")\n    \nif __name__ == '__main__':\n    import os, sys\n    if len(sys.argv)>1:   \n       temp = sys.argv[1]\n       temp = temp.strip()\n       if len(temp)>1:\n          rootfn, ext = os.path.splitext(temp)\n          if len(ext)<1:\n             INIfn = rootfn+'.ini'\n          else:\n             INIfn = temp             \n       main(INIfn)\n    \n/for DMView\n/used with DMView.py\n\n\n[Build FS]\nBuild_FS_flag = 1        / 1: Build flat start (FS) using the tool; 0: Don't use the tool to"
  },
  {
    "id": "chunk_2074",
    "text": "tart (FS) using the tool; 0: Don't use the tool to build FS, users must build FS by themselves and provide a converted case and a snap file\n\n[Input files]\ninput_path = CASEs\\WIRTZ\nunconv_casefile = wirtz.sav        / unconverted case (if Build_FS_flag=1, must provide it, otherwise optional)\nconv_casefile = wirtz_cnv.sav      / converted case (if Build_FS_flag=0, must provide it, otherwise optional)\nsnapfile = wirtz.snp               / snap file (if Build_FS_flag=0, must provide it, otherwise opt"
  },
  {
    "id": "chunk_2075",
    "text": "if Build_FS_flag=0, must provide it, otherwise optional)\nmodel_file_lst = ['WIRTZ.dyr']     / The list contains dyr and dll files (always provide a dll file if the model has it; dyr files are only needed if Build_FS_flag=1; obj/lib files are unaccepted with PSS/e 35), each file needs to have single quotation, use comma (no speicific order needed) for multpile files\n\n\n[Tests]\n/\n/A TEST list is comprised of two items: Test type and Test data. \n/Both items need to have single quotation.\n/\n/The firs"
  },
  {
    "id": "chunk_2076",
    "text": "h items need to have single quotation.\n/\n/The first item is the test type. It can be any of the following:\n/ 1.  FS (flat start) \n/ 2.  VOLT (voltage response test, including ERUN, HVRT, LVRT and any other voltage response test)\n/ 3.  FREQ (frequency response test, including GRUN and any other frequency response test)\n/ 4.  VOLTFREQ (voltage and frequency response test)\n/ 5.  SCR (fixed SCR test), including SCR, SCR_SMALL, SCR_LARGE\n/ 6.  SCMVA (fixed SCMVA test), including SCMVA, SCMVA_SMALL, S"
  },
  {
    "id": "chunk_2077",
    "text": "fixed SCMVA test), including SCMVA, SCMVA_SMALL, SCMVA_LARGE\n/ 7.  SCR2 (Variable SCR test)\n/ 8.  SCMVA2 (Variable SCMVA test)\n/ 9.  FAULT (fault test, intened to be applied to synchronous generators)\n/10.  CCT(Critical Clearing time test)\n/\n/The second item is the test data. Depending on the test type, the test data could be one of the following: \n/ 1. Simulation time (sec) for FS test; or \n/ 2. EXEL file for VOLT, FREQ, and VOLTFREQ test; or \n/ 3. SCR numbers (Use comma for multiple numbers) f"
  },
  {
    "id": "chunk_2078",
    "text": " 3. SCR numbers (Use comma for multiple numbers) for SCR test; or  \n/ 4. SCMVA numbers (Use comma for multiple numbers) for SCMVA test; or  \n/ 5: A sequentail SCR numbers (Use -> for multiple numbers), time interval for each change in seconds, fault option (1: 3P fault; 0: no fault) at each change time, for SCR2 test; or \n/ 6: A sequentail SCMVA numbers (Use -> for multiple numbers), time interval for each change in seconds, fault option (1: 3P fault; 0: no fault) at each change time, for SMVA2 "
  },
  {
    "id": "chunk_2079",
    "text": "ault; 0: no fault) at each change time, for SMVA2 test; or\n/ 7: Fault admittance for FAULT test; or\n/ 8: CCT test parameters for CCT test.\n/The tests can be added as many as users want. \n/The test name must start from 'Test' and each test name needs to be unique\n/Add '/' to comment out any specific test.\n/\n/Test 1 to Test 9 are ERCOT dynamic model quality tests\nTest01_FS = ['FS', '10']\n/Test02_VOLTDOWN = ['VOLT','DATAs\\\\ERCOT_VOLT-STEP-DOWN.xlsx']\n/Test03_VOLTUP = ['VOLT','DATAs\\\\ERCOT_VOLT-STEP"
  },
  {
    "id": "chunk_2080",
    "text": "]\n/Test03_VOLTUP = ['VOLT','DATAs\\\\ERCOT_VOLT-STEP-UP.xlsx']\nTest04_FRQDOWN = ['FREQ','DATAs\\\\ERCOT_FRQ-STEP-DOWN.xlsx']\n/Test05_FRQUP = ['FREQ','DATAs\\\\ERCOT_FRQ-STEP-UP.xlsx']\n/Test06_HVRT = ['VOLT','DATAs\\\\ERCOT_HVRT.xlsx']\n/Test07_LVRT = ['VOLT','DATAs\\\\ERCOT_LVRT.xlsx']\n/Test08_SCR2 = ['SCR2', '5->3->1.5->1.2, 5, 1'] /Variable SCR test: SCR is changed from 5 to 3 to 1.5 to 1.2, the time interval of the change is 5 seconds, 3P fault is applied at each change time.\nTest09_FAULT =['FAULT', '-2"
  },
  {
    "id": "chunk_2081",
    "text": "d at each change time.\nTest09_FAULT =['FAULT', '-2e10'] / Fault test: -2e10 is the fault admittance, it is inteneded to be applied to synchronous generators\n/\n/Test 10 to 16 are other model tests\n/Test10_MVRT = ['VOLT','DATAs\\\\ERCOT_Multi-LVRT.xlsx'] /multiple LVRT test\n/Test11_SCR = ['SCR', '5, 3, 1.5'] /Fixed SCR tests (including SCR_Large and SCR_Small) for SCR of 5, 3, and 1.5, each test is run seperatly \n/Test12_SCR = ['SCR_LARGE', '5, 3, 1.5'] /Fixed SCR_Large tests for SCR of 5, 3, and 1."
  },
  {
    "id": "chunk_2082",
    "text": "5'] /Fixed SCR_Large tests for SCR of 5, 3, and 1.5, each test is run seperatly \n/Test13_SCR = ['SCR_SMALL', '5, 3, 1.5'] /Fixed SCR_Small tests for SCR of 5, 3, and 1.5, each test is run seperatly \n/Test14_SCMVA = ['SCMVA', '5000, 3000, 1500'] /Fixed SCMVA test for SCMVA of 5000, 3000, and 1500, each test is run seperatly \n/Test15_SCMVA2 = ['SCMVA2', '5000->3000->1500->1200, 5, 1'] /Varialbe SCMVA test: SCMVA is changed from 5000 to 3000 to 1500 to 1200, the time interval of the change is 5 sec"
  },
  {
    "id": "chunk_2083",
    "text": " to 1200, the time interval of the change is 5 seconds, 3P fault is applied at each change time.\n/Test16_CCT = ['CCT','9:54:6,999'] /CCT test: a 3P fault applied to bus 999, the fault clear time range is between 9 to 54 cycles and the interval is 6 cycles.\n\n[Settings]\nPlot_Flag = 1 /1: plot the output file into PDF files; 0: Do not plot (default value)\nPlot_SCR_scale = [1, 6]\n/Plot_POWR_scale = [-3,3]\n/Plot_FREQ_scale = [-0.1, 0.1]\n/Plot_VARS_scale = [-1, 2]\n/Plot_VOLT_scale = [-0.1, 1.5]\n/Plot_"
  },
  {
    "id": "chunk_2084",
    "text": "le = [-1, 2]\n/Plot_VOLT_scale = [-0.1, 1.5]\n/Plot_TIELINE_scale =[-150,300]\n/Time_Step = 0.004166667 /time step(delta), in sec, 0.004166667 (default value)\n/Frq_filter_ratio = 4 /frequency filter constant, in ratio of time step, 4 (default value = 4*delta)\n/Accel_Factor =0.8 /acceleration factors, 0.8 by default\n/Max_Iter= 99 /maximum iteration, 99 by default\n/Fault_duration = 0.1 /fault duration (sec), it is only applied to SCR/SCR2/SCMVA/SCMVA2 tests\n/PSS_VER = 35.3 /PSSE version\n\n[info]\n/comm"
  },
  {
    "id": "chunk_2085",
    "text": " tests\n/PSS_VER = 35.3 /PSSE version\n\n[info]\n/comments start from /\n/run as:\n/open _dos33 window, key in:\n/python dmview.py wind        \n\n'''\nPRC.py (PreRequisites Check)\n'''\ndef versiontuple(v):\n    return tuple(map(int, (v.split(\".\"))))\n\nimport os,sys\nimport glob\npython_path, _ = os.path.split(sys.executable)\npy_ver = sys.version.split('(')[0]\n\nmsg = ''\nflag = 1\ntry:\n    msg = 'Avaible PSS/e minor versions under Python '+py_ver+ ': \\n'\n    psse35_lst = glob.glob(python_path + r\"\\\\Lib\\\\site-pac"
  },
  {
    "id": "chunk_2086",
    "text": "35_lst = glob.glob(python_path + r\"\\\\Lib\\\\site-packages\\\\psse35*.py\", recursive = True) + glob.glob(python_path + r\"\\\\Lib\\\\site-packages\\\\psse35*.pyc\", recursive = True)\n    psse_ver_lst = []\n    for psse35_i in psse35_lst:\n        psse_ver = os.path.splitext(os.path.basename(psse35_i))[0]\n        if len(psse_ver)>6:\n            if psse_ver not in psse_ver_lst:\n                psse_ver_lst.append(psse_ver)\n                msg = msg + '     ' + psse_ver +'\\n'\n    msg = msg + 'Please only use avai"
  },
  {
    "id": "chunk_2087",
    "text": "se_ver +'\\n'\n    msg = msg + 'Please only use available PSS/e versions under Python '+ py_ver\n    import psse35\n    import psspy\n    psspy.psseinit()\nexcept:\n    msg = 'PSSE 35 NOT available\\n'\n    flag = 0\ntry:\n    import openpyxl\nexcept:\n    msg = msg + 'Please install openpyxl using python pip: pip install openpyxl\\n' \n    flag = 0\ntry:\n    import matplotlib\n    if versiontuple(matplotlib.__version__)>versiontuple(\"3.4.3\"):\n        msg = msg + 'Your matplotlib may not work with psse plot\\n'\n "
  },
  {
    "id": "chunk_2088",
    "text": " 'Your matplotlib may not work with psse plot\\n'\n        msg = msg + 'Please install matplotlib (3.4.3) using python pip: pip install matplotlib==3.4.3\\n'\n        flag = 0\nexcept:\n    msg = msg + 'Please install matplotlib (3.4.3) using python pip: pip install matplotlib==3.4.3\\n'\n    flag = 0\n\n\n \nimport tkinter\nfrom tkinter import messagebox\ntop =  tkinter.Tk()\ntop.withdraw()\n\nif flag:\n    msg = msg + '\\n\\nDMView ready to use\\n\\n'\n    messagebox.showinfo(\"SUCCESS\",msg)\nelse:\n    messagebox.show"
  },
  {
    "id": "chunk_2089",
    "text": ".showinfo(\"SUCCESS\",msg)\nelse:\n    messagebox.showinfo(\"ERROR!!!\",msg)\n\n\n \n\n/an example of thermal generation project (synchronous generators) for ERCOT dynamic model quality test\n\n[Build FS]\nBuild_FS_flag = 1       \nIB_check_flag = 0       \n\n[Input files]\ninput_path = CASEs\\Thermal \nunconv_casefile = Thermal.sav        \nmodel_file_lst = ['Thermal.dyr']   \n\n[Tests]\nTest1_FS = ['FS','10']\nTest2_VOLTDOWN = ['VOLT','DATAs\\\\ERCOT_VOLT-STEP-DOWN.xlsx']\nTest3_VOLTUP = ['VOLT','DATAs\\\\ERCOT_VOLT-STEP-U"
  },
  {
    "id": "chunk_2090",
    "text": "]\nTest3_VOLTUP = ['VOLT','DATAs\\\\ERCOT_VOLT-STEP-UP.xlsx']\nTest4_FRQDOWN = ['FREQ','DATAs\\\\ERCOT_FRQ-STEP-DOWN.xlsx']\nTest5_FRQUP = ['FREQ','DATAs\\\\ERCOT_FRQ-STEP-UP.xlsx']\nTest6_FAULT = ['FAULT', '-2e10'] /-2e10 is the fault admittance, this test is intended to be applied to synchronous generators\n\n\n[Settings]\nPlot_Flag = 1 \n\n@rem run3x.bat\n@echo OFF\necho %date% %time%\nSet PYTHONROOT=C:\\Users\\%username%\\AppData\\Local\\Programs\\Python\nSet PYVER=NONE\nif EXIST \"%PYTHONROOT%\\Python37\" set PYVER=37\ni"
  },
  {
    "id": "chunk_2091",
    "text": "NE\nif EXIST \"%PYTHONROOT%\\Python37\" set PYVER=37\nif EXIST \"%PYTHONROOT%\\Python38\" set PYVER=38\nif EXIST \"%PYTHONROOT%\\Python39\" set PYVER=39\nSet PYTHONHOME=%PYTHONROOT%\\Python%PYVER%\\\nSET PATH=%PYTHONHOME%;%PYTHONHOME%SCRIPTs;%PATH%\nIF %PYVER%==NONE (echo ERROR!!! Please install python 3.9 or 3.8 or 3.7) ELSE (echo PATHs set: python %PYVER%)\nif NOT EXIST \"C:\\Program Files\\PTI\\PSSE35\" echo ERROR!!! Please install PSS/e 35 at C:\\Program Files\\PTI\\PSSE35 \npython dmview.py %*\n\n\n# Get Load stats with"
  },
  {
    "id": "chunk_2092",
    "text": "SSE35 \npython dmview.py %*\n\n\n# Get Load stats with GUI\n\nimport wx\nimport pandas as pd\nimport pyodbc\nimport datetime\nfrom dateutil.relativedelta import relativedelta\nimport Etude\nimport copy\nimport shutil\nimport os\nimport numpy as np\nimport sys\nimport tempfile\nimport xlsxwriter\nimport pathlib\nimport glob\n\n#### psspy import ####\n# I'm not sure if this belongs here in this package or if this belongs in main()\nPSSE_PATH = r'C:\\Program Files\\PTI\\PSSE35\\35.3\\PSSBIN_39'\nsys.path.append(PSSE_PATH)\nos.en"
  },
  {
    "id": "chunk_2093",
    "text": "5\\35.3\\PSSBIN_39'\nsys.path.append(PSSE_PATH)\nos.environ['PATH'] += ';' + PSSE_PATH\nimport psspy\n\n########### Etude import ###########\nETUDE_PATH = os.path.dirname(__file__) # Based on this, Etude.py must be in the same directory as this script in order to import Etude\nsys.path.append(ETUDE_PATH)\nos.environ['PATH'] += ';' + ETUDE_PATH\nimport Etude\n\n### Create temp directory for file management ###\ntemporary_directory = tempfile.TemporaryDirectory()\ntmp_dir = temporary_directory.name\n\n#### Supress"
  },
  {
    "id": "chunk_2094",
    "text": ")\ntmp_dir = temporary_directory.name\n\n#### Supress all the PSSE outputs for now\npsspy.progress_output(2,tempfile.NamedTemporaryFile().name,[0,0]) #suppress progress output from PSS/E\npsspy.t_alert_output(2,tempfile.NamedTemporaryFile().name,[0,0]) #write t alerts from PSS/E to temp file\npsspy.alert_output(2,tempfile.NamedTemporaryFile().name,[0,0]) #write alerts from PSS/E to temp file\npsspy.report_output(2,tempfile.NamedTemporaryFile().name,[0,0]) #write report from PSS/E to temp file\n\n# list o"
  },
  {
    "id": "chunk_2095",
    "text": "]) #write report from PSS/E to temp file\n\n# list of cases to evaluate CNTB\ntarget_directory = r'E:\\NicoleL\\Planning\\SSWG\\23SSWG_U1_Cases_Logs_Reports_Pass9_09282023\\cases_and_logs'\ntarget_output_directory = r'E:\\NicoleL\\Planning\\SSWG\\23SSWG_U1_Cases_Logs_Reports_Pass9_09282023\\cases_and_logs\\CNTB_reports'\ncase_list = glob.glob(target_directory+r'\\*.raw')\n#print(case_list)\n\nfor case in case_list:\n    psspy.read(0,case) # open case\n    psspy.bsys(0,0,[0.48,345.],2,[7,907],0,[],0,[],0,[]) #set bsys"
  },
  {
    "id": "chunk_2096",
    "text": ",0,[0.48,345.],2,[7,907],0,[],0,[],0,[]) #set bsys to areas 7 and 907\n    temp_PSSE_output = tmp_dir+r'\\PSSE_capture.txt' #capture report output from PSS/E\n    \n    psspy.report_output(2,temp_PSSE_output,0) #capture report output from PSS/E\n    psspy.cntb(0,0,1,[0,0,0],[0.0,0.0]) #run CNTB \n    Etude.silenceAllPSSE() #silence the output so PSSE lets go of the tempfile\n\n    #write the report to a text document\n    rawfilename = os.path.splitext(os.path.basename(case))[0]\n    reportName = target_o"
  },
  {
    "id": "chunk_2097",
    "text": ".path.basename(case))[0]\n    reportName = target_output_directory+r'\\{}_CNTB_output.txt'.format(rawfilename)\n    f = open(reportName,'w')\n    f.write(Etude.getFileByteData(temp_PSSE_output).decode('UTF-8'))\n    f.close()\n    \n\n# Get Load stats with GUI\n\nimport wx\nimport pandas as pd\nimport pyodbc\nimport datetime\nfrom dateutil.relativedelta import relativedelta\nimport copy\nimport shutil\nimport os\nimport numpy as np\nimport sys\nimport tempfile\nimport xlsxwriter\nimport pathlib\nimport glob\nimport jso"
  },
  {
    "id": "chunk_2098",
    "text": "t xlsxwriter\nimport pathlib\nimport glob\nimport json\nimport requests\nimport logging\nimport struct\nimport time\nimport tkinter\nfrom tkinter import Tk\nfrom tkinter import Button\nfrom tkinter import filedialog\nimport warnings\n\n### Get psspy bin\nprint('Select the bin location for the PSSE psspy.pyc and redirect.pyc files. Please use PSSE 35.6.')\nroot = Tk()\nPSSE_PATH = filedialog.askdirectory(initialdir = r'C:\\Program Files\\PTI\\PSSE35')\nroot.mainloop\nif (pathlib.Path(r'{0}\\psspy.pyc'.format(PSSE_PATH)"
  },
  {
    "id": "chunk_2099",
    "text": "f (pathlib.Path(r'{0}\\psspy.pyc'.format(PSSE_PATH)).exists() == False) | (pathlib.Path(r'{0}\\redirect.pyc'.format(PSSE_PATH)).exists() == False):\n    print('No psspy.pyc and/or redirect.pyc package found at bin directory supplied {0}'.format(PSSE_PATH))\n    exit()\nroot.destroy()\n\n#### PSS/E session initialization ####\nsys.path.append(PSSE_PATH)\nos.environ['PATH'] += ';' + PSSE_PATH\nimport psspy\nimport redirect\nredirect.psse2py()                                  ## Set output to Python Shell\nierr"
  },
  {
    "id": "chunk_2100",
    "text": "                ## Set output to Python Shell\nierr = psspy.psseinit(0)                            ## Initialize PSSE\n\n# ignore warnings to avoid terminal message clutter.\nwarnings.filterwarnings('ignore')\n\n########### FUNCTION DEFINITIONS ###########\n\ndef getAccReportViolations(Report): # pass location of PSSE text acc report \n    File1 = open(Report,'br')    \n    Dict1 = File1.readlines()        \n    iter_Dict1 = iter(Dict1) # iterating over the iter, see https://stackoverflow.com/questions/215"
  },
  {
    "id": "chunk_2101",
    "text": " iter, see https://stackoverflow.com/questions/21594302/is-there-a-way-to-remember-the-position-in-a-python-iterator      \n    BrOL1 = None\n    SwdOL1 = None        \n    VoltOL1 = None      \n    LdLoss1 = None      \n    ConvRes1 = None\n    Con_File_Name1 = None\n    CA_Violations = None # adding this Nonetype assignment on 6/14/2021, not sure why but this appears to be a problem now with recent updates.\n\n    BrOL1 = pd.DataFrame(columns=['Monitored_Branch','Contingency_Label','Rating','MW','Mvar'"
  },
  {
    "id": "chunk_2102",
    "text": "d_Branch','Contingency_Label','Rating','MW','Mvar','MVA','%'])      \n    SwdOL1 = pd.DataFrame(columns=['Monitored_SWD','Contingency_Label','Rating','MW','Mvar','MVA','%','SWD_Loop'])\n    VoltOL1 = pd.DataFrame(columns=['System','Contingency_Label','Bus','V-Cont','V-Init','V-Max','V-Min'])        \n    LdLoss1 = pd.DataFrame(columns=['Bus','Contingency_Label','Load(MW)'])        \n    ConvRes1 = pd.DataFrame(columns=['Contingency_Label','Termination_State','Flow#','Volt#','Load'])        \n    Con_"
  },
  {
    "id": "chunk_2103",
    "text": "n_State','Flow#','Volt#','Load'])        \n    Con_File_Name1 = \"\"\n\n    #read report data into pandas dataframes\n\n    BrOL_fields = []\n    SwdOL_fields = []\n    VoltOL_fields = []\n    LdLoss_fields = []\n    ConvRes_fields = []\n\n    for line in iter_Dict1:\n        if \"CONTINGENCY DESCRIPTION FILE:\" in line.decode(\"utf-8\"):\n            Con_File_Name1 = line[30:]\n            break\n    for line in iter_Dict1:\n        #print line\n        if \"<--------------------- MONITORED BRANCH --------------------"
  },
  {
    "id": "chunk_2104",
    "text": "------------ MONITORED BRANCH ---------------------> <----- CONTINGENCY LABEL ------>   RATING       MW     Mvar      MVA      %\" in line.decode(\"utf-8\"):\n            #print \"Found Branch OL section of report\"\n            fieldwidths = (62,-1,32,-1,8,-1,8,-1,8,-1,8,-1,6) # field widths of ACCC report Branch OL section, negative width represent ignored padding fields\n            fmtstring = ' '.join('{}{}'.format(abs(fw), 'x' if fw < 0 else 's')\n                                    for fw in field"
  },
  {
    "id": "chunk_2105",
    "text": "                                   for fw in fieldwidths)\n            fieldstruct = struct.Struct(fmtstring)\n            parse = fieldstruct.unpack_from\n            break\n    for line in iter_Dict1:\n        if len(line.decode(\"utf-8\")) == 2: #= '\\n': #to find encoded newline, look for a line of length 2\n            #print \"Found end of Branch OL section of report (newline found)\"\n            BrOL1 = pd.DataFrame(data = BrOL_fields, columns=['Monitored_Branch','Contingency_Label','Rating','MW','M"
  },
  {
    "id": "chunk_2106",
    "text": "tored_Branch','Contingency_Label','Rating','MW','Mvar','MVA','%'])\n\n            break\n        #print parse(line)\n        BrOL_fields.append(parse(line))\n\n    for line in iter_Dict1:\n        #print line\n        if \"<-------- MONITORED  SWD --------> <----- CONTINGENCY LABEL ------>   RATING       MW     Mvar      MVA      %   SWD LOOP\" in line.decode(\"utf-8\"):\n            #print \"Found SWD OL section of report\"\n            fieldwidths = (34,-1,32,-1,8,-1,8,-1,8,-1,8,-1,6,-1,10) # field widths of "
  },
  {
    "id": "chunk_2107",
    "text": "-1,8,-1,8,-1,8,-1,8,-1,6,-1,10) # field widths of ACCC report SWD OL section, negative width represent ignored padding fields\n            fmtstring = ' '.join('{}{}'.format(abs(fw), 'x' if fw < 0 else 's')\n                                    for fw in fieldwidths)\n            fieldstruct = struct.Struct(fmtstring)\n            parse = fieldstruct.unpack_from\n            break\n    for line in iter_Dict1:\n        if len(line.decode(\"utf-8\")) == 2: #= '\\n': #to find encoded newline, look for a line "
  },
  {
    "id": "chunk_2108",
    "text": "= '\\n': #to find encoded newline, look for a line of length 2\n            #print \"Found end of SWD OL section of report (newline found)\"\n            SwdOL1 = pd.DataFrame(data = SwdOL_fields, columns=['Monitored_SWD','Contingency_Label','Rating','MW','Mvar','MVA','%','SWD_Loop'])\n\n            break\n        #print parse(line)\n        SwdOL_fields.append(parse(line))\n\n    for line in iter_Dict1:\n        if \"SYSTEM                                       <----- CONTINGENCY LABEL ------> <---------- B"
  },
  {
    "id": "chunk_2109",
    "text": "    <----- CONTINGENCY LABEL ------> <---------- B U S ---------->   V-CONT   V-INIT   V-MAX    V-MIN\" in line.decode(\"utf-8\"):\n            #print \"Found Voltage violation section of report\"\n            fieldwidths = (44,-1,32,-1,29,-1,8,-1,8,-1,7,-1,8) # field widths of ACCC report Thermal OL section, negative width represent ignored padding fields\n            fmtstring = ' '.join('{}{}'.format(abs(fw), 'x' if fw < 0 else 's')\n                                    for fw in fieldwidths)\n         "
  },
  {
    "id": "chunk_2110",
    "text": "                  for fw in fieldwidths)\n            fieldstruct = struct.Struct(fmtstring)\n            parse = fieldstruct.unpack_from\n            break\n    for line in iter_Dict1:\n        if len(line.decode(\"utf-8\")) == 2: #= '\\n': #to find encoded newline, look for a line of length 2\n            #print \"Found end of Voltage Violation section of report (newline found)\"\n            VoltOL1 = pd.DataFrame(data = VoltOL_fields, columns=['System','Contingency_Label','Bus','V-Cont','V-Init','V-Max'"
  },
  {
    "id": "chunk_2111",
    "text": "Contingency_Label','Bus','V-Cont','V-Init','V-Max','V-Min'])\n            break\n        #print parse(line)\n        VoltOL_fields.append(parse(line))\n    for line in iter_Dict1:\n        #print line\n        if \"<---------- B U S ----------> <----- CONTINGENCY LABEL ------> LOAD(MW)\" in line.decode(\"utf-8\"):\n            #print \"Found Load Loss section of report\"\n            fieldwidths = (29,-1,32,-1,8) # field widths of ACCC report Thermal OL section, negative width represent ignored padding fields"
  },
  {
    "id": "chunk_2112",
    "text": "n, negative width represent ignored padding fields\n            fmtstring = ' '.join('{}{}'.format(abs(fw), 'x' if fw < 0 else 's')\n                                    for fw in fieldwidths)\n            fieldstruct = struct.Struct(fmtstring)\n            parse = fieldstruct.unpack_from\n            break\n    for line in iter_Dict1:\n        if len(line.decode(\"utf-8\")) == 2: #= '\\n': #to find encoded newline, look for a line of length 2\n            #print \"Found end of Load Loss section of report (n"
  },
  {
    "id": "chunk_2113",
    "text": "print \"Found end of Load Loss section of report (newline found)\"\n            LdLoss1 = pd.DataFrame(data = LdLoss_fields, columns=['Bus','Contingency_Label','Load(MW)'])\n            break\n        #print parse(line)\n        LdLoss_fields.append(parse(line))\n\n    for line in iter_Dict1:\n        #print line\n        if \"<TERMINATION  STATE> FLOW#  SWD# VOLT#  LOAD\" in line.decode(\"utf-8\"):\n            #print \"Found Convergence section of report\"\n            fieldwidths = (32,20,-1,5,-1,5,-1,5,-1,5) "
  },
  {
    "id": "chunk_2114",
    "text": "        fieldwidths = (32,20,-1,5,-1,5,-1,5,-1,5) # field widths of ACCC report Thermal OL section, negative width represent ignored padding fields\n            fmtstring = ' '.join('{}{}'.format(abs(fw), 'x' if fw < 0 else 's')\n                                    for fw in fieldwidths)\n            fieldstruct = struct.Struct(fmtstring)\n            parse = fieldstruct.unpack_from\n            break\n    for line in iter_Dict1:\n        if len(line.decode(\"utf-8\")) == 2: #= '\\n': #to find encoded new"
  },
  {
    "id": "chunk_2115",
    "text": "code(\"utf-8\")) == 2: #= '\\n': #to find encoded newline, look for a line of length 2\n            #print \"Found end of Convergence section of report (newline found)\"\n            ConvRes1 = pd.DataFrame(data = ConvRes_fields, columns=['Contingency_Label','Termination_State','Flow#','SWD#','Volt#','Load'])               \n            break\n        #print parse(line)\n        ConvRes_fields.append(parse(line))\n\n    \n    BrOL1['ViolationType']=b'Br Thermal'\n    \n    SwdOL1['ViolationType']=b'SWD Thermal"
  },
  {
    "id": "chunk_2116",
    "text": "al'\n    \n    SwdOL1['ViolationType']=b'SWD Thermal'\n        \n    VoltOL1['ViolationType']=b'Voltage'\n    VoltOL1['Rating']=b'1'\n        \n    LdLoss1['ViolationType']=b'LdLoss'\n    LdLoss1['Rating']=b'0'\n        \n    ConvRes1['VioValue']=b'1'\n    ConvRes1['Rating']=b'0'\n    ConvRes1['Location']=ConvRes1['Contingency_Label']\n\n    CA_Violations = pd.DataFrame(columns=['ViolationType','Contingency','Location','VioValue','Rating'])\n    CA_Violations = CA_Violations.append([BrOL1[['ViolationType','Con"
  },
  {
    "id": "chunk_2117",
    "text": " CA_Violations.append([BrOL1[['ViolationType','Contingency_Label','Monitored_Branch','%','Rating']].rename(columns={'Contingency_Label':'Contingency', \\\n                    'Monitored_Branch':'Location','%':'VioValue'}),SwdOL1[['ViolationType','Contingency_Label','Monitored_SWD','%','Rating']].rename(columns={'Contingency_Label':'Contingency', \\\n                    'Monitored_SWD':'Location','%':'VioValue'}),VoltOL1[['ViolationType','Contingency_Label','Bus','V-Cont','Rating']].rename(columns={'"
  },
  {
    "id": "chunk_2118",
    "text": "Label','Bus','V-Cont','Rating']].rename(columns={'Contingency_Label':'Contingency', \\\n                    'Bus':'Location', 'V-Cont':'VioValue'}),LdLoss1[['ViolationType','Contingency_Label','Bus','Load(MW)','Rating']].rename(columns={'Contingency_Label':'Contingency', \\\n                    'Bus':'Location','Load(MW)':'VioValue'}),ConvRes1[['Contingency_Label','Termination_State','VioValue','Rating','Location']].rename \\\n                    (columns={'Contingency_Label':'Contingency','Terminatio"
  },
  {
    "id": "chunk_2119",
    "text": "mns={'Contingency_Label':'Contingency','Termination_State':'ViolationType'})],ignore_index=True,sort=False)\n    \n    #decode for human consumption\n    CA_Violations['ViolationType'] = CA_Violations['ViolationType'].str.decode(encoding = 'UTF-8')\n    CA_Violations['ViolationType'] = CA_Violations['ViolationType'].str.strip() #remove leading and trailing spaces\n    CA_Violations['Contingency'] = CA_Violations['Contingency'].str.decode(encoding = 'UTF-8')\n    CA_Violations['Contingency'] = CA_Viola"
  },
  {
    "id": "chunk_2120",
    "text": "TF-8')\n    CA_Violations['Contingency'] = CA_Violations['Contingency'].str.strip() #remove leading and trailing spaces \n    CA_Violations['Location'] = CA_Violations['Location'].str.decode(encoding = 'UTF-8')\n    CA_Violations['Location'] = CA_Violations['Location'].str.strip() #remove leading and trailing spaces\n    CA_Violations['VioValue'] = CA_Violations['VioValue'].str.decode(encoding = 'UTF-8')\n    CA_Violations['VioValue'] = CA_Violations['VioValue'].str.strip() #remove leading and traili"
  },
  {
    "id": "chunk_2121",
    "text": "'VioValue'].str.strip() #remove leading and trailing spaces\n    CA_Violations['VioValue'] = pd.to_numeric(CA_Violations['VioValue']) #convert strings to numbers\n    CA_Violations['Rating'] = CA_Violations['Rating'].str.decode(encoding = 'UTF-8')\n    CA_Violations['Rating'] = CA_Violations['Rating'].str.strip() #remove leading and trailing spaces\n    CA_Violations['Rating'] = pd.to_numeric(CA_Violations['Rating']) #convert strings to numbers\n\n    return CA_Violations\n\ndef getAllXFRData(CASELOCATI"
  },
  {
    "id": "chunk_2122",
    "text": "return CA_Violations\n\ndef getAllXFRData(CASELOCATION):\n    PSSEOpenCase(CASELOCATION)\n\n    SID = -1\n    \n    char_data_desired_2W = ['ID','XFRNAME','VECTORGROUP']\n    int_data_desired_2W = ['FROMNUMBER','TONUMBER','STATUS']\n    char_ierr_2W, carray_2W = psspy.atrnchar(SID, 1,3,2,1,char_data_desired_2W) #get all transformers, single entry\n    int_ierr_2W, iarray_2W = psspy.atrnint(SID, 1,3,2,1,int_data_desired_2W)\n\n    char_data_desired_3W = ['ID','XFRNAME','VECTORGROUP']\n    int_data_desired_3W "
  },
  {
    "id": "chunk_2123",
    "text": ",'XFRNAME','VECTORGROUP']\n    int_data_desired_3W = ['WIND1NUMBER','WIND2NUMBER','WIND3NUMBER','STATUS']\n    char_ierr_3W, carray_3W = psspy.atr3char(SID, 1,3,2,1, char_data_desired_3W) #get all transformers\n    int_ierr_3W, iarray_3W = psspy.atr3int(SID, 1,3,2,1,int_data_desired_3W)\n\n    if char_ierr_2W!=0 or int_ierr_2W!=0 or char_ierr_3W!=0 or int_ierr_3W!=0 : #check for errors and if any encountered, return empty dataframe\n        return pd.DataFrame(['Unable to get transformer data.'])\n    "
  },
  {
    "id": "chunk_2124",
    "text": "ataFrame(['Unable to get transformer data.'])\n    else:\n        # compile 2-winding XFR data into a dataframe\n        allColumns_2W = char_data_desired_2W+int_data_desired_2W\n        allData_2W = carray_2W+iarray_2W\n        DF_dict_2W = dict(zip(allColumns_2W,allData_2W))\n        DF_2W = pd.DataFrame(DF_dict_2W)\n        DF_2W = DF_2W.rename(columns={'FROMNUMBER':'WIND1NUMBER','TONUMBER':'WIND2NUMBER'}) #rename the columns for easier appending\n        # compile 3-winding XFR data into a dataframe"
  },
  {
    "id": "chunk_2125",
    "text": "     # compile 3-winding XFR data into a dataframe\n        allColumns_3W = char_data_desired_3W+int_data_desired_3W\n        allData_3W = carray_3W+iarray_3W\n        DF_dict_3W = dict(zip(allColumns_3W,allData_3W))\n        DF_3W = pd.DataFrame(DF_dict_3W)\n        # append the 2W and 3W data together\n        DF_all = DF_2W.append(DF_3W, ignore_index=True)\n        return DF_all\n\ndef getAllLineData(CASELOCATION):\n    PSSEOpenCase(CASELOCATION)\n\n    SID = -1\n    \n    char_data_desired = ['ID']\n    in"
  },
  {
    "id": "chunk_2126",
    "text": "ID = -1\n    \n    char_data_desired = ['ID']\n    int_data_desired = ['FROMNUMBER','TONUMBER','STATUS']\n    char_ierr, carray = psspy.abrnchar(SID, 1,3,2,1,char_data_desired) #get all branches, single entry\n    int_ierr, iarray = psspy.abrnint(SID, 1,3,2,1,int_data_desired) #get all branches, single entry\n\n    if SID != -1:\n        PSSE_SID_manager.decoupleDynamicSID(SID_manager,PSSESUBSYS)\n\n    if char_ierr!=0 or int_ierr!=0 : #check for errors and if any encountered, return empty dataframe\n     "
  },
  {
    "id": "chunk_2127",
    "text": "d if any encountered, return empty dataframe\n        return pd.DataFrame(['Unable to get line data.'])\n    else:\n        allColumns = char_data_desired+int_data_desired\n        allData = carray+iarray\n        DF_dict = dict(zip(allColumns,allData))\n        return pd.DataFrame(DF_dict)\n\ndef getAllFixedShuntData(CASELOCATION):\n    PSSEOpenCase(CASELOCATION)\n\n    SID = -1\n    \n    char_data_desired = ['ID','NAME']\n    complex_data_desired = ['O_SHUNTACT']\n    int_data_desired = ['NUMBER','STATION',"
  },
  {
    "id": "chunk_2128",
    "text": "TACT']\n    int_data_desired = ['NUMBER','STATION','STATUS']\n    char_ierr, carray = psspy.afxshuntchar(SID, 4, char_data_desired) #get for all machines and all buses\n    comp_ierr, xarray = psspy.afxshuntcplx(SID, 4, complex_data_desired)\n    int_ierr, iarray = psspy.afxshuntint(SID, 4, int_data_desired)\n\n    if char_ierr!=0 or comp_ierr!=0 or int_ierr!=0 : #check for errors and if any encountered, return empty dataframe\n        return pd.DataFrame(['Unable to get case fixed shunt data.'])\n    e"
  },
  {
    "id": "chunk_2129",
    "text": "me(['Unable to get case fixed shunt data.'])\n    else:\n        allColumns = char_data_desired+complex_data_desired+int_data_desired\n        allData = carray+xarray+iarray\n        DF_dict = dict(zip(allColumns,allData))\n        return pd.DataFrame(DF_dict)\n\ndef getAllSwShuntData(CASELOCATION):\n\n    PSSEOpenCase(CASELOCATION)\n\n    SID = -1\n    \n    char_data_desired = ['ID','NAME']\n    complex_data_desired = ['O_YSWACT']\n    int_data_desired = ['NUMBER','STATION', 'AREA', 'ZONE', 'STATUS','OWNER']"
  },
  {
    "id": "chunk_2130",
    "text": "MBER','STATION', 'AREA', 'ZONE', 'STATUS','OWNER']\n    char_ierr, carray = psspy.aswshchar(SID, 4, char_data_desired) #get for all machines and all buses\n    comp_ierr, xarray = psspy.aswshcplx(SID, 4, complex_data_desired)\n    int_ierr, iarray = psspy.aswshint(SID, 4, int_data_desired)\n\n    if char_ierr!=0 or comp_ierr!=0 or int_ierr!=0 : #check for errors and if any encountered, return empty dataframe\n        return pd.DataFrame(['Unable to get case switched shunt data.'])\n    else:\n        al"
  },
  {
    "id": "chunk_2131",
    "text": " case switched shunt data.'])\n    else:\n        allColumns = char_data_desired+complex_data_desired+int_data_desired\n        allData = carray+xarray+iarray\n        DF_dict = dict(zip(allColumns,allData))\n        return pd.DataFrame(DF_dict)\n\ndef getAllLoadData(CASELOCATION):\n    PSSEOpenCase(CASELOCATION)\n    \n    SID = -1\n    \n    char_data_desired = ['ID','NAME','LODTYPE']\n    complex_data_desired = ['TOTALACT']\n    int_data_desired = ['NUMBER','STATION', 'AREA', 'ZONE', 'STATUS','OWNER','SCAL"
  },
  {
    "id": "chunk_2132",
    "text": ",'STATION', 'AREA', 'ZONE', 'STATUS','OWNER','SCALE','INTRPT']\n    char_ierr, carray = psspy.aloadchar(SID, 4, char_data_desired) #get for all machines and all buses\n    comp_ierr, xarray = psspy.aloadcplx(SID, 4, complex_data_desired)\n    int_ierr, iarray = psspy.aloadint(SID, 4, int_data_desired)\n\n    if char_ierr!=0 or comp_ierr!=0 or int_ierr!=0 : #check for errors and if any encountered, return empty dataframe\n        return pd.DataFrame(['Unable to get case load data.'])\n    else:\n        "
  },
  {
    "id": "chunk_2133",
    "text": "nable to get case load data.'])\n    else:\n        allColumns = char_data_desired+complex_data_desired+int_data_desired\n        allData = carray+xarray+iarray\n        DF_dict = dict(zip(allColumns,allData))\n        return pd.DataFrame(DF_dict)\n\ndef getAllBusData(CASELOCATION):\n    PSSEOpenCase(CASELOCATION)\n    SID = -1\n    \n    char_data_desired = ['NAME','EXNAME']\n    real_data_desired = ['BASE','NVLMLO','NVLMHI','EVLMLO','EVLMHI']\n    int_data_desired = ['NUMBER','AREA','OWNER','ZONE']\n    cha"
  },
  {
    "id": "chunk_2134",
    "text": "desired = ['NUMBER','AREA','OWNER','ZONE']\n    char_ierr, carray = psspy.abuschar(SID, 2, char_data_desired) \n    comp_ierr, xarray = psspy.abusreal(SID, 2, real_data_desired)\n    int_ierr, iarray = psspy.abusint(SID, 2, int_data_desired)\n\n    if char_ierr!=0 or comp_ierr!=0 or int_ierr!=0 : #check for errors and if any encountered, return empty dataframe\n        return pd.DataFrame(['Unable to get bus data. char_ierr = {0}, comp_ierr = {1}, int_ierr = {2}. SID = {3}'.format(char_ierr,comp_ierr,"
  },
  {
    "id": "chunk_2135",
    "text": "ierr = {2}. SID = {3}'.format(char_ierr,comp_ierr,int_ierr,SID)])\n    else:\n        allColumns = char_data_desired+real_data_desired+int_data_desired\n        allData = carray+xarray+iarray\n        DF_dict = dict(zip(allColumns,allData))\n        return pd.DataFrame(DF_dict)\n\ndef PSSESetSubSystem(SID,USEKV,BASEKV,NUMAREA,AREAS,NUMBUS,BUSES,NUMOWNER,OWNERS,NUMZONE,ZONES): \n    ierr = psspy.bsys(SID,USEKV,BASEKV,NUMAREA,AREAS,NUMBUS,BUSES,NUMOWNER,OWNERS,NUMZONE,ZONES)\n    if ierr != 0:\n        rais"
  },
  {
    "id": "chunk_2136",
    "text": "NERS,NUMZONE,ZONES)\n    if ierr != 0:\n        raise RuntimeError('PSSESetSubSystem did not work. the psspy.bsys ierr returned is: {}'.format(ierr))\n    return ierr\n\ndef PSSESaveCase(PSSESAVECASE):\n    ierr = psspy.save(PSSESAVECASE) #save case\n    if ierr != 0: \n        raise RuntimeError('PSSPY error code {} when calling psspy.save(). See PSSE API documentation for details.'.format(ierr))\n        sys.exit()\n    return ierr\n\ndef getBusInconsistencies():\n    \n    in_service_branches = psspy.abrni"
  },
  {
    "id": "chunk_2137",
    "text": "cies():\n    \n    in_service_branches = psspy.abrnint(-1,1,3,1,1,['FROMNUMBER','TONUMBER','STATUS','FROMSECTION','TOSECTION'])[1] #in_service_branches[0] is list of FROMBUS's, n_service_branches[1] is list of TOBUS's\n    # make df for in_service_br_busses\n    from_buses = pd.DataFrame({'Bus Number':in_service_branches[0],'Bus Section':in_service_branches[3]})\n    to_buses = pd.DataFrame({'Bus Number':in_service_branches[1],'Bus Section':in_service_branches[4]})\n    in_service_br_busses = pd.conca"
  },
  {
    "id": "chunk_2138",
    "text": "_branches[4]})\n    in_service_br_busses = pd.concat([from_buses,to_buses],ignore_index=True)\n    in_service_br_busses = in_service_br_busses.drop_duplicates() #drop duplicates to avoid duplicating work\n\n        \n    all_busses = psspy.abusint(-1,2,['NUMBER','TYPE','SECTION','AREA'])[1] #all_busses[0] is list of busses, all_busses[1] is list of statuses, all_busses[2] is list of sections\n    #make df for all buses\n    buses = pd.DataFrame({'Bus Number':all_busses[0],'Bus Section':all_busses[2],'B"
  },
  {
    "id": "chunk_2139",
    "text": "mber':all_busses[0],'Bus Section':all_busses[2],'Bus Type':all_busses[1],'Bus Area':all_busses[3]})\n        \n    in_service_2w_xfr = psspy.atrnint(-1,1,3,1,1,['FROMNUMBER','TONUMBER','STATUS','FROMSECTION','TOSECTION'])[1] #this only returns in-service transformers\n    from_bus_2w_xfr = pd.DataFrame({'Bus Number':in_service_2w_xfr[0],'Bus Section':in_service_2w_xfr[3]})\n    to_bus_2w_xfr = pd.DataFrame({'Bus Number':in_service_2w_xfr[1],'Bus Section':in_service_2w_xfr[4]})\n    in_service_2w_xfr_"
  },
  {
    "id": "chunk_2140",
    "text": "ion':in_service_2w_xfr[4]})\n    in_service_2w_xfr_buses = pd.concat([from_bus_2w_xfr,to_bus_2w_xfr],ignore_index=True)\n    in_service_2w_xfr_buses = in_service_2w_xfr_buses.drop_duplicates()\n\n    in_service_3w_xfr = psspy.atr3int(-1,1,3,1,1,['WIND1NUMBER','WIND2NUMBER','WIND3NUMBER','STATUS','WIND1SECTION','WIND2SECTION','WIND3SECTION'])[1]\n\n    # make in_service_3w_xfr_buses a dataframe\n    in_service_3w_xfr_buses = pd.DataFrame()\n    #make dataframe for more sophisticated data comparison\n    i"
  },
  {
    "id": "chunk_2141",
    "text": "frame for more sophisticated data comparison\n    in_service_3w_xfr_df = pd.DataFrame({'WIND1NUMBER':in_service_3w_xfr[0],'WIND2NUMBER':in_service_3w_xfr[1],'WIND3NUMBER':in_service_3w_xfr[2],'STATUS':in_service_3w_xfr[3],'WIND1SECTION':in_service_3w_xfr[4],'WIND2SECTION':in_service_3w_xfr[5],'WIND3SECTION':in_service_3w_xfr[6]})\n    # get in service buses for status = 1\n    stat1_df = in_service_3w_xfr_df.loc[in_service_3w_xfr_df['STATUS']==1]\n    for entry in stat1_df.index:\n        in_service "
  },
  {
    "id": "chunk_2142",
    "text": "  for entry in stat1_df.index:\n        in_service = pd.DataFrame({'Bus Number':[stat1_df.at[entry,'WIND1NUMBER'],stat1_df.at[entry,'WIND2NUMBER'],stat1_df.at[entry,'WIND3NUMBER']], \\\n            'Bus Section':[stat1_df.at[entry,'WIND1SECTION'],stat1_df.at[entry,'WIND2SECTION'],stat1_df.at[entry,'WIND3SECTION']]}) #all windings in-service when status = 1\n        in_service_3w_xfr_buses = pd.concat([in_service_3w_xfr_buses,in_service],ignore_index=True)\n\n    # get in service buses for status = 2\n "
  },
  {
    "id": "chunk_2143",
    "text": "True)\n\n    # get in service buses for status = 2\n    stat2_df = in_service_3w_xfr_df.loc[in_service_3w_xfr_df['STATUS']==2]\n    for entry in stat2_df.index:\n        in_service = pd.DataFrame({'Bus Number':[stat2_df.at[entry,'WIND1NUMBER'],stat2_df.at[entry,'WIND3NUMBER']], \\\n            'Bus Section':[stat2_df.at[entry,'WIND1SECTION'],stat2_df.at[entry,'WIND3SECTION']]}) #windings 1 and 3 in-service when status = 2\n        in_service_3w_xfr_buses = pd.concat([in_service_3w_xfr_buses,in_service],"
  },
  {
    "id": "chunk_2144",
    "text": " = pd.concat([in_service_3w_xfr_buses,in_service],ignore_index=True)\n    # get in service buses for status = 3\n    stat3_df = in_service_3w_xfr_df.loc[in_service_3w_xfr_df['STATUS']==3]\n    for entry in stat3_df.index:\n        in_service = pd.DataFrame({'Bus Number':[stat3_df.at[entry,'WIND1NUMBER'],stat3_df.at[entry,'WIND2NUMBER']], \\\n            'Bus Section':[stat3_df.at[entry,'WIND1SECTION'],stat3_df.at[entry,'WIND2SECTION']]}) #windings 1 and 2 in-service when status = 3\n        in_service_"
  },
  {
    "id": "chunk_2145",
    "text": "d 2 in-service when status = 3\n        in_service_3w_xfr_buses = pd.concat([in_service_3w_xfr_buses,in_service],ignore_index=True)\n    # get in service buses for status = 4\n    stat4_df = in_service_3w_xfr_df.loc[in_service_3w_xfr_df['STATUS']==4]\n    for entry in stat4_df.index:\n        in_service = pd.DataFrame({'Bus Number':[stat4_df.at[entry,'WIND2NUMBER'],stat4_df.at[entry,'WIND3NUMBER']], \\\n            'Bus Section':[stat4_df.at[entry,'WIND2SECTION'],stat4_df.at[entry,'WIND3SECTION']]}) #w"
  },
  {
    "id": "chunk_2146",
    "text": "2SECTION'],stat4_df.at[entry,'WIND3SECTION']]}) #windings 2 and 3 in-service when status = 4\n        in_service_3w_xfr_buses = pd.concat([in_service_3w_xfr_buses,in_service],ignore_index=True)\n\n    all_in_service_element_buses = pd.concat([in_service_br_busses,in_service_2w_xfr_buses,in_service_3w_xfr_buses],ignore_index=True)\n    all_in_service_element_buses = all_in_service_element_buses.drop_duplicates()\n    all_in_service_element_buses['Has in-service branches'] = 'True'\n\n    bus_summary = p"
  },
  {
    "id": "chunk_2147",
    "text": "n-service branches'] = 'True'\n\n    bus_summary = pd.merge(buses,all_in_service_element_buses,on=['Bus Number','Bus Section'],how='left')\n    results_to_return = bus_summary.loc[(((bus_summary['Bus Type'] == 1)|(bus_summary['Bus Type'] == 2))&(bus_summary['Has in-service branches'] != 'True'))\\\n        |((bus_summary['Bus Type'] == 4)&(bus_summary['Has in-service branches'] == 'True'))]\n    \n    return results_to_return\n\ndef getFileByteData(GETBYTEDATAFILE):\n    try:\n        if type(GETBYTEDATAFI"
  },
  {
    "id": "chunk_2148",
    "text": "EDATAFILE):\n    try:\n        if type(GETBYTEDATAFILE) == tempfile._TemporaryFileWrapper:\n            FileByteData = GETBYTEDATAFILE.read()\n            GETBYTEDATAFILE.seek(0)\n        else:\n            f = open(GETBYTEDATAFILE,'r+b')\n            FileByteData = f.read()\n            f.close()\n        return FileByteData\n    except:\n        raise RuntimeError('There was a problem reading the data from {}. Check the file.'.format(GETBYTEDATAFILE))\n        sys.exit()\n\ndef silenceAllPSSE():\n    psspy.s"
  },
  {
    "id": "chunk_2149",
    "text": "     sys.exit()\n\ndef silenceAllPSSE():\n    psspy.set_progress_verbose(0) #set to limit messages\n    psspy.progress_output(2,tempfile.NamedTemporaryFile().name,[0,0]) #silence progress output from PSS/E\n    psspy.report_output(2,tempfile.NamedTemporaryFile().name,[0,0]) #silence report output from PSS/E to temp file\n    psspy.t_alert_output(2,tempfile.NamedTemporaryFile().name,[0,0]) #silence alert output\n    psspy.alert_output(2,tempfile.NamedTemporaryFile().name,[0,0]) #silece alert outputs\n\nde"
  },
  {
    "id": "chunk_2150",
    "text": "poraryFile().name,[0,0]) #silece alert outputs\n\ndef PSSEOpenCase(PSSEOPENCASE):\n    if pathlib.Path(PSSEOPENCASE).suffix == '.sav':\n        ierr = psspy.case(PSSEOPENCASE) #open case\n        if ierr != 0: \n            raise RuntimeError('PSSPY error code {0} when calling psspy.case({1}). See PSSE API documentation for details.'.format(ierr,PSSEOPENCASE))\n            sys.exit()\n    if pathlib.Path(PSSEOPENCASE).suffix == '.raw':\n        ierr = psspy.read(0,PSSEOPENCASE)\n        if ierr != 0: \n   "
  },
  {
    "id": "chunk_2151",
    "text": "py.read(0,PSSEOPENCASE)\n        if ierr != 0: \n            raise RuntimeError('PSSPY error code {0} when calling psspy.read(0,{1}). See PSSE API documentation for details.'.format(ierr,PSSEOPENCASE))\n            sys.exit()\n    return ierr\n\ndef make_clickable(url, name):\n    return '<a href=\"{}\" rel=\"noopener noreferrer\" target=\"_blank\">{}</a>'.format(url,name)\n\ndef makeTempDirectory():\n    ### Create temp directory for file management ###\n    temporary_directory = tempfile.TemporaryDirectory()\n "
  },
  {
    "id": "chunk_2152",
    "text": "porary_directory = tempfile.TemporaryDirectory()\n    tmp_dir = temporary_directory.name\n    print('Created temp directory {0}.'.format(tmp_dir))\n    return temporary_directory\n\ndef suppressAllPSSEOutputs():\n    #### Supress all the PSSE outputs for now\n    psspy.progress_output(2,tempfile.NamedTemporaryFile().name,[0,0]) #suppress progress output from PSS/E\n    psspy.t_alert_output(2,tempfile.NamedTemporaryFile().name,[0,0]) #write t alerts from PSS/E to temp file\n    psspy.alert_output(2,tempfi"
  },
  {
    "id": "chunk_2153",
    "text": "PSS/E to temp file\n    psspy.alert_output(2,tempfile.NamedTemporaryFile().name,[0,0]) #write alerts from PSS/E to temp file\n    psspy.report_output(2,tempfile.NamedTemporaryFile().name,[0,0]) #write report from PSS/E to temp file\n\ndef getCNTBCheckData(tmp_dir,SAVLOCATION,target_output_directory,rawfilename,CNTB_messages,areaList):\n    #tmp_dir_CNTB = makeTempDirectory().name\n    PSSEOpenCase(SAVLOCATION) #open the save case\n    psspy.bsys(0,0,[0.48,345.],len(areaList),areaList,0,[],0,[],0,[]) #s"
  },
  {
    "id": "chunk_2154",
    "text": "48,345.],len(areaList),areaList,0,[],0,[],0,[]) #set bsys to areas provided by the user\n    temp_PSSE_output = tmp_dir+r'\\PSSE_capture.txt' #capture report output from PSS/E\n    \n    ierr = psspy.report_output(2,temp_PSSE_output,0) #capture report output from PSS/E\n    if ierr != 0:\n        raise RuntimeError('Problem calling psspy.report_output. Directory location: {0}. ierr = {1}'.format(temp_PSSE_output,ierr))\n    psspy.cntb(0,0,1,[0,0,0],[0.0,0.0]) #run CNTB \n    silenceAllPSSE() #silence th"
  },
  {
    "id": "chunk_2155",
    "text": ",0.0]) #run CNTB \n    silenceAllPSSE() #silence the output so PSSE lets go of the tempfile\n    # PSSESaveCase(target_output_directory+r'\\{0}.sav'.format(rawfilename))\n    # PSSECloseCase()\n    #write the report to a text document\n    data_to_write = getFileByteData(temp_PSSE_output).decode('UTF-8')\n    \n    # reportName = target_output_directory+r'\\text_reports\\{}_CNTB_output.txt'.format(rawfilename)\n    # f = open(reportName,'w')\n    # f.write(data_to_write)\n    # f.close()\n\n    #partition the "
  },
  {
    "id": "chunk_2156",
    "text": "ata_to_write)\n    # f.close()\n\n    #partition the data to put in a csv for easier reading\n    message_delimiter = '\\nBus '\n    all_messages = data_to_write.split(message_delimiter)\n    CNTB_messages_tmp = pd.DataFrame({'{0}'.format(rawfilename):all_messages})\n    CNTB_messages_tmp['{0}'.format(rawfilename)] = 'Bus '+CNTB_messages_tmp['{0}'.format(rawfilename)]\n    CNTB_messages_tmp['Bus'] = CNTB_messages_tmp['{0}'.format(rawfilename)]\n    CNTB_messages_tmp['Area'] =CNTB_messages_tmp['Bus'].str.e"
  },
  {
    "id": "chunk_2157",
    "text": "ssages_tmp['Area'] =CNTB_messages_tmp['Bus'].str.extract(r'area ([0-9]+)')\n    CNTB_messages_tmp['Bus'] = CNTB_messages_tmp['Bus'].str.extract(r'Bus ([0-9]+)') #CNTB_messages_tmp['Bus'].str.slice(stop=10).str.rstrip().str.rstrip('[')\n    CNTB_messages_tmp.loc[CNTB_messages_tmp['{0}'.format(rawfilename)].str.contains('Warning'),'Type'] = 'Warning'\n    CNTB_messages_tmp.loc[CNTB_messages_tmp['{0}'.format(rawfilename)].str.contains('ERROR'),'Type'] = 'ERROR'\n\n    CNTB_messages_tmp.loc[CNTB_messages"
  },
  {
    "id": "chunk_2158",
    "text": "= 'ERROR'\n\n    CNTB_messages_tmp.loc[CNTB_messages_tmp['Type'].isnull(),'Type'] = 'Other'\n    CNTB_messages_tmp = CNTB_messages_tmp[['Bus','Area','Type','{0}'.format(rawfilename)]]\n    CNTB_messages_tmp = CNTB_messages_tmp.loc[(CNTB_messages_tmp['Type']=='ERROR')|(CNTB_messages_tmp['Type']=='Warning')]\n    #CNTB_messages_tmp.to_csv(target_output_directory+'\\CNTB_messages_tmp.csv')\n\n    if CNTB_messages.empty == True:\n        CNTB_messages = CNTB_messages_tmp #pd.concat([CNTB_messages,CNTB_messag"
  },
  {
    "id": "chunk_2159",
    "text": "messages_tmp #pd.concat([CNTB_messages,CNTB_messages_tmp],ignore_index=True)\n        CNTB_messages = CNTB_messages.drop_duplicates() #drop duplicate values to keep the dataset smaller\n    else:\n        CNTB_messages = pd.merge(CNTB_messages,CNTB_messages_tmp,how='outer',on=['Bus','Area','Type'])\n        CNTB_messages = CNTB_messages.drop_duplicates() #drop duplicate values to keep the dataset smaller\n    return CNTB_messages\n\ndef getBusData(savLocation,target_output_directory,rawfilename,BusData"
  },
  {
    "id": "chunk_2160",
    "text": "cation,target_output_directory,rawfilename,BusData,areaList):\n    \n    busData_tmp = getAllBusData(savLocation)\n    #busData_tmp.to_csv(target_output_directory+r'\\busData_tmp.csv')\n    allBusesInSelectedAreas = busData_tmp.loc[(busData_tmp['AREA'].isin(areaList))]\n    allBusesInSelectedAreas = allBusesInSelectedAreas[['NUMBER','NAME','AREA','OWNER','NVLMLO','NVLMHI','EVLMLO','EVLMHI']]\n    allBusesInSelectedAreas = allBusesInSelectedAreas.round({'NVLMLO':2,'NVLMHI':2,'EVLMLO':2,'EVLMHI':2})\n    "
  },
  {
    "id": "chunk_2161",
    "text": "'NVLMLO':2,'NVLMHI':2,'EVLMLO':2,'EVLMHI':2})\n    allBusesInSelectedAreas['{0}'.format(rawfilename)]='TRUE'\n\n    if BusData.empty == True:\n        BusData = allBusesInSelectedAreas #pd.concat([CNTB_messages,CNTB_messages_tmp],ignore_index=True)\n        BusData = BusData.drop_duplicates() #drop duplicate values to keep the dataset smaller\n    else:\n        BusData = pd.merge(BusData,allBusesInSelectedAreas,how='outer',on=['NUMBER','NAME','AREA','OWNER','NVLMLO','NVLMHI','EVLMLO','EVLMHI'])\n      "
  },
  {
    "id": "chunk_2162",
    "text": "WNER','NVLMLO','NVLMHI','EVLMLO','EVLMHI'])\n        BusData = BusData.drop_duplicates() #drop duplicate values to keep the dataset smaller\n\n    #BusData = BusData.round({'NVLMLO':2,'NVLMHI':2,'EVLMLO':2,'EVLMHI':2})\n    return BusData\n\ndef get900kBuses(BusData):\n    all900k_buses = BusData.loc[BusData['NUMBER']>=900000]\n    return all900k_buses\n\ndef getLdData(savLocation,allLoads,rawfilename,areaList):\n    # Get load data to report on any 0-MVA or disconnected loads in selected areas\n    loadDat"
  },
  {
    "id": "chunk_2163",
    "text": "r disconnected loads in selected areas\n    loadData_tmp = getAllLoadData(savLocation)\n    loadData_tmp = loadData_tmp.loc[(loadData_tmp['AREA'].isin(areaList))] # only keep the selected areas\n    loadData_tmp = loadData_tmp[['ID','NAME','LODTYPE','TOTALACT','NUMBER','STATION','AREA','ZONE','STATUS','OWNER']]\n    loadData_tmp['{0}'.format(rawfilename)]='TRUE'\n    if allLoads.empty == True:\n        allLoads = loadData_tmp\n        allLoads = allLoads.drop_duplicates()\n    else:\n        allLoads = a"
  },
  {
    "id": "chunk_2164",
    "text": "s.drop_duplicates()\n    else:\n        allLoads = allLoads.merge(loadData_tmp,how='outer',on=['ID','NAME','LODTYPE','TOTALACT','NUMBER','STATION','AREA','ZONE','STATUS','OWNER'])\n        allLoads = allLoads.drop_duplicates()\n    return loadData_tmp\n\ndef getLdDataTotalsReportedInCaseColumn(savLocation,allLoads,rawfilename,areaList):\n    # Get load data to report on any 0-MVA or disconnected loads in selected areas\n    loadData_tmp = getAllLoadData(savLocation)\n    loadData_tmp = loadData_tmp.loc[("
  },
  {
    "id": "chunk_2165",
    "text": "savLocation)\n    loadData_tmp = loadData_tmp.loc[(loadData_tmp['AREA'].isin(areaList))] # only keep the selected areas\n    loadData_tmp = loadData_tmp[['ID','NAME','LODTYPE','TOTALACT','NUMBER','STATION','AREA','ZONE','STATUS','OWNER']]\n    loadData_tmp['{0}'.format(rawfilename)]=loadData_tmp['TOTALACT']\n    loadData_tmp = loadData_tmp[['ID','NAME','LODTYPE','NUMBER','STATION','AREA','ZONE','STATUS','OWNER','{0}'.format(rawfilename)]]\n    if allLoads.empty == True:\n        allLoads = loadData_tm"
  },
  {
    "id": "chunk_2166",
    "text": "oads.empty == True:\n        allLoads = loadData_tmp\n        allLoads = allLoads.drop_duplicates()\n    else:\n        allLoads = allLoads.merge(loadData_tmp,how='outer',on=['ID','NAME','LODTYPE','NUMBER','STATION','AREA','ZONE','STATUS','OWNER'])\n        allLoads = allLoads.drop_duplicates()\n    return loadData_tmp\n\ndef getDisconnectedLoads(loadData_tmp,allDisconnectedLds):\n    disconnectedLds = loadData_tmp.loc[loadData_tmp['STATUS']==0]\n    if allDisconnectedLds.empty == True:\n        allDisconn"
  },
  {
    "id": "chunk_2167",
    "text": "lDisconnectedLds.empty == True:\n        allDisconnectedLds = disconnectedLds\n        allDisconnectedLds = allDisconnectedLds.drop_duplicates()\n    else:\n        allDisconnectedLds = allDisconnectedLds.merge(disconnectedLds,how='outer',on=['ID','NAME','LODTYPE','TOTALACT','NUMBER','STATION','AREA','ZONE','STATUS','OWNER'])\n        allDisconnectedLds = allDisconnectedLds.drop_duplicates()\n    return allDisconnectedLds\n\ndef getZeroLoads(loadData_tmp,allZeroLds):\n    zeroLds = loadData_tmp.loc[loadD"
  },
  {
    "id": "chunk_2168",
    "text": ",allZeroLds):\n    zeroLds = loadData_tmp.loc[loadData_tmp['TOTALACT']==complex(0,0)]\n    if allZeroLds.empty == True:\n        allZeroLds = zeroLds\n        allZeroLds = allZeroLds.drop_duplicates()\n    else:\n        allZeroLds = allZeroLds.merge(zeroLds,how='outer',on=['ID','NAME','LODTYPE','TOTALACT','NUMBER','STATION','AREA','ZONE','STATUS','OWNER'])\n        allZeroLds = allZeroLds.drop_duplicates()\n    return allZeroLds\n\ndef getDisconnectedShunts(savLocation,rawfilename,alldisconnected_shunts,"
  },
  {
    "id": "chunk_2169",
    "text": "ts(savLocation,rawfilename,alldisconnected_shunts,areaList):\n    # find shunt devices that are in a status of disconnected\n    SwShunts = getAllSwShuntData(savLocation)\n    SwShunts = SwShunts.loc[SwShunts['AREA'].isin(areaList)] # filter down to the specific requested areas\n    disconnected_SwShunts = SwShunts.loc[SwShunts['STATUS']==0]\n    disconnected_SwShunts = disconnected_SwShunts[['ID','NAME','NUMBER','AREA','STATUS']]\n    FixedShunts = getAllFixedShuntData(savLocation)\n    BusAreaMap = g"
  },
  {
    "id": "chunk_2170",
    "text": "tAllFixedShuntData(savLocation)\n    BusAreaMap = getAllBusData(savLocation)[['NUMBER','AREA']]\n    FixedShunts = FixedShunts.merge(BusAreaMap,how='left',on='NUMBER')\n    FixedShunts = FixedShunts.loc[FixedShunts['AREA'].isin(areaList)] # filter down to the specific requested areas\n    disconnected_FixedShunts = FixedShunts.loc[FixedShunts['STATUS']==0]\n    disconnected_FixedShunts = disconnected_FixedShunts[['ID','NAME','NUMBER','AREA','STATUS']]\n    disconnected_shunts = pd.concat([disconnected"
  },
  {
    "id": "chunk_2171",
    "text": "\n    disconnected_shunts = pd.concat([disconnected_SwShunts,disconnected_FixedShunts],ignore_index=True)\n\n    disconnected_shunts['{0}'.format(rawfilename)] = 'TRUE'\n\n    if alldisconnected_shunts.empty == True:\n        alldisconnected_shunts = disconnected_shunts\n        alldisconnected_shunts = alldisconnected_shunts.drop_duplicates()\n    else:\n        alldisconnected_shunts = alldisconnected_shunts.merge(disconnected_shunts,how='outer',on=['ID','NAME','NUMBER','AREA','STATUS'])\n        alldis"
  },
  {
    "id": "chunk_2172",
    "text": "','NAME','NUMBER','AREA','STATUS'])\n        alldisconnected_shunts = alldisconnected_shunts.drop_duplicates()  \n    return alldisconnected_shunts\n\ndef getAllBusInconsistencies(rawfilename,allBusInconsistencies):\n    # Get bus inconsistencies\n    caseBusInconsistencies = getBusInconsistencies()\n    caseBusInconsistencies['{0}'.format(rawfilename)] = 'TRUE'\n    if allBusInconsistencies.empty == True:\n        allBusInconsistencies = caseBusInconsistencies\n        allBusInconsistencies=allBusInconsi"
  },
  {
    "id": "chunk_2173",
    "text": "encies\n        allBusInconsistencies=allBusInconsistencies.drop_duplicates()\n    else:\n        allBusInconsistencies = pd.merge(allBusInconsistencies,caseBusInconsistencies,how='outer',on=['Bus Number','Bus Section','Bus Type','Bus Area','Has in-service branches'])\n        allBusInconsistencies=allBusInconsistencies.drop_duplicates()\n    return allBusInconsistencies\n\ndef getTREEIslands(tmp_dir,rawfilename,allIslands):\n    # Run TREE to get island information\n    # prepare a report to capture TRE"
  },
  {
    "id": "chunk_2174",
    "text": " information\n    # prepare a report to capture TREE outputs \n    caseTreeData = []\n    temp_TREE_output = tmp_dir+r'\\TREE_capture.txt' #capture report output from PSS/E   \n    psspy.progress_output(2,temp_TREE_output,0) #capture report output from PSS/E\n    ierr, num_island_buses = psspy.tree(1,0) #initialize TREE \n    while num_island_buses > 0:\n        silenceAllPSSE() #silence the output so PSSE lets go of the tempfile\n        tree_data = getFileByteData(temp_TREE_output).decode('UTF-8')\n    "
  },
  {
    "id": "chunk_2175",
    "text": "ileByteData(temp_TREE_output).decode('UTF-8')\n        os.remove(temp_TREE_output) #get rid of the temp file\n        save_data = tree_data.split('ISLAND:\\r\\n')[1] #get data to save\n        caseTreeData.append(save_data)\n        psspy.progress_output(2,temp_TREE_output,0) #capture report output from PSS/E\n        ierr, num_island_buses = psspy.tree(2,0) # leave the current island alone and run TREE again check for another island\n\n    psspy.progress_output(2,tempfile.NamedTemporaryFile().name,[0,0]"
  },
  {
    "id": "chunk_2176",
    "text": "_output(2,tempfile.NamedTemporaryFile().name,[0,0]) #suppress progress output from PSS/E \n    CaseTreeIslands = pd.DataFrame({'Island':caseTreeData})\n    CaseTreeIslands['{0}'.format(rawfilename)] = 'TRUE'\n    if allIslands.empty == True:\n        allIslands = CaseTreeIslands\n        allIslands = allIslands.drop_duplicates()\n    else:\n        allIslands = pd.merge(allIslands,CaseTreeIslands,how='outer',on='Island')\n        allIslands = allIslands.drop_duplicates()\n    return allIslands\n\ndef getPS"
  },
  {
    "id": "chunk_2177",
    "text": "drop_duplicates()\n    return allIslands\n\ndef getPSSEpfChecks(tmp_dir,rawfilename,allPFCheckResults,allPFCheckTypes,areaList):\n    # run the PSSE powerflow checks for the case\n    SID_for_checks = 1\n    PSSESetSubSystem(SID=SID_for_checks,USEKV=1,BASEKV=1,NUMAREA=len(areaList),AREAS=areaList,NUMBUS=0,BUSES=[],NUMOWNER=0,OWNERS=[],NUMZONE=0,ZONES=[])\n    #psspy.bsys(0,0,[0.48,345.],1,[],0,[],0,[],0,[]) # set SID 0\n    for checkType in allPFCheckTypes.keys():\n        #print('Doing PSSE PF check for"
  },
  {
    "id": "chunk_2178",
    "text": "es.keys():\n        #print('Doing PSSE PF check for {0}'.format(checkType))\n        silenceAllPSSE() #silence the output\n        temp_pfcheck_output = tmp_dir+r'\\pfcheck_capture.txt' #capture report output from PSS/E   \n        psspy.report_output(2,temp_pfcheck_output,0) #capture report output from PSS/E\n        ierr = psspy.check_powerflow_data(SID_for_checks,0,allPFCheckTypes[checkType])\n        if ierr != 0:\n            print('Problem with running check_powerflow_data. ierr={0}'.format(ierr))"
  },
  {
    "id": "chunk_2179",
    "text": "ning check_powerflow_data. ierr={0}'.format(ierr))\n        silenceAllPSSE() #silence the output so PSSE lets go of the tempfile\n        pfcheck_data = str(getFileByteData(temp_pfcheck_output).decode('UTF-8'))\n        pfcheck_data = \"\"\"{0}\"\"\".format(pfcheck_data)\n        save_data = pd.DataFrame({'PF Check Message':pfcheck_data.split('\\r\\n\\r\\n')}) #get data to save\n        \n        save_data = save_data.loc[(save_data['PF Check Message'].str.strip()!='')&\\\n            (save_data['PF Check Message"
  },
  {
    "id": "chunk_2180",
    "text": "()!='')&\\\n            (save_data['PF Check Message'].str.strip()!='Powerflow data checks')&\\\n            (save_data['PF Check Message'].str.strip().str.contains(' messages:')==False)]\n        #save_data = save_data['PF Check Message']\n        save_data['{0}'.format(rawfilename)] = 'TRUE'\n        save_data = save_data[['PF Check Message','{0}'.format(rawfilename)]]\n        if len(allPFCheckResults[checkType].columns)<1:\n            allPFCheckResults[checkType] = save_data\n            #allPFCheckR"
  },
  {
    "id": "chunk_2181",
    "text": "ts[checkType] = save_data\n            #allPFCheckResults[checkType] = allPFCheckResults[checkType].drop_duplicates()\n        else:\n            allPFCheckResults[checkType] = pd.merge(allPFCheckResults[checkType],save_data,how='outer',on='PF Check Message')\n            allPFCheckResults[checkType] = allPFCheckResults[checkType].drop_duplicates()\n\n    return allPFCheckResults\n\ndef getBrEndVoltageInconsistencies(savLocation,rawfilename,allBrTerminalVoltageInconsistencies,areaList):\n    # Check for "
  },
  {
    "id": "chunk_2182",
    "text": "VoltageInconsistencies,areaList):\n    # Check for line branch elements that connect buses with different base voltages\n    busData_tmp = getAllBusData(savLocation)\n    branchData = getAllLineData(savLocation)\n    brTerminalBaseCheck = pd.merge(branchData,busData_tmp[['NUMBER','NAME','BASE','AREA','OWNER']],how='left',left_on='FROMNUMBER',right_on='NUMBER')\n    brTerminalBaseCheck = pd.merge(brTerminalBaseCheck,busData_tmp[['NUMBER','NAME','BASE','AREA','OWNER']],how='left',left_on='TONUMBER',rig"
  },
  {
    "id": "chunk_2183",
    "text": "'AREA','OWNER']],how='left',left_on='TONUMBER',right_on='NUMBER',suffixes=('_FromBus','_ToBus'))\n    #branchData.to_csv(target_output_directory+r'\\branchData.csv')\n    #brTerminalBaseCheck.to_csv(target_output_directory+r'\\brTerminalBaseCheck.csv')\n    inconsistent_line_terminal_base_voltages = brTerminalBaseCheck.loc[(brTerminalBaseCheck['BASE_FromBus']!=brTerminalBaseCheck['BASE_ToBus'])\\\n        &((brTerminalBaseCheck['AREA_FromBus'].isin(areaList))|(brTerminalBaseCheck['AREA_ToBus'].isin(are"
  },
  {
    "id": "chunk_2184",
    "text": "List))|(brTerminalBaseCheck['AREA_ToBus'].isin(areaList)))]\n    #inconsistent_line_terminal_base_voltages.to_csv(target_output_directory+r'\\inconsistent_line_terminal_base_voltages.csv')\n    inconsistent_line_terminal_base_voltages['{0}'.format(rawfilename)] = 'TRUE'\n\n    if allBrTerminalVoltageInconsistencies.empty == True:\n        allBrTerminalVoltageInconsistencies = inconsistent_line_terminal_base_voltages\n        allBrTerminalVoltageInconsistencies = allBrTerminalVoltageInconsistencies.drop"
  },
  {
    "id": "chunk_2185",
    "text": "tencies = allBrTerminalVoltageInconsistencies.drop_duplicates()\n    else:\n        allBrTerminalVoltageInconsistencies = pd.merge(allBrTerminalVoltageInconsistencies,inconsistent_line_terminal_base_voltages,how='outer',\\\n            on=['ID','FROMNUMBER','TONUMBER','STATUS','NUMBER_FromBus','NAME_FromBus','BASE_FromBus','AREA_FromBus','OWNER_FromBus','NUMBER_ToBus','NAME_ToBus','BASE_ToBus','AREA_ToBus','OWNER_ToBus'])\n        allBrTerminalVoltageInconsistencies = allBrTerminalVoltageInconsistenc"
  },
  {
    "id": "chunk_2186",
    "text": "Inconsistencies = allBrTerminalVoltageInconsistencies.drop_duplicates()\n    return allBrTerminalVoltageInconsistencies\n\ndef getRawxJSON(tmp_dir,rawfilename):\n    temp_rawx_location = tmp_dir+r'\\{0}.rawx'.format(rawfilename)\n    psspy.writerawxsubsys(0,1,[1,1,1,0,0],r\"\"\"{0}\"\"\".format(temp_rawx_location),\"\")\n    with open(temp_rawx_location,'r') as file:\n\t    data = file.read()\n    raw_data_json = json.loads(data)\n    return raw_data_json\n\ndef getNodeBreakerData(raw_data_json):\n    desired_element"
  },
  {
    "id": "chunk_2187",
    "text": "odeBreakerData(raw_data_json):\n    desired_elements = ['sub', 'subnode', 'subswd', 'subterm','load', 'fixshunt', 'generator', 'acline', 'sysswd', 'transformer','swshunt','facts','twotermdc','bus']\n    dataframe_dict = {}\n    for element in desired_elements:\n        dataframe_dict[element] = pd.DataFrame(raw_data_json['network'][element]['data'],columns=raw_data_json['network'][element]['fields'])\n    # get all terminate-able equipment into a single dataset\n    fixShunts = dataframe_dict['fixshun"
  },
  {
    "id": "chunk_2188",
    "text": "le dataset\n    fixShunts = dataframe_dict['fixshunt'][['ibus','shntid']].rename(columns={'shntid':'eqid'})\n    fixShunts['equipmentType'] = 'fixshunt'\n    fixShunts['name'] = ''\n    fixShunts['type'] = 'F'\n    swShunts = dataframe_dict['swshunt'][['ibus','shntid']].rename(columns={'shntid':'eqid'})\n    swShunts['equipmentType'] = 'swshunt'\n    swShunts['name'] = ''\n    swShunts['type'] = 'S'\n    facts = dataframe_dict['facts'][['ibus','jbus','name']].rename(columns={'name':'eqid'})\n    facts['eq"
  },
  {
    "id": "chunk_2189",
    "text": "e']].rename(columns={'name':'eqid'})\n    facts['equipmentType'] = 'facts'\n    facts['name'] = ''\n    facts['type'] = 'A'\n    acLines = dataframe_dict['acline'][['ibus','jbus','ckt','name']].rename(columns={'ckt':'eqid'})\n    acLines['equipmentType'] = 'acline'\n    acLines['type'] = 'B'\n    twotermdc = dataframe_dict['twotermdc'][['ipi','name']].rename(columns={'ipi':'ibus','name':'eqid'})\n    twotermdc['equipmentType'] = 'twotermdc'\n    twotermdc['type'] = 'D'\n    generators = dataframe_dict['ge"
  },
  {
    "id": "chunk_2190",
    "text": "['type'] = 'D'\n    generators = dataframe_dict['generator'][['ibus','machid']].rename(columns={'machid':'eqid'})\n    generators['equipmentType'] = 'generator'\n    generators['name'] = ''\n    generators['type'] = 'M'\n    loads = dataframe_dict['load'][['ibus','loadid']].rename(columns={'loadid':'eqid'})\n    loads['equipmentType'] = 'load'\n    loads['name'] = ''\n    loads['type'] = 'L'\n    transformers = dataframe_dict['transformer'][['ibus','jbus','kbus','ckt','name']].rename(columns={'ckt':'eqid"
  },
  {
    "id": "chunk_2191",
    "text": ",'kbus','ckt','name']].rename(columns={'ckt':'eqid'})\n    transformers['equipmentType'] = 'transformer'\n    transformers.loc[transformers['kbus']==0,'type'] = '2'\n    transformers.loc[transformers['kbus']!=0,'type'] = '3'\n    sysSwds = dataframe_dict['sysswd'][['ibus','jbus','ckt','name','stat','nstat']].rename(columns={'ckt':'eqid'})\n    sysSwds['equipmentType'] = 'system switching device'\n    sysSwds['type'] = 'B'\n\n    all_termable_equip = pd.concat([fixShunts,acLines,generators,loads,transfor"
  },
  {
    "id": "chunk_2192",
    "text": "oncat([fixShunts,acLines,generators,loads,transformers,sysSwds,swShunts,facts,twotermdc],ignore_index=True)\n    all_termable_equip['kbus'] = all_termable_equip['kbus'].replace(0,np.nan)\n    all_termable_equip['jbus'] = all_termable_equip['jbus'].replace(0,np.nan)\n    all_termable_equip['EquipmentID'] = all_termable_equip.index # we'll need this later\n\n    # join the terminable equipment to their corresponding substation and node, if available\n    # first, format the subterm df for greater clarit"
  },
  {
    "id": "chunk_2193",
    "text": " # first, format the subterm df for greater clarity: because ibus/jbus/and kbus are not consistently assigned\n    subterm_formatted = dataframe_dict['subterm'].rename(columns={'isub':'sub','inode':'node','ibus':'bus','jbus':'IDbusA','kbus':'IDbusB','eqid':'IDequip'})\n    # second, join all_termable_equip to subterm_formatted on the ID fields -- this will be giant\n    ibus_node_table = pd.merge(all_termable_equip,subterm_formatted, how = 'left', left_on = ['ibus','eqid','type'], right_on = ['bus'"
  },
  {
    "id": "chunk_2194",
    "text": "eft_on = ['ibus','eqid','type'], right_on = ['bus','IDequip','type'])\n    ibus_node_table = ibus_node_table.loc[\\\n        ((ibus_node_table['jbus'].isna()==True)|((ibus_node_table['jbus']==ibus_node_table['IDbusA'])|(ibus_node_table['jbus']==ibus_node_table['IDbusB'])))\\\n        &((ibus_node_table['kbus'].isna()==True)|(ibus_node_table['kbus']==ibus_node_table['IDbusA'])|(ibus_node_table['kbus']==ibus_node_table['IDbusB']))] # this is the data set for which the node bus is ibus of the equipment\n"
  },
  {
    "id": "chunk_2195",
    "text": "t for which the node bus is ibus of the equipment\n    ibus_node_table = ibus_node_table[['EquipmentID','ibus','jbus','kbus','eqid','equipmentType','stat','nstat','name','sub','node','type']]\n    ibus_node_table = ibus_node_table.rename(columns={'sub':'isub','node':'inode'})\n    ibus_node_table = ibus_node_table.drop_duplicates()\n    jbus_node_table = pd.merge(all_termable_equip,subterm_formatted, how = 'left', left_on = ['jbus','eqid','type'], right_on = ['bus','IDequip','type'])\n    jbus_node_t"
  },
  {
    "id": "chunk_2196",
    "text": "ght_on = ['bus','IDequip','type'])\n    jbus_node_table = jbus_node_table.loc[\\\n        ((jbus_node_table['ibus'].isna()==True)|((jbus_node_table['ibus']==jbus_node_table['IDbusA'])|(jbus_node_table['ibus']==jbus_node_table['IDbusB'])))\\\n        &((jbus_node_table['kbus'].isna()==True)|((jbus_node_table['kbus']==jbus_node_table['IDbusA'])|(jbus_node_table['kbus']==jbus_node_table['IDbusB'])))] # this is the data set for which the node bus is jbus of the equipment\n    jbus_node_table = jbus_node_t"
  },
  {
    "id": "chunk_2197",
    "text": "of the equipment\n    jbus_node_table = jbus_node_table[['EquipmentID','ibus','jbus','kbus','eqid','equipmentType','stat','nstat','name','sub','node','type']]\n    jbus_node_table = jbus_node_table.rename(columns={'sub':'jsub','node':'jnode'})\n    jbus_node_table = jbus_node_table.drop_duplicates()\n    kbus_node_table = pd.merge(all_termable_equip,subterm_formatted, how = 'left', left_on = ['kbus','eqid','type'], right_on = ['bus','IDequip','type'])\n    kbus_node_table = kbus_node_table.loc[\\\n    "
  },
  {
    "id": "chunk_2198",
    "text": ")\n    kbus_node_table = kbus_node_table.loc[\\\n        ((kbus_node_table['ibus'].isna()==True)|((kbus_node_table['ibus']==kbus_node_table['IDbusA'])|(kbus_node_table['ibus']==kbus_node_table['IDbusB'])))\\\n        &((kbus_node_table['jbus'].isna()==True)|((kbus_node_table['jbus']==kbus_node_table['IDbusA'])|(kbus_node_table['jbus']==kbus_node_table['IDbusB'])))] # this is the data set for which the node bus is kbus of the equipment\n    kbus_node_table = kbus_node_table[['EquipmentID','ibus','jbus'"
  },
  {
    "id": "chunk_2199",
    "text": "ble = kbus_node_table[['EquipmentID','ibus','jbus','kbus','eqid','equipmentType','stat','nstat','name','sub','node','type']]\n    kbus_node_table = kbus_node_table.rename(columns={'sub':'ksub','node':'knode'})\n    kbus_node_table = kbus_node_table.drop_duplicates()\n\n    all_termable_equip_with_nodes = pd.merge(all_termable_equip,ibus_node_table,how='left',on=['EquipmentID','ibus','jbus','kbus','eqid','equipmentType','stat','nstat','name','type'])\n    all_termable_equip_with_nodes = pd.merge(all_t"
  },
  {
    "id": "chunk_2200",
    "text": "    all_termable_equip_with_nodes = pd.merge(all_termable_equip_with_nodes,jbus_node_table,how='left',on=['EquipmentID','ibus','jbus','kbus','eqid','equipmentType','stat','nstat','name','type'])\n    all_termable_equip_with_nodes = pd.merge(all_termable_equip_with_nodes,kbus_node_table,how='left',on=['EquipmentID','ibus','jbus','kbus','eqid','equipmentType','stat','nstat','name','type'])\n\n    # add the substation switching devices to the all_termable_equip_with_nodes df\n    # get sub switching de"
  },
  {
    "id": "chunk_2201",
    "text": "ble_equip_with_nodes df\n    # get sub switching device data\n    subSwds = dataframe_dict['subswd']\n    subSwds['jsub'] = subSwds['isub'] # adding jsub column for easier concatenation with all_termable_equip_with_nodes\n    subSwds['equipmentType'] = subSwds['type'].map({1:'Subswd - GEN',2:'Subswd - CB',3:'Subswd - DSC'}) #.astype(str)\n    subSwds=subSwds.rename(columns={'swdid':'eqid'})\n    subSwds = subSwds[['isub','inode','jsub','jnode','eqid','name','equipmentType','type','stat','nstat']]\n    "
  },
  {
    "id": "chunk_2202",
    "text": "name','equipmentType','type','stat','nstat']]\n    # the sub node data and join to sub switching deivce data\n    subNodes = dataframe_dict['subnode']\n    subNodes = subNodes.rename(columns={'isub':'sub','inode':'node','ibus':'bus'})\n    subNodes = subNodes[['sub','node','bus','name']]\n    subNodes=subNodes.drop_duplicates()\n    isubNodes=subNodes.rename(columns={'sub':'isub','node':'inode','bus':'ibus','name':'inode_name'})\n    jsubNodes=subNodes.rename(columns={'sub':'jsub','node':'jnode','bus':"
  },
  {
    "id": "chunk_2203",
    "text": "rename(columns={'sub':'jsub','node':'jnode','bus':'jbus','name':'jnode_name'})\n    subSwds = pd.merge(subSwds,isubNodes,how='left',on=['isub','inode'])\n    subSwds = pd.merge(subSwds,jsubNodes,how='left',on=['jsub','jnode'])\n    subSwds.index += len(all_termable_equip_with_nodes.index)\n    subSwds['EquipmentID']=subSwds.index\n\n    # add the sys swd stype back into the dataset (it has to show as 'B' to join to the sub terminations, since 2 and 3 refer only to transformers in the subterm data)\n   "
  },
  {
    "id": "chunk_2204",
    "text": "efer only to transformers in the subterm data)\n    sysSwdWType = sysSwds = dataframe_dict['sysswd'][['ibus','jbus','ckt','name','stat','nstat','stype']].rename(columns={'ckt':'eqid'}) # the field stype refers to the switch type, where 2 is a breaker and 3 is a disconnect\n    all_termable_equip_with_nodes_incl_subswds = all_termable_equip_with_nodes.merge(sysSwdWType,how='left',on=['ibus','jbus','eqid','name','stat','nstat'])\n    all_termable_equip_with_nodes_incl_subswds.loc[all_termable_equip_w"
  },
  {
    "id": "chunk_2205",
    "text": "p_with_nodes_incl_subswds.loc[all_termable_equip_with_nodes_incl_subswds['equipmentType']=='system switching device','type']=\\\n        all_termable_equip_with_nodes_incl_subswds['stype'] #replace type with stype for system switching devices\n    all_termable_equip_with_nodes_incl_subswds = all_termable_equip_with_nodes_incl_subswds.drop('stype',axis=1) #drop the stype column\n    all_termable_equip_with_nodes_incl_subswds = all_termable_equip_with_nodes_incl_subswds.drop_duplicates() #drop any dup"
  },
  {
    "id": "chunk_2206",
    "text": "nodes_incl_subswds.drop_duplicates() #drop any duplicates introduced\n    # add substation switching devices to all_termable_equip_with_nodes\n    all_termable_equip_with_nodes_incl_subswds = pd.concat([all_termable_equip_with_nodes_incl_subswds,subSwds],ignore_index=False)\n\n    return (ibus_node_table, jbus_node_table, kbus_node_table, all_termable_equip_with_nodes,dataframe_dict,all_termable_equip_with_nodes_incl_subswds)\n\ndef getInvalidSetpointsContinuousShunts(allSwShunts,rawfilename,allSwShun"
  },
  {
    "id": "chunk_2207",
    "text": "ContinuousShunts(allSwShunts,rawfilename,allSwShuntsWithInvalidSetpoints,savLocation,areaList):\n    # check Binit values for switched shunt\n    busData_tmp = getAllBusData(savLocation)[['NUMBER','AREA']].rename(columns={'NUMBER':'ibus'})\n    allSwShuntsWithArea = allSwShunts.merge(busData_tmp,how='left',on='ibus')\n    SwShunts = allSwShuntsWithArea.loc[allSwShuntsWithArea['AREA'].isin(areaList)] #get requested area shunts only\n    SwShunts = SwShunts.loc[SwShunts['modsw']==2] #only get continuou"
  },
  {
    "id": "chunk_2208",
    "text": "unts.loc[SwShunts['modsw']==2] #only get continuous-control-type shunts\n    #print(SwShunts)\n    SwShuntsWithInvalidSetpoints = SwShunts.loc[(SwShunts['vswhi']!=SwShunts['vswlo'])]\n    SwShuntsWithInvalidSetpoints = SwShuntsWithInvalidSetpoints[['ibus','AREA','shntid','modsw','swreg','vswhi','vswlo']]\n    SwShuntsWithInvalidSetpoints['{0}'.format(rawfilename)] = 'TRUE'\n\n    if allSwShuntsWithInvalidSetpoints.empty==True:\n        allSwShuntsWithInvalidSetpoints = SwShuntsWithInvalidSetpoints\n    "
  },
  {
    "id": "chunk_2209",
    "text": "validSetpoints = SwShuntsWithInvalidSetpoints\n        allSwShuntsWithInvalidSetpoints = allSwShuntsWithInvalidSetpoints.drop_duplicates()\n    else:\n        allSwShuntsWithInvalidSetpoints = allSwShuntsWithInvalidSetpoints.merge(SwShuntsWithInvalidSetpoints,how='outer',\\\n            on=['ibus','AREA','shntid','modsw','swreg','vswhi','vswlo'])\n        allSwShuntsWithInvalidSetpoints = allSwShuntsWithInvalidSetpoints.drop_duplicates()\n    return allSwShuntsWithInvalidSetpoints\n\ndef getInvalidBinitS"
  },
  {
    "id": "chunk_2210",
    "text": "SwShuntsWithInvalidSetpoints\n\ndef getInvalidBinitShunts(allSwShunts,rawfilename,allSwShuntsWithInvalidBinit,savLocation,areaList):\n    # check Binit values for switched shunt\n    busData_tmp = getAllBusData(savLocation)[['NUMBER','AREA']].rename(columns={'NUMBER':'ibus'})\n    allSwShuntsWithArea = allSwShunts.merge(busData_tmp,how='left',on='ibus')\n    SwShunts = allSwShuntsWithArea.loc[allSwShuntsWithArea['AREA'].isin(areaList)] #get requested area shunts only\n    SwShunts = SwShunts.loc[SwShun"
  },
  {
    "id": "chunk_2211",
    "text": "rea shunts only\n    SwShunts = SwShunts.loc[SwShunts['modsw']==1] #only get discreet-control-type shunts\n    SwShuntsWithInvalidBinit = SwShunts.loc[(SwShunts['binit']!=0)\\\n        &(SwShunts['binit']!=SwShunts['b1'])\\\n        &(SwShunts['binit']!=SwShunts['b2'])\\\n        &(SwShunts['binit']!=SwShunts['b3'])\\\n        &(SwShunts['binit']!=SwShunts['b4'])\\\n        &(SwShunts['binit']!=SwShunts['b5'])\\\n        &(SwShunts['binit']!=SwShunts['b6'])\\\n        &(SwShunts['binit']!=SwShunts['b7'])\\\n     "
  },
  {
    "id": "chunk_2212",
    "text": "       &(SwShunts['binit']!=SwShunts['b7'])\\\n        &(SwShunts['binit']!=SwShunts['b8'])\\\n        &(SwShunts['binit']!=SwShunts['b1']+SwShunts['b2'])\\\n        &(SwShunts['binit']!=SwShunts['b1']+SwShunts['b2']+SwShunts['b3'])\\\n        &(SwShunts['binit']!=SwShunts['b1']+SwShunts['b2']+SwShunts['b3']+SwShunts['b4'])\\\n        &(SwShunts['binit']!=SwShunts['b1']+SwShunts['b2']+SwShunts['b3']+SwShunts['b4']+SwShunts['b5'])\\\n        &(SwShunts['binit']!=SwShunts['b1']+SwShunts['b2']+SwShunts['b3']+S"
  },
  {
    "id": "chunk_2213",
    "text": "']!=SwShunts['b1']+SwShunts['b2']+SwShunts['b3']+SwShunts['b4']+SwShunts['b5']+SwShunts['b6'])\\\n        &(SwShunts['binit']!=SwShunts['b1']+SwShunts['b2']+SwShunts['b3']+SwShunts['b4']+SwShunts['b5']+SwShunts['b6']+SwShunts['b7'])\\\n        &(SwShunts['binit']!=SwShunts['b1']+SwShunts['b2']+SwShunts['b3']+SwShunts['b4']+SwShunts['b5']+SwShunts['b6']+SwShunts['b7']+SwShunts['b8'])]\n    SwShuntsWithInvalidBinit = SwShuntsWithInvalidBinit[['ibus','AREA','shntid','modsw','swreg','binit']]\n    SwShunt"
  },
  {
    "id": "chunk_2214",
    "text": "EA','shntid','modsw','swreg','binit']]\n    SwShuntsWithInvalidBinit['{0}'.format(rawfilename)] = 'TRUE'\n    \n    if allSwShuntsWithInvalidBinit.empty==True:\n        allSwShuntsWithInvalidBinit = SwShuntsWithInvalidBinit\n        allSwShuntsWithInvalidBinit = allSwShuntsWithInvalidBinit.drop_duplicates()\n    else:\n        allSwShuntsWithInvalidBinit = allSwShuntsWithInvalidBinit.merge(SwShuntsWithInvalidBinit,how='outer',\\\n            on=['ibus','AREA','shntid','modsw','swreg','binit'])\n        al"
  },
  {
    "id": "chunk_2215",
    "text": "REA','shntid','modsw','swreg','binit'])\n        allSwShuntsWithInvalidBinit = allSwShuntsWithInvalidBinit.drop_duplicates()\n    return allSwShuntsWithInvalidBinit\n\ndef getSolutionData(rawfilename,allCaseSolveData):\n    error_map = {0:'no error occurred',1:'invalid OPTIONS value',2:'generators are converted',\n    3:'buses in island(s) without a swing bus; use activity TREE',\n    4:'bus type code and series element status inconsistencies',\n    5:'prerequisite requirements for API are not met'}\n   "
  },
  {
    "id": "chunk_2216",
    "text": "rerequisite requirements for API are not met'}\n    flag_map = {0:'tap adj',1:'area interchange adj',2:'phase shift adj',\n    3:'dc tap adj',4:'sw shunt adj',5:'flat start',6:'var limit',7:'non-divergent sol'}\n    fdns_configuration_step1 = [1,1,1,1,1,1,0,0]\n    fdns_configuration_step1_labels = dict(zip(flag_map.values(),fdns_configuration_step1))\n    fdns_configuration_step2 = [1,1,1,1,1,0,0,0]\n    fdns_configuration_step2_labels = dict(zip(flag_map.values(),fdns_configuration_step2))\n    fnsl_"
  },
  {
    "id": "chunk_2217",
    "text": "_map.values(),fdns_configuration_step2))\n    fnsl_configuration_step3 = [1,1,1,1,1,0,0,0]\n    fnsl_configuration_step3_labels = dict(zip(flag_map.values(),fnsl_configuration_step3))\n    step1_solution_dict = fdns_configuration_step1_labels.copy()\n    step2_solution_dict = fdns_configuration_step2_labels.copy()\n    step3_solution_dict = fnsl_configuration_step3_labels.copy()\n    # do step 1 solve\n    ierr_fdns_1 = psspy.fdns(fdns_configuration_step1)\n    #print('ierr_fdns is {0}'.format(ierr_fdns"
  },
  {
    "id": "chunk_2218",
    "text": "p1)\n    #print('ierr_fdns is {0}'.format(ierr_fdns))\n    if ierr_fdns_1 == 0:\n        solveIterat_fdns_1 = psspy.iterat() #number of iterations of solution\n        solveSysmsm_fdns_1 = psspy.sysmsm() #total MVA mismatch of solution\n        solutionString_fdns_1 = psspy.solstr()\n        step1_solution_dict.update({'Step':1,'Solution Method':'fdns',\n        'Iterations':solveIterat_fdns_1,'Mismatch':solveSysmsm_fdns_1,'Solution Str':solutionString_fdns_1,\n        'ierr':error_map[ierr_fdns_1]})\n  "
  },
  {
    "id": "chunk_2219",
    "text": "fdns_1,\n        'ierr':error_map[ierr_fdns_1]})\n        # do step 2 solve\n        ierr_fdns_2 = psspy.fdns(fdns_configuration_step2)\n        if ierr_fdns_2 == 0:\n            solveIterat_fdns_2 = psspy.iterat() #number of iterations of solution\n            solveSysmsm_fdns_2 = psspy.sysmsm() #total MVA mismatch of solution\n            solutionString_fdns_2 = psspy.solstr()\n            step2_solution_dict.update({'Step':2,'Solution Method':'fdns',\n            'Iterations':solveIterat_fdns_2,'Misma"
  },
  {
    "id": "chunk_2220",
    "text": "            'Iterations':solveIterat_fdns_2,'Mismatch':solveSysmsm_fdns_2,\n            'Solution Str':solutionString_fdns_2,'ierr':error_map[ierr_fdns_2]})\n            # do step 3 solve\n            ierr_fnsl_3 = psspy.fdns(fnsl_configuration_step3)\n            if ierr_fnsl_3 == 0:\n                solveIterat_fnsl_3 = psspy.iterat() #number of iterations of solution\n                solveSysmsm_fnsl_3  = psspy.sysmsm() #total MVA mismatch of solution\n                solutionString_fnsl_3  = psspy."
  },
  {
    "id": "chunk_2221",
    "text": "on\n                solutionString_fnsl_3  = psspy.solstr()\n                step3_solution_dict.update({'Step':3,'Solution Method':'fnsl',\n                'Iterations':solveIterat_fnsl_3 ,'Mismatch':solveSysmsm_fnsl_3 ,\n                'Solution Str':solutionString_fnsl_3 ,'ierr':error_map[ierr_fnsl_3 ]})\n            else:\n                step3_solution_dict.update({'Step':3,'Solution Method':'fnsl',\n                'Iterations':'NA' ,'Mismatch':'NA' ,\n                'Solution Str':'NA' ,'ierr':"
  },
  {
    "id": "chunk_2222",
    "text": "NA' ,\n                'Solution Str':'NA' ,'ierr':error_map[ierr_fnsl_3 ]})\n        else:\n            step2_solution_dict.update({'Step':2,'Solution Method':'fdns',\n            'Iterations':'NA','Mismatch':'NA',\n            'Solution Str':'NA','ierr':error_map[ierr_fdns_2]})\n    else:\n        step1_solution_dict.update({'Step':1,'Solution Method':'fdns',\n        'Iterations':'NA','Mismatch':'NA','Solution Str':'NA',\n        'ierr':error_map[ierr_fdns_1]})\n        step2_solution_dict.update({'Ste"
  },
  {
    "id": "chunk_2223",
    "text": "fdns_1]})\n        step2_solution_dict.update({'Step':2,'Solution Method':'NA',\n        'Iterations':'NA','Mismatch':'NA','Solution Str':'NA',\n        'ierr':'NA (not attempted)'})\n        step3_solution_dict.update({'Step':3,'Solution Method':'NA',\n        'Iterations':'NA','Mismatch':'NA','Solution Str':'NA',\n        'ierr':'NA (not attempted)'})\n    three_step_solution_dict = dict(zip(step1_solution_dict,zip(step1_solution_dict.values(),step2_solution_dict.values(),step3_solution_dict.values()"
  },
  {
    "id": "chunk_2224",
    "text": "olution_dict.values(),step3_solution_dict.values())))\n    three_step_solution_data = pd.DataFrame.from_dict(three_step_solution_dict)\n    three_step_solution_data['Case'] = '{0}'.format(rawfilename)\n\n    if allCaseSolveData.empty == True:\n        allCaseSolveData = three_step_solution_data\n        allCaseSolveData = allCaseSolveData.drop_duplicates()\n    else:\n        # allCaseSolveData = allCaseSolveData.merge(two_step_solution_data,how='outer',\\\n        #     on=['Step','Solution Method','Iter"
  },
  {
    "id": "chunk_2225",
    "text": "\\\n        #     on=['Step','Solution Method','Iterations','Mismatch','Solution Str','ierr',\\\n        #     'tap adj','area interchange adj','phase shift adj','dc tap adj',\\\n        #     'sw shunt adj','flat start','var limit','non-divergent sol'])\n        allCaseSolveData = pd.concat([allCaseSolveData,three_step_solution_data],ignore_index=True)\n        allCaseSolveData = allCaseSolveData.drop_duplicates()\n\n    return allCaseSolveData\n\ndef getCAConvergenceData(CASELOCATION,rawfilename,allCAData"
  },
  {
    "id": "chunk_2226",
    "text": "ConvergenceData(CASELOCATION,rawfilename,allCAData,areaList,temp_dir):\n\n    # generate confile for all single branch elements in the selected areas\n    tempConFileLoc = r'{0}\\temp.con'.format(temp_dir)\n    generateAllSingleBranchAndXFRContingencies(CASELOCATION,areaList,tempConFileLoc)\n\n    # generate sub and mon files \n    tempSubFileLoc = r'{0}\\temp.sub'.format(temp_dir)\n    f = open(tempSubFileLoc,\"w\")\n    f.write(\"SUBSYSTEM 'temp'\\n\")\n    for AR in areaList:\n        f.write(\"AREA {0}\\n\".form"
  },
  {
    "id": "chunk_2227",
    "text": " AR in areaList:\n        f.write(\"AREA {0}\\n\".format(AR))\n    f.write(\"END\\nEND\")\n    f.close()\n    tempMonFileLoc = r'{0}\\temp.mon'.format(temp_dir)\n    f = open(tempMonFileLoc,\"w\")\n    f.write(\"\"\"MONITOR VOLTAGE RANGE SUBSYSTEM 'temp' 0.920 1.050\n    MONITOR VOLTAGE DEVIATION SUBSYSTEM 'temp' 0.070 0.070\n    MONITOR BRANCHES IN SUBSYSTEM 'temp'\n    MONITOR TIES FROM SUBSYSTEM 'temp'\n    END\"\"\")\n    f.close()\n\n    # open the case and perform three-step solve from flat start\n    psspy.case(CASEL"
  },
  {
    "id": "chunk_2228",
    "text": "ee-step solve from flat start\n    psspy.case(CASELOCATION) #re-open case in psse\n    fdns_configuration_step1 = [1,1,1,1,1,1,0,0]\n    fdns_configuration_step2 = [1,1,1,1,1,0,0,0]\n    fnsl_configuration_step3 = [1,1,1,1,1,0,0,0]\n    ierr_fdns_1 = psspy.fdns(fdns_configuration_step1)\n    ierr_fdns_2 = psspy.fdns(fdns_configuration_step2)\n    ierr_fnsl_3 = psspy.fdns(fnsl_configuration_step3)\n\n    # set solution parameters\n    CA_TOL = 0.01\n    CA_TAPADJ = 1\n    CA_AREAINT = 1\n    CA_PHADJ = 1\n    "
  },
  {
    "id": "chunk_2229",
    "text": "APADJ = 1\n    CA_AREAINT = 1\n    CA_PHADJ = 1\n    CA_DCTAP = 1\n    CA_SWSH = 1\n    CA_SOL = 1 # 'FDNS':0,'FNSL':1,'NSOL':0\n    CA_NONDIV = 0\n    CA_INDMOT = 0\n    CA_INDMACH = 0\n    CA_DISP = 0\n    CA_ZIP = 0\n\n    # generate dfax \n    tempDfaxFileLoc = r'{0}\\temp.dfax'.format(temp_dir)\n    ierr = psspy.dfax([1,1],tempSubFileLoc,tempMonFileLoc,tempConFileLoc,tempDfaxFileLoc)\n\n    # run accc\n    tempAccFileLoc = r'{0}\\temp.acc'.format(temp_dir)\n    accc_ierr = psspy.accc_with_dsp_3(CA_TOL,[CA_TAPA"
  },
  {
    "id": "chunk_2230",
    "text": " accc_ierr = psspy.accc_with_dsp_3(CA_TOL,[CA_TAPADJ,CA_AREAINT,CA_PHADJ,CA_DCTAP,CA_SWSH,CA_SOL,CA_NONDIV,CA_INDMOT,CA_INDMACH,CA_DISP,CA_ZIP],\"\",tempDfaxFileLoc,tempAccFileLoc,\"\",\"\",\"\")\n\n    # parse accc results\n    accc_output_temp = r'{0}\\accc_output_temp.txt'.format(temp_dir)\n    # report configs\n    stat1 = 0 #spreadsheet report\n    stat2 = 1 #rate 1 for base case violations\n    stat3 = 2 #rate 2 for CA violations\n    stat4 = 1 #bc SWD ratings set\n    stat5 = 2 #ca SWD ratings set\n    stat"
  },
  {
    "id": "chunk_2231",
    "text": "ngs set\n    stat5 = 2 #ca SWD ratings set\n    stat6 = 1 #voltage bc normal limit\n    stat7 = 1 #voltage ca normal limit\n    stat8 = 0 #exclude interfaces from report?\n    stat9 = 1 #run voltage limit check\n    stat10 = 1 #exclude elements with bc violations in ca violations\n    stat11 = 1 #exclude elements with bc violations in ca violations\n    stat12 = 0 #exclude cases with no ol's\n    stat13 = 0 #do not report post-tripping action solutions\n    stat14 = 1 #report loss of loads\n    ACCC_STATUS"
  },
  {
    "id": "chunk_2232",
    "text": "  stat14 = 1 #report loss of loads\n    ACCC_STATUSES = [stat1,stat2,stat3,stat4,stat5,stat6,stat7,stat8,stat9,stat10,stat11,stat12,stat13,stat14]\n    intv1 = 0 #lv range violations filter\n    intv2 = 0 #hv range violations filter\n    intv3 = 0 #voltage deviation violations filter\n    intv4 = 0 #largest num of busses in disconnected island\n    intv5 = 6000 #max number of element in avail capacity table\n    ACCC_INTVALS = [intv1,intv2,intv3,intv4,intv5]\n    rlvl1 = 0.5 #bus mismatch convergence\n  "
  },
  {
    "id": "chunk_2233",
    "text": "ntv5]\n    rlvl1 = 0.5 #bus mismatch convergence\n    rlvl2 = 5.0 #system mismatch convergence tolerance in MVA\n    rlvl3 = 98 #percent of flow rating I MADE THIS LOW FOR DEV, SHOULD BE CLOSE TO 100\n    rlvl4 = 0 #min contingency case flow change from base case value\n    rlvl5 = 0 #min contingency case percent loading increase from base case\n    rlvl6 = 0 #min contingency case voltage change from base case value\n    rlvl7 = 99999 #cutoff threshold for available capacity table\n    ACCC_REALVALS = ["
  },
  {
    "id": "chunk_2234",
    "text": "for available capacity table\n    ACCC_REALVALS = [rlvl1,rlvl2,rlvl3,rlvl4,rlvl5,rlvl6,rlvl7]\n    psspy.report_output(2,accc_output_temp,[0,0])\n    accc_report_ierr = psspy.accc_single_run_report_5(ACCC_STATUSES,ACCC_INTVALS,ACCC_REALVALS,tempAccFileLoc)\n    CAresults = getAccReportViolations(accc_output_temp) # parse the acc output report and return a dataframe of results\n\n    if type(CAresults) != type(None): \n        ConvergedContingencies = CAresults.loc[CAresults['ViolationType']=='Met conve"
  },
  {
    "id": "chunk_2235",
    "text": "results.loc[CAresults['ViolationType']=='Met convergence to']\n        AllContingencies = CAresults.loc[CAresults['ViolationType'].isin(['Met convergence to','Iteration limit ex','Blown up'])]\n        numConvergedContingencies = ConvergedContingencies.shape[0]\n        numAllContingencies = AllContingencies.shape[0]\n        CAdata = pd.DataFrame({'ConvergedContingencies':[numConvergedContingencies],'TotalContingencies':[numAllContingencies]})\n        CAdata['Case'] = '{0}'.format(rawfilename)\n    "
  },
  {
    "id": "chunk_2236",
    "text": "   CAdata['Case'] = '{0}'.format(rawfilename)\n    else:\n        CAdata = pd.DataFrame({'ConvergedContingencies':['NA'],'TotalContingencies':['NA'],'UnableToObtainBaseCase':['True']})\n        CAdata['Case'] = '{0}'.format(rawfilename)\n    if allCAData.empty == True:\n        allCAData = CAdata\n        allCAData = allCAData.drop_duplicates()\n    else:\n        allCAData = pd.concat([allCAData,CAdata],ignore_index=True)\n        allCAData = allCAData.drop_duplicates()\n\n    return allCAData\n\ndef getInc"
  },
  {
    "id": "chunk_2237",
    "text": "rop_duplicates()\n\n    return allCAData\n\ndef getIncorrectShuntRemoteBuses(allSwShunts,rawfilename,allIncorrectShuntRemoteBuses,savLocation,areaList):\n    busData_tmp = getAllBusData(savLocation)[['NUMBER','AREA']].rename(columns={'NUMBER':'ibus'})\n    allSwShuntsWithArea = allSwShunts.merge(busData_tmp,how='left',on='ibus')\n    SwShunts = allSwShuntsWithArea.loc[allSwShuntsWithArea['AREA'].isin(areaList)] #get requested area shunts only\n    incorrectShuntRemoteBus = SwShunts.loc[((SwShunts['swreg"
  },
  {
    "id": "chunk_2238",
    "text": "ectShuntRemoteBus = SwShunts.loc[((SwShunts['swreg']>=9700)&(SwShunts['swreg']<=9999))|\\\n                                            ((SwShunts['swreg']>=94000)&(SwShunts['swreg']<=99999))|\\\n                                            ((SwShunts['swreg']>=100000)&(SwShunts['swreg']<=199999))]\n    incorrectShuntRemoteBus = incorrectShuntRemoteBus[['ibus','AREA','shntid','modsw','swreg']]\n    incorrectShuntRemoteBus['{0}'.format(rawfilename)] = 'TRUE'\n    if allIncorrectShuntRemoteBuses.empty==Tru"
  },
  {
    "id": "chunk_2239",
    "text": "UE'\n    if allIncorrectShuntRemoteBuses.empty==True:\n        allIncorrectShuntRemoteBuses = incorrectShuntRemoteBus\n        allIncorrectShuntRemoteBuses = allIncorrectShuntRemoteBuses.drop_duplicates()\n    else:\n        allIncorrectShuntRemoteBuses = allIncorrectShuntRemoteBuses.merge(incorrectShuntRemoteBus,how='outer',\\\n            on=['ibus','AREA','shntid','modsw','swreg'])\n        allIncorrectShuntRemoteBuses = allIncorrectShuntRemoteBuses.drop_duplicates()\n    return allIncorrectShuntRemot"
  },
  {
    "id": "chunk_2240",
    "text": "rop_duplicates()\n    return allIncorrectShuntRemoteBuses\n\ndef getIncorrectGenRemoteBuses(allGenerators,rawfilename,allIncorrectGenRemoteBuses,savLocation,areaList):\n    busData_tmp = getAllBusData(savLocation)[['NUMBER','AREA']].rename(columns={'NUMBER':'ibus'})\n    allGeneratorsWithArea = allGenerators.merge(busData_tmp,how='left',on='ibus')\n    Generators = allGeneratorsWithArea.loc[allGeneratorsWithArea['AREA'].isin(areaList)] #get requested area shunts only\n    incorrectGeneratorRemoteBus = "
  },
  {
    "id": "chunk_2241",
    "text": "rea shunts only\n    incorrectGeneratorRemoteBus = Generators.loc[((Generators['ireg']>=9700)&(Generators['ireg']<=9999))|\\\n                                            ((Generators['ireg']>=94000)&(Generators['ireg']<=99999))|\\\n                                            ((Generators['ireg']>=100000)&(Generators['ireg']<=199999))]\n    incorrectGeneratorRemoteBus = incorrectGeneratorRemoteBus[['ibus','AREA','machid','ireg','nreg']]\n    incorrectGeneratorRemoteBus['{0}'.format(rawfilename)] = 'TRUE"
  },
  {
    "id": "chunk_2242",
    "text": "eratorRemoteBus['{0}'.format(rawfilename)] = 'TRUE'\n    if allIncorrectGenRemoteBuses.empty == True:\n        allIncorrectGenRemoteBuses = incorrectGeneratorRemoteBus\n        allIncorrectGenRemoteBuses = allIncorrectGenRemoteBuses.drop_duplicates()\n    else:\n        allIncorrectGenRemoteBuses = allIncorrectGenRemoteBuses.merge(incorrectGeneratorRemoteBus,how='outer',\\\n        on=['ibus','AREA','machid','ireg','nreg'])\n        allIncorrectGenRemoteBuses = allIncorrectGenRemoteBuses.drop_duplicates"
  },
  {
    "id": "chunk_2243",
    "text": "Buses = allIncorrectGenRemoteBuses.drop_duplicates()\n    return allIncorrectGenRemoteBuses\n\ndef generateAllSingleBranchAndXFRContingencies(CASELOCATION,areaList,tempConFileLoc):\n    allBranches = getAllLineData(CASELOCATION)\n    allXFRs = getAllXFRData(CASELOCATION)\n    all2WXFRs = allXFRs.loc[allXFRs['WIND3NUMBER'].isnull()==True]\n    all3WXFRs = allXFRs.loc[allXFRs['WIND3NUMBER'].isnull()==False]\n\n    confileLocation = tempConFileLoc\n    f = open(confileLocation,\"w\")\n    contCounter = 1\n    fo"
  },
  {
    "id": "chunk_2244",
    "text": "en(confileLocation,\"w\")\n    contCounter = 1\n    for br in allBranches.index:\n        busI = allBranches.at[br,'FROMNUMBER']\n        busJ = allBranches.at[br,'TONUMBER']\n        cktID = allBranches.at[br,'ID']\n        strToWrite = r\"OPEN BRANCH FROM BUS {0} TO BUS {1} CKT {2}\".format(busI,busJ,cktID)\n        f.write(\"CONTINGENCY '{0}'\".format(str(contCounter)))\n        f.write(\"\\n\")\n        f.write(strToWrite)\n        f.write(\"\\n\")\n        f.write(\"END\")\n        f.write(\"\\n\")\n        contCounter "
  },
  {
    "id": "chunk_2245",
    "text": "(\"END\")\n        f.write(\"\\n\")\n        contCounter = contCounter+1\n    for br in all2WXFRs.index:\n        busI = all2WXFRs.at[br,'WIND1NUMBER']\n        busJ = all2WXFRs.at[br,'WIND2NUMBER']\n        cktID = all2WXFRs.at[br,'ID']\n        strToWrite = r\"OPEN BRANCH FROM BUS {0} TO BUS {1} CKT {2}\".format(busI,busJ,cktID)\n        f.write(\"CONTINGENCY '{0}'\".format(str(contCounter)))\n        f.write(\"\\n\")\n        f.write(strToWrite)\n        f.write(\"\\n\")\n        f.write(\"END\")\n        f.write(\"\\n\")\n  "
  },
  {
    "id": "chunk_2246",
    "text": "\")\n        f.write(\"END\")\n        f.write(\"\\n\")\n        contCounter = contCounter+1\n    for br in all3WXFRs.index:\n        busI = all3WXFRs.at[br,'WIND1NUMBER']\n        busJ = all3WXFRs.at[br,'WIND2NUMBER']\n        busK = int(all3WXFRs.at[br,'WIND3NUMBER'])\n        cktID = all3WXFRs.at[br,'ID']\n        strToWrite = r\"OPEN BRANCH FROM BUS {0} TO BUS {1} TO BUS {2} CKT {3}\".format(busI,busJ,busK,cktID)\n        f.write(\"CONTINGENCY '{0}'\".format(str(contCounter)))\n        f.write(\"\\n\")\n        f.wr"
  },
  {
    "id": "chunk_2247",
    "text": "(contCounter)))\n        f.write(\"\\n\")\n        f.write(strToWrite)\n        f.write(\"\\n\")\n        f.write(\"END\")\n        f.write(\"\\n\")\n        contCounter = contCounter+1\n    f.write(\"END\")\n    f.close()\n    return\n\ndef getQAReports(CASEDIRECTORY,OUTPUTDIRECTORY,DESIRED_QA_LIST,AREALIST):\n    ### DESIRED_QA_LIST is a list of requested reports to be created, it may include the following entries:\n    ### '900k_buses','CNTB_check','out_of_range_buses','disconnected_shunts','disconnected_loads',\n    #"
  },
  {
    "id": "chunk_2248",
    "text": ",'disconnected_shunts','disconnected_loads',\n    ### 'zero_loads', 'multiple_branches_terminating_on_node', 'invalid_Binit_switched_shunts',\n    ### 'TREE_islands', 'unterminated_elements', 'br_remote_end_voltage_inconsistencies',\n    ### 'bus_type_inconsistencies', 'incorrect_voltage_bus_limits', 'TLD_bus_updates',\n    ### 'check_solvability','check_CA_performance', 'PSSE_pf_checks'\n\n    ### create a dictionary of the request reports\n    available_reports = ['900k_buses','TREE_islands','bus_typ"
  },
  {
    "id": "chunk_2249",
    "text": "le_reports = ['900k_buses','TREE_islands','bus_type_inconsistencies','CNTB_check',\n    'disconnected_shunts', 'invalid_Binit_switched_shunts','invalid_setpts_continuous_shunts',\n    'incorrect_shunt_remote_buses','incorrect_gen_remote_buses','br_remote_end_voltage_inconsistencies',\n    'check_solvability','check_CA_performance','PSSE_pf_checks','all_lds','disconnected_loads',\n    'zero_loads'\n    ]\n    report_dict = {}\n    for report in available_reports:\n        if report in DESIRED_QA_LIST:\n  "
  },
  {
    "id": "chunk_2250",
    "text": "_reports:\n        if report in DESIRED_QA_LIST:\n            report_dict[report] = 1\n        else:\n            report_dict[report] = 0\n\n    ### Create temp directory for file management ###\n    #TMP_DIR = makeTempDirectory()\n    temporary_directory = tempfile.TemporaryDirectory()\n    TMP_DIR = temporary_directory.name\n    print('Created temp directory {0}.'.format(TMP_DIR))\n\n    #### Supress all the PSSE outputs for now\n    suppressAllPSSEOutputs()\n\n    ### Get the list of raw cases to process an"
  },
  {
    "id": "chunk_2251",
    "text": ")\n\n    ### Get the list of raw cases to process and define\n    target_directory = CASEDIRECTORY.GetPath()\n    case_list = glob.glob(target_directory+r'\\*.raw')\n\n    ### Prepare the output directory\n    target_output_directory = OUTPUTDIRECTORY.GetPath()+r'\\QA_results_{}'.format(str(datetime.datetime.now().date()))\n    os.makedirs(target_output_directory) #create auto QA check output file\n\n    ### set up logger\n    today_date = str(datetime.date.today())\n    logging.basicConfig(filename='{0}\\log_"
  },
  {
    "id": "chunk_2252",
    "text": "oday())\n    logging.basicConfig(filename='{0}\\log_file'.format(target_output_directory),filemode='a',level=logging.DEBUG,format='%(name)s - %(levelname)s - %(message)s')\n    logging.debug('{0} execute start at {1}'.format(sys.argv[0],datetime.datetime.now()))\n    logging.debug('All required files and directories selected. Now running the following QA reports for the areas {0}:'.format(','.join(map(str,AREALIST))))\n    logging.debug(DESIRED_QA_LIST)\n\n    ### Prepare blank dataframes for results\n "
  },
  {
    "id": "chunk_2253",
    "text": "T)\n\n    ### Prepare blank dataframes for results\n    CNTB_messages = pd.DataFrame()\n    BusData = pd.DataFrame()   \n    allBusInconsistencies = pd.DataFrame()\n    allIslands = pd.DataFrame()\n    allBrTerminalVoltageInconsistencies = pd.DataFrame()\n    allDisconnectedLds = pd.DataFrame()\n    allZeroLds = pd.DataFrame()\n    allLoads = pd.DataFrame()\n    allLoadsWithTotalsColumn = pd.DataFrame()    \n    allSwShuntsWithInvalidBinit = pd.DataFrame()\n    alldisconnected_shunts = pd.DataFrame()\n    all"
  },
  {
    "id": "chunk_2254",
    "text": "   alldisconnected_shunts = pd.DataFrame()\n    all900k_buses = pd.DataFrame()   \n    allCaseSolveData = pd.DataFrame()\n    allIncorrectShuntRemoteBuses = pd.DataFrame()\n    allIncorrectGenRemoteBuses = pd.DataFrame()\n    allCAData = pd.DataFrame()\n    allSwShuntsWithInvalidSetpoints = pd.DataFrame()\n    # PSSE check powerflow data dataframes\n    allPFCheckTypes = {'bus data':1,'load data':2,'plant data':3,'generator unit data':4,\n    'induction machine data':5,'fixed bus shunt data':6,'switched "
  },
  {
    "id": "chunk_2255",
    "text": "achine data':5,'fixed bus shunt data':6,'switched shunt data':7,\n    'non-transformer branch data':8,'two-winding transformer data':9,\n    'three-winding transformer data':10,'transformer impedance table correciton data':11,\n    'two-terminal dc line data':13,'multi-terminal dc line data':14,\n    'VSC dc line data':15,'FACTS device data':16,'GNE device data':17,\n    'area interchange data':18,'owner data':19,'zone data':20}\n    allPFCheckResults = {}\n    for checkType in allPFCheckTypes:\n       "
  },
  {
    "id": "chunk_2256",
    "text": "= {}\n    for checkType in allPFCheckTypes:\n        allPFCheckResults[checkType] = pd.DataFrame()\n\n    ### Process all raw files according to which reports were requested\n    counter = 1\n    for case in case_list:\n        ### read in the raw file\n        print('processesing case {0} out of {1}'.format(counter,len(case_list)))   \n        rawfilename = os.path.splitext(os.path.basename(case))[0]\n        logging.debug('processesing raw {0} -- case {1} out of {2}'.format(rawfilename,counter,len(case_"
  },
  {
    "id": "chunk_2257",
    "text": "} out of {2}'.format(rawfilename,counter,len(case_list)))\n        counter = counter+1\n        psspy.read(0,case) # open case\n\n        ### save the open case as a sav\n        savLocation = target_output_directory+r'\\{0}.sav'.format(rawfilename)\n        PSSESaveCase(savLocation)\n\n        ### if no areas were chosen by the user, get a list of all areas in the open case\n        if AREALIST == []:\n            int_data_desired = ['NUMBER']\n            int_ierr, iarray = psspy.aareaint(-1, 2, int_data_"
  },
  {
    "id": "chunk_2258",
    "text": "int_ierr, iarray = psspy.aareaint(-1, 2, int_data_desired)\n            allAreas = iarray[0]\n            AREALIST = allAreas\n        \n\n        ### if requested, do the solvability check. If the solvability check indicates that the case did not solve, then do not attempt CA check\n        if (report_dict['check_solvability'] == 1)|(report_dict['check_CA_performance'] == 1):\n            #allCaseSolveData = getSolutionData(rawfilename,allCaseSolveData)# TO TROUBLESHOOT, uncomment this line and commen"
  },
  {
    "id": "chunk_2259",
    "text": ")# TO TROUBLESHOOT, uncomment this line and comment out the following try/except block\n            try:\n                psspy.case(savLocation) #re-open case in psse\n                allCaseSolveData = getSolutionData(rawfilename,allCaseSolveData)\n                \n            except:\n                print('PROBLEM WITH CHECK SOLVABILITY. PROBLEM ENCOUNTERED WHILE RUNNING getSolutionData().')\n                logging.debug('PROBLEM WITH CHECK SOLVABILITY. PROBLEM ENCOUNTERED WHILE RUNNING getSoluti"
  },
  {
    "id": "chunk_2260",
    "text": "ILITY. PROBLEM ENCOUNTERED WHILE RUNNING getSolutionData(): ', exc_info=True)\n\n\n        ### if requested, do the CA check. If the solvability check indicates that the case did not solve, then this will not be attempted.\n        if report_dict['check_CA_performance'] == 1:\n            # check last powerflow solution\n            latestSolution = allCaseSolveData.loc[(allCaseSolveData['Case']==rawfilename)&(allCaseSolveData['Step']==3)]\n            latestSolution = latestSolution.reset_index()\n    "
  },
  {
    "id": "chunk_2261",
    "text": "latestSolution = latestSolution.reset_index()\n            if (latestSolution.at[0,'Solution Str'] != 'Met convergence tolerances                      '):\n                noData = pd.DataFrame({'Case':[rawfilename],'CANotAttemptedDuetoNon-SolvedRAW':['True']})\n                allCAData = pd.concat([allCAData,noData],ignore_index=True)\n            else:\n                #allCAData = getCAConvergenceData(savLocation,rawfilename,allCAData,AREALIST,TMP_DIR) # TO TROUBLESHOOT, uncomment this line and c"
  },
  {
    "id": "chunk_2262",
    "text": "_DIR) # TO TROUBLESHOOT, uncomment this line and comment out the following try/except block\n                try:\n                    psspy.case(savLocation) #re-open case in psse\n                    allCAData = getCAConvergenceData(savLocation,rawfilename,allCAData,AREALIST,TMP_DIR)\n                except:\n                    print('PROBLEM WITH GETTING CA CONVERGENCE. PROBLEM ENCOUNTERED WHILE RUNNING getCAConvergenceData().')\n                    logging.debug('PROBLEM WITH GETTING CA CONVERGEN"
  },
  {
    "id": "chunk_2263",
    "text": "  logging.debug('PROBLEM WITH GETTING CA CONVERGENCE. PROBLEM ENCOUNTERED WHILE RUNNING getCAConvergenceData(): ', exc_info=True)\n\n        ### if requested, do the CNTB check\n        if report_dict['CNTB_check'] == 1:\n            #CNTB_messages = getCNTBCheckData(TMP_DIR,savLocation,target_output_directory,rawfilename,CNTB_messages) # TO TROUBLESHOOT, uncomment this line and comment out the following try/except block\n            try:\n                CNTB_messages = getCNTBCheckData(TMP_DIR,savLo"
  },
  {
    "id": "chunk_2264",
    "text": "    CNTB_messages = getCNTBCheckData(TMP_DIR,savLocation,target_output_directory,rawfilename,CNTB_messages,AREALIST)\n            except:\n                print('PROBLEM WITH GETTING CNTB REPORT. PROBLEM ENCOUNTERED WHILE RUNNING getCNTBCheckData().')\n                logging.debug('PROBLEM WITH GETTING CNTB REPORT. PROBLEM ENCOUNTERED WHILE RUNNING getCNTBCheckData(): ', exc_info=True)\n        \n        \n        ### if any bus-related reports requested, get the bus data and extract the relevant dat"
  },
  {
    "id": "chunk_2265",
    "text": "ted, get the bus data and extract the relevant data\n        if (report_dict['900k_buses'] == 1): # for ERCOT-only distribution\n            #BusData = getBusData(savLocation,target_output_directory,rawfilename,BusData,AREALIST) # TO TROUBLESHOOT, uncomment this line and comment out the following try/except block\n            try:\n                BusData = getBusData(savLocation,target_output_directory,rawfilename,BusData,AREALIST)\n            except:\n                print('PROBLEM ENCOUNTERED WITH"
  },
  {
    "id": "chunk_2266",
    "text": "t:\n                print('PROBLEM ENCOUNTERED WITH GETTING BUS DATA. PROBLEM ENCOUNTERED WHILE RUNNING getBusData().')\n                logging.debug('PROBLEM ENCOUNTERED WITH GETTING BUS DATA. PROBLEM ENCOUNTERED WHILE RUNNING getBusData(): ', exc_info=True)\n            if (report_dict['900k_buses'] == 1) & (BusData.empty == False):\n                #all900k_buses = get900kBuses(BusData) #to troubleshoot, uncomment this line and comment out the following try/except block\n                try:\n    "
  },
  {
    "id": "chunk_2267",
    "text": "llowing try/except block\n                try:\n                    all900k_buses = get900kBuses(BusData)\n                except:\n                    print('PROBLEM ENCOUNTERED WHILE RUNNING get900kBuses().')\n                    logging.debug('PROBLEM ENCOUNTERED WHILE RUNNING get900kBuses().', exc_info=True)     \n            \n        ### if requested, get all the load data\n        if (report_dict['all_lds'] == 1)|(report_dict['disconnected_loads'] == 1)|(report_dict['zero_loads'] == 1):\n         "
  },
  {
    "id": "chunk_2268",
    "text": " == 1)|(report_dict['zero_loads'] == 1):\n            #thisCaseLoadData = getLdData(savLocation,allLoads,rawfilename,AREALIST) #FOR TROUBLESHOOTING, uncomment this line and comment out the following try/except block\n            try:\n                thisCaseAllLoadData = getLdDataTotalsReportedInCaseColumn(savLocation,allLoads,rawfilename,AREALIST)\n                if allLoads.empty == True:\n                    allLoads = thisCaseAllLoadData\n                    allLoads = allLoads.drop_duplicates()"
  },
  {
    "id": "chunk_2269",
    "text": "             allLoads = allLoads.drop_duplicates()\n                else:\n                    allLoads = allLoads.merge(thisCaseAllLoadData,how='outer',on=['ID','NAME','LODTYPE','NUMBER','STATION','AREA','ZONE','STATUS','OWNER'])\n                    allLoads = allLoads.drop_duplicates()\n\n            except:\n                print('PROBLEM ENCOUNTERED WITH GETTING LOAD DATA. PROBLEM ENCOUNTERED WHILE RUNNING getLdDataTotalsReportedInCaseColumn()')\n                logging.debug('PROBLEM ENCOUNTERED "
  },
  {
    "id": "chunk_2270",
    "text": "               logging.debug('PROBLEM ENCOUNTERED WITH GETTING LOAD DATA. PROBLEM ENCOUNTERED WHILE RUNNING getLdDataTotalsReportedInCaseColumn(): ', exc_info=True)\n            \n            #thisCaseLoadData = getLdData(savLocation,allLoads,rawfilename,AREALIST) #FOR TROUBLESHOOTING, uncomment this line and comment out the following try/except block\n            try:\n                thisCaseLoadData = getLdData(savLocation,allLoadsWithTotalsColumn,rawfilename,AREALIST)\n                if allLoads"
  },
  {
    "id": "chunk_2271",
    "text": ",rawfilename,AREALIST)\n                if allLoadsWithTotalsColumn.empty == True:\n                    allLoadsWithTotalsColumn = thisCaseLoadData\n                    allLoadsWithTotalsColumn = allLoadsWithTotalsColumn.drop_duplicates()\n                else:\n                    allLoadsWithTotalsColumn = allLoadsWithTotalsColumn.merge(thisCaseLoadData,how='outer',on=['ID','NAME','LODTYPE','TOTALACT','NUMBER','STATION','AREA','ZONE','STATUS','OWNER'])\n                    allLoadsWithTotalsColumn ="
  },
  {
    "id": "chunk_2272",
    "text": "'])\n                    allLoadsWithTotalsColumn = allLoadsWithTotalsColumn.drop_duplicates()\n            except:\n                print('PROBLEM ENCOUNTERED WITH GETTING LOAD DATA. PROBLEM ENCOUNTERED WHILE RUNNING getLdData()')\n                logging.debug('PROBLEM ENCOUNTERED WITH GETTING LOAD DATA. PROBLEM ENCOUNTERED WHILE RUNNING getLdData(): ', exc_info=True)\n\n            if report_dict['disconnected_loads'] == 1:\n                #allDisconnectedLds = getDisconnectedLoads(thisCaseLoadData"
  },
  {
    "id": "chunk_2273",
    "text": "nnectedLds = getDisconnectedLoads(thisCaseLoadData,allDisconnectedLds) #FOR TROUBLESHOOTING, uncomment this line and comment out the following try/except block\n                try:\n                    allDisconnectedLds = getDisconnectedLoads(thisCaseLoadData,allDisconnectedLds)\n                except:\n                    print('PROBLEM ENCOUNTERED WHILE RUNNING getDisconnectedLoads()')\n                    logging.debug('PROBLEM ENCOUNTERED WHILE RUNNING getDisconnectedLoads(): ', exc_info=True)"
  },
  {
    "id": "chunk_2274",
    "text": " RUNNING getDisconnectedLoads(): ', exc_info=True)\n            if report_dict['zero_loads'] == 1:\n                #allZeroLds = getZeroLoads(thisCaseLoadData,allZeroLds) #TO TROUBLESHOOT, uncomment this line and comment out the following try/except block\n                try:\n                    allZeroLds = getZeroLoads(thisCaseLoadData,allZeroLds)\n                except:\n                    print('PROBLEM ENCOUNTERED WHILE RUNNING getZeroLoads().')\n                    logging.debug('PROBLEM ENC"
  },
  {
    "id": "chunk_2275",
    "text": ".')\n                    logging.debug('PROBLEM ENCOUNTERED WHILE RUNNING getZeroLoads(): ', exc_info=True)\n            \n\n        ### if requested, get the disconnected shunts\n        if report_dict['disconnected_shunts'] == 1:\n            #alldisconnected_shunts = getDisconnectedShunts(savLocation,rawfilename,alldisconnected_shunts,AREALIST) # TO TROUBLESHOOT, uncomment this line and comment out the following try/except block\n            try:\n                alldisconnected_shunts = getDisconnec"
  },
  {
    "id": "chunk_2276",
    "text": "             alldisconnected_shunts = getDisconnectedShunts(savLocation,rawfilename,alldisconnected_shunts,AREALIST)\n            except:\n                print('PROBLEM ENCOUNTERED WITH GETTING SHUNT DATA. PROBLEM ENCOUNTERED WHILE RUNNING getDisconnectedShunts().')\n                logging.debug('PROBLEM ENCOUNTERED WITH GETTING SHUNT DATA. PROBLEM ENCOUNTERED WHILE RUNNING getDisconnectedShunts(): ', exc_info=True)\n\n        ### if requested, get the bus inconsistencies\n        if report_dict['bu"
  },
  {
    "id": "chunk_2277",
    "text": "the bus inconsistencies\n        if report_dict['bus_type_inconsistencies'] == 1:\n            #allBusInconsistencies = getAllBusInconsistencies(rawfilename,allBusInconsistencies) # TO TROUBLESHOOT, uncomment this line and comment out the following try/except block\n            try:\n                psspy.case(savLocation) #re-open case in psse\n                allBusInconsistencies = getAllBusInconsistencies(rawfilename,allBusInconsistencies)\n            except:\n                print('PROBLEM ENCOUN"
  },
  {
    "id": "chunk_2278",
    "text": "     except:\n                print('PROBLEM ENCOUNTERED WITH GETTING BUS INCONSISTENCIES. PROBLEM ENCOUNTERED WHILE RUNNING getAllBusInconsistencies()')\n                logging.debug('PROBLEM ENCOUNTERED WITH GETTING BUS INCONSISTENCIES. PROBLEM ENCOUNTERED WHILE RUNNING getAllBusInconsistencies(): ', exc_info=True)\n\n    \n        ### if requested, get the islands from TREE\n        if report_dict['TREE_islands'] == 1:\n            #allIslands = getTREEIslands(TMP_DIR,rawfilename,allIslands) # TO T"
  },
  {
    "id": "chunk_2279",
    "text": "TREEIslands(TMP_DIR,rawfilename,allIslands) # TO TROUBLESHOOT, uncomment this line and comment out the following try/except block\n            try:\n                psspy.case(savLocation) #re-open case in psse\n                allIslands = getTREEIslands(TMP_DIR,rawfilename,allIslands)\n            except:\n                print('PROBLEM ENCOUNTERED WITH GETTING ISLAND DATA. PROBLEM ENCOUNTERED WHILE RUNNING getTREEIslands()')\n                logging.debug('PROBLEM ENCOUNTERED WITH GETTING ISLAND DA"
  },
  {
    "id": "chunk_2280",
    "text": ".debug('PROBLEM ENCOUNTERED WITH GETTING ISLAND DATA. PROBLEM ENCOUNTERED WHILE RUNNING getTREEIslands(): ', exc_info=True)\n        ### if requested, get the PSSE pf check reports\n        if report_dict['PSSE_pf_checks'] == 1:\n            #allPFCheckResults = getPSSEpfChecks(TMP_DIR,rawfilename,allPFCheckResults,allPFCheckTypes,AREALIST) # TO TROUBLESHOOT, uncomment this line and comment out the following try/except block\n            try:\n                psspy.case(savLocation) #re-open case in "
  },
  {
    "id": "chunk_2281",
    "text": "         psspy.case(savLocation) #re-open case in psse\n                allPFCheckResults = getPSSEpfChecks(TMP_DIR,rawfilename,allPFCheckResults,allPFCheckTypes,AREALIST)\n            except:\n                print('PROBLEM ENCOUNTERED WITH GETTING PSSE PF CHECKS. PROBLEM ENCOUNTERED WHILE RUNNING getPSSEpfChecks()')\n                logging.debug('PROBLEM ENCOUNTERED WITH GETTING PSSE PF CHECKS. PROBLEM ENCOUNTERED WHILE RUNNING getPSSEpfChecks(): ', exc_info=True)\n\n        ### if requested, get t"
  },
  {
    "id": "chunk_2282",
    "text": "', exc_info=True)\n\n        ### if requested, get the branch remote end voltage inconsistencies\n        if report_dict['br_remote_end_voltage_inconsistencies'] == 1:\n            #allBrTerminalVoltageInconsistencies = getBrEndVoltageInconsistencies(savLocation,rawfilename,allBrTerminalVoltageInconsistencies,AREALIST)# TO TROUBLESHOOT, uncomment this line and comment out the following try/except block\n            try:\n                allBrTerminalVoltageInconsistencies = getBrEndVoltageInconsistenc"
  },
  {
    "id": "chunk_2283",
    "text": "ltageInconsistencies = getBrEndVoltageInconsistencies(savLocation,rawfilename,allBrTerminalVoltageInconsistencies,AREALIST)\n            except:\n                print('PROBLEM ENCOUNTERED WITH GETTING BRANCH TERMINAL VOLTAGE INCONSISTENCIES. PROBLEM ENCOUNTERED WHEN RUNNING getBrEndVoltageInconsistencies()')\n                logging.debug('PROBLEM ENCOUNTERED WITH GETTING BRANCH TERMINAL VOLTAGE INCONSISTENCIES. PROBLEM ENCOUNTERED WHEN RUNNING getBrEndVoltageInconsistencies(): ', exc_info=True)\n\n"
  },
  {
    "id": "chunk_2284",
    "text": "BrEndVoltageInconsistencies(): ', exc_info=True)\n\n        ### if any node-breaker checks are required, get the raw model in JSON format and extract the node breaker data\n        # this is the if statement for the ERCOT-distributed version\n        if ((report_dict['invalid_Binit_switched_shunts'] == 1)\\\n            | (report_dict['incorrect_shunt_remote_buses'] == 1) | (report_dict['incorrect_gen_remote_buses'] == 1) \\\n            | (report_dict['invalid_setpts_continuous_shunts'] == 1)):\n       "
  },
  {
    "id": "chunk_2285",
    "text": "invalid_setpts_continuous_shunts'] == 1)):\n            #RAW_JSON = getRawxJSON(TMP_DIR,rawfilename) # TO TROUBLESHOOT, uncomment this line and comment out the following try/except block\n            try:\n                psspy.case(savLocation) #re-open case in psse\n                RAW_JSON = getRawxJSON(TMP_DIR,rawfilename)\n            except:\n                print('PROBLEM ENCOUNTERED WHEN GETTING RAWX DATA FROM CASE. PROBLEM ENCOUNTERED WHILE RUNNING getRawxJSON()')\n                logging.debu"
  },
  {
    "id": "chunk_2286",
    "text": "NNING getRawxJSON()')\n                logging.debug('PROBLEM ENCOUNTERED WHEN GETTING RAWX DATA FROM CASE. PROBLEM ENCOUNTERED WHILE RUNNING getRawxJSON(): ', exc_info=True)\n            #IBUS_NODE_DATA, JBUS_NODE_DATA, KBUS_NODE_DATA, ALL_TERMABLE_EQUIP_W_NODE_DATA, ALL_ELEMENT_DATA_DICT = getNodeBreakerData(RAW_JSON)# TO TROUBLESHOOT, uncomment this line and comment out the following try/except block\n            try:\n                IBUS_NODE_DATA, JBUS_NODE_DATA, KBUS_NODE_DATA, ALL_TERMABLE_E"
  },
  {
    "id": "chunk_2287",
    "text": "TA, JBUS_NODE_DATA, KBUS_NODE_DATA, ALL_TERMABLE_EQUIP_W_NODE_DATA, \\\n                    ALL_ELEMENT_DATA_DICT, ALL_TERMABLE_EQUIP_W_NODE_DATA_INCL_SUBSWDS = getNodeBreakerData(RAW_JSON)\n            except:\n                print('PROBLEM ENCOUNTERED WITH PROCESSESING NODE-BREAKER DATA. PROBLEM ENCOUNTERED WHILE RUNNING getNodeBreakerData()')\n                logging.debug('PROBLEM ENCOUNTERED WITH PROCESSESING NODE-BREAKER DATA. PROBLEM ENCOUNTERED WHILE RUNNING getNodeBreakerData(): ', exc_info"
  },
  {
    "id": "chunk_2288",
    "text": "ED WHILE RUNNING getNodeBreakerData(): ', exc_info=True)\n           \n            if report_dict['invalid_Binit_switched_shunts'] == 1:\n                #allSwShuntsWithInvalidBinit = getInvalidBinitShunts(ALL_ELEMENT_DATA_DICT['swshunt'],rawfilename,allSwShuntsWithInvalidBinit,savLocation,AREALIST)# TO TROUBLESHOOT, uncomment this line and comment out the following try/except block\n                try:\n                    allSwShuntsWithInvalidBinit = getInvalidBinitShunts(ALL_ELEMENT_DATA_DICT['"
  },
  {
    "id": "chunk_2289",
    "text": "it = getInvalidBinitShunts(ALL_ELEMENT_DATA_DICT['swshunt'],rawfilename,allSwShuntsWithInvalidBinit,savLocation,AREALIST)\n                except:\n                    print('PROBLEM ENCOUNTERED WITH GETTING INVALID BINIT VALUES. PROBLEM ENCOUNTERED WHILE RUNNING getInvalidBinitShunts()')\n                    logging.debug('PROBLEM ENCOUNTERED WITH GETTING INVALID BINIT VALUES. PROBLEM ENCOUNTERED WHILE RUNNING getInvalidBinitShunts(): ', exc_info=True)\n            if report_dict['invalid_setpts_co"
  },
  {
    "id": "chunk_2290",
    "text": "rue)\n            if report_dict['invalid_setpts_continuous_shunts'] == 1:\n                #allSwShuntsWithInvalidSetpoints = getInvalidSetpointsContinuousShunts(ALL_ELEMENT_DATA_DICT['swshunt'],rawfilename,allSwShuntsWithInvalidSetpoints,savLocation,AREALIST)# TO TROUBLESHOOT, uncomment this line and comment out the following try/except block\n                try:\n                    allSwShuntsWithInvalidSetpoints = getInvalidSetpointsContinuousShunts(ALL_ELEMENT_DATA_DICT['swshunt'],rawfilename"
  },
  {
    "id": "chunk_2291",
    "text": "hunts(ALL_ELEMENT_DATA_DICT['swshunt'],rawfilename,allSwShuntsWithInvalidSetpoints,savLocation,AREALIST)\n                except:\n                    print('PROBLEM ENCOUNTERED WITH GETTING INVALID SHUNT SETPOINT VALUES. PROBLEM ENCOUNTERED WHILE RUNNING getInvalidSetpointsContinuousShunts()')\n                    logging.debug('PROBLEM ENCOUNTERED WITH GETTING INVALID SHUNT SETPOINT VALUES. PROBLEM ENCOUNTERED WHILE RUNNING getInvalidSetpointsContinuousShunts(): ', exc_info=True)\n            ### "
  },
  {
    "id": "chunk_2292",
    "text": "inuousShunts(): ', exc_info=True)\n            ### if requested, get the incorrect switched shun remote bus report\n            if report_dict['incorrect_shunt_remote_buses'] == 1:\n                #allIncorrectShuntRemoteBuses = getIncorrectShuntRemoteBuses(ALL_ELEMENT_DATA_DICT['swshunt'],rawfilename,allIncorrectShuntRemoteBuses,savLocation,AREALIST)# TO TROUBLESHOOT, uncomment this line and comment out the following try/except block\n                try:\n                    allIncorrectShuntRemot"
  },
  {
    "id": "chunk_2293",
    "text": "   try:\n                    allIncorrectShuntRemoteBuses = getIncorrectShuntRemoteBuses(ALL_ELEMENT_DATA_DICT['swshunt'],rawfilename,allIncorrectShuntRemoteBuses,savLocation,AREALIST)\n                except:\n                    print('PROBLEM ENCOUNTERED WITH GETTING INCORRECT SHUNT REMOTE BUSES. PROBLEM ENCOUNTERED WHILLE RUNNING getIncorrectShuntRemoteBuses()')\n                    logging.debug('PROBLEM ENCOUNTERED WITH GETTING INCORRECT SHUNT REMOTE BUSES. PROBLEM ENCOUNTERED WHILLE RUNNING g"
  },
  {
    "id": "chunk_2294",
    "text": "REMOTE BUSES. PROBLEM ENCOUNTERED WHILLE RUNNING getIncorrectShuntRemoteBuses(): ', exc_info=True)\n            ### if requested, get the incorrect generator remote bus report\n            if report_dict['incorrect_gen_remote_buses'] == 1:\n                #allIncorrectGenRemoteBuses = getIncorrectGenRemoteBuses(ALL_ELEMENT_DATA_DICT['generator'],rawfilename,allIncorrectGenRemoteBuses,savLocation,AREALIST)# TO TROUBLESHOOT, uncomment this line and comment out the following try/except block\n        "
  },
  {
    "id": "chunk_2295",
    "text": "omment out the following try/except block\n                try:\n                    allIncorrectGenRemoteBuses = getIncorrectGenRemoteBuses(ALL_ELEMENT_DATA_DICT['generator'],rawfilename,allIncorrectGenRemoteBuses,savLocation,AREALIST)\n                except:\n                    print('PROBLEM ENCOUNTERED WITH GETTING INCORRECT GENERATOR REMOTE BUSES. PROBLEM ENCOUNTERED WHILLE RUNNING getIncorrectGenRemoteBuses()')\n                    logging.debug('PROBLEM ENCOUNTERED WITH GETTING INCORRECT GEN"
  },
  {
    "id": "chunk_2296",
    "text": "ug('PROBLEM ENCOUNTERED WITH GETTING INCORRECT GENERATOR REMOTE BUSES. PROBLEM ENCOUNTERED WHILLE RUNNING getIncorrectGenRemoteBuses(): ', exc_info=True)\n\n\n    ### Save the reports\n    logging.debug('Processing cases is complete. Now creating reports')\n    summaryReport = pd.DataFrame(columns=['Report','Number of Results','Location'])\n    # make excel for CNTB messages\n    if report_dict['CNTB_check']==1:\n        logging.debug('Creating CNTB Report')\n        #CNTB_messages.to_csv(target_output_d"
  },
  {
    "id": "chunk_2297",
    "text": "rt')\n        #CNTB_messages.to_csv(target_output_directory+r'\\all_CNTB_messages.csv')\n        CNTB_excelWriter = pd.ExcelWriter(target_output_directory+r'\\all_CNTB_messages.xlsx')\n        CNTB_errors = CNTB_messages.loc[CNTB_messages['Type']=='ERROR']\n        CNTB_warnings = CNTB_messages.loc[CNTB_messages['Type']=='Warning']\n        #CNTB_other = CNTB_messages.loc[CNTB_messages_tmp['Type']=='Other']\n        CNTB_errors.to_excel(CNTB_excelWriter,sheet_name='Errors')\n        CNTB_warnings.to_exce"
  },
  {
    "id": "chunk_2298",
    "text": "sheet_name='Errors')\n        CNTB_warnings.to_excel(CNTB_excelWriter,sheet_name='Warnings')\n        #CNTB_other.to_excel(CNTB_excelWriter,sheet_name='Other')\n        CNTB_excelWriter.save()\n        # insert metadata to summaryReport\n        sumData = pd.DataFrame({'Report':['CNTB_errors','CNTB_warnings'],\n        'Number of Results':[CNTB_errors.index.size,CNTB_warnings.index.size],\n        'Location':[target_output_directory+r'\\all_CNTB_messages.xlsx',target_output_directory+r'\\all_CNTB_message"
  },
  {
    "id": "chunk_2299",
    "text": ".xlsx',target_output_directory+r'\\all_CNTB_messages.xlsx']})\n        summaryReport = pd.concat([summaryReport,sumData],ignore_index=True)\n\n    # make excel for PSSE_pf_check_results    \n    if report_dict['PSSE_pf_checks'] == 1:\n        logging.debug('Creating PSSE_pf_checks report')\n        PSSEpfCheck_excelWriter = pd.ExcelWriter(target_output_directory+r'\\all_PSSE_pf_checks.xlsx')\n        for checkType in allPFCheckResults.keys():\n            sheet_name_max = checkType[0:30]\n            allPF"
  },
  {
    "id": "chunk_2300",
    "text": "sheet_name_max = checkType[0:30]\n            allPFCheckResults[checkType].to_excel(PSSEpfCheck_excelWriter,sheet_name='{0}'.format(sheet_name_max))\n            # insert metadata to summaryReport\n            sumData = pd.DataFrame({'Report':['PSSE PF Check - {0}'.format(checkType)],\n            'Number of Results':[allPFCheckResults[checkType].index.size],\n            'Location':[target_output_directory+r'\\all_PSSE_pf_checks.xlsx']})\n            summaryReport = pd.concat([summaryReport,sumData],i"
  },
  {
    "id": "chunk_2301",
    "text": "ummaryReport = pd.concat([summaryReport,sumData],ignore_index=True)\n        PSSEpfCheck_excelWriter.save()\n            \n    \n\n    # make csv reports for all the other reports\n    report_to_data_dictionary = {'900k_buses':all900k_buses,\\\n                                'disconnected_shunts':alldisconnected_shunts,\\\n                                'disconnected_loads':allDisconnectedLds,\\\n                                'zero_loads':allZeroLds,\\\n                                'invalid_Binit_switc"
  },
  {
    "id": "chunk_2302",
    "text": "                              'invalid_Binit_switched_shunts':allSwShuntsWithInvalidBinit,\\\n                                'TREE_islands':allIslands,\\\n                                'br_remote_end_voltage_inconsistencies':allBrTerminalVoltageInconsistencies,\\\n                                'bus_type_inconsistencies':allBusInconsistencies,\\\n                                'all_lds':allLoads,\\\n                                'check_solvability':allCaseSolveData,\\\n                               "
  },
  {
    "id": "chunk_2303",
    "text": "allCaseSolveData,\\\n                                'incorrect_shunt_remote_buses':allIncorrectShuntRemoteBuses,\\\n                                'incorrect_gen_remote_buses':allIncorrectGenRemoteBuses,\\\n                                'check_CA_performance':allCAData,\\\n                                'invalid_setpts_continuous_shunts':allSwShuntsWithInvalidSetpoints}\n    for report in report_to_data_dictionary.keys():\n        if report_dict[report]==1:\n            logging.debug('Creating {0} rep"
  },
  {
    "id": "chunk_2304",
    "text": "t]==1:\n            logging.debug('Creating {0} report'.format(report))\n            report_to_data_dictionary[report].to_csv(target_output_directory+r'\\{0}.csv'.format(report))\n            # insert metadata to summaryReport\n            sumData = pd.DataFrame({'Report':[report],\n            'Number of Results':[report_to_data_dictionary[report].index.size],\n            'Location':[target_output_directory+r'\\{0}.csv'.format(report)]})\n            summaryReport = pd.concat([summaryReport,sumData],ig"
  },
  {
    "id": "chunk_2305",
    "text": "mmaryReport = pd.concat([summaryReport,sumData],ignore_index=True)\n\n    # create summary report\n    logging.debug('Creating summary report.')\n    summaryReport['Location'] = summaryReport['Location'].apply(lambda x: make_clickable(x, x))\n    summaryReport = summaryReport.sort_values(by=['Number of Results'],ascending=False)\n    summary_html = summaryReport.to_html(render_links=True,escape=False)\n    text_file = open(target_output_directory+r'\\SummaryReport.html','w')\n    text_file.write(summary_"
  },
  {
    "id": "chunk_2306",
    "text": "maryReport.html','w')\n    text_file.write(summary_html)\n    text_file.close()\n    logging.debug('Reports completed.')\n    logging.debug('Done.')\n    logging.shutdown()\n\n########### CLASS DEFINITIONS ##############\nclass SSWGCaseQA(wx.Frame):\n    def __init__(self):\n        self.SelectedAreas = []\n        self.SelectedBuses = []\n        self.AllAreas = [] # replace with real data from case when the corresponding button is selected\n        self.AllBuses = [] # replace with real data from case when"
  },
  {
    "id": "chunk_2307",
    "text": "Buses = [] # replace with real data from case when the corresponding button is selected\n        self.chosenAreas = []\n        self.chosenBuses = []\n        wx.Frame.__init__(self,None,wx.ID_ANY,\"Perform quality assurance checks on raw file(s).\",size =(1000,600))\n        self.panel = wx.Panel(self, wx.ID_ANY)\n\n        # make wrapper\n        self.wrapper = wx.FlexGridSizer(4,1,20,20) # wx.FlexGridSizer(2,1,20,20)\n        self.wrapper.AddGrowableCol(0)\n\n\n        #select an SSWG cases directory\n    "
  },
  {
    "id": "chunk_2308",
    "text": "(0)\n\n\n        #select an SSWG cases directory\n        self.label1 = wx.StaticText(self.panel)\n        self.caseDirectory = wx.DirPickerCtrl(self.panel, size=(800,25))\n        row1 = wx.StaticBoxSizer(wx.StaticBox(self.panel, 1, 'Please select the SSWG raw case directory (all .raw files in the selected directory will be analyzed):'), orient=wx.HORIZONTAL)\n        row1.Add(self.label1,0,wx.TOP | wx.RIGHT,10)\n        row1.Add(self.caseDirectory)\n\n        self.wrapper.Add(row1,50,wx.TOP | wx.LEFT | "
  },
  {
    "id": "chunk_2309",
    "text": "      self.wrapper.Add(row1,50,wx.TOP | wx.LEFT | wx.RIGHT | wx.ALIGN_CENTER,20)\n\n        #select model areas for report generation\n        self.label3 = wx.StaticText(self.panel)\n        #self.conFile = wx.FilePickerCtrl(self.panel, size=(800,25),wildcard=\"*.con\")\n        self.reportAreas = wx.TextCtrl(self.panel, size=(800,25),value=\"\")\n        row3 = wx.StaticBoxSizer(wx.StaticBox(self.panel, 1, 'Please provide a comma-separated list of areas for reporting (leave blank to get results for enti"
  },
  {
    "id": "chunk_2310",
    "text": "for reporting (leave blank to get results for entire model):'), orient=wx.HORIZONTAL)\n        row3.Add(self.label3,0,wx.TOP | wx.RIGHT,10)\n        row3.Add(self.reportAreas)\n        self.wrapper.Add(row3,50,wx.TOP | wx.LEFT | wx.RIGHT | wx.ALIGN_CENTER,20)\n        # self.panel.SetSizerAndFit(wrapper)\n        # self.Centre()\n\n        #select an output directory\n        self.label2 = wx.StaticText(self.panel)\n        self.dirCtrl = wx.DirPickerCtrl(self.panel, size=(800,25))\n        row2 = wx.Stat"
  },
  {
    "id": "chunk_2311",
    "text": "(self.panel, size=(800,25))\n        row2 = wx.StaticBoxSizer(wx.StaticBox(self.panel, 1, 'Please select the output location for reports:'), orient=wx.HORIZONTAL)\n        row2.Add(self.label2,0,wx.TOP | wx.RIGHT,10)\n        row2.Add(self.dirCtrl)\n\n        self.wrapper.Add(row2,50,wx.TOP | wx.LEFT | wx.RIGHT | wx.ALIGN_CENTER,20)\n        self.panel.SetSizerAndFit(self.wrapper)\n        self.Centre()\n\n        # report selection radio buttons\n        self.RB_900k_buses = wx.CheckBox(self.panel,11,lab"
  },
  {
    "id": "chunk_2312",
    "text": "self.RB_900k_buses = wx.CheckBox(self.panel,11,label='900k+ buses',pos =(100,275))\n        self.RB_900k_buses.SetValue(True)\n        self.RB_TREE_islands = wx.CheckBox(self.panel,22,label='TREE_islands',pos =(300,275))\n        self.RB_TREE_islands.SetValue(True)\n        self.RB_bus_type_inconsistencies = wx.CheckBox(self.panel,33,label='Bus type inconsistencies',pos =(500,275))\n        self.RB_bus_type_inconsistencies.SetValue(True)\n        self.RB_CNTB_check = wx.CheckBox(self.panel,33,label='C"
  },
  {
    "id": "chunk_2313",
    "text": "RB_CNTB_check = wx.CheckBox(self.panel,33,label='CNTB check',pos =(700,275))\n        self.RB_CNTB_check.SetValue(True)\n        self.RB_disconnected_shunts = wx.CheckBox(self.panel,44,label='Disconnected shunts',pos =(100,300))\n        self.RB_disconnected_shunts.SetValue(True)\n        self.RB_invalid_Binit_switched_shunts = wx.CheckBox(self.panel,55,label='Invalid Binit sw. shunts',pos =(300,300))\n        self.RB_invalid_Binit_switched_shunts.SetValue(True)\n        self.RB_invalid_setpts_continu"
  },
  {
    "id": "chunk_2314",
    "text": "Value(True)\n        self.RB_invalid_setpts_continuous_shunts = wx.CheckBox(self.panel,66,label='Invalid VHi-VLo cont. ctrl. shunts',pos =(500,300))\n        self.RB_invalid_setpts_continuous_shunts.SetValue(True)\n        self.RB_incorrect_shunt_remote_buses = wx.CheckBox(self.panel,77,label='Non-POI Shunt Remote Bus',pos =(700,300))\n        self.RB_incorrect_shunt_remote_buses.SetValue(True)\n        self.RB_incorrect_gen_remote_buses = wx.CheckBox(self.panel,88,label='Non-POI Gen Remote Bus',pos "
  },
  {
    "id": "chunk_2315",
    "text": "(self.panel,88,label='Non-POI Gen Remote Bus',pos =(100,325))\n        self.RB_incorrect_gen_remote_buses.SetValue(True)\n        self.RB_br_remote_end_voltage_inconsistencies = wx.CheckBox(self.panel,99,label='Inconsistent line end voltages',pos =(300,325))\n        self.RB_br_remote_end_voltage_inconsistencies.SetValue(True)\n        self.RB_check_solvability = wx.CheckBox(self.panel,111,label='Check solvability',pos =(500,325))\n        self.RB_check_solvability.SetValue(True)\n        self.RB_chec"
  },
  {
    "id": "chunk_2316",
    "text": "ck_solvability.SetValue(True)\n        self.RB_check_CA_performance = wx.CheckBox(self.panel,222,label='Check CA performance (sng. br. elem)',pos =(700,325))\n        self.RB_check_CA_performance.SetValue(True)\n        self.RB_PSSE_pf_checks = wx.CheckBox(self.panel,333,label='PSSE pf checks',pos =(100,350))\n        self.RB_PSSE_pf_checks.SetValue(True)\n        self.RB_all_lds = wx.CheckBox(self.panel,444,label='All loads report',pos =(300,350))\n        self.RB_all_lds.SetValue(True)\n        self."
  },
  {
    "id": "chunk_2317",
    "text": "      self.RB_all_lds.SetValue(True)\n        self.RB_disconnected_loads = wx.CheckBox(self.panel,555,label='Disconnected loads',pos =(500,350))\n        self.RB_disconnected_loads.SetValue(True)\n        self.RB_zero_loads = wx.CheckBox(self.panel,666,label='0 MVA loads',pos =(700,350))\n        self.RB_zero_loads.SetValue(True)\n\n        # button push\n        self.generateQAReports = wx.Button(self.panel,-1, \"Generate Selected QA Reports\", pos=(400, 450))\n        self.generateQAReports.Bind(wx.EVT_"
  },
  {
    "id": "chunk_2318",
    "text": " 450))\n        self.generateQAReports.Bind(wx.EVT_BUTTON, self.generateQAReportsBtnEvent, self.generateQAReports)\n\n    def generateQAReportsBtnEvent(self, event):\n        if self.caseDirectory.GetPath() == '':\n            self.nocaseDirectoryChosenMessage = wx.MessageBox('Choose a valid SSWG case directory to read the unprocessed raw files from.')\n            return\n        if self.dirCtrl.GetPath() == '':\n            self.nooutputDirectoryChosenMessage = wx.MessageBox('Choose an output director"
  },
  {
    "id": "chunk_2319",
    "text": "Message = wx.MessageBox('Choose an output directory for the output reports.')\n            return\n        if self.reportAreas.GetLineText(0) == '':\n            areaList = []\n        else:\n            try:\n                areaList = self.reportAreas.GetLineText(0).split(\",\")\n                areaList = [int(x) for x in areaList]\n            except:\n                areaList = None\n        if areaList == None:\n            self.areaErrorMessage = wx.MessageBox('Type a comma-separated list of areas for"
  },
  {
    "id": "chunk_2320",
    "text": "ssageBox('Type a comma-separated list of areas for which to run the QA checks. (For example: \"1, 2, 3\"). Do not enter any newline characters. Leave this blank if you want to run the reports for the entire model, regardless of area.')\n        runAllReportsList = ['900k_buses','TREE_islands','bus_type_inconsistencies','CNTB_check',\n        'disconnected_shunts', 'invalid_Binit_switched_shunts','invalid_setpts_continuous_shunts',\n        'incorrect_shunt_remote_buses','incorrect_gen_remote_buses','"
  },
  {
    "id": "chunk_2321",
    "text": "shunt_remote_buses','incorrect_gen_remote_buses','br_remote_end_voltage_inconsistencies',\n        'check_solvability','check_CA_performance','PSSE_pf_checks','all_lds','disconnected_loads',\n        'zero_loads']\n        reportSelections = [self.RB_900k_buses.GetValue(),\n        self.RB_TREE_islands.GetValue(),\n        self.RB_bus_type_inconsistencies.GetValue(),\n        self.RB_CNTB_check.GetValue(),\n        self.RB_disconnected_shunts.GetValue(),\n        self.RB_invalid_Binit_switched_shunts.Ge"
  },
  {
    "id": "chunk_2322",
    "text": ",\n        self.RB_invalid_Binit_switched_shunts.GetValue(),\n        self.RB_invalid_setpts_continuous_shunts.GetValue(),\n        self.RB_incorrect_shunt_remote_buses.GetValue(),\n        self.RB_incorrect_gen_remote_buses.GetValue(),\n        self.RB_br_remote_end_voltage_inconsistencies.GetValue(),\n        self.RB_check_solvability.GetValue(),\n        self.RB_check_CA_performance.GetValue(),\n        self.RB_PSSE_pf_checks.GetValue(),\n        self.RB_all_lds.GetValue(),\n        self.RB_disconnecte"
  },
  {
    "id": "chunk_2323",
    "text": "RB_all_lds.GetValue(),\n        self.RB_disconnected_loads.GetValue(),\n        self.RB_zero_loads.GetValue()]\n        AllReportsDict = dict(zip(runAllReportsList,reportSelections))\n        RequestedReportsDict = {key: value for key, value in AllReportsDict.items() if value == True}\n        \n        \n        #trigger the report creation\n\n        print('All required files and directories selected. Now running the following QA reports:')\n        print(list(RequestedReportsDict.keys()))\n        \n\n   "
  },
  {
    "id": "chunk_2324",
    "text": "t(list(RequestedReportsDict.keys()))\n        \n\n        getQAReports(CASEDIRECTORY=self.caseDirectory,OUTPUTDIRECTORY=self.dirCtrl,DESIRED_QA_LIST=list(RequestedReportsDict.keys()),AREALIST=areaList)\n        print('Done!')\n\n        self.QAReportsComplete = wx.MessageBox('SSWG QA reports complete. Go to {} to see results.'.format(self.dirCtrl.GetPath()))\n\n############ MAIN ###############\nif __name__ == \"__main__\":\n    app = wx.App(False)\n    frame = SSWGCaseQA() # for general SSWG distribution\n  "
  },
  {
    "id": "chunk_2325",
    "text": " = SSWGCaseQA() # for general SSWG distribution\n    frame.Show()\n    app.MainLoop()\n\n\n\n    # Get Load stats with GUI\n\nimport wx\nimport pandas as pd\nimport pyodbc\nimport datetime\nfrom dateutil.relativedelta import relativedelta\nimport copy\nimport shutil\nimport os\nimport numpy as np\nimport sys\nimport tempfile\nimport xlsxwriter\nimport pathlib\nimport glob\nimport json\nimport requests\nimport logging\nimport struct\nimport time\nimport tkinter\nfrom tkinter import Tk\nfrom tkinter import Button\nfrom tkinter"
  },
  {
    "id": "chunk_2326",
    "text": " import Tk\nfrom tkinter import Button\nfrom tkinter import filedialog\nimport warnings\nimport io\n\n### Get psspy bin\nprint('Select the bin location for the PSSE psspy.pyc and redirect.pyc files. Please use PSSE 35.6.')\nroot = Tk()\nPSSE_PATH = filedialog.askdirectory(initialdir = r'C:\\Program Files\\PTI\\PSSE35')\nroot.mainloop\nif (pathlib.Path(r'{0}\\psspy.pyc'.format(PSSE_PATH)).exists() == False) | (pathlib.Path(r'{0}\\redirect.pyc'.format(PSSE_PATH)).exists() == False):\n    print('No psspy.pyc and/or"
  },
  {
    "id": "chunk_2327",
    "text": "exists() == False):\n    print('No psspy.pyc and/or redirect.pyc package found at bin directory supplied {0}'.format(PSSE_PATH))\n    exit()\nroot.destroy()\n\n#### PSS/E session initialization ####\nsys.path.append(PSSE_PATH)\nos.environ['PATH'] += ';' + PSSE_PATH\nimport psspy\nimport redirect\nredirect.psse2py()                                  ## Set output to Python Shell\nierr = psspy.psseinit(0)                            ## Initialize PSSE\n\n# ignore warnings to avoid terminal message clutter.\nwarni"
  },
  {
    "id": "chunk_2328",
    "text": " warnings to avoid terminal message clutter.\nwarnings.filterwarnings('ignore')\n\n########### FUNCTION DEFINITIONS ###########\n\ndef parseBrViolationReport(BR_REPORTDATA):\n    #define column names and specs:\n    BR_col_names = ['From Bus Number','From Bus Name','From Bus kV','From Bus Area','To Bus Number','To Bus Name',\\\n        'To Bus kV','To Bus Area','Circuit ID','Loading','Rating A',r'Rating A % Loading','Rating B',r'Rating B % Loading','Rating C',r'Rating C % Loading']\n    BR_col_specs = [(0"
  },
  {
    "id": "chunk_2329",
    "text": "g C',r'Rating C % Loading']\n    BR_col_specs = [(0,11),(11,23),(23,31),(31,35),(35,47),(47,59),(59,67),(67,72),(72,76),(76,85),(85,91),(91,101),(101,108),(108,115),(115,123),(123,131)]\n\n    #define relevant header limits\n    lookup_limit1 = 'PTI INTERACTIVE POWER SYSTEM SIMULATOR'\n    lookup_limit2 = 'BUS#-SCT'\n    lookup_none = '* NONE *'\n    headerFlag = False\n\n    #read in report data and determine which lines contain header limits\n    BR_data = io.StringIO(getFileByteData(BR_REPORTDATA).deco"
  },
  {
    "id": "chunk_2330",
    "text": " = io.StringIO(getFileByteData(BR_REPORTDATA).decode('utf-8'))\n    BR_data_formatted = io.StringIO()\n    for num, line in enumerate(BR_data,1):\n        if lookup_limit1 in line:\n            headerFlag = True\n            continue\n        if lookup_limit2 in line:\n            headerFlag = False\n            continue\n        if lookup_none in line:\n            continue\n        if headerFlag == False:\n            BR_data_formatted.write(line)\n\n    #remove the header data from the report \n    BR_data_"
  },
  {
    "id": "chunk_2331",
    "text": "move the header data from the report \n    BR_data_formatted.seek(0) #go to top of the file    \n    BR_DF = pd.read_fwf(BR_data_formatted,names=BR_col_names,colspecs=BR_col_specs)\n\n    # set dtypes of each column to ensure consistency, added 12/27/22 because sometimes nullvalues come back as object dtype\n    # updated 1/17/2023 to fix the datatype of To Bus Number to str, because 3-winding xfr's actually don't have a To bus number and have a string in this column\n    convert_dict = {'From Bus Num"
  },
  {
    "id": "chunk_2332",
    "text": "g in this column\n    convert_dict = {'From Bus Number':int,\\\n        'From Bus Name':str,\\\n        'From Bus kV':str,\\\n        'From Bus Area':int,\\\n        'To Bus Number':str,\\\n        'To Bus Name':str,\\\n        'To Bus kV':str,\\\n        'To Bus Area':int,\\\n        'Circuit ID':str,\\\n        'Loading':float,\\\n        'Rating A':float,\\\n        r'Rating A % Loading':float,\\\n        'Rating B':float,\\\n        r'Rating B % Loading':float,\\\n        'Rating C':float,\\\n        r'Rating C % Loading'"
  },
  {
    "id": "chunk_2333",
    "text": "  'Rating C':float,\\\n        r'Rating C % Loading':float}\n    BR_DF = BR_DF.astype(convert_dict,errors='ignore') # updating 2/6/24 to avoid pandas throwing errors for PSSE reporting '*******' for unreasonably large numbers\n    return BR_DF\n\ndef parseVoltViolationReport(VOLT_REPORTDATA):\n    #define column names and specs:\n    VT_col_names = ['Bus Number','Bus Name','Bus kV','V(pu)','V Limit']\n    VT_col_specs_left = [(0,11),(11,23),(23,30),(30,37),(37,43)]\n    VT_col_specs_right = [(49,58),(58,7"
  },
  {
    "id": "chunk_2334",
    "text": "),(37,43)]\n    VT_col_specs_right = [(49,58),(58,70),(70,77),(77,84),(84,90)]\n\n    #define relevant header limits\n    lookup_limit1 = 'PTI INTERACTIVE POWER SYSTEM SIMULATOR'\n    lookup_limit2 = 'BUS#-SCT'\n    lookup_low_voltage = 'BUSES WITH VOLTAGE LESS THAN'\n    lookup_high_voltage = 'BUSES WITH VOLTAGE GREATER THAN'\n    lookup_none = '* NONE *'\n    headerFlag = False\n    voltageFlag = None\n\n    #read in report data and remove header data\n    VT_data = io.StringIO(getFileByteData(VOLT_REPORTD"
  },
  {
    "id": "chunk_2335",
    "text": "VT_data = io.StringIO(getFileByteData(VOLT_REPORTDATA).decode('utf-8'))\n    Low_VT_data_formatted = io.StringIO()\n    Hi_VT_data_formatted = io.StringIO()\n    for num, line in enumerate(VT_data,1):\n        if lookup_limit1 in line:\n            headerFlag = True\n            continue\n        if lookup_limit2 in line:\n            headerFlag = False\n            continue\n        if lookup_high_voltage in line:\n            voltageFlag = 'HIGH'\n            continue\n        if lookup_low_voltage in line"
  },
  {
    "id": "chunk_2336",
    "text": "    continue\n        if lookup_low_voltage in line:\n            voltageFlag = 'LOW'\n            continue\n        if lookup_none in line:\n            continue\n        if headerFlag == False:\n            if voltageFlag == 'HIGH':\n                Hi_VT_data_formatted.write(line)\n            if voltageFlag == 'LOW':\n                Low_VT_data_formatted.write(line)\n\n\n    Low_VT_data_formatted.seek(0) #go to top of the file  \n    Hi_VT_data_formatted.seek(0) #go to top of the file   \n\n    Low_VT_DF_l"
  },
  {
    "id": "chunk_2337",
    "text": "seek(0) #go to top of the file   \n\n    Low_VT_DF_left = pd.read_fwf(Low_VT_data_formatted,names=VT_col_names,colspecs=VT_col_specs_left)\n    Low_VT_DF_right = pd.read_fwf(Low_VT_data_formatted,names=VT_col_names,colspecs=VT_col_specs_left)\n    Low_VT_DF = Low_VT_DF_left.append(Low_VT_DF_right,ignore_index=True)\n    Low_VT_DF['Voltage Violation Type'] = 'LOW'\n\n    Hi_VT_DF_left = pd.read_fwf(Hi_VT_data_formatted,names=VT_col_names,colspecs=VT_col_specs_left)\n    Hi_VT_DF_right = pd.read_fwf(Hi_VT"
  },
  {
    "id": "chunk_2338",
    "text": "specs_left)\n    Hi_VT_DF_right = pd.read_fwf(Hi_VT_data_formatted,names=VT_col_names,colspecs=VT_col_specs_left)\n    Hi_VT_DF = Hi_VT_DF_left.append(Hi_VT_DF_right,ignore_index=True)\n    Hi_VT_DF['Voltage Violation Type'] = 'HIGH'\n\n    VT_DF = pd.concat([Low_VT_DF,Hi_VT_DF],ignore_index=True) \n    VT_DF = VT_DF.loc[VT_DF['Bus Number'].notnull()==True]\n    VT_DF['Bus Number'] = VT_DF['Bus Number'].astype(str)\n\n    return VT_DF\n\ndef getAccReportViolations(Report): # pass location of PSSE text acc "
  },
  {
    "id": "chunk_2339",
    "text": "lations(Report): # pass location of PSSE text acc report \n    File1 = open(Report,'br')    \n    Dict1 = File1.readlines()        \n    iter_Dict1 = iter(Dict1) # iterating over the iter, see https://stackoverflow.com/questions/21594302/is-there-a-way-to-remember-the-position-in-a-python-iterator      \n    BrOL1 = None\n    SwdOL1 = None        \n    VoltOL1 = None      \n    LdLoss1 = None      \n    ConvRes1 = None\n    Con_File_Name1 = None\n    CA_Violations = None # adding this Nonetype assignment "
  },
  {
    "id": "chunk_2340",
    "text": "olations = None # adding this Nonetype assignment on 6/14/2021, not sure why but this appears to be a problem now with recent updates.\n\n    BrOL1 = pd.DataFrame(columns=['Monitored_Branch','Contingency_Label','Rating','MW','Mvar','MVA','%'])      \n    SwdOL1 = pd.DataFrame(columns=['Monitored_SWD','Contingency_Label','Rating','MW','Mvar','MVA','%','SWD_Loop'])\n    VoltOL1 = pd.DataFrame(columns=['System','Contingency_Label','Bus','V-Cont','V-Init','V-Max','V-Min'])        \n    LdLoss1 = pd.DataF"
  },
  {
    "id": "chunk_2341",
    "text": "','V-Max','V-Min'])        \n    LdLoss1 = pd.DataFrame(columns=['Bus','Contingency_Label','Load(MW)'])        \n    ConvRes1 = pd.DataFrame(columns=['Contingency_Label','Termination_State','Flow#','Volt#','Load'])        \n    Con_File_Name1 = \"\"\n\n    #read report data into pandas dataframes\n\n    BrOL_fields = []\n    SwdOL_fields = []\n    VoltOL_fields = []\n    LdLoss_fields = []\n    ConvRes_fields = []\n\n    for line in iter_Dict1:\n        if \"CONTINGENCY DESCRIPTION FILE:\" in line.decode(\"utf-8\")"
  },
  {
    "id": "chunk_2342",
    "text": "INGENCY DESCRIPTION FILE:\" in line.decode(\"utf-8\"):\n            Con_File_Name1 = line[30:]\n            break\n    for line in iter_Dict1:\n        #print line\n        if \"<--------------------- MONITORED BRANCH ---------------------> <----- CONTINGENCY LABEL ------>   RATING       MW     Mvar      MVA      %\" in line.decode(\"utf-8\"):\n            #print \"Found Branch OL section of report\"\n            fieldwidths = (62,-1,32,-1,8,-1,8,-1,8,-1,8,-1,6) # field widths of ACCC report Branch OL section, "
  },
  {
    "id": "chunk_2343",
    "text": " # field widths of ACCC report Branch OL section, negative width represent ignored padding fields\n            fmtstring = ' '.join('{}{}'.format(abs(fw), 'x' if fw < 0 else 's')\n                                    for fw in fieldwidths)\n            fieldstruct = struct.Struct(fmtstring)\n            parse = fieldstruct.unpack_from\n            break\n    for line in iter_Dict1:\n        if len(line.decode(\"utf-8\")) == 2: #= '\\n': #to find encoded newline, look for a line of length 2\n            #pri"
  },
  {
    "id": "chunk_2344",
    "text": "line, look for a line of length 2\n            #print \"Found end of Branch OL section of report (newline found)\"\n            BrOL1 = pd.DataFrame(data = BrOL_fields, columns=['Monitored_Branch','Contingency_Label','Rating','MW','Mvar','MVA','%'])\n\n            break\n        #print parse(line)\n        BrOL_fields.append(parse(line))\n\n    for line in iter_Dict1:\n        #print line\n        if \"<-------- MONITORED  SWD --------> <----- CONTINGENCY LABEL ------>   RATING       MW     Mvar      MVA    "
  },
  {
    "id": "chunk_2345",
    "text": "EL ------>   RATING       MW     Mvar      MVA      %   SWD LOOP\" in line.decode(\"utf-8\"):\n            #print \"Found SWD OL section of report\"\n            fieldwidths = (34,-1,32,-1,8,-1,8,-1,8,-1,8,-1,6,-1,10) # field widths of ACCC report SWD OL section, negative width represent ignored padding fields\n            fmtstring = ' '.join('{}{}'.format(abs(fw), 'x' if fw < 0 else 's')\n                                    for fw in fieldwidths)\n            fieldstruct = struct.Struct(fmtstring)\n     "
  },
  {
    "id": "chunk_2346",
    "text": "      fieldstruct = struct.Struct(fmtstring)\n            parse = fieldstruct.unpack_from\n            break\n    for line in iter_Dict1:\n        if len(line.decode(\"utf-8\")) == 2: #= '\\n': #to find encoded newline, look for a line of length 2\n            #print \"Found end of SWD OL section of report (newline found)\"\n            SwdOL1 = pd.DataFrame(data = SwdOL_fields, columns=['Monitored_SWD','Contingency_Label','Rating','MW','Mvar','MVA','%','SWD_Loop'])\n\n            break\n        #print parse("
  },
  {
    "id": "chunk_2347",
    "text": "D_Loop'])\n\n            break\n        #print parse(line)\n        SwdOL_fields.append(parse(line))\n\n    for line in iter_Dict1:\n        if \"SYSTEM                                       <----- CONTINGENCY LABEL ------> <---------- B U S ---------->   V-CONT   V-INIT   V-MAX    V-MIN\" in line.decode(\"utf-8\"):\n            #print \"Found Voltage violation section of report\"\n            fieldwidths = (44,-1,32,-1,29,-1,8,-1,8,-1,7,-1,8) # field widths of ACCC report Thermal OL section, negative width re"
  },
  {
    "id": "chunk_2348",
    "text": " ACCC report Thermal OL section, negative width represent ignored padding fields\n            fmtstring = ' '.join('{}{}'.format(abs(fw), 'x' if fw < 0 else 's')\n                                    for fw in fieldwidths)\n            fieldstruct = struct.Struct(fmtstring)\n            parse = fieldstruct.unpack_from\n            break\n    for line in iter_Dict1:\n        if len(line.decode(\"utf-8\")) == 2: #= '\\n': #to find encoded newline, look for a line of length 2\n            #print \"Found end of "
  },
  {
    "id": "chunk_2349",
    "text": "line of length 2\n            #print \"Found end of Voltage Violation section of report (newline found)\"\n            VoltOL1 = pd.DataFrame(data = VoltOL_fields, columns=['System','Contingency_Label','Bus','V-Cont','V-Init','V-Max','V-Min'])\n            break\n        #print parse(line)\n        VoltOL_fields.append(parse(line))\n    for line in iter_Dict1:\n        #print line\n        if \"<---------- B U S ----------> <----- CONTINGENCY LABEL ------> LOAD(MW)\" in line.decode(\"utf-8\"):\n            #pr"
  },
  {
    "id": "chunk_2350",
    "text": "LOAD(MW)\" in line.decode(\"utf-8\"):\n            #print \"Found Load Loss section of report\"\n            fieldwidths = (29,-1,32,-1,8) # field widths of ACCC report Thermal OL section, negative width represent ignored padding fields\n            fmtstring = ' '.join('{}{}'.format(abs(fw), 'x' if fw < 0 else 's')\n                                    for fw in fieldwidths)\n            fieldstruct = struct.Struct(fmtstring)\n            parse = fieldstruct.unpack_from\n            break\n    for line in it"
  },
  {
    "id": "chunk_2351",
    "text": "t.unpack_from\n            break\n    for line in iter_Dict1:\n        if len(line.decode(\"utf-8\")) == 2: #= '\\n': #to find encoded newline, look for a line of length 2\n            #print \"Found end of Load Loss section of report (newline found)\"\n            LdLoss1 = pd.DataFrame(data = LdLoss_fields, columns=['Bus','Contingency_Label','Load(MW)'])\n            break\n        #print parse(line)\n        LdLoss_fields.append(parse(line))\n\n    for line in iter_Dict1:\n        #print line\n        if \"<TE"
  },
  {
    "id": "chunk_2352",
    "text": "in iter_Dict1:\n        #print line\n        if \"<TERMINATION  STATE> FLOW#  SWD# VOLT#  LOAD\" in line.decode(\"utf-8\"):\n            #print \"Found Convergence section of report\"\n            fieldwidths = (32,20,-1,5,-1,5,-1,5,-1,5) # field widths of ACCC report Thermal OL section, negative width represent ignored padding fields\n            fmtstring = ' '.join('{}{}'.format(abs(fw), 'x' if fw < 0 else 's')\n                                    for fw in fieldwidths)\n            fieldstruct = struct.S"
  },
  {
    "id": "chunk_2353",
    "text": "in fieldwidths)\n            fieldstruct = struct.Struct(fmtstring)\n            parse = fieldstruct.unpack_from\n            break\n    for line in iter_Dict1:\n        if len(line.decode(\"utf-8\")) == 2: #= '\\n': #to find encoded newline, look for a line of length 2\n            #print \"Found end of Convergence section of report (newline found)\"\n            ConvRes1 = pd.DataFrame(data = ConvRes_fields, columns=['Contingency_Label','Termination_State','Flow#','SWD#','Volt#','Load'])               \n  "
  },
  {
    "id": "chunk_2354",
    "text": ",'Flow#','SWD#','Volt#','Load'])               \n            break\n        #print parse(line)\n        ConvRes_fields.append(parse(line))\n\n    \n    BrOL1['ViolationType']=b'Br Thermal'\n    \n    SwdOL1['ViolationType']=b'SWD Thermal'\n        \n    VoltOL1['ViolationType']=b'Voltage'\n    VoltOL1['Rating']=b'1'\n        \n    LdLoss1['ViolationType']=b'LdLoss'\n    LdLoss1['Rating']=b'0'\n        \n    ConvRes1['VioValue']=b'1'\n    ConvRes1['Rating']=b'0'\n    ConvRes1['Location']=ConvRes1['Contingency_Labe"
  },
  {
    "id": "chunk_2355",
    "text": "   ConvRes1['Location']=ConvRes1['Contingency_Label']\n\n    CA_Violations = pd.DataFrame(columns=['ViolationType','Contingency','Location','VioValue','Rating'])\n    CA_Violations = CA_Violations.append([BrOL1[['ViolationType','Contingency_Label','Monitored_Branch','%','Rating']].rename(columns={'Contingency_Label':'Contingency', \\\n                    'Monitored_Branch':'Location','%':'VioValue'}),SwdOL1[['ViolationType','Contingency_Label','Monitored_SWD','%','Rating']].rename(columns={'Contingen"
  },
  {
    "id": "chunk_2356",
    "text": "red_SWD','%','Rating']].rename(columns={'Contingency_Label':'Contingency', \\\n                    'Monitored_SWD':'Location','%':'VioValue'}),VoltOL1[['ViolationType','Contingency_Label','Bus','V-Cont','Rating']].rename(columns={'Contingency_Label':'Contingency', \\\n                    'Bus':'Location', 'V-Cont':'VioValue'}),LdLoss1[['ViolationType','Contingency_Label','Bus','Load(MW)','Rating']].rename(columns={'Contingency_Label':'Contingency', \\\n                    'Bus':'Location','Load(MW)':'"
  },
  {
    "id": "chunk_2357",
    "text": "\n                    'Bus':'Location','Load(MW)':'VioValue'}),ConvRes1[['Contingency_Label','Termination_State','VioValue','Rating','Location']].rename \\\n                    (columns={'Contingency_Label':'Contingency','Termination_State':'ViolationType'})],ignore_index=True,sort=False)\n    \n    #decode for human consumption\n    CA_Violations['ViolationType'] = CA_Violations['ViolationType'].str.decode(encoding = 'UTF-8')\n    CA_Violations['ViolationType'] = CA_Violations['ViolationType'].str.str"
  },
  {
    "id": "chunk_2358",
    "text": "ionType'] = CA_Violations['ViolationType'].str.strip() #remove leading and trailing spaces\n    CA_Violations['Contingency'] = CA_Violations['Contingency'].str.decode(encoding = 'UTF-8')\n    CA_Violations['Contingency'] = CA_Violations['Contingency'].str.strip() #remove leading and trailing spaces \n    CA_Violations['Location'] = CA_Violations['Location'].str.decode(encoding = 'UTF-8')\n    CA_Violations['Location'] = CA_Violations['Location'].str.strip() #remove leading and trailing spaces\n    CA"
  },
  {
    "id": "chunk_2359",
    "text": "strip() #remove leading and trailing spaces\n    CA_Violations['VioValue'] = CA_Violations['VioValue'].str.decode(encoding = 'UTF-8')\n    CA_Violations['VioValue'] = CA_Violations['VioValue'].str.strip() #remove leading and trailing spaces\n    CA_Violations['VioValue'] = pd.to_numeric(CA_Violations['VioValue']) #convert strings to numbers\n    CA_Violations['Rating'] = CA_Violations['Rating'].str.decode(encoding = 'UTF-8')\n    CA_Violations['Rating'] = CA_Violations['Rating'].str.strip() #remove l"
  },
  {
    "id": "chunk_2360",
    "text": "'] = CA_Violations['Rating'].str.strip() #remove leading and trailing spaces\n    CA_Violations['Rating'] = pd.to_numeric(CA_Violations['Rating']) #convert strings to numbers\n\n    return CA_Violations\n\ndef getAllXFRData(CASELOCATION):\n    PSSEOpenCase(CASELOCATION)\n\n    SID = -1\n    \n    char_data_desired_2W = ['ID','XFRNAME','VECTORGROUP']\n    int_data_desired_2W = ['FROMNUMBER','TONUMBER','STATUS']\n    char_ierr_2W, carray_2W = psspy.atrnchar(SID, 1,3,2,1,char_data_desired_2W) #get all transfor"
  },
  {
    "id": "chunk_2361",
    "text": "D, 1,3,2,1,char_data_desired_2W) #get all transformers, single entry\n    int_ierr_2W, iarray_2W = psspy.atrnint(SID, 1,3,2,1,int_data_desired_2W)\n\n    char_data_desired_3W = ['ID','XFRNAME','VECTORGROUP']\n    int_data_desired_3W = ['WIND1NUMBER','WIND2NUMBER','WIND3NUMBER','STATUS']\n    char_ierr_3W, carray_3W = psspy.atr3char(SID, 1,3,2,1, char_data_desired_3W) #get all transformers\n    int_ierr_3W, iarray_3W = psspy.atr3int(SID, 1,3,2,1,int_data_desired_3W)\n\n    if char_ierr_2W!=0 or int_ierr_"
  },
  {
    "id": "chunk_2362",
    "text": "a_desired_3W)\n\n    if char_ierr_2W!=0 or int_ierr_2W!=0 or char_ierr_3W!=0 or int_ierr_3W!=0 : #check for errors and if any encountered, return empty dataframe\n        return pd.DataFrame(['Unable to get transformer data.'])\n    else:\n        # compile 2-winding XFR data into a dataframe\n        allColumns_2W = char_data_desired_2W+int_data_desired_2W\n        allData_2W = carray_2W+iarray_2W\n        DF_dict_2W = dict(zip(allColumns_2W,allData_2W))\n        DF_2W = pd.DataFrame(DF_dict_2W)\n       "
  },
  {
    "id": "chunk_2363",
    "text": ")\n        DF_2W = pd.DataFrame(DF_dict_2W)\n        DF_2W = DF_2W.rename(columns={'FROMNUMBER':'WIND1NUMBER','TONUMBER':'WIND2NUMBER'}) #rename the columns for easier appending\n        # compile 3-winding XFR data into a dataframe\n        allColumns_3W = char_data_desired_3W+int_data_desired_3W\n        allData_3W = carray_3W+iarray_3W\n        DF_dict_3W = dict(zip(allColumns_3W,allData_3W))\n        DF_3W = pd.DataFrame(DF_dict_3W)\n        # append the 2W and 3W data together\n        DF_all = DF_2"
  },
  {
    "id": "chunk_2364",
    "text": " the 2W and 3W data together\n        DF_all = DF_2W.append(DF_3W, ignore_index=True)\n        return DF_all\n\ndef getAllLineData(CASELOCATION):\n    PSSEOpenCase(CASELOCATION)\n\n    SID = -1\n    \n    char_data_desired = ['ID']\n    int_data_desired = ['FROMNUMBER','TONUMBER','STATUS']\n    char_ierr, carray = psspy.abrnchar(SID, 1,3,2,1,char_data_desired) #get all branches, single entry\n    int_ierr, iarray = psspy.abrnint(SID, 1,3,2,1,int_data_desired) #get all branches, single entry\n\n    if SID != -"
  },
  {
    "id": "chunk_2365",
    "text": ") #get all branches, single entry\n\n    if SID != -1:\n        PSSE_SID_manager.decoupleDynamicSID(SID_manager,PSSESUBSYS)\n\n    if char_ierr!=0 or int_ierr!=0 : #check for errors and if any encountered, return empty dataframe\n        return pd.DataFrame(['Unable to get line data.'])\n    else:\n        allColumns = char_data_desired+int_data_desired\n        allData = carray+iarray\n        DF_dict = dict(zip(allColumns,allData))\n        return pd.DataFrame(DF_dict)\n\ndef getAllFixedShuntData(CASELOCAT"
  },
  {
    "id": "chunk_2366",
    "text": "Frame(DF_dict)\n\ndef getAllFixedShuntData(CASELOCATION):\n    PSSEOpenCase(CASELOCATION)\n\n    SID = -1\n    \n    char_data_desired = ['ID','NAME']\n    complex_data_desired = ['O_SHUNTACT']\n    int_data_desired = ['NUMBER','STATION','STATUS']\n    char_ierr, carray = psspy.afxshuntchar(SID, 4, char_data_desired) #get for all machines and all buses\n    comp_ierr, xarray = psspy.afxshuntcplx(SID, 4, complex_data_desired)\n    int_ierr, iarray = psspy.afxshuntint(SID, 4, int_data_desired)\n\n    if char_ie"
  },
  {
    "id": "chunk_2367",
    "text": "shuntint(SID, 4, int_data_desired)\n\n    if char_ierr!=0 or comp_ierr!=0 or int_ierr!=0 : #check for errors and if any encountered, return empty dataframe\n        return pd.DataFrame(['Unable to get case fixed shunt data.'])\n    else:\n        allColumns = char_data_desired+complex_data_desired+int_data_desired\n        allData = carray+xarray+iarray\n        DF_dict = dict(zip(allColumns,allData))\n        return pd.DataFrame(DF_dict)\n\ndef getAllSwShuntData(CASELOCATION):\n\n    PSSEOpenCase(CASELOCAT"
  },
  {
    "id": "chunk_2368",
    "text": "untData(CASELOCATION):\n\n    PSSEOpenCase(CASELOCATION)\n\n    SID = -1\n    \n    char_data_desired = ['ID','NAME']\n    complex_data_desired = ['O_YSWACT']\n    int_data_desired = ['NUMBER','STATION', 'AREA', 'ZONE', 'STATUS','OWNER']\n    char_ierr, carray = psspy.aswshchar(SID, 4, char_data_desired) #get for all machines and all buses\n    comp_ierr, xarray = psspy.aswshcplx(SID, 4, complex_data_desired)\n    int_ierr, iarray = psspy.aswshint(SID, 4, int_data_desired)\n\n    if char_ierr!=0 or comp_ierr"
  },
  {
    "id": "chunk_2369",
    "text": "nt_data_desired)\n\n    if char_ierr!=0 or comp_ierr!=0 or int_ierr!=0 : #check for errors and if any encountered, return empty dataframe\n        return pd.DataFrame(['Unable to get case switched shunt data.'])\n    else:\n        allColumns = char_data_desired+complex_data_desired+int_data_desired\n        allData = carray+xarray+iarray\n        DF_dict = dict(zip(allColumns,allData))\n        return pd.DataFrame(DF_dict)\n\ndef getAllLoadData(CASELOCATION):\n    PSSEOpenCase(CASELOCATION)\n    \n    SID ="
  },
  {
    "id": "chunk_2370",
    "text": "ON):\n    PSSEOpenCase(CASELOCATION)\n    \n    SID = -1\n    \n    char_data_desired = ['ID','NAME','LODTYPE']\n    complex_data_desired = ['TOTALACT']\n    int_data_desired = ['NUMBER','STATION', 'AREA', 'ZONE', 'STATUS','OWNER','SCALE','INTRPT']\n    char_ierr, carray = psspy.aloadchar(SID, 4, char_data_desired) #get for all machines and all buses\n    comp_ierr, xarray = psspy.aloadcplx(SID, 4, complex_data_desired)\n    int_ierr, iarray = psspy.aloadint(SID, 4, int_data_desired)\n\n    if char_ierr!=0 "
  },
  {
    "id": "chunk_2371",
    "text": "nt(SID, 4, int_data_desired)\n\n    if char_ierr!=0 or comp_ierr!=0 or int_ierr!=0 : #check for errors and if any encountered, return empty dataframe\n        return pd.DataFrame(['Unable to get case load data.'])\n    else:\n        allColumns = char_data_desired+complex_data_desired+int_data_desired\n        allData = carray+xarray+iarray\n        DF_dict = dict(zip(allColumns,allData))\n        return pd.DataFrame(DF_dict)\n\ndef getAllBusData(CASELOCATION):\n    PSSEOpenCase(CASELOCATION)\n    SID = -1\n"
  },
  {
    "id": "chunk_2372",
    "text": "ION):\n    PSSEOpenCase(CASELOCATION)\n    SID = -1\n    \n    char_data_desired = ['NAME','EXNAME']\n    real_data_desired = ['BASE','NVLMLO','NVLMHI','EVLMLO','EVLMHI']\n    int_data_desired = ['NUMBER','AREA','OWNER','ZONE','SECTION','TYPE']\n    char_ierr, carray = psspy.abuschar(SID, 2, char_data_desired) \n    comp_ierr, xarray = psspy.abusreal(SID, 2, real_data_desired)\n    int_ierr, iarray = psspy.abusint(SID, 2, int_data_desired)\n\n    if char_ierr!=0 or comp_ierr!=0 or int_ierr!=0 : #check for "
  },
  {
    "id": "chunk_2373",
    "text": "rr!=0 or comp_ierr!=0 or int_ierr!=0 : #check for errors and if any encountered, return empty dataframe\n        return pd.DataFrame(['Unable to get bus data. char_ierr = {0}, comp_ierr = {1}, int_ierr = {2}. SID = {3}'.format(char_ierr,comp_ierr,int_ierr,SID)])\n    else:\n        allColumns = char_data_desired+real_data_desired+int_data_desired\n        allData = carray+xarray+iarray\n        DF_dict = dict(zip(allColumns,allData))\n        return pd.DataFrame(DF_dict)\n\ndef PSSESetSubSystem(SID,USEK"
  },
  {
    "id": "chunk_2374",
    "text": ".DataFrame(DF_dict)\n\ndef PSSESetSubSystem(SID,USEKV,BASEKV,NUMAREA,AREAS,NUMBUS,BUSES,NUMOWNER,OWNERS,NUMZONE,ZONES): \n    ierr = psspy.bsys(SID,USEKV,BASEKV,NUMAREA,AREAS,NUMBUS,BUSES,NUMOWNER,OWNERS,NUMZONE,ZONES)\n    if ierr != 0:\n        raise RuntimeError('PSSESetSubSystem did not work. the psspy.bsys ierr returned is: {}'.format(ierr))\n    return ierr\n\ndef PSSESaveCase(PSSESAVECASE):\n    ierr = psspy.save(PSSESAVECASE) #save case\n    if ierr != 0: \n        raise RuntimeError('PSSPY error c"
  },
  {
    "id": "chunk_2375",
    "text": "r != 0: \n        raise RuntimeError('PSSPY error code {} when calling psspy.save(). See PSSE API documentation for details.'.format(ierr))\n        sys.exit()\n    return ierr\n\ndef getBusInconsistencies():\n    \n    in_service_branches = psspy.abrnint(-1,1,3,1,1,['FROMNUMBER','TONUMBER','STATUS','FROMSECTION','TOSECTION'])[1] #in_service_branches[0] is list of FROMBUS's, n_service_branches[1] is list of TOBUS's\n    # make df for in_service_br_busses\n    from_buses = pd.DataFrame({'Bus Number':in_se"
  },
  {
    "id": "chunk_2376",
    "text": "\n    from_buses = pd.DataFrame({'Bus Number':in_service_branches[0],'Bus Section':in_service_branches[3]})\n    to_buses = pd.DataFrame({'Bus Number':in_service_branches[1],'Bus Section':in_service_branches[4]})\n    in_service_br_busses = pd.concat([from_buses,to_buses],ignore_index=True)\n    in_service_br_busses = in_service_br_busses.drop_duplicates() #drop duplicates to avoid duplicating work\n\n        \n    all_busses = psspy.abusint(-1,2,['NUMBER','TYPE','SECTION','AREA'])[1] #all_busses[0] is"
  },
  {
    "id": "chunk_2377",
    "text": "ER','TYPE','SECTION','AREA'])[1] #all_busses[0] is list of busses, all_busses[1] is list of statuses, all_busses[2] is list of sections\n    #make df for all buses\n    buses = pd.DataFrame({'Bus Number':all_busses[0],'Bus Section':all_busses[2],'Bus Type':all_busses[1],'Bus Area':all_busses[3]})\n        \n    in_service_2w_xfr = psspy.atrnint(-1,1,3,1,1,['FROMNUMBER','TONUMBER','STATUS','FROMSECTION','TOSECTION'])[1] #this only returns in-service transformers\n    from_bus_2w_xfr = pd.DataFrame({'B"
  },
  {
    "id": "chunk_2378",
    "text": "ransformers\n    from_bus_2w_xfr = pd.DataFrame({'Bus Number':in_service_2w_xfr[0],'Bus Section':in_service_2w_xfr[3]})\n    to_bus_2w_xfr = pd.DataFrame({'Bus Number':in_service_2w_xfr[1],'Bus Section':in_service_2w_xfr[4]})\n    in_service_2w_xfr_buses = pd.concat([from_bus_2w_xfr,to_bus_2w_xfr],ignore_index=True)\n    in_service_2w_xfr_buses = in_service_2w_xfr_buses.drop_duplicates()\n\n    in_service_3w_xfr = psspy.atr3int(-1,1,3,1,1,['WIND1NUMBER','WIND2NUMBER','WIND3NUMBER','STATUS','WIND1SECTI"
  },
  {
    "id": "chunk_2379",
    "text": "','WIND2NUMBER','WIND3NUMBER','STATUS','WIND1SECTION','WIND2SECTION','WIND3SECTION'])[1]\n\n    # make in_service_3w_xfr_buses a dataframe\n    in_service_3w_xfr_buses = pd.DataFrame()\n    #make dataframe for more sophisticated data comparison\n    in_service_3w_xfr_df = pd.DataFrame({'WIND1NUMBER':in_service_3w_xfr[0],'WIND2NUMBER':in_service_3w_xfr[1],'WIND3NUMBER':in_service_3w_xfr[2],'STATUS':in_service_3w_xfr[3],'WIND1SECTION':in_service_3w_xfr[4],'WIND2SECTION':in_service_3w_xfr[5],'WIND3SECTI"
  },
  {
    "id": "chunk_2380",
    "text": "4],'WIND2SECTION':in_service_3w_xfr[5],'WIND3SECTION':in_service_3w_xfr[6]})\n    # get in service buses for status = 1\n    stat1_df = in_service_3w_xfr_df.loc[in_service_3w_xfr_df['STATUS']==1]\n    for entry in stat1_df.index:\n        in_service = pd.DataFrame({'Bus Number':[stat1_df.at[entry,'WIND1NUMBER'],stat1_df.at[entry,'WIND2NUMBER'],stat1_df.at[entry,'WIND3NUMBER']], \\\n            'Bus Section':[stat1_df.at[entry,'WIND1SECTION'],stat1_df.at[entry,'WIND2SECTION'],stat1_df.at[entry,'WIND3SE"
  },
  {
    "id": "chunk_2381",
    "text": "t[entry,'WIND2SECTION'],stat1_df.at[entry,'WIND3SECTION']]}) #all windings in-service when status = 1\n        in_service_3w_xfr_buses = pd.concat([in_service_3w_xfr_buses,in_service],ignore_index=True)\n\n    # get in service buses for status = 2\n    stat2_df = in_service_3w_xfr_df.loc[in_service_3w_xfr_df['STATUS']==2]\n    for entry in stat2_df.index:\n        in_service = pd.DataFrame({'Bus Number':[stat2_df.at[entry,'WIND1NUMBER'],stat2_df.at[entry,'WIND3NUMBER']], \\\n            'Bus Section':[s"
  },
  {
    "id": "chunk_2382",
    "text": "ry,'WIND3NUMBER']], \\\n            'Bus Section':[stat2_df.at[entry,'WIND1SECTION'],stat2_df.at[entry,'WIND3SECTION']]}) #windings 1 and 3 in-service when status = 2\n        in_service_3w_xfr_buses = pd.concat([in_service_3w_xfr_buses,in_service],ignore_index=True)\n    # get in service buses for status = 3\n    stat3_df = in_service_3w_xfr_df.loc[in_service_3w_xfr_df['STATUS']==3]\n    for entry in stat3_df.index:\n        in_service = pd.DataFrame({'Bus Number':[stat3_df.at[entry,'WIND1NUMBER'],sta"
  },
  {
    "id": "chunk_2383",
    "text": "'Bus Number':[stat3_df.at[entry,'WIND1NUMBER'],stat3_df.at[entry,'WIND2NUMBER']], \\\n            'Bus Section':[stat3_df.at[entry,'WIND1SECTION'],stat3_df.at[entry,'WIND2SECTION']]}) #windings 1 and 2 in-service when status = 3\n        in_service_3w_xfr_buses = pd.concat([in_service_3w_xfr_buses,in_service],ignore_index=True)\n    # get in service buses for status = 4\n    stat4_df = in_service_3w_xfr_df.loc[in_service_3w_xfr_df['STATUS']==4]\n    for entry in stat4_df.index:\n        in_service = pd"
  },
  {
    "id": "chunk_2384",
    "text": "r entry in stat4_df.index:\n        in_service = pd.DataFrame({'Bus Number':[stat4_df.at[entry,'WIND2NUMBER'],stat4_df.at[entry,'WIND3NUMBER']], \\\n            'Bus Section':[stat4_df.at[entry,'WIND2SECTION'],stat4_df.at[entry,'WIND3SECTION']]}) #windings 2 and 3 in-service when status = 4\n        in_service_3w_xfr_buses = pd.concat([in_service_3w_xfr_buses,in_service],ignore_index=True)\n\n    all_in_service_element_buses = pd.concat([in_service_br_busses,in_service_2w_xfr_buses,in_service_3w_xfr_b"
  },
  {
    "id": "chunk_2385",
    "text": "busses,in_service_2w_xfr_buses,in_service_3w_xfr_buses],ignore_index=True)\n    all_in_service_element_buses = all_in_service_element_buses.drop_duplicates()\n    all_in_service_element_buses['Has in-service branches'] = 'True'\n\n    bus_summary = pd.merge(buses,all_in_service_element_buses,on=['Bus Number','Bus Section'],how='left')\n    results_to_return = bus_summary.loc[(((bus_summary['Bus Type'] == 1)|(bus_summary['Bus Type'] == 2))&(bus_summary['Has in-service branches'] != 'True'))\\\n        |"
  },
  {
    "id": "chunk_2386",
    "text": "['Has in-service branches'] != 'True'))\\\n        |((bus_summary['Bus Type'] == 4)&(bus_summary['Has in-service branches'] == 'True'))]\n    \n    return results_to_return\n\ndef getFileByteData(GETBYTEDATAFILE):\n    try:\n        if type(GETBYTEDATAFILE) == tempfile._TemporaryFileWrapper:\n            FileByteData = GETBYTEDATAFILE.read()\n            GETBYTEDATAFILE.seek(0)\n        else:\n            f = open(GETBYTEDATAFILE,'r+b')\n            FileByteData = f.read()\n            f.close()\n        retur"
  },
  {
    "id": "chunk_2387",
    "text": "ata = f.read()\n            f.close()\n        return FileByteData\n    except:\n        raise RuntimeError('There was a problem reading the data from {}. Check the file.'.format(GETBYTEDATAFILE))\n        sys.exit()\n\ndef silenceAllPSSE():\n    psspy.set_progress_verbose(0) #set to limit messages\n    psspy.progress_output(2,tempfile.NamedTemporaryFile().name,[0,0]) #silence progress output from PSS/E\n    psspy.report_output(2,tempfile.NamedTemporaryFile().name,[0,0]) #silence report output from PSS/E "
  },
  {
    "id": "chunk_2388",
    "text": "e().name,[0,0]) #silence report output from PSS/E to temp file\n    psspy.t_alert_output(2,tempfile.NamedTemporaryFile().name,[0,0]) #silence alert output\n    psspy.alert_output(2,tempfile.NamedTemporaryFile().name,[0,0]) #silece alert outputs\n\ndef PSSEOpenCase(PSSEOPENCASE):\n    if pathlib.Path(PSSEOPENCASE).suffix == '.sav':\n        ierr = psspy.case(PSSEOPENCASE) #open case\n        if ierr != 0: \n            raise RuntimeError('PSSPY error code {0} when calling psspy.case({1}). See PSSE API do"
  },
  {
    "id": "chunk_2389",
    "text": " {0} when calling psspy.case({1}). See PSSE API documentation for details.'.format(ierr,PSSEOPENCASE))\n            sys.exit()\n    if pathlib.Path(PSSEOPENCASE).suffix == '.raw':\n        ierr = psspy.read(0,PSSEOPENCASE)\n        if ierr != 0: \n            raise RuntimeError('PSSPY error code {0} when calling psspy.read(0,{1}). See PSSE API documentation for details.'.format(ierr,PSSEOPENCASE))\n            sys.exit()\n    return ierr\n\ndef make_clickable(url, name):\n    return '<a href=\"{}\" rel=\"noo"
  },
  {
    "id": "chunk_2390",
    "text": "able(url, name):\n    return '<a href=\"{}\" rel=\"noopener noreferrer\" target=\"_blank\">{}</a>'.format(url,name)\n\ndef makeTempDirectory():\n    ### Create temp directory for file management ###\n    temporary_directory = tempfile.TemporaryDirectory()\n    tmp_dir = temporary_directory.name\n    print('Created temp directory {0}.'.format(tmp_dir))\n    return temporary_directory\n\ndef suppressAllPSSEOutputs():\n    #### Supress all the PSSE outputs for now\n    psspy.progress_output(2,tempfile.NamedTemporary"
  },
  {
    "id": "chunk_2391",
    "text": "   psspy.progress_output(2,tempfile.NamedTemporaryFile().name,[0,0]) #suppress progress output from PSS/E\n    psspy.t_alert_output(2,tempfile.NamedTemporaryFile().name,[0,0]) #write t alerts from PSS/E to temp file\n    psspy.alert_output(2,tempfile.NamedTemporaryFile().name,[0,0]) #write alerts from PSS/E to temp file\n    psspy.report_output(2,tempfile.NamedTemporaryFile().name,[0,0]) #write report from PSS/E to temp file\n\ndef getCNTBCheckData(tmp_dir,SAVLOCATION,target_output_directory,rawfilen"
  },
  {
    "id": "chunk_2392",
    "text": "p_dir,SAVLOCATION,target_output_directory,rawfilename,CNTB_messages,areaList):\n    #tmp_dir_CNTB = makeTempDirectory().name\n    PSSEOpenCase(SAVLOCATION) #open the save case\n    psspy.bsys(0,0,[0.48,345.],len(areaList),areaList,0,[],0,[],0,[]) #set bsys to areas provided by the user\n    temp_PSSE_output = tmp_dir+r'\\PSSE_capture.txt' #capture report output from PSS/E\n    \n    ierr = psspy.report_output(2,temp_PSSE_output,0) #capture report output from PSS/E\n    if ierr != 0:\n        raise Runtim"
  },
  {
    "id": "chunk_2393",
    "text": " from PSS/E\n    if ierr != 0:\n        raise RuntimeError('Problem calling psspy.report_output. Directory location: {0}. ierr = {1}'.format(temp_PSSE_output,ierr))\n    psspy.cntb(0,0,1,[0,0,0],[0.0,0.0]) #run CNTB \n    silenceAllPSSE() #silence the output so PSSE lets go of the tempfile\n    # PSSESaveCase(target_output_directory+r'\\{0}.sav'.format(rawfilename))\n    # PSSECloseCase()\n    #write the report to a text document\n    data_to_write = getFileByteData(temp_PSSE_output).decode('UTF-8')\n    "
  },
  {
    "id": "chunk_2394",
    "text": "ileByteData(temp_PSSE_output).decode('UTF-8')\n    \n    # reportName = target_output_directory+r'\\text_reports\\{}_CNTB_output.txt'.format(rawfilename)\n    # f = open(reportName,'w')\n    # f.write(data_to_write)\n    # f.close()\n\n    #partition the data to put in a csv for easier reading\n    message_delimiter = '\\nBus '\n    all_messages = data_to_write.split(message_delimiter)\n    CNTB_messages_tmp = pd.DataFrame({'{0}'.format(rawfilename):all_messages})\n    CNTB_messages_tmp['{0}'.format(rawfilena"
  },
  {
    "id": "chunk_2395",
    "text": "ges})\n    CNTB_messages_tmp['{0}'.format(rawfilename)] = 'Bus '+CNTB_messages_tmp['{0}'.format(rawfilename)]\n    CNTB_messages_tmp['Bus'] = CNTB_messages_tmp['{0}'.format(rawfilename)]\n    CNTB_messages_tmp['Area'] =CNTB_messages_tmp['Bus'].str.extract(r'area ([0-9]+)')\n    CNTB_messages_tmp['Bus'] = CNTB_messages_tmp['Bus'].str.extract(r'Bus ([0-9]+)') #CNTB_messages_tmp['Bus'].str.slice(stop=10).str.rstrip().str.rstrip('[')\n    CNTB_messages_tmp.loc[CNTB_messages_tmp['{0}'.format(rawfilename)]"
  },
  {
    "id": "chunk_2396",
    "text": "p.loc[CNTB_messages_tmp['{0}'.format(rawfilename)].str.contains('Warning'),'Type'] = 'Warning'\n    CNTB_messages_tmp.loc[CNTB_messages_tmp['{0}'.format(rawfilename)].str.contains('ERROR'),'Type'] = 'ERROR'\n\n    CNTB_messages_tmp.loc[CNTB_messages_tmp['Type'].isnull(),'Type'] = 'Other'\n    CNTB_messages_tmp = CNTB_messages_tmp[['Bus','Area','Type','{0}'.format(rawfilename)]]\n    CNTB_messages_tmp = CNTB_messages_tmp.loc[(CNTB_messages_tmp['Type']=='ERROR')|(CNTB_messages_tmp['Type']=='Warning')]\n"
  },
  {
    "id": "chunk_2397",
    "text": "='ERROR')|(CNTB_messages_tmp['Type']=='Warning')]\n    #CNTB_messages_tmp.to_csv(target_output_directory+'\\CNTB_messages_tmp.csv')\n\n    if CNTB_messages.empty == True:\n        CNTB_messages = CNTB_messages_tmp #pd.concat([CNTB_messages,CNTB_messages_tmp],ignore_index=True)\n        CNTB_messages = CNTB_messages.drop_duplicates() #drop duplicate values to keep the dataset smaller\n    else:\n        CNTB_messages = pd.merge(CNTB_messages,CNTB_messages_tmp,how='outer',on=['Bus','Area','Type'])\n       "
  },
  {
    "id": "chunk_2398",
    "text": "_tmp,how='outer',on=['Bus','Area','Type'])\n        CNTB_messages = CNTB_messages.drop_duplicates() #drop duplicate values to keep the dataset smaller\n    return CNTB_messages\n\ndef getBusData(savLocation,target_output_directory,rawfilename,BusData,areaList):\n    \n    busData_tmp = getAllBusData(savLocation)\n    #busData_tmp.to_csv(target_output_directory+r'\\busData_tmp.csv')\n    allBusesInSelectedAreas = busData_tmp.loc[(busData_tmp['AREA'].isin(areaList))]\n    allBusesInSelectedAreas = allBusesI"
  },
  {
    "id": "chunk_2399",
    "text": "reaList))]\n    allBusesInSelectedAreas = allBusesInSelectedAreas[['NUMBER','NAME','SECTION','TYPE','AREA','OWNER','NVLMLO','NVLMHI','EVLMLO','EVLMHI']] # added section and type\n    allBusesInSelectedAreas = allBusesInSelectedAreas.round({'NVLMLO':2,'NVLMHI':2,'EVLMLO':2,'EVLMHI':2})\n    allBusesInSelectedAreas['{0}'.format(rawfilename)]='TRUE'\n\n    if BusData.empty == True:\n        BusData = allBusesInSelectedAreas #pd.concat([CNTB_messages,CNTB_messages_tmp],ignore_index=True)\n        BusData ="
  },
  {
    "id": "chunk_2400",
    "text": "messages_tmp],ignore_index=True)\n        BusData = BusData.drop_duplicates() #drop duplicate values to keep the dataset smaller\n    else:\n        BusData = pd.merge(BusData,allBusesInSelectedAreas,how='outer',on=['NUMBER','NAME','SECTION','TYPE','AREA','OWNER','NVLMLO','NVLMHI','EVLMLO','EVLMHI']) # added section and type\n        BusData = BusData.drop_duplicates() #drop duplicate values to keep the dataset smaller\n\n    #BusData = BusData.round({'NVLMLO':2,'NVLMHI':2,'EVLMLO':2,'EVLMHI':2})\n    "
  },
  {
    "id": "chunk_2401",
    "text": "'NVLMLO':2,'NVLMHI':2,'EVLMLO':2,'EVLMHI':2})\n    return BusData\n\ndef get900kBuses(BusData):\n    all900k_buses = BusData.loc[BusData['NUMBER']>=900000]\n    return all900k_buses\n\ndef getDisconnectedBuses(BusData):\n    alldisconnected_buses = BusData.loc[BusData['TYPE']==4]\n    return alldisconnected_buses\n\ndef getLdData(savLocation,allLoads,rawfilename,areaList):\n    # Get load data to report on any 0-MVA or disconnected loads in selected areas\n    loadData_tmp = getAllLoadData(savLocation)\n    l"
  },
  {
    "id": "chunk_2402",
    "text": "  loadData_tmp = getAllLoadData(savLocation)\n    loadData_tmp = loadData_tmp.loc[(loadData_tmp['AREA'].isin(areaList))] # only keep the selected areas\n    loadData_tmp = loadData_tmp[['ID','NAME','LODTYPE','TOTALACT','NUMBER','STATION','AREA','ZONE','STATUS','OWNER']]\n    loadData_tmp['{0}'.format(rawfilename)]='TRUE'\n    if allLoads.empty == True:\n        allLoads = loadData_tmp\n        allLoads = allLoads.drop_duplicates()\n    else:\n        allLoads = allLoads.merge(loadData_tmp,how='outer',on"
  },
  {
    "id": "chunk_2403",
    "text": "Loads = allLoads.merge(loadData_tmp,how='outer',on=['ID','NAME','LODTYPE','TOTALACT','NUMBER','STATION','AREA','ZONE','STATUS','OWNER'])\n        allLoads = allLoads.drop_duplicates()\n    return loadData_tmp\n\ndef getLdDataTotalsReportedInCaseColumn(savLocation,allLoads,rawfilename,areaList):\n    # Get load data to report on any 0-MVA or disconnected loads in selected areas\n    loadData_tmp = getAllLoadData(savLocation)\n    loadData_tmp = loadData_tmp.loc[(loadData_tmp['AREA'].isin(areaList))] # o"
  },
  {
    "id": "chunk_2404",
    "text": "tmp.loc[(loadData_tmp['AREA'].isin(areaList))] # only keep the selected areas\n    loadData_tmp = loadData_tmp[['ID','NAME','LODTYPE','TOTALACT','NUMBER','STATION','AREA','ZONE','STATUS','OWNER']]\n    loadData_tmp['{0}'.format(rawfilename)]=loadData_tmp['TOTALACT']\n    loadData_tmp = loadData_tmp[['ID','NAME','LODTYPE','NUMBER','STATION','AREA','ZONE','STATUS','OWNER','{0}'.format(rawfilename)]]\n    if allLoads.empty == True:\n        allLoads = loadData_tmp\n        allLoads = allLoads.drop_duplic"
  },
  {
    "id": "chunk_2405",
    "text": "adData_tmp\n        allLoads = allLoads.drop_duplicates()\n    else:\n        allLoads = allLoads.merge(loadData_tmp,how='outer',on=['ID','NAME','LODTYPE','NUMBER','STATION','AREA','ZONE','STATUS','OWNER'])\n        allLoads = allLoads.drop_duplicates()\n    return loadData_tmp\n\ndef getDisconnectedLoads(loadData_tmp,allDisconnectedLds):\n    disconnectedLds = loadData_tmp.loc[loadData_tmp['STATUS']==0]\n    if allDisconnectedLds.empty == True:\n        allDisconnectedLds = disconnectedLds\n        allDis"
  },
  {
    "id": "chunk_2406",
    "text": "llDisconnectedLds = disconnectedLds\n        allDisconnectedLds = allDisconnectedLds.drop_duplicates()\n    else:\n        allDisconnectedLds = allDisconnectedLds.merge(disconnectedLds,how='outer',on=['ID','NAME','LODTYPE','TOTALACT','NUMBER','STATION','AREA','ZONE','STATUS','OWNER'])\n        allDisconnectedLds = allDisconnectedLds.drop_duplicates()\n    return allDisconnectedLds\n\ndef getZeroLoads(loadData_tmp,allZeroLds):\n    zeroLds = loadData_tmp.loc[loadData_tmp['TOTALACT']==complex(0,0)]\n    if"
  },
  {
    "id": "chunk_2407",
    "text": "loc[loadData_tmp['TOTALACT']==complex(0,0)]\n    if allZeroLds.empty == True:\n        allZeroLds = zeroLds\n        allZeroLds = allZeroLds.drop_duplicates()\n    else:\n        allZeroLds = allZeroLds.merge(zeroLds,how='outer',on=['ID','NAME','LODTYPE','TOTALACT','NUMBER','STATION','AREA','ZONE','STATUS','OWNER'])\n        allZeroLds = allZeroLds.drop_duplicates()\n    return allZeroLds\n\ndef getDisconnectedShunts(savLocation,rawfilename,alldisconnected_shunts,areaList):\n    # find shunt devices that "
  },
  {
    "id": "chunk_2408",
    "text": "d_shunts,areaList):\n    # find shunt devices that are in a status of disconnected\n    SwShunts = getAllSwShuntData(savLocation)\n    SwShunts = SwShunts.loc[SwShunts['AREA'].isin(areaList)] # filter down to the specific requested areas\n    disconnected_SwShunts = SwShunts.loc[SwShunts['STATUS']==0]\n    disconnected_SwShunts = disconnected_SwShunts[['ID','NAME','NUMBER','AREA','STATUS']]\n    FixedShunts = getAllFixedShuntData(savLocation)\n    BusAreaMap = getAllBusData(savLocation)[['NUMBER','AREA"
  },
  {
    "id": "chunk_2409",
    "text": "eaMap = getAllBusData(savLocation)[['NUMBER','AREA']]\n    FixedShunts = FixedShunts.merge(BusAreaMap,how='left',on='NUMBER')\n    FixedShunts = FixedShunts.loc[FixedShunts['AREA'].isin(areaList)] # filter down to the specific requested areas\n    disconnected_FixedShunts = FixedShunts.loc[FixedShunts['STATUS']==0]\n    disconnected_FixedShunts = disconnected_FixedShunts[['ID','NAME','NUMBER','AREA','STATUS']]\n    disconnected_shunts = pd.concat([disconnected_SwShunts,disconnected_FixedShunts],ignor"
  },
  {
    "id": "chunk_2410",
    "text": "connected_SwShunts,disconnected_FixedShunts],ignore_index=True)\n\n    disconnected_shunts['{0}'.format(rawfilename)] = 'TRUE'\n\n    if alldisconnected_shunts.empty == True:\n        alldisconnected_shunts = disconnected_shunts\n        alldisconnected_shunts = alldisconnected_shunts.drop_duplicates()\n    else:\n        alldisconnected_shunts = alldisconnected_shunts.merge(disconnected_shunts,how='outer',on=['ID','NAME','NUMBER','AREA','STATUS'])\n        alldisconnected_shunts = alldisconnected_shunts"
  },
  {
    "id": "chunk_2411",
    "text": "   alldisconnected_shunts = alldisconnected_shunts.drop_duplicates()  \n    return alldisconnected_shunts\n\ndef getAllBusInconsistencies(rawfilename,allBusInconsistencies):\n    # Get bus inconsistencies\n    caseBusInconsistencies = getBusInconsistencies()\n    caseBusInconsistencies['{0}'.format(rawfilename)] = 'TRUE'\n    if allBusInconsistencies.empty == True:\n        allBusInconsistencies = caseBusInconsistencies\n        allBusInconsistencies=allBusInconsistencies.drop_duplicates()\n    else:\n    "
  },
  {
    "id": "chunk_2412",
    "text": "usInconsistencies.drop_duplicates()\n    else:\n        allBusInconsistencies = pd.merge(allBusInconsistencies,caseBusInconsistencies,how='outer',on=['Bus Number','Bus Section','Bus Type','Bus Area','Has in-service branches'])\n        allBusInconsistencies=allBusInconsistencies.drop_duplicates()\n    return allBusInconsistencies\n\ndef getTREEIslands(tmp_dir,rawfilename,allIslands):\n    # Run TREE to get island information\n    # prepare a report to capture TREE outputs \n    caseTreeData = []\n    temp"
  },
  {
    "id": "chunk_2413",
    "text": "pture TREE outputs \n    caseTreeData = []\n    temp_TREE_output = tmp_dir+r'\\TREE_capture.txt' #capture report output from PSS/E   \n    psspy.progress_output(2,temp_TREE_output,0) #capture report output from PSS/E\n    ierr, num_island_buses = psspy.tree(1,0) #initialize TREE \n    while num_island_buses > 0:\n        silenceAllPSSE() #silence the output so PSSE lets go of the tempfile\n        tree_data = getFileByteData(temp_TREE_output).decode('UTF-8')\n        os.remove(temp_TREE_output) #get rid "
  },
  {
    "id": "chunk_2414",
    "text": "-8')\n        os.remove(temp_TREE_output) #get rid of the temp file\n        save_data = tree_data.split('ISLAND:\\r\\n')[1] #get data to save\n        caseTreeData.append(save_data)\n        psspy.progress_output(2,temp_TREE_output,0) #capture report output from PSS/E\n        ierr, num_island_buses = psspy.tree(2,0) # leave the current island alone and run TREE again check for another island\n\n    psspy.progress_output(2,tempfile.NamedTemporaryFile().name,[0,0]) #suppress progress output from PSS/E \n "
  },
  {
    "id": "chunk_2415",
    "text": "ame,[0,0]) #suppress progress output from PSS/E \n    CaseTreeIslands = pd.DataFrame({'Island':caseTreeData})\n    CaseTreeIslands['{0}'.format(rawfilename)] = 'TRUE'\n    if allIslands.empty == True:\n        allIslands = CaseTreeIslands\n        allIslands = allIslands.drop_duplicates()\n    else:\n        allIslands = pd.merge(allIslands,CaseTreeIslands,how='outer',on='Island')\n        allIslands = allIslands.drop_duplicates()\n    return allIslands\n\ndef getPSSEpfChecks(tmp_dir,rawfilename,allPFCheck"
  },
  {
    "id": "chunk_2416",
    "text": "def getPSSEpfChecks(tmp_dir,rawfilename,allPFCheckResults,allPFCheckTypes,areaList):\n    # run the PSSE powerflow checks for the case\n    SID_for_checks = 1\n    PSSESetSubSystem(SID=SID_for_checks,USEKV=1,BASEKV=1,NUMAREA=len(areaList),AREAS=areaList,NUMBUS=0,BUSES=[],NUMOWNER=0,OWNERS=[],NUMZONE=0,ZONES=[])\n    #psspy.bsys(0,0,[0.48,345.],1,[],0,[],0,[],0,[]) # set SID 0\n    for checkType in allPFCheckTypes.keys():\n        #print('Doing PSSE PF check for {0}'.format(checkType))\n        silenceA"
  },
  {
    "id": "chunk_2417",
    "text": "check for {0}'.format(checkType))\n        silenceAllPSSE() #silence the output\n        temp_pfcheck_output = tmp_dir+r'\\pfcheck_capture.txt' #capture report output from PSS/E   \n        psspy.report_output(2,temp_pfcheck_output,0) #capture report output from PSS/E\n        ierr = psspy.check_powerflow_data(SID_for_checks,0,allPFCheckTypes[checkType])\n        if ierr != 0:\n            print('Problem with running check_powerflow_data. ierr={0}'.format(ierr))\n        silenceAllPSSE() #silence the ou"
  },
  {
    "id": "chunk_2418",
    "text": "at(ierr))\n        silenceAllPSSE() #silence the output so PSSE lets go of the tempfile\n        pfcheck_data = str(getFileByteData(temp_pfcheck_output).decode('UTF-8'))\n        pfcheck_data = \"\"\"{0}\"\"\".format(pfcheck_data)\n        save_data = pd.DataFrame({'PF Check Message':pfcheck_data.split('\\r\\n\\r\\n')}) #get data to save\n        \n        save_data = save_data.loc[(save_data['PF Check Message'].str.strip()!='')&\\\n            (save_data['PF Check Message'].str.strip()!='Powerflow data checks')&"
  },
  {
    "id": "chunk_2419",
    "text": "k Message'].str.strip()!='Powerflow data checks')&\\\n            (save_data['PF Check Message'].str.strip().str.contains(' messages:')==False)]\n        #save_data = save_data['PF Check Message']\n        save_data['{0}'.format(rawfilename)] = 'TRUE'\n        save_data = save_data[['PF Check Message','{0}'.format(rawfilename)]]\n        if len(allPFCheckResults[checkType].columns)<1:\n            allPFCheckResults[checkType] = save_data\n            #allPFCheckResults[checkType] = allPFCheckResults[che"
  },
  {
    "id": "chunk_2420",
    "text": "lPFCheckResults[checkType] = allPFCheckResults[checkType].drop_duplicates()\n        else:\n            allPFCheckResults[checkType] = pd.merge(allPFCheckResults[checkType],save_data,how='outer',on='PF Check Message')\n            allPFCheckResults[checkType] = allPFCheckResults[checkType].drop_duplicates()\n\n    return allPFCheckResults\n\ndef getBrEndVoltageInconsistencies(savLocation,rawfilename,allBrTerminalVoltageInconsistencies,areaList):\n    # Check for line branch elements that connect buses w"
  },
  {
    "id": "chunk_2421",
    "text": "heck for line branch elements that connect buses with different base voltages\n    busData_tmp = getAllBusData(savLocation)\n    branchData = getAllLineData(savLocation)\n    brTerminalBaseCheck = pd.merge(branchData,busData_tmp[['NUMBER','NAME','BASE','AREA','OWNER']],how='left',left_on='FROMNUMBER',right_on='NUMBER')\n    brTerminalBaseCheck = pd.merge(brTerminalBaseCheck,busData_tmp[['NUMBER','NAME','BASE','AREA','OWNER']],how='left',left_on='TONUMBER',right_on='NUMBER',suffixes=('_FromBus','_ToB"
  },
  {
    "id": "chunk_2422",
    "text": "MBER',right_on='NUMBER',suffixes=('_FromBus','_ToBus'))\n    #branchData.to_csv(target_output_directory+r'\\branchData.csv')\n    #brTerminalBaseCheck.to_csv(target_output_directory+r'\\brTerminalBaseCheck.csv')\n    inconsistent_line_terminal_base_voltages = brTerminalBaseCheck.loc[(brTerminalBaseCheck['BASE_FromBus']!=brTerminalBaseCheck['BASE_ToBus'])\\\n        &((brTerminalBaseCheck['AREA_FromBus'].isin(areaList))|(brTerminalBaseCheck['AREA_ToBus'].isin(areaList)))]\n    #inconsistent_line_terminal"
  },
  {
    "id": "chunk_2423",
    "text": ".isin(areaList)))]\n    #inconsistent_line_terminal_base_voltages.to_csv(target_output_directory+r'\\inconsistent_line_terminal_base_voltages.csv')\n    inconsistent_line_terminal_base_voltages['{0}'.format(rawfilename)] = 'TRUE'\n\n    if allBrTerminalVoltageInconsistencies.empty == True:\n        allBrTerminalVoltageInconsistencies = inconsistent_line_terminal_base_voltages\n        allBrTerminalVoltageInconsistencies = allBrTerminalVoltageInconsistencies.drop_duplicates()\n    else:\n        allBrTerm"
  },
  {
    "id": "chunk_2424",
    "text": "cies.drop_duplicates()\n    else:\n        allBrTerminalVoltageInconsistencies = pd.merge(allBrTerminalVoltageInconsistencies,inconsistent_line_terminal_base_voltages,how='outer',\\\n            on=['ID','FROMNUMBER','TONUMBER','STATUS','NUMBER_FromBus','NAME_FromBus','BASE_FromBus','AREA_FromBus','OWNER_FromBus','NUMBER_ToBus','NAME_ToBus','BASE_ToBus','AREA_ToBus','OWNER_ToBus'])\n        allBrTerminalVoltageInconsistencies = allBrTerminalVoltageInconsistencies.drop_duplicates()\n    return allBrTer"
  },
  {
    "id": "chunk_2425",
    "text": "onsistencies.drop_duplicates()\n    return allBrTerminalVoltageInconsistencies\n\ndef getRawxJSON(tmp_dir,rawfilename):\n    temp_rawx_location = tmp_dir+r'\\{0}.rawx'.format(rawfilename)\n    psspy.writerawxsubsys(0,1,[1,1,1,0,0],r\"\"\"{0}\"\"\".format(temp_rawx_location),\"\")\n    with open(temp_rawx_location,'r') as file:\n\t    data = file.read()\n    raw_data_json = json.loads(data)\n    return raw_data_json\n\ndef getNodeBreakerData(raw_data_json):\n    desired_elements = ['sub', 'subnode', 'subswd', 'subterm"
  },
  {
    "id": "chunk_2426",
    "text": "d_elements = ['sub', 'subnode', 'subswd', 'subterm','load', 'fixshunt', 'generator', 'acline', 'sysswd', 'transformer','swshunt','facts','twotermdc','bus']\n    dataframe_dict = {}\n    for element in desired_elements:\n        dataframe_dict[element] = pd.DataFrame(raw_data_json['network'][element]['data'],columns=raw_data_json['network'][element]['fields'])\n    # get all terminate-able equipment into a single dataset\n    fixShunts = dataframe_dict['fixshunt'][['ibus','shntid']].rename(columns={'s"
  },
  {
    "id": "chunk_2427",
    "text": "['fixshunt'][['ibus','shntid']].rename(columns={'shntid':'eqid'})\n    fixShunts['equipmentType'] = 'fixshunt'\n    fixShunts['name'] = ''\n    fixShunts['type'] = 'F'\n    swShunts = dataframe_dict['swshunt'][['ibus','shntid']].rename(columns={'shntid':'eqid'})\n    swShunts['equipmentType'] = 'swshunt'\n    swShunts['name'] = ''\n    swShunts['type'] = 'S'\n    facts = dataframe_dict['facts'][['ibus','jbus','name']].rename(columns={'name':'eqid'})\n    facts['equipmentType'] = 'facts'\n    facts['name']"
  },
  {
    "id": "chunk_2428",
    "text": "facts['equipmentType'] = 'facts'\n    facts['name'] = ''\n    facts['type'] = 'A'\n    acLines = dataframe_dict['acline'][['ibus','jbus','ckt','name']].rename(columns={'ckt':'eqid'})\n    acLines['equipmentType'] = 'acline'\n    acLines['type'] = 'B'\n    twotermdc = dataframe_dict['twotermdc'][['ipi','name']].rename(columns={'ipi':'ibus','name':'eqid'})\n    twotermdc['equipmentType'] = 'twotermdc'\n    twotermdc['type'] = 'D'\n    generators = dataframe_dict['generator'][['ibus','machid']].rename(colum"
  },
  {
    "id": "chunk_2429",
    "text": "_dict['generator'][['ibus','machid']].rename(columns={'machid':'eqid'})\n    generators['equipmentType'] = 'generator'\n    generators['name'] = ''\n    generators['type'] = 'M'\n    loads = dataframe_dict['load'][['ibus','loadid']].rename(columns={'loadid':'eqid'})\n    loads['equipmentType'] = 'load'\n    loads['name'] = ''\n    loads['type'] = 'L'\n    transformers = dataframe_dict['transformer'][['ibus','jbus','kbus','ckt','name']].rename(columns={'ckt':'eqid'})\n    transformers['equipmentType'] = '"
  },
  {
    "id": "chunk_2430",
    "text": "kt':'eqid'})\n    transformers['equipmentType'] = 'transformer'\n    transformers.loc[transformers['kbus']==0,'type'] = '2'\n    transformers.loc[transformers['kbus']!=0,'type'] = '3'\n    sysSwds = dataframe_dict['sysswd'][['ibus','jbus','ckt','name','stat','nstat']].rename(columns={'ckt':'eqid'})\n    sysSwds['equipmentType'] = 'system switching device'\n    sysSwds['type'] = 'B'\n\n    all_termable_equip = pd.concat([fixShunts,acLines,generators,loads,transformers,sysSwds,swShunts,facts,twotermdc],ig"
  },
  {
    "id": "chunk_2431",
    "text": ",transformers,sysSwds,swShunts,facts,twotermdc],ignore_index=True)\n    all_termable_equip['kbus'] = all_termable_equip['kbus'].replace(0,np.nan)\n    all_termable_equip['jbus'] = all_termable_equip['jbus'].replace(0,np.nan)\n    all_termable_equip['EquipmentID'] = all_termable_equip.index # we'll need this later\n\n    # join the terminable equipment to their corresponding substation and node, if available\n    # first, format the subterm df for greater clarity: because ibus/jbus/and kbus are not con"
  },
  {
    "id": "chunk_2432",
    "text": "er clarity: because ibus/jbus/and kbus are not consistently assigned\n    subterm_formatted = dataframe_dict['subterm'].rename(columns={'isub':'sub','inode':'node','ibus':'bus','jbus':'IDbusA','kbus':'IDbusB','eqid':'IDequip'})\n    # second, join all_termable_equip to subterm_formatted on the ID fields -- this will be giant\n    ibus_node_table = pd.merge(all_termable_equip,subterm_formatted, how = 'left', left_on = ['ibus','eqid','type'], right_on = ['bus','IDequip','type'])\n    ibus_node_table ="
  },
  {
    "id": "chunk_2433",
    "text": " = ['bus','IDequip','type'])\n    ibus_node_table = ibus_node_table.loc[\\\n        ((ibus_node_table['jbus'].isna()==True)|((ibus_node_table['jbus']==ibus_node_table['IDbusA'])|(ibus_node_table['jbus']==ibus_node_table['IDbusB'])))\\\n        &((ibus_node_table['kbus'].isna()==True)|(ibus_node_table['kbus']==ibus_node_table['IDbusA'])|(ibus_node_table['kbus']==ibus_node_table['IDbusB']))] # this is the data set for which the node bus is ibus of the equipment\n    ibus_node_table = ibus_node_table[['E"
  },
  {
    "id": "chunk_2434",
    "text": "quipment\n    ibus_node_table = ibus_node_table[['EquipmentID','ibus','jbus','kbus','eqid','equipmentType','stat','nstat','name','sub','node','type']]\n    ibus_node_table = ibus_node_table.rename(columns={'sub':'isub','node':'inode'})\n    ibus_node_table = ibus_node_table.drop_duplicates()\n    jbus_node_table = pd.merge(all_termable_equip,subterm_formatted, how = 'left', left_on = ['jbus','eqid','type'], right_on = ['bus','IDequip','type'])\n    jbus_node_table = jbus_node_table.loc[\\\n        ((jb"
  },
  {
    "id": "chunk_2435",
    "text": "us_node_table = jbus_node_table.loc[\\\n        ((jbus_node_table['ibus'].isna()==True)|((jbus_node_table['ibus']==jbus_node_table['IDbusA'])|(jbus_node_table['ibus']==jbus_node_table['IDbusB'])))\\\n        &((jbus_node_table['kbus'].isna()==True)|((jbus_node_table['kbus']==jbus_node_table['IDbusA'])|(jbus_node_table['kbus']==jbus_node_table['IDbusB'])))] # this is the data set for which the node bus is jbus of the equipment\n    jbus_node_table = jbus_node_table[['EquipmentID','ibus','jbus','kbus',"
  },
  {
    "id": "chunk_2436",
    "text": "us_node_table[['EquipmentID','ibus','jbus','kbus','eqid','equipmentType','stat','nstat','name','sub','node','type']]\n    jbus_node_table = jbus_node_table.rename(columns={'sub':'jsub','node':'jnode'})\n    jbus_node_table = jbus_node_table.drop_duplicates()\n    kbus_node_table = pd.merge(all_termable_equip,subterm_formatted, how = 'left', left_on = ['kbus','eqid','type'], right_on = ['bus','IDequip','type'])\n    kbus_node_table = kbus_node_table.loc[\\\n        ((kbus_node_table['ibus'].isna()==Tru"
  },
  {
    "id": "chunk_2437",
    "text": "oc[\\\n        ((kbus_node_table['ibus'].isna()==True)|((kbus_node_table['ibus']==kbus_node_table['IDbusA'])|(kbus_node_table['ibus']==kbus_node_table['IDbusB'])))\\\n        &((kbus_node_table['jbus'].isna()==True)|((kbus_node_table['jbus']==kbus_node_table['IDbusA'])|(kbus_node_table['jbus']==kbus_node_table['IDbusB'])))] # this is the data set for which the node bus is kbus of the equipment\n    kbus_node_table = kbus_node_table[['EquipmentID','ibus','jbus','kbus','eqid','equipmentType','stat','ns"
  },
  {
    "id": "chunk_2438",
    "text": "s','jbus','kbus','eqid','equipmentType','stat','nstat','name','sub','node','type']]\n    kbus_node_table = kbus_node_table.rename(columns={'sub':'ksub','node':'knode'})\n    kbus_node_table = kbus_node_table.drop_duplicates()\n\n    all_termable_equip_with_nodes = pd.merge(all_termable_equip,ibus_node_table,how='left',on=['EquipmentID','ibus','jbus','kbus','eqid','equipmentType','stat','nstat','name','type'])\n    all_termable_equip_with_nodes = pd.merge(all_termable_equip_with_nodes,jbus_node_table,"
  },
  {
    "id": "chunk_2439",
    "text": "rge(all_termable_equip_with_nodes,jbus_node_table,how='left',on=['EquipmentID','ibus','jbus','kbus','eqid','equipmentType','stat','nstat','name','type'])\n    all_termable_equip_with_nodes = pd.merge(all_termable_equip_with_nodes,kbus_node_table,how='left',on=['EquipmentID','ibus','jbus','kbus','eqid','equipmentType','stat','nstat','name','type'])\n\n    # add the substation switching devices to the all_termable_equip_with_nodes df\n    # get sub switching device data\n    subSwds = dataframe_dict['s"
  },
  {
    "id": "chunk_2440",
    "text": "tching device data\n    subSwds = dataframe_dict['subswd']\n    subSwds['jsub'] = subSwds['isub'] # adding jsub column for easier concatenation with all_termable_equip_with_nodes\n    subSwds['equipmentType'] = subSwds['type'].map({1:'Subswd - GEN',2:'Subswd - CB',3:'Subswd - DSC'}) #.astype(str)\n    subSwds=subSwds.rename(columns={'swdid':'eqid'})\n    subSwds = subSwds[['isub','inode','jsub','jnode','eqid','name','equipmentType','type','stat','nstat']]\n    # the sub node data and join to sub switc"
  },
  {
    "id": "chunk_2441",
    "text": "t']]\n    # the sub node data and join to sub switching deivce data\n    subNodes = dataframe_dict['subnode']\n    subNodes = subNodes.rename(columns={'isub':'sub','inode':'node','ibus':'bus'})\n    subNodes = subNodes[['sub','node','bus','name']]\n    subNodes=subNodes.drop_duplicates()\n    isubNodes=subNodes.rename(columns={'sub':'isub','node':'inode','bus':'ibus','name':'inode_name'})\n    jsubNodes=subNodes.rename(columns={'sub':'jsub','node':'jnode','bus':'jbus','name':'jnode_name'})\n    subSwds "
  },
  {
    "id": "chunk_2442",
    "text": "e','bus':'jbus','name':'jnode_name'})\n    subSwds = pd.merge(subSwds,isubNodes,how='left',on=['isub','inode'])\n    subSwds = pd.merge(subSwds,jsubNodes,how='left',on=['jsub','jnode'])\n    subSwds.index += len(all_termable_equip_with_nodes.index)\n    subSwds['EquipmentID']=subSwds.index\n\n    # add the sys swd stype back into the dataset (it has to show as 'B' to join to the sub terminations, since 2 and 3 refer only to transformers in the subterm data)\n    sysSwdWType = sysSwds = dataframe_dict['"
  },
  {
    "id": "chunk_2443",
    "text": "data)\n    sysSwdWType = sysSwds = dataframe_dict['sysswd'][['ibus','jbus','ckt','name','stat','nstat','stype']].rename(columns={'ckt':'eqid'}) # the field stype refers to the switch type, where 2 is a breaker and 3 is a disconnect\n    all_termable_equip_with_nodes_incl_subswds = all_termable_equip_with_nodes.merge(sysSwdWType,how='left',on=['ibus','jbus','eqid','name','stat','nstat'])\n    all_termable_equip_with_nodes_incl_subswds.loc[all_termable_equip_with_nodes_incl_subswds['equipmentType']=="
  },
  {
    "id": "chunk_2444",
    "text": "e_equip_with_nodes_incl_subswds['equipmentType']=='system switching device','type']=\\\n        all_termable_equip_with_nodes_incl_subswds['stype'] #replace type with stype for system switching devices\n    all_termable_equip_with_nodes_incl_subswds = all_termable_equip_with_nodes_incl_subswds.drop('stype',axis=1) #drop the stype column\n    all_termable_equip_with_nodes_incl_subswds = all_termable_equip_with_nodes_incl_subswds.drop_duplicates() #drop any duplicates introduced\n    # add substation s"
  },
  {
    "id": "chunk_2445",
    "text": "p any duplicates introduced\n    # add substation switching devices to all_termable_equip_with_nodes\n    all_termable_equip_with_nodes_incl_subswds = pd.concat([all_termable_equip_with_nodes_incl_subswds,subSwds],ignore_index=False)\n\n    return (ibus_node_table, jbus_node_table, kbus_node_table, all_termable_equip_with_nodes,dataframe_dict,all_termable_equip_with_nodes_incl_subswds)\n\ndef getInvalidSetpointsContinuousShunts(allSwShunts,rawfilename,allSwShuntsWithInvalidSetpoints,savLocation,areaLi"
  },
  {
    "id": "chunk_2446",
    "text": "allSwShuntsWithInvalidSetpoints,savLocation,areaList):\n    # check Binit values for switched shunt\n    busData_tmp = getAllBusData(savLocation)[['NUMBER','AREA']].rename(columns={'NUMBER':'ibus'})\n    allSwShuntsWithArea = allSwShunts.merge(busData_tmp,how='left',on='ibus')\n    SwShunts = allSwShuntsWithArea.loc[allSwShuntsWithArea['AREA'].isin(areaList)] #get requested area shunts only\n    SwShunts = SwShunts.loc[SwShunts['modsw']==2] #only get continuous-control-type shunts\n    #print(SwShunts"
  },
  {
    "id": "chunk_2447",
    "text": "continuous-control-type shunts\n    #print(SwShunts)\n    SwShuntsWithInvalidSetpoints = SwShunts.loc[(SwShunts['vswhi']!=SwShunts['vswlo'])]\n    SwShuntsWithInvalidSetpoints = SwShuntsWithInvalidSetpoints[['ibus','AREA','shntid','modsw','swreg','vswhi','vswlo']]\n    SwShuntsWithInvalidSetpoints['{0}'.format(rawfilename)] = 'TRUE'\n\n    if allSwShuntsWithInvalidSetpoints.empty==True:\n        allSwShuntsWithInvalidSetpoints = SwShuntsWithInvalidSetpoints\n        allSwShuntsWithInvalidSetpoints = all"
  },
  {
    "id": "chunk_2448",
    "text": "ints\n        allSwShuntsWithInvalidSetpoints = allSwShuntsWithInvalidSetpoints.drop_duplicates()\n    else:\n        allSwShuntsWithInvalidSetpoints = allSwShuntsWithInvalidSetpoints.merge(SwShuntsWithInvalidSetpoints,how='outer',\\\n            on=['ibus','AREA','shntid','modsw','swreg','vswhi','vswlo'])\n        allSwShuntsWithInvalidSetpoints = allSwShuntsWithInvalidSetpoints.drop_duplicates()\n    return allSwShuntsWithInvalidSetpoints\n\ndef getInvalidBinitShunts(allSwShunts,rawfilename,allSwShunts"
  },
  {
    "id": "chunk_2449",
    "text": "lidBinitShunts(allSwShunts,rawfilename,allSwShuntsWithInvalidBinit,savLocation,areaList):\n    # check Binit values for switched shunt\n    busData_tmp = getAllBusData(savLocation)[['NUMBER','AREA']].rename(columns={'NUMBER':'ibus'})\n    allSwShuntsWithArea = allSwShunts.merge(busData_tmp,how='left',on='ibus')\n    SwShunts = allSwShuntsWithArea.loc[allSwShuntsWithArea['AREA'].isin(areaList)] #get requested area shunts only\n    SwShunts = SwShunts.loc[SwShunts['modsw']==1] #only get discreet-contro"
  },
  {
    "id": "chunk_2450",
    "text": "oc[SwShunts['modsw']==1] #only get discreet-control-type shunts\n    SwShuntsWithInvalidBinit = SwShunts.loc[(SwShunts['binit']!=0)\\\n        &(SwShunts['binit']!=SwShunts['b1'])\\\n        &(SwShunts['binit']!=SwShunts['b2'])\\\n        &(SwShunts['binit']!=SwShunts['b3'])\\\n        &(SwShunts['binit']!=SwShunts['b4'])\\\n        &(SwShunts['binit']!=SwShunts['b5'])\\\n        &(SwShunts['binit']!=SwShunts['b6'])\\\n        &(SwShunts['binit']!=SwShunts['b7'])\\\n        &(SwShunts['binit']!=SwShunts['b8'])\\\n"
  },
  {
    "id": "chunk_2451",
    "text": "])\\\n        &(SwShunts['binit']!=SwShunts['b8'])\\\n        &(SwShunts['binit']!=SwShunts['b1']+SwShunts['b2'])\\\n        &(SwShunts['binit']!=SwShunts['b1']+SwShunts['b2']+SwShunts['b3'])\\\n        &(SwShunts['binit']!=SwShunts['b1']+SwShunts['b2']+SwShunts['b3']+SwShunts['b4'])\\\n        &(SwShunts['binit']!=SwShunts['b1']+SwShunts['b2']+SwShunts['b3']+SwShunts['b4']+SwShunts['b5'])\\\n        &(SwShunts['binit']!=SwShunts['b1']+SwShunts['b2']+SwShunts['b3']+SwShunts['b4']+SwShunts['b5']+SwShunts['b6"
  },
  {
    "id": "chunk_2452",
    "text": "s['b3']+SwShunts['b4']+SwShunts['b5']+SwShunts['b6'])\\\n        &(SwShunts['binit']!=SwShunts['b1']+SwShunts['b2']+SwShunts['b3']+SwShunts['b4']+SwShunts['b5']+SwShunts['b6']+SwShunts['b7'])\\\n        &(SwShunts['binit']!=SwShunts['b1']+SwShunts['b2']+SwShunts['b3']+SwShunts['b4']+SwShunts['b5']+SwShunts['b6']+SwShunts['b7']+SwShunts['b8'])]\n    SwShuntsWithInvalidBinit = SwShuntsWithInvalidBinit[['ibus','AREA','shntid','modsw','swreg','binit']]\n    SwShuntsWithInvalidBinit['{0}'.format(rawfilenam"
  },
  {
    "id": "chunk_2453",
    "text": "  SwShuntsWithInvalidBinit['{0}'.format(rawfilename)] = 'TRUE'\n    \n    if allSwShuntsWithInvalidBinit.empty==True:\n        allSwShuntsWithInvalidBinit = SwShuntsWithInvalidBinit\n        allSwShuntsWithInvalidBinit = allSwShuntsWithInvalidBinit.drop_duplicates()\n    else:\n        allSwShuntsWithInvalidBinit = allSwShuntsWithInvalidBinit.merge(SwShuntsWithInvalidBinit,how='outer',\\\n            on=['ibus','AREA','shntid','modsw','swreg','binit'])\n        allSwShuntsWithInvalidBinit = allSwShuntsWi"
  },
  {
    "id": "chunk_2454",
    "text": "       allSwShuntsWithInvalidBinit = allSwShuntsWithInvalidBinit.drop_duplicates()\n    return allSwShuntsWithInvalidBinit\n\ndef getSolutionData(rawfilename,allCaseSolveData,areaList,allVoltageViolations,allThermalViolations,temp_dir,AllBusArea):\n    error_map = {0:'no error occurred',1:'invalid OPTIONS value',2:'generators are converted',\n    3:'buses in island(s) without a swing bus; use activity TREE',\n    4:'bus type code and series element status inconsistencies',\n    5:'prerequisite requirem"
  },
  {
    "id": "chunk_2455",
    "text": "tus inconsistencies',\n    5:'prerequisite requirements for API are not met'}\n    flag_map = {0:'tap adj',1:'area interchange adj',2:'phase shift adj',\n    3:'dc tap adj',4:'sw shunt adj',5:'flat start',6:'var limit',7:'non-divergent sol'}\n    fdns_configuration_step1 = [1,1,1,1,1,1,0,0]\n    fdns_configuration_step1_labels = dict(zip(flag_map.values(),fdns_configuration_step1))\n    fdns_configuration_step2 = [1,1,1,1,1,0,0,0]\n    fdns_configuration_step2_labels = dict(zip(flag_map.values(),fdns_c"
  },
  {
    "id": "chunk_2456",
    "text": "n_step2_labels = dict(zip(flag_map.values(),fdns_configuration_step2))\n    fnsl_configuration_step3 = [1,1,1,1,1,0,0,0]\n    fnsl_configuration_step3_labels = dict(zip(flag_map.values(),fnsl_configuration_step3))\n    step1_solution_dict = fdns_configuration_step1_labels.copy()\n    step2_solution_dict = fdns_configuration_step2_labels.copy()\n    step3_solution_dict = fnsl_configuration_step3_labels.copy()\n    # do step 1 solve\n    ierr_fdns_1 = psspy.fdns(fdns_configuration_step1)\n    #print('ierr"
  },
  {
    "id": "chunk_2457",
    "text": "py.fdns(fdns_configuration_step1)\n    #print('ierr_fdns is {0}'.format(ierr_fdns))\n    if ierr_fdns_1 == 0:\n        solveIterat_fdns_1 = psspy.iterat() #number of iterations of solution\n        solveSysmsm_fdns_1 = psspy.sysmsm() #total MVA mismatch of solution\n        solutionString_fdns_1 = psspy.solstr()\n        step1_solution_dict.update({'Step':1,'Solution Method':'fdns',\n        'Iterations':solveIterat_fdns_1,'Mismatch':solveSysmsm_fdns_1,'Solution Str':solutionString_fdns_1,\n        'ier"
  },
  {
    "id": "chunk_2458",
    "text": "'Solution Str':solutionString_fdns_1,\n        'ierr':error_map[ierr_fdns_1]})\n        # do step 2 solve\n        ierr_fdns_2 = psspy.fdns(fdns_configuration_step2)\n        if ierr_fdns_2 == 0:\n            solveIterat_fdns_2 = psspy.iterat() #number of iterations of solution\n            solveSysmsm_fdns_2 = psspy.sysmsm() #total MVA mismatch of solution\n            solutionString_fdns_2 = psspy.solstr()\n            step2_solution_dict.update({'Step':2,'Solution Method':'fdns',\n            'Iterati"
  },
  {
    "id": "chunk_2459",
    "text": "':2,'Solution Method':'fdns',\n            'Iterations':solveIterat_fdns_2,'Mismatch':solveSysmsm_fdns_2,\n            'Solution Str':solutionString_fdns_2,'ierr':error_map[ierr_fdns_2]})\n            # do step 3 solve\n            ierr_fnsl_3 = psspy.fdns(fnsl_configuration_step3)\n            if ierr_fnsl_3 == 0:\n                solveIterat_fnsl_3 = psspy.iterat() #number of iterations of solution\n                solveSysmsm_fnsl_3  = psspy.sysmsm() #total MVA mismatch of solution\n                s"
  },
  {
    "id": "chunk_2460",
    "text": " #total MVA mismatch of solution\n                solutionString_fnsl_3  = psspy.solstr()\n                step3_solution_dict.update({'Step':3,'Solution Method':'fnsl',\n                'Iterations':solveIterat_fnsl_3 ,'Mismatch':solveSysmsm_fnsl_3 ,\n                'Solution Str':solutionString_fnsl_3 ,'ierr':error_map[ierr_fnsl_3 ]})\n                # if solution converged, get voltage and branch violations\n                if solutionString_fnsl_3 == 'Met convergence tolerances                  "
  },
  {
    "id": "chunk_2461",
    "text": "3 == 'Met convergence tolerances                      ':\n                    # get BC Violations\n                    temp_PSSE_report_output1 = temp_dir+r'\\PSSE_capture1.txt' #capture progress output from PSS/E\n                    temp_PSSE_report_output2 = temp_dir+r'\\PSSE_capture2.txt' #capture progress output from PSS/E\n\n                    psspy.report_output(2,temp_PSSE_report_output1,0) #capture progress output from PSS/E\n                    psspy.set_progress_verbose(-1) #set to output al"
  },
  {
    "id": "chunk_2462",
    "text": "  psspy.set_progress_verbose(-1) #set to output all messages\n\n                    BC_violations_SID = 1\n                    PSSESetSubSystem(SID=BC_violations_SID,USEKV=1,BASEKV=1,NUMAREA=len(areaList),AREAS=areaList,NUMBUS=0,BUSES=[],NUMOWNER=0,OWNERS=[],NUMZONE=0,ZONES=[])            \n\n                    # get Branch and voltage violations and read report\n                    psspy.rate_2(BC_violations_SID,0,1,1,1,0, 98.0) #get branch violations report\n                    silenceAllPSSE() #res"
  },
  {
    "id": "chunk_2463",
    "text": "s report\n                    silenceAllPSSE() #reset the outputs\n                    psspy.report_output(2,temp_PSSE_report_output2,0) #capture progress output from PSS/E\n                    psspy.checkvoltagelimits(BC_violations_SID,0,1,0) #get voltage violation report\n                    silenceAllPSSE() #reset the outputs\n                    # process Branch violations\n                    BCbranchViolations = parseBrViolationReport(temp_PSSE_report_output1)\n                    BCbranchViolati"
  },
  {
    "id": "chunk_2464",
    "text": "eport_output1)\n                    BCbranchViolations['{0}'.format(rawfilename)] = BCbranchViolations['Loading']\n                    BCbranchViolations = BCbranchViolations[['From Bus Number','From Bus Name','To Bus Number','To Bus Name','Circuit ID','Rating A','{0}'.format(rawfilename)]]\n                    BCbranchViolations['From Bus Number'] = BCbranchViolations['From Bus Number'].astype(str)\n                    BCbranchViolations['To Bus Number'] = BCbranchViolations['To Bus Number'].astype"
  },
  {
    "id": "chunk_2465",
    "text": "ber'] = BCbranchViolations['To Bus Number'].astype(str)\n                    # extract Bus and section numbers from the bus columns\n                    BCbranchViolations['FromBusNum'] = BCbranchViolations['From Bus Number'].str.extract(r'([0-9]+)',expand=True)[0].astype(int,errors='raise')\n                    BCbranchViolations['FromBusSection'] = BCbranchViolations['From Bus Number'].str.extract(r'-\\s+([0-9]+)').astype(int,errors='ignore')\n                    BCbranchViolations['ToBusNum'] = BC"
  },
  {
    "id": "chunk_2466",
    "text": "               BCbranchViolations['ToBusNum'] = BCbranchViolations['To Bus Number'].str.extract(r'([0-9]+)',expand=True)[0].astype(int,errors='raise') #r'([0-9]+)-'\n                    BCbranchViolations['ToBusSection'] = BCbranchViolations['To Bus Number'].str.extract(r'-\\s+([0-9]+)').astype(int,errors='ignore')\n                    # join Areas to To and From buses\n                    AllBusArea['NUMBER'] = AllBusArea['NUMBER'].astype(int)\n                    FromBusAreas = AllBusArea.rename(co"
  },
  {
    "id": "chunk_2467",
    "text": "               FromBusAreas = AllBusArea.rename(columns={'NUMBER':'FromBusNum','AREA':'FromBusArea'})\n                    BCbranchViolations = BCbranchViolations.merge(FromBusAreas,how='left',on='FromBusNum')\n                    ToBusAreas = AllBusArea.rename(columns={'NUMBER':'ToBusNum','AREA':'ToBusArea'})\n                    BCbranchViolations = BCbranchViolations.merge(ToBusAreas,how='left',on='ToBusNum')\n                    BCbranchViolations = BCbranchViolations[['From Bus Number','FromBus"
  },
  {
    "id": "chunk_2468",
    "text": "s = BCbranchViolations[['From Bus Number','FromBusNum','FromBusSection','FromBusArea',\\\n                        'From Bus Name','To Bus Number','ToBusNum','ToBusSection','ToBusArea','To Bus Name','Circuit ID','Rating A','{0}'.format(rawfilename)]]\n                    # process voltage violations\n                    BCvoltViolations = parseVoltViolationReport(temp_PSSE_report_output2)\n                    BCvoltViolations['{0}'.format(rawfilename)] = BCvoltViolations['V(pu)']\n                    B"
  },
  {
    "id": "chunk_2469",
    "text": " = BCvoltViolations['V(pu)']\n                    BCvoltViolations=BCvoltViolations[['Bus Number','Bus Name','Bus kV','V Limit','Voltage Violation Type','{0}'.format(rawfilename)]]\n                    # # extract Bus and section numbers from the bus columns\n                    BCvoltViolations['BusNum'] = BCvoltViolations['Bus Number'].str.extract(r'([0-9]+)',expand=True)[0].astype(int,errors='raise')\n                    BCvoltViolations['BusSection'] = BCvoltViolations['Bus Number'].str.extract("
  },
  {
    "id": "chunk_2470",
    "text": "on'] = BCvoltViolations['Bus Number'].str.extract(r'-\\s+([0-9]+)').astype(int,errors='ignore')\n                    # join Areas to buses\n                    VBusAreas = AllBusArea.rename(columns={'NUMBER':'BusNum'})\n                    BCvoltViolations = BCvoltViolations.merge(VBusAreas,how='left',on='BusNum')\n                    BCvoltViolations = BCvoltViolations[['Bus Number','BusNum','BusSection','Bus Name','Bus kV','V Limit','Voltage Violation Type','AREA','{0}'.format(rawfilename)]]\n\n     "
  },
  {
    "id": "chunk_2471",
    "text": "on Type','AREA','{0}'.format(rawfilename)]]\n\n                    if allVoltageViolations.empty == True:\n                        allVoltageViolations = BCvoltViolations\n                        allVoltageViolations = allVoltageViolations.drop_duplicates()\n                    else:\n                        allVoltageViolations = allVoltageViolations.merge(BCvoltViolations,how='outer',on=['Bus Number','BusNum','BusSection','AREA',\\\n                            'Bus Name','Bus kV','V Limit','Voltage Vi"
  },
  {
    "id": "chunk_2472",
    "text": "         'Bus Name','Bus kV','V Limit','Voltage Violation Type'])\n                        allVoltageViolations = allVoltageViolations.drop_duplicates()\n                    if allThermalViolations.empty == True:\n                        allThermalViolations = BCbranchViolations\n                        allThermalViolations = allThermalViolations.drop_duplicates()\n                    else:\n                        allThermalViolations = allThermalViolations.merge(BCbranchViolations,how='outer',on=['F"
  },
  {
    "id": "chunk_2473",
    "text": "ations.merge(BCbranchViolations,how='outer',on=['From Bus Number','From Bus Name',\\\n                            'FromBusNum','FromBusSection','FromBusArea','To Bus Number','ToBusNum','ToBusSection','ToBusArea','To Bus Name',\\\n                            'Circuit ID','Rating A'])\n                        allThermalViolations = allThermalViolations.drop_duplicates()\n            else:\n                step3_solution_dict.update({'Step':3,'Solution Method':'fnsl',\n                'Iterations':'NA' ,'M"
  },
  {
    "id": "chunk_2474",
    "text": "hod':'fnsl',\n                'Iterations':'NA' ,'Mismatch':'NA' ,\n                'Solution Str':'NA' ,'ierr':error_map[ierr_fnsl_3 ]})\n        else:\n            step2_solution_dict.update({'Step':2,'Solution Method':'fdns',\n            'Iterations':'NA','Mismatch':'NA',\n            'Solution Str':'NA','ierr':error_map[ierr_fdns_2]})\n    else:\n        step1_solution_dict.update({'Step':1,'Solution Method':'fdns',\n        'Iterations':'NA','Mismatch':'NA','Solution Str':'NA',\n        'ierr':error"
  },
  {
    "id": "chunk_2475",
    "text": "ch':'NA','Solution Str':'NA',\n        'ierr':error_map[ierr_fdns_1]})\n        step2_solution_dict.update({'Step':2,'Solution Method':'NA',\n        'Iterations':'NA','Mismatch':'NA','Solution Str':'NA',\n        'ierr':'NA (not attempted)'})\n        step3_solution_dict.update({'Step':3,'Solution Method':'NA',\n        'Iterations':'NA','Mismatch':'NA','Solution Str':'NA',\n        'ierr':'NA (not attempted)'})\n    three_step_solution_dict = dict(zip(step1_solution_dict,zip(step1_solution_dict.values"
  },
  {
    "id": "chunk_2476",
    "text": "step1_solution_dict,zip(step1_solution_dict.values(),step2_solution_dict.values(),step3_solution_dict.values())))\n    three_step_solution_data = pd.DataFrame.from_dict(three_step_solution_dict)\n    three_step_solution_data['Case'] = '{0}'.format(rawfilename)\n\n    if allCaseSolveData.empty == True:\n        allCaseSolveData = three_step_solution_data\n        allCaseSolveData = allCaseSolveData.drop_duplicates()\n    else:\n        # allCaseSolveData = allCaseSolveData.merge(two_step_solution_data,ho"
  },
  {
    "id": "chunk_2477",
    "text": "= allCaseSolveData.merge(two_step_solution_data,how='outer',\\\n        #     on=['Step','Solution Method','Iterations','Mismatch','Solution Str','ierr',\\\n        #     'tap adj','area interchange adj','phase shift adj','dc tap adj',\\\n        #     'sw shunt adj','flat start','var limit','non-divergent sol'])\n        allCaseSolveData = pd.concat([allCaseSolveData,three_step_solution_data],ignore_index=True)\n        allCaseSolveData = allCaseSolveData.drop_duplicates()\n\n    return allCaseSolveData,"
  },
  {
    "id": "chunk_2478",
    "text": "ta.drop_duplicates()\n\n    return allCaseSolveData, allVoltageViolations, allThermalViolations\n\ndef getCAConvergenceData(CASELOCATION,rawfilename,allCAData,areaList,temp_dir, allUnsolvedContingencies):\n\n    # generate confile for all single branch elements in the selected areas\n    tempConFileLoc = r'{0}\\temp.con'.format(temp_dir)\n    generateAllSingleBranchAndXFRContingencies(CASELOCATION,areaList,tempConFileLoc)\n\n    # generate sub and mon files \n    tempSubFileLoc = r'{0}\\temp.sub'.format(temp"
  },
  {
    "id": "chunk_2479",
    "text": " \n    tempSubFileLoc = r'{0}\\temp.sub'.format(temp_dir)\n    f = open(tempSubFileLoc,\"w\")\n    f.write(\"SUBSYSTEM 'temp'\\n\")\n    for AR in areaList:\n        f.write(\"AREA {0}\\n\".format(AR))\n    f.write(\"END\\nEND\")\n    f.close()\n    tempMonFileLoc = r'{0}\\temp.mon'.format(temp_dir)\n    f = open(tempMonFileLoc,\"w\")\n    f.write(\"\"\"MONITOR VOLTAGE RANGE SUBSYSTEM 'temp' 0.920 1.050\n    MONITOR VOLTAGE DEVIATION SUBSYSTEM 'temp' 0.070 0.070\n    MONITOR BRANCHES IN SUBSYSTEM 'temp'\n    MONITOR TIES FROM"
  },
  {
    "id": "chunk_2480",
    "text": "BRANCHES IN SUBSYSTEM 'temp'\n    MONITOR TIES FROM SUBSYSTEM 'temp'\n    END\"\"\")\n    f.close()\n\n    # open the case and perform three-step solve from flat start\n    psspy.case(CASELOCATION) #re-open case in psse\n    fdns_configuration_step1 = [1,1,1,1,1,1,0,0]\n    fdns_configuration_step2 = [1,1,1,1,1,0,0,0]\n    fnsl_configuration_step3 = [1,1,1,1,1,0,0,0]\n    ierr_fdns_1 = psspy.fdns(fdns_configuration_step1)\n    ierr_fdns_2 = psspy.fdns(fdns_configuration_step2)\n    ierr_fnsl_3 = psspy.fdns(fns"
  },
  {
    "id": "chunk_2481",
    "text": "figuration_step2)\n    ierr_fnsl_3 = psspy.fdns(fnsl_configuration_step3)\n\n    # set solution parameters\n    CA_TOL = 0.01\n    CA_TAPADJ = 1\n    CA_AREAINT = 1\n    CA_PHADJ = 1\n    CA_DCTAP = 1\n    CA_SWSH = 1\n    CA_SOL = 1 # 'FDNS':0,'FNSL':1,'NSOL':0\n    CA_NONDIV = 0\n    CA_INDMOT = 0\n    CA_INDMACH = 0\n    CA_DISP = 0\n    CA_ZIP = 0\n\n    # generate dfax \n    tempDfaxFileLoc = r'{0}\\temp.dfax'.format(temp_dir)\n    ierr = psspy.dfax([1,1],tempSubFileLoc,tempMonFileLoc,tempConFileLoc,tempDfaxFi"
  },
  {
    "id": "chunk_2482",
    "text": "ubFileLoc,tempMonFileLoc,tempConFileLoc,tempDfaxFileLoc)\n\n    # run accc\n    tempAccFileLoc = r'{0}\\temp.acc'.format(temp_dir)\n    accc_ierr = psspy.accc_with_dsp_3(CA_TOL,[CA_TAPADJ,CA_AREAINT,CA_PHADJ,CA_DCTAP,CA_SWSH,CA_SOL,CA_NONDIV,CA_INDMOT,CA_INDMACH,CA_DISP,CA_ZIP],\"\",tempDfaxFileLoc,tempAccFileLoc,\"\",\"\",\"\")\n\n    # parse accc results\n    accc_output_temp = r'{0}\\accc_output_temp.txt'.format(temp_dir)\n    # report configs\n    stat1 = 0 #spreadsheet report\n    stat2 = 1 #rate 1 for base ca"
  },
  {
    "id": "chunk_2483",
    "text": "readsheet report\n    stat2 = 1 #rate 1 for base case violations\n    stat3 = 2 #rate 2 for CA violations\n    stat4 = 1 #bc SWD ratings set\n    stat5 = 2 #ca SWD ratings set\n    stat6 = 1 #voltage bc normal limit\n    stat7 = 1 #voltage ca normal limit\n    stat8 = 0 #exclude interfaces from report?\n    stat9 = 1 #run voltage limit check\n    stat10 = 1 #exclude elements with bc violations in ca violations\n    stat11 = 1 #exclude elements with bc violations in ca violations\n    stat12 = 0 #exclude ca"
  },
  {
    "id": "chunk_2484",
    "text": "ations in ca violations\n    stat12 = 0 #exclude cases with no ol's\n    stat13 = 0 #do not report post-tripping action solutions\n    stat14 = 1 #report loss of loads\n    ACCC_STATUSES = [stat1,stat2,stat3,stat4,stat5,stat6,stat7,stat8,stat9,stat10,stat11,stat12,stat13,stat14]\n    intv1 = 0 #lv range violations filter\n    intv2 = 0 #hv range violations filter\n    intv3 = 0 #voltage deviation violations filter\n    intv4 = 0 #largest num of busses in disconnected island\n    intv5 = 6000 #max number "
  },
  {
    "id": "chunk_2485",
    "text": " disconnected island\n    intv5 = 6000 #max number of element in avail capacity table\n    ACCC_INTVALS = [intv1,intv2,intv3,intv4,intv5]\n    rlvl1 = 0.5 #bus mismatch convergence\n    rlvl2 = 5.0 #system mismatch convergence tolerance in MVA\n    rlvl3 = 98 #percent of flow rating I MADE THIS LOW FOR DEV, SHOULD BE CLOSE TO 100\n    rlvl4 = 0 #min contingency case flow change from base case value\n    rlvl5 = 0 #min contingency case percent loading increase from base case\n    rlvl6 = 0 #min contingen"
  },
  {
    "id": "chunk_2486",
    "text": "crease from base case\n    rlvl6 = 0 #min contingency case voltage change from base case value\n    rlvl7 = 99999 #cutoff threshold for available capacity table\n    ACCC_REALVALS = [rlvl1,rlvl2,rlvl3,rlvl4,rlvl5,rlvl6,rlvl7]\n    psspy.report_output(2,accc_output_temp,[0,0])\n    accc_report_ierr = psspy.accc_single_run_report_5(ACCC_STATUSES,ACCC_INTVALS,ACCC_REALVALS,tempAccFileLoc)\n    CAresults = getAccReportViolations(accc_output_temp) # parse the acc output report and return a dataframe of res"
  },
  {
    "id": "chunk_2487",
    "text": "he acc output report and return a dataframe of results\n\n    if type(CAresults) != type(None): \n        ConvergedContingencies = CAresults.loc[CAresults['ViolationType']=='Met convergence to']\n        AllContingencies = CAresults.loc[CAresults['ViolationType'].isin(['Met convergence to','Iteration limit ex','Blown up'])]\n        AllNonConvergedContingencies = CAresults.loc[CAresults['ViolationType'].isin(['Iteration limit ex','Blown up'])][['ViolationType','Location']]\n        AllNonConvergedCont"
  },
  {
    "id": "chunk_2488",
    "text": "tionType','Location']]\n        AllNonConvergedContingencies['{0}'.format(rawfilename)] = 'TRUE'\n        numConvergedContingencies = ConvergedContingencies.shape[0]\n        numAllContingencies = AllContingencies.shape[0]\n        numNonConvergedContingencies = AllNonConvergedContingencies.shape[0]\n        CAdata = pd.DataFrame({'TotalContingencies':[numAllContingencies],'ConvergedContingencies':[numConvergedContingencies],\\\n            'NonconvergedContingencies':[numNonConvergedContingencies]})\n "
  },
  {
    "id": "chunk_2489",
    "text": "dContingencies':[numNonConvergedContingencies]})\n        CAdata['PercentConverged'] = CAdata['ConvergedContingencies'] /CAdata['TotalContingencies'] \n        CAdata['Case'] = '{0}'.format(rawfilename)\n    else:\n        CAdata = pd.DataFrame({'TotalContingencies':['NA'],'ConvergedContingencies':['NA'],'NonconvergedContingencies':['NA'],\\\n            'PercentConverged':['NA'],'UnableToObtainBaseCase':['True']})\n        CAdata['Case'] = '{0}'.format(rawfilename)\n    if allCAData.empty == True:\n    "
  },
  {
    "id": "chunk_2490",
    "text": "(rawfilename)\n    if allCAData.empty == True:\n        allCAData = CAdata\n        allCAData = allCAData.drop_duplicates()\n    else:\n        allCAData = pd.concat([allCAData,CAdata],ignore_index=True)\n        allCAData = allCAData.drop_duplicates()\n    if allUnsolvedContingencies.empty == True:\n        allUnsolvedContingencies = AllNonConvergedContingencies\n    else:\n        allUnsolvedContingencies = allUnsolvedContingencies.merge(AllNonConvergedContingencies,how='outer',on=['ViolationType','Loca"
  },
  {
    "id": "chunk_2491",
    "text": "ontingencies,how='outer',on=['ViolationType','Location'])\n\n    return allCAData, allUnsolvedContingencies\n\ndef getIncorrectShuntRemoteBuses(allSwShunts,rawfilename,allIncorrectShuntRemoteBuses,savLocation,areaList):\n    busData_tmp = getAllBusData(savLocation)[['NUMBER','AREA']].rename(columns={'NUMBER':'ibus'})\n    allSwShuntsWithArea = allSwShunts.merge(busData_tmp,how='left',on='ibus')\n    SwShunts = allSwShuntsWithArea.loc[allSwShuntsWithArea['AREA'].isin(areaList)] #get requested area shunt"
  },
  {
    "id": "chunk_2492",
    "text": "['AREA'].isin(areaList)] #get requested area shunts only\n    incorrectShuntRemoteBus = SwShunts.loc[((SwShunts['swreg']>=9700)&(SwShunts['swreg']<=9999))|\\\n                                            ((SwShunts['swreg']>=94000)&(SwShunts['swreg']<=99999))|\\\n                                            ((SwShunts['swreg']>=100000)&(SwShunts['swreg']<=199999))]\n    incorrectShuntRemoteBus = incorrectShuntRemoteBus[['ibus','AREA','shntid','modsw','swreg']]\n    incorrectShuntRemoteBus['{0}'.format(ra"
  },
  {
    "id": "chunk_2493",
    "text": "reg']]\n    incorrectShuntRemoteBus['{0}'.format(rawfilename)] = 'TRUE'\n    if allIncorrectShuntRemoteBuses.empty==True:\n        allIncorrectShuntRemoteBuses = incorrectShuntRemoteBus\n        allIncorrectShuntRemoteBuses = allIncorrectShuntRemoteBuses.drop_duplicates()\n    else:\n        allIncorrectShuntRemoteBuses = allIncorrectShuntRemoteBuses.merge(incorrectShuntRemoteBus,how='outer',\\\n            on=['ibus','AREA','shntid','modsw','swreg'])\n        allIncorrectShuntRemoteBuses = allIncorrectS"
  },
  {
    "id": "chunk_2494",
    "text": "      allIncorrectShuntRemoteBuses = allIncorrectShuntRemoteBuses.drop_duplicates()\n    return allIncorrectShuntRemoteBuses\n\ndef getIncorrectGenRemoteBuses(allGenerators,rawfilename,allIncorrectGenRemoteBuses,savLocation,areaList):\n    busData_tmp = getAllBusData(savLocation)[['NUMBER','AREA']].rename(columns={'NUMBER':'ibus'})\n    allGeneratorsWithArea = allGenerators.merge(busData_tmp,how='left',on='ibus')\n    Generators = allGeneratorsWithArea.loc[allGeneratorsWithArea['AREA'].isin(areaList)]"
  },
  {
    "id": "chunk_2495",
    "text": ".loc[allGeneratorsWithArea['AREA'].isin(areaList)] #get requested area shunts only\n    incorrectGeneratorRemoteBus = Generators.loc[((Generators['ireg']>=9700)&(Generators['ireg']<=9999))|\\\n                                            ((Generators['ireg']>=94000)&(Generators['ireg']<=99999))|\\\n                                            ((Generators['ireg']>=100000)&(Generators['ireg']<=199999))]\n    incorrectGeneratorRemoteBus = incorrectGeneratorRemoteBus[['ibus','AREA','machid','ireg','nreg']]"
  },
  {
    "id": "chunk_2496",
    "text": "rRemoteBus[['ibus','AREA','machid','ireg','nreg']]\n    incorrectGeneratorRemoteBus['{0}'.format(rawfilename)] = 'TRUE'\n    if allIncorrectGenRemoteBuses.empty == True:\n        allIncorrectGenRemoteBuses = incorrectGeneratorRemoteBus\n        allIncorrectGenRemoteBuses = allIncorrectGenRemoteBuses.drop_duplicates()\n    else:\n        allIncorrectGenRemoteBuses = allIncorrectGenRemoteBuses.merge(incorrectGeneratorRemoteBus,how='outer',\\\n        on=['ibus','AREA','machid','ireg','nreg'])\n        allI"
  },
  {
    "id": "chunk_2497",
    "text": "ibus','AREA','machid','ireg','nreg'])\n        allIncorrectGenRemoteBuses = allIncorrectGenRemoteBuses.drop_duplicates()\n    return allIncorrectGenRemoteBuses\n\ndef generateAllSingleBranchAndXFRContingencies(CASELOCATION,areaList,tempConFileLoc):\n    allBranches = getAllLineData(CASELOCATION)\n    allXFRs = getAllXFRData(CASELOCATION)\n    all2WXFRs = allXFRs.loc[allXFRs['WIND3NUMBER'].isnull()==True]\n    all3WXFRs = allXFRs.loc[allXFRs['WIND3NUMBER'].isnull()==False]\n\n    confileLocation = tempConF"
  },
  {
    "id": "chunk_2498",
    "text": "].isnull()==False]\n\n    confileLocation = tempConFileLoc\n    f = open(confileLocation,\"w\")\n    contCounter = 1\n    for br in allBranches.index:\n        busI = allBranches.at[br,'FROMNUMBER']\n        busJ = allBranches.at[br,'TONUMBER']\n        cktID = allBranches.at[br,'ID']\n        strToWrite = r\"OPEN BRANCH FROM BUS {0} TO BUS {1} CKT {2}\".format(busI,busJ,cktID)\n        strToID = 'LN_{0}-{1}_ID:{2}'.format(busI,busJ,cktID)\n        f.write(\"CONTINGENCY '{0}'\".format(str(strToID))) #f.write(\"CO"
  },
  {
    "id": "chunk_2499",
    "text": "TINGENCY '{0}'\".format(str(strToID))) #f.write(\"CONTINGENCY '{0}'\".format(str(contCounter)))\n        f.write(\"\\n\")\n        f.write(strToWrite)\n        f.write(\"\\n\")\n        f.write(\"END\")\n        f.write(\"\\n\")\n        contCounter = contCounter+1\n    for br in all2WXFRs.index:\n        busI = all2WXFRs.at[br,'WIND1NUMBER']\n        busJ = all2WXFRs.at[br,'WIND2NUMBER']\n        cktID = all2WXFRs.at[br,'ID']\n        strToWrite = r\"OPEN BRANCH FROM BUS {0} TO BUS {1} CKT {2}\".format(busI,busJ,cktID)\n "
  },
  {
    "id": "chunk_2500",
    "text": " {0} TO BUS {1} CKT {2}\".format(busI,busJ,cktID)\n        strToID = '2WXFR_{0}-{1}_ID:{2}'.format(busI,busJ,cktID)\n        f.write(\"CONTINGENCY '{0}'\".format(str(strToID))) #f.write(\"CONTINGENCY '{0}'\".format(str(contCounter)))\n        f.write(\"\\n\")\n        f.write(strToWrite)\n        f.write(\"\\n\")\n        f.write(\"END\")\n        f.write(\"\\n\")\n        contCounter = contCounter+1\n    for br in all3WXFRs.index:\n        busI = all3WXFRs.at[br,'WIND1NUMBER']\n        busJ = all3WXFRs.at[br,'WIND2NUMBER"
  },
  {
    "id": "chunk_2501",
    "text": "MBER']\n        busJ = all3WXFRs.at[br,'WIND2NUMBER']\n        busK = int(all3WXFRs.at[br,'WIND3NUMBER'])\n        cktID = all3WXFRs.at[br,'ID']\n        strToWrite = r\"OPEN BRANCH FROM BUS {0} TO BUS {1} TO BUS {2} CKT {3}\".format(busI,busJ,busK,cktID)\n        strToID = '3WXFR_{0}-{1}-{2}_ID:{3}'.format(busI,busJ,busK,cktID)\n        f.write(\"CONTINGENCY '{0}'\".format(str(strToID))) #f.write(\"CONTINGENCY '{0}'\".format(str(contCounter)))\n        f.write(\"\\n\")\n        f.write(strToWrite)\n        f.wri"
  },
  {
    "id": "chunk_2502",
    "text": "te(\"\\n\")\n        f.write(strToWrite)\n        f.write(\"\\n\")\n        f.write(\"END\")\n        f.write(\"\\n\")\n        contCounter = contCounter+1\n    f.write(\"END\")\n    f.close()\n    return\n\ndef getQAReports(CASEDIRECTORY,OUTPUTDIRECTORY,DESIRED_QA_LIST,AREALIST):\n    ### DESIRED_QA_LIST is a list of requested reports to be created, it may include the following entries:\n    ### '900k_buses','CNTB_check','out_of_range_buses','disconnected_shunts','disconnected_loads',\n    ### 'zero_loads', 'multiple_br"
  },
  {
    "id": "chunk_2503",
    "text": "nnected_loads',\n    ### 'zero_loads', 'multiple_branches_terminating_on_node', 'invalid_Binit_switched_shunts',\n    ### 'TREE_islands', 'unterminated_elements', 'br_remote_end_voltage_inconsistencies',\n    ### 'bus_type_inconsistencies', 'incorrect_voltage_bus_limits', 'TLD_bus_updates',\n    ### 'check_solvability','check_CA_performance', 'PSSE_pf_checks'\n\n    ### create a dictionary of the request reports\n    available_reports = ['900k_buses','TREE_islands','bus_type_inconsistencies','CNTB_chec"
  },
  {
    "id": "chunk_2504",
    "text": "REE_islands','bus_type_inconsistencies','CNTB_check',\n    'disconnected_shunts', 'invalid_Binit_switched_shunts','invalid_setpts_continuous_shunts',\n    'incorrect_shunt_remote_buses','incorrect_gen_remote_buses','br_remote_end_voltage_inconsistencies',\n    'check_solvability','check_CA_performance','PSSE_pf_checks','all_lds','disconnected_loads',\n    'zero_loads','disconnected_buses'\n    ]\n    report_dict = {}\n    for report in available_reports:\n        if report in DESIRED_QA_LIST:\n          "
  },
  {
    "id": "chunk_2505",
    "text": ":\n        if report in DESIRED_QA_LIST:\n            report_dict[report] = 1\n        else:\n            report_dict[report] = 0\n\n    ### Create temp directory for file management ###\n    #TMP_DIR = makeTempDirectory()\n    temporary_directory = tempfile.TemporaryDirectory()\n    TMP_DIR = temporary_directory.name\n    print('Created temp directory {0}.'.format(TMP_DIR))\n\n    #### Supress all the PSSE outputs for now\n    suppressAllPSSEOutputs()\n\n    ### Get the list of raw cases to process and define"
  },
  {
    "id": "chunk_2506",
    "text": "## Get the list of raw cases to process and define\n    target_directory = CASEDIRECTORY.GetPath()\n    case_list = sorted(glob.glob(target_directory+r'\\*.raw')) #to sort raws by name\n\n    ### Prepare the output directory\n    target_output_directory = OUTPUTDIRECTORY.GetPath()+r'\\QA_results_{}'.format(str(datetime.datetime.now().date()))\n    os.makedirs(target_output_directory) #create auto QA check output file\n\n    ### set up logger\n    today_date = str(datetime.date.today())\n    logging.basicCon"
  },
  {
    "id": "chunk_2507",
    "text": " = str(datetime.date.today())\n    logging.basicConfig(filename='{0}\\log_file'.format(target_output_directory),filemode='a',level=logging.DEBUG,format='%(name)s - %(levelname)s - %(message)s')\n    logging.debug('{0} execute start at {1}'.format(sys.argv[0],datetime.datetime.now()))\n    logging.debug('All required files and directories selected. Now running the following QA reports for the areas {0}:'.format(','.join(map(str,AREALIST))))\n    logging.debug(DESIRED_QA_LIST)\n\n    ### Prepare blank da"
  },
  {
    "id": "chunk_2508",
    "text": "g.debug(DESIRED_QA_LIST)\n\n    ### Prepare blank dataframes for results\n    CNTB_messages = pd.DataFrame()\n    BusData = pd.DataFrame()   \n    allBusInconsistencies = pd.DataFrame()\n    allIslands = pd.DataFrame()\n    allBrTerminalVoltageInconsistencies = pd.DataFrame()\n    allDisconnectedLds = pd.DataFrame()\n    allZeroLds = pd.DataFrame()\n    allLoads = pd.DataFrame()\n    allLoadsWithTotalsColumn = pd.DataFrame()    \n    allSwShuntsWithInvalidBinit = pd.DataFrame()\n    alldisconnected_shunts = "
  },
  {
    "id": "chunk_2509",
    "text": "nit = pd.DataFrame()\n    alldisconnected_shunts = pd.DataFrame()\n    all900k_buses = pd.DataFrame()   \n    alldisconnected_buses = pd.DataFrame() \n    allCaseSolveData = pd.DataFrame()\n    allVoltageViolations = pd.DataFrame()\n    allThermalViolations = pd.DataFrame()\n    allIncorrectShuntRemoteBuses = pd.DataFrame()\n    allIncorrectGenRemoteBuses = pd.DataFrame()\n    allCAData = pd.DataFrame()\n    allUnsolvedContingencies = pd.DataFrame()\n    allSwShuntsWithInvalidSetpoints = pd.DataFrame()\n   "
  },
  {
    "id": "chunk_2510",
    "text": "lSwShuntsWithInvalidSetpoints = pd.DataFrame()\n    # PSSE check powerflow data dataframes\n    allPFCheckTypes = {'bus data':1,'load data':2,'plant data':3,'generator unit data':4,\n    'induction machine data':5,'fixed bus shunt data':6,'switched shunt data':7,\n    'non-transformer branch data':8,'two-winding transformer data':9,\n    'three-winding transformer data':10,'transformer impedance table correciton data':11,\n    'two-terminal dc line data':13,'multi-terminal dc line data':14,\n    'VSC d"
  },
  {
    "id": "chunk_2511",
    "text": "a':13,'multi-terminal dc line data':14,\n    'VSC dc line data':15,'FACTS device data':16,'GNE device data':17,\n    'area interchange data':18,'owner data':19,'zone data':20}\n    allPFCheckResults = {}\n    for checkType in allPFCheckTypes:\n        allPFCheckResults[checkType] = pd.DataFrame()\n\n    ### Process all raw files according to which reports were requested\n    counter = 1\n    for case in case_list:\n        ### read in the raw file\n        print('processesing case {0} out of {1}'.format(co"
  },
  {
    "id": "chunk_2512",
    "text": "print('processesing case {0} out of {1}'.format(counter,len(case_list)))   \n        rawfilename = os.path.splitext(os.path.basename(case))[0]\n        logging.debug('processesing raw {0} -- case {1} out of {2}'.format(rawfilename,counter,len(case_list)))\n        counter = counter+1\n        psspy.read(0,case) # open case\n\n        ### save the open case as a sav\n        savLocation = target_output_directory+r'\\{0}.sav'.format(rawfilename)\n        PSSESaveCase(savLocation)\n\n        ### if no areas w"
  },
  {
    "id": "chunk_2513",
    "text": "SESaveCase(savLocation)\n\n        ### if no areas were chosen by the user, get a list of all areas in the open case\n        if AREALIST == []:\n            int_data_desired = ['NUMBER']\n            int_ierr, iarray = psspy.aareaint(-1, 2, int_data_desired)\n            allAreas = iarray[0]\n            AREALIST = allAreas\n        \n\n        ### if requested, do the solvability check. If the solvability check indicates that the case did not solve, then do not attempt CA check\n        if (report_dict['"
  },
  {
    "id": "chunk_2514",
    "text": " do not attempt CA check\n        if (report_dict['check_solvability'] == 1)|(report_dict['check_CA_performance'] == 1):\n            #allCaseSolveData = getSolutionData(rawfilename,allCaseSolveData)# TO TROUBLESHOOT, uncomment this line and comment out the following try/except block\n            try:\n                psspy.case(savLocation) #re-open case in psse\n                AllBusArea = getBusData(savLocation,target_output_directory,rawfilename,BusData,ALLAREALIST)[['NUMBER','AREA']] #get bus d"
  },
  {
    "id": "chunk_2515",
    "text": "BusData,ALLAREALIST)[['NUMBER','AREA']] #get bus data for reports to join area to report results\n                allCaseSolveData,allVoltageViolations,allThermalViolations = getSolutionData(rawfilename,allCaseSolveData,AREALIST,allVoltageViolations,allThermalViolations,TMP_DIR,AllBusArea)\n                \n            except:\n                print('PROBLEM WITH CHECK SOLVABILITY. PROBLEM ENCOUNTERED WHILE RUNNING getSolutionData().')\n                logging.debug('PROBLEM WITH CHECK SOLVABILITY. "
  },
  {
    "id": "chunk_2516",
    "text": "   logging.debug('PROBLEM WITH CHECK SOLVABILITY. PROBLEM ENCOUNTERED WHILE RUNNING getSolutionData(): ', exc_info=True)\n\n\n        ### if requested, do the CA check. If the solvability check indicates that the case did not solve, then this will not be attempted.\n        if report_dict['check_CA_performance'] == 1:\n            # check last powerflow solution\n            latestSolution = allCaseSolveData.loc[(allCaseSolveData['Case']==rawfilename)&(allCaseSolveData['Step']==3)]\n            latestS"
  },
  {
    "id": "chunk_2517",
    "text": "(allCaseSolveData['Step']==3)]\n            latestSolution = latestSolution.reset_index()\n            if (latestSolution.at[0,'Solution Str'] != 'Met convergence tolerances                      '):\n                noData = pd.DataFrame({'Case':[rawfilename],'CANotAttemptedDuetoNon-SolvedRAW':['True']})\n                allCAData = pd.concat([allCAData,noData],ignore_index=True)\n            else:\n                #allCAData = getCAConvergenceData(savLocation,rawfilename,allCAData,AREALIST,TMP_DIR) #"
  },
  {
    "id": "chunk_2518",
    "text": "Location,rawfilename,allCAData,AREALIST,TMP_DIR) # TO TROUBLESHOOT, uncomment this line and comment out the following try/except block\n                try:\n                    psspy.case(savLocation) #re-open case in psse\n                    allCAData, allUnsolvedContingencies  = getCAConvergenceData(savLocation,rawfilename,allCAData,AREALIST,TMP_DIR,allUnsolvedContingencies)\n                except:\n                    print('PROBLEM WITH GETTING CA CONVERGENCE. PROBLEM ENCOUNTERED WHILE RUNNING"
  },
  {
    "id": "chunk_2519",
    "text": " CA CONVERGENCE. PROBLEM ENCOUNTERED WHILE RUNNING getCAConvergenceData().')\n                    logging.debug('PROBLEM WITH GETTING CA CONVERGENCE. PROBLEM ENCOUNTERED WHILE RUNNING getCAConvergenceData(): ', exc_info=True)\n\n        ### if requested, do the CNTB check\n        if report_dict['CNTB_check'] == 1:\n            #CNTB_messages = getCNTBCheckData(TMP_DIR,savLocation,target_output_directory,rawfilename,CNTB_messages) # TO TROUBLESHOOT, uncomment this line and comment out the following t"
  },
  {
    "id": "chunk_2520",
    "text": "ncomment this line and comment out the following try/except block\n            try:\n                CNTB_messages = getCNTBCheckData(TMP_DIR,savLocation,target_output_directory,rawfilename,CNTB_messages,AREALIST)\n            except:\n                print('PROBLEM WITH GETTING CNTB REPORT. PROBLEM ENCOUNTERED WHILE RUNNING getCNTBCheckData().')\n                logging.debug('PROBLEM WITH GETTING CNTB REPORT. PROBLEM ENCOUNTERED WHILE RUNNING getCNTBCheckData(): ', exc_info=True)\n        \n        \n"
  },
  {
    "id": "chunk_2521",
    "text": "BCheckData(): ', exc_info=True)\n        \n        \n        ### if any bus-related reports requested, get the bus data and extract the relevant data\n        if (report_dict['900k_buses'] == 1)|(report_dict['disconnected_buses'] == 1): # for ERCOT-only distribution\n            #BusData = getBusData(savLocation,target_output_directory,rawfilename,BusData,AREALIST) # TO TROUBLESHOOT, uncomment this line and comment out the following try/except block\n            try:\n                BusData = getBusDa"
  },
  {
    "id": "chunk_2522",
    "text": "           try:\n                BusData = getBusData(savLocation,target_output_directory,rawfilename,BusData,AREALIST)\n            except:\n                print('PROBLEM ENCOUNTERED WITH GETTING BUS DATA. PROBLEM ENCOUNTERED WHILE RUNNING getBusData().')\n                logging.debug('PROBLEM ENCOUNTERED WITH GETTING BUS DATA. PROBLEM ENCOUNTERED WHILE RUNNING getBusData(): ', exc_info=True)\n            if (report_dict['900k_buses'] == 1) & (BusData.empty == False):\n                #all900k_buse"
  },
  {
    "id": "chunk_2523",
    "text": "ata.empty == False):\n                #all900k_buses = get900kBuses(BusData) #to troubleshoot, uncomment this line and comment out the following try/except block\n                try:\n                    all900k_buses = get900kBuses(BusData)\n                except:\n                    print('PROBLEM ENCOUNTERED WHILE RUNNING get900kBuses().')\n                    logging.debug('PROBLEM ENCOUNTERED WHILE RUNNING get900kBuses().', exc_info=True)     \n            if (report_dict['disconnected_buses'] "
  },
  {
    "id": "chunk_2524",
    "text": "            if (report_dict['disconnected_buses'] == 1) & (BusData.empty == False):\n                #alldisconnected_buses = getDisconnectedBuses(BusData) #to troubleshoot, uncomment this line and comment out the following try/except block\n                try:\n                    alldisconnected_buses = getDisconnectedBuses(BusData)\n                except:\n                    print('PROBLEM ENCOUNTERED WHILE RUNNING getDisconnectedBuses().')\n                    logging.debug('PROBLEM ENCOUNTERED"
  },
  {
    "id": "chunk_2525",
    "text": "                logging.debug('PROBLEM ENCOUNTERED WHILE RUNNING getDisconnectedBuses().', exc_info=True) \n            \n        ### if requested, get all the load data\n        if (report_dict['all_lds'] == 1)|(report_dict['disconnected_loads'] == 1)|(report_dict['zero_loads'] == 1):\n            #thisCaseLoadData = getLdData(savLocation,allLoads,rawfilename,AREALIST) #FOR TROUBLESHOOTING, uncomment this line and comment out the following try/except block\n            try:\n                thisCaseA"
  },
  {
    "id": "chunk_2526",
    "text": "t block\n            try:\n                thisCaseAllLoadData = getLdDataTotalsReportedInCaseColumn(savLocation,allLoads,rawfilename,AREALIST)\n                if allLoads.empty == True:\n                    allLoads = thisCaseAllLoadData\n                    allLoads = allLoads.drop_duplicates()\n                else:\n                    allLoads = allLoads.merge(thisCaseAllLoadData,how='outer',on=['ID','NAME','LODTYPE','NUMBER','STATION','AREA','ZONE','STATUS','OWNER'])\n                    allLoads"
  },
  {
    "id": "chunk_2527",
    "text": "E','STATUS','OWNER'])\n                    allLoads = allLoads.drop_duplicates()\n\n            except:\n                print('PROBLEM ENCOUNTERED WITH GETTING LOAD DATA. PROBLEM ENCOUNTERED WHILE RUNNING getLdDataTotalsReportedInCaseColumn()')\n                logging.debug('PROBLEM ENCOUNTERED WITH GETTING LOAD DATA. PROBLEM ENCOUNTERED WHILE RUNNING getLdDataTotalsReportedInCaseColumn(): ', exc_info=True)\n            \n            #thisCaseLoadData = getLdData(savLocation,allLoads,rawfilename,AREA"
  },
  {
    "id": "chunk_2528",
    "text": " = getLdData(savLocation,allLoads,rawfilename,AREALIST) #FOR TROUBLESHOOTING, uncomment this line and comment out the following try/except block\n            try:\n                thisCaseLoadData = getLdData(savLocation,allLoadsWithTotalsColumn,rawfilename,AREALIST)\n                if allLoadsWithTotalsColumn.empty == True:\n                    allLoadsWithTotalsColumn = thisCaseLoadData\n                    allLoadsWithTotalsColumn = allLoadsWithTotalsColumn.drop_duplicates()\n                else:"
  },
  {
    "id": "chunk_2529",
    "text": "talsColumn.drop_duplicates()\n                else:\n                    allLoadsWithTotalsColumn = allLoadsWithTotalsColumn.merge(thisCaseLoadData,how='outer',on=['ID','NAME','LODTYPE','TOTALACT','NUMBER','STATION','AREA','ZONE','STATUS','OWNER'])\n                    allLoadsWithTotalsColumn = allLoadsWithTotalsColumn.drop_duplicates()\n            except:\n                print('PROBLEM ENCOUNTERED WITH GETTING LOAD DATA. PROBLEM ENCOUNTERED WHILE RUNNING getLdData()')\n                logging.debu"
  },
  {
    "id": "chunk_2530",
    "text": "RUNNING getLdData()')\n                logging.debug('PROBLEM ENCOUNTERED WITH GETTING LOAD DATA. PROBLEM ENCOUNTERED WHILE RUNNING getLdData(): ', exc_info=True)\n\n            if report_dict['disconnected_loads'] == 1:\n                #allDisconnectedLds = getDisconnectedLoads(thisCaseLoadData,allDisconnectedLds) #FOR TROUBLESHOOTING, uncomment this line and comment out the following try/except block\n                try:\n                    allDisconnectedLds = getDisconnectedLoads(thisCaseLoadDa"
  },
  {
    "id": "chunk_2531",
    "text": "connectedLds = getDisconnectedLoads(thisCaseLoadData,allDisconnectedLds)\n                except:\n                    print('PROBLEM ENCOUNTERED WHILE RUNNING getDisconnectedLoads()')\n                    logging.debug('PROBLEM ENCOUNTERED WHILE RUNNING getDisconnectedLoads(): ', exc_info=True)\n            if report_dict['zero_loads'] == 1:\n                #allZeroLds = getZeroLoads(thisCaseLoadData,allZeroLds) #TO TROUBLESHOOT, uncomment this line and comment out the following try/except block\n  "
  },
  {
    "id": "chunk_2532",
    "text": " and comment out the following try/except block\n                try:\n                    allZeroLds = getZeroLoads(thisCaseLoadData,allZeroLds)\n                except:\n                    print('PROBLEM ENCOUNTERED WHILE RUNNING getZeroLoads().')\n                    logging.debug('PROBLEM ENCOUNTERED WHILE RUNNING getZeroLoads(): ', exc_info=True)\n            \n\n        ### if requested, get the disconnected shunts\n        if report_dict['disconnected_shunts'] == 1:\n            #alldisconnected_s"
  },
  {
    "id": "chunk_2533",
    "text": "cted_shunts'] == 1:\n            #alldisconnected_shunts = getDisconnectedShunts(savLocation,rawfilename,alldisconnected_shunts,AREALIST) # TO TROUBLESHOOT, uncomment this line and comment out the following try/except block\n            try:\n                alldisconnected_shunts = getDisconnectedShunts(savLocation,rawfilename,alldisconnected_shunts,AREALIST)\n            except:\n                print('PROBLEM ENCOUNTERED WITH GETTING SHUNT DATA. PROBLEM ENCOUNTERED WHILE RUNNING getDisconnectedShu"
  },
  {
    "id": "chunk_2534",
    "text": "OBLEM ENCOUNTERED WHILE RUNNING getDisconnectedShunts().')\n                logging.debug('PROBLEM ENCOUNTERED WITH GETTING SHUNT DATA. PROBLEM ENCOUNTERED WHILE RUNNING getDisconnectedShunts(): ', exc_info=True)\n\n        ### if requested, get the bus inconsistencies\n        if report_dict['bus_type_inconsistencies'] == 1:\n            #allBusInconsistencies = getAllBusInconsistencies(rawfilename,allBusInconsistencies) # TO TROUBLESHOOT, uncomment this line and comment out the following try/except"
  },
  {
    "id": "chunk_2535",
    "text": "this line and comment out the following try/except block\n            try:\n                psspy.case(savLocation) #re-open case in psse\n                allBusInconsistencies = getAllBusInconsistencies(rawfilename,allBusInconsistencies)\n            except:\n                print('PROBLEM ENCOUNTERED WITH GETTING BUS INCONSISTENCIES. PROBLEM ENCOUNTERED WHILE RUNNING getAllBusInconsistencies()')\n                logging.debug('PROBLEM ENCOUNTERED WITH GETTING BUS INCONSISTENCIES. PROBLEM ENCOUNTERED"
  },
  {
    "id": "chunk_2536",
    "text": "H GETTING BUS INCONSISTENCIES. PROBLEM ENCOUNTERED WHILE RUNNING getAllBusInconsistencies(): ', exc_info=True)\n\n    \n        ### if requested, get the islands from TREE\n        if report_dict['TREE_islands'] == 1:\n            #allIslands = getTREEIslands(TMP_DIR,rawfilename,allIslands) # TO TROUBLESHOOT, uncomment this line and comment out the following try/except block\n            try:\n                psspy.case(savLocation) #re-open case in psse\n                allIslands = getTREEIslands(TMP_"
  },
  {
    "id": "chunk_2537",
    "text": "e\n                allIslands = getTREEIslands(TMP_DIR,rawfilename,allIslands)\n            except:\n                print('PROBLEM ENCOUNTERED WITH GETTING ISLAND DATA. PROBLEM ENCOUNTERED WHILE RUNNING getTREEIslands()')\n                logging.debug('PROBLEM ENCOUNTERED WITH GETTING ISLAND DATA. PROBLEM ENCOUNTERED WHILE RUNNING getTREEIslands(): ', exc_info=True)\n        ### if requested, get the PSSE pf check reports\n        if report_dict['PSSE_pf_checks'] == 1:\n            #allPFCheckResults"
  },
  {
    "id": "chunk_2538",
    "text": "E_pf_checks'] == 1:\n            #allPFCheckResults = getPSSEpfChecks(TMP_DIR,rawfilename,allPFCheckResults,allPFCheckTypes,AREALIST) # TO TROUBLESHOOT, uncomment this line and comment out the following try/except block\n            try:\n                psspy.case(savLocation) #re-open case in psse\n                allPFCheckResults = getPSSEpfChecks(TMP_DIR,rawfilename,allPFCheckResults,allPFCheckTypes,AREALIST)\n            except:\n                print('PROBLEM ENCOUNTERED WITH GETTING PSSE PF CH"
  },
  {
    "id": "chunk_2539",
    "text": "print('PROBLEM ENCOUNTERED WITH GETTING PSSE PF CHECKS. PROBLEM ENCOUNTERED WHILE RUNNING getPSSEpfChecks()')\n                logging.debug('PROBLEM ENCOUNTERED WITH GETTING PSSE PF CHECKS. PROBLEM ENCOUNTERED WHILE RUNNING getPSSEpfChecks(): ', exc_info=True)\n\n        ### if requested, get the branch remote end voltage inconsistencies\n        if report_dict['br_remote_end_voltage_inconsistencies'] == 1:\n            #allBrTerminalVoltageInconsistencies = getBrEndVoltageInconsistencies(savLocatio"
  },
  {
    "id": "chunk_2540",
    "text": "encies = getBrEndVoltageInconsistencies(savLocation,rawfilename,allBrTerminalVoltageInconsistencies,AREALIST)# TO TROUBLESHOOT, uncomment this line and comment out the following try/except block\n            try:\n                allBrTerminalVoltageInconsistencies = getBrEndVoltageInconsistencies(savLocation,rawfilename,allBrTerminalVoltageInconsistencies,AREALIST)\n            except:\n                print('PROBLEM ENCOUNTERED WITH GETTING BRANCH TERMINAL VOLTAGE INCONSISTENCIES. PROBLEM ENCOUNTE"
  },
  {
    "id": "chunk_2541",
    "text": "TERMINAL VOLTAGE INCONSISTENCIES. PROBLEM ENCOUNTERED WHEN RUNNING getBrEndVoltageInconsistencies()')\n                logging.debug('PROBLEM ENCOUNTERED WITH GETTING BRANCH TERMINAL VOLTAGE INCONSISTENCIES. PROBLEM ENCOUNTERED WHEN RUNNING getBrEndVoltageInconsistencies(): ', exc_info=True)\n\n        ### if any node-breaker checks are required, get the raw model in JSON format and extract the node breaker data\n        # this is the if statement for the ERCOT-distributed version\n        if ((repor"
  },
  {
    "id": "chunk_2542",
    "text": "r the ERCOT-distributed version\n        if ((report_dict['invalid_Binit_switched_shunts'] == 1)\\\n            | (report_dict['incorrect_shunt_remote_buses'] == 1) | (report_dict['incorrect_gen_remote_buses'] == 1) \\\n            | (report_dict['invalid_setpts_continuous_shunts'] == 1)):\n            #RAW_JSON = getRawxJSON(TMP_DIR,rawfilename) # TO TROUBLESHOOT, uncomment this line and comment out the following try/except block\n            try:\n                psspy.case(savLocation) #re-open case "
  },
  {
    "id": "chunk_2543",
    "text": "            psspy.case(savLocation) #re-open case in psse\n                RAW_JSON = getRawxJSON(TMP_DIR,rawfilename)\n            except:\n                print('PROBLEM ENCOUNTERED WHEN GETTING RAWX DATA FROM CASE. PROBLEM ENCOUNTERED WHILE RUNNING getRawxJSON()')\n                logging.debug('PROBLEM ENCOUNTERED WHEN GETTING RAWX DATA FROM CASE. PROBLEM ENCOUNTERED WHILE RUNNING getRawxJSON(): ', exc_info=True)\n            #IBUS_NODE_DATA, JBUS_NODE_DATA, KBUS_NODE_DATA, ALL_TERMABLE_EQUIP_W_N"
  },
  {
    "id": "chunk_2544",
    "text": "_NODE_DATA, KBUS_NODE_DATA, ALL_TERMABLE_EQUIP_W_NODE_DATA, ALL_ELEMENT_DATA_DICT = getNodeBreakerData(RAW_JSON)# TO TROUBLESHOOT, uncomment this line and comment out the following try/except block\n            try:\n                IBUS_NODE_DATA, JBUS_NODE_DATA, KBUS_NODE_DATA, ALL_TERMABLE_EQUIP_W_NODE_DATA, \\\n                    ALL_ELEMENT_DATA_DICT, ALL_TERMABLE_EQUIP_W_NODE_DATA_INCL_SUBSWDS = getNodeBreakerData(RAW_JSON)\n            except:\n                print('PROBLEM ENCOUNTERED WITH P"
  },
  {
    "id": "chunk_2545",
    "text": "\n                print('PROBLEM ENCOUNTERED WITH PROCESSESING NODE-BREAKER DATA. PROBLEM ENCOUNTERED WHILE RUNNING getNodeBreakerData()')\n                logging.debug('PROBLEM ENCOUNTERED WITH PROCESSESING NODE-BREAKER DATA. PROBLEM ENCOUNTERED WHILE RUNNING getNodeBreakerData(): ', exc_info=True)\n           \n            if report_dict['invalid_Binit_switched_shunts'] == 1:\n                #allSwShuntsWithInvalidBinit = getInvalidBinitShunts(ALL_ELEMENT_DATA_DICT['swshunt'],rawfilename,allSwShu"
  },
  {
    "id": "chunk_2546",
    "text": "_ELEMENT_DATA_DICT['swshunt'],rawfilename,allSwShuntsWithInvalidBinit,savLocation,AREALIST)# TO TROUBLESHOOT, uncomment this line and comment out the following try/except block\n                try:\n                    allSwShuntsWithInvalidBinit = getInvalidBinitShunts(ALL_ELEMENT_DATA_DICT['swshunt'],rawfilename,allSwShuntsWithInvalidBinit,savLocation,AREALIST)\n                except:\n                    print('PROBLEM ENCOUNTERED WITH GETTING INVALID BINIT VALUES. PROBLEM ENCOUNTERED WHILE RUN"
  },
  {
    "id": "chunk_2547",
    "text": "NVALID BINIT VALUES. PROBLEM ENCOUNTERED WHILE RUNNING getInvalidBinitShunts()')\n                    logging.debug('PROBLEM ENCOUNTERED WITH GETTING INVALID BINIT VALUES. PROBLEM ENCOUNTERED WHILE RUNNING getInvalidBinitShunts(): ', exc_info=True)\n            if report_dict['invalid_setpts_continuous_shunts'] == 1:\n                #allSwShuntsWithInvalidSetpoints = getInvalidSetpointsContinuousShunts(ALL_ELEMENT_DATA_DICT['swshunt'],rawfilename,allSwShuntsWithInvalidSetpoints,savLocation,AREALIS"
  },
  {
    "id": "chunk_2548",
    "text": "llSwShuntsWithInvalidSetpoints,savLocation,AREALIST)# TO TROUBLESHOOT, uncomment this line and comment out the following try/except block\n                try:\n                    allSwShuntsWithInvalidSetpoints = getInvalidSetpointsContinuousShunts(ALL_ELEMENT_DATA_DICT['swshunt'],rawfilename,allSwShuntsWithInvalidSetpoints,savLocation,AREALIST)\n                except:\n                    print('PROBLEM ENCOUNTERED WITH GETTING INVALID SHUNT SETPOINT VALUES. PROBLEM ENCOUNTERED WHILE RUNNING get"
  },
  {
    "id": "chunk_2549",
    "text": "OINT VALUES. PROBLEM ENCOUNTERED WHILE RUNNING getInvalidSetpointsContinuousShunts()')\n                    logging.debug('PROBLEM ENCOUNTERED WITH GETTING INVALID SHUNT SETPOINT VALUES. PROBLEM ENCOUNTERED WHILE RUNNING getInvalidSetpointsContinuousShunts(): ', exc_info=True)\n            ### if requested, get the incorrect switched shun remote bus report\n            if report_dict['incorrect_shunt_remote_buses'] == 1:\n                #allIncorrectShuntRemoteBuses = getIncorrectShuntRemoteBuses(A"
  },
  {
    "id": "chunk_2550",
    "text": "tShuntRemoteBuses = getIncorrectShuntRemoteBuses(ALL_ELEMENT_DATA_DICT['swshunt'],rawfilename,allIncorrectShuntRemoteBuses,savLocation,AREALIST)# TO TROUBLESHOOT, uncomment this line and comment out the following try/except block\n                try:\n                    allIncorrectShuntRemoteBuses = getIncorrectShuntRemoteBuses(ALL_ELEMENT_DATA_DICT['swshunt'],rawfilename,allIncorrectShuntRemoteBuses,savLocation,AREALIST)\n                except:\n                    print('PROBLEM ENCOUNTERED WI"
  },
  {
    "id": "chunk_2551",
    "text": "\n                    print('PROBLEM ENCOUNTERED WITH GETTING INCORRECT SHUNT REMOTE BUSES. PROBLEM ENCOUNTERED WHILLE RUNNING getIncorrectShuntRemoteBuses()')\n                    logging.debug('PROBLEM ENCOUNTERED WITH GETTING INCORRECT SHUNT REMOTE BUSES. PROBLEM ENCOUNTERED WHILLE RUNNING getIncorrectShuntRemoteBuses(): ', exc_info=True)\n            ### if requested, get the incorrect generator remote bus report\n            if report_dict['incorrect_gen_remote_buses'] == 1:\n                #al"
  },
  {
    "id": "chunk_2552",
    "text": "rrect_gen_remote_buses'] == 1:\n                #allIncorrectGenRemoteBuses = getIncorrectGenRemoteBuses(ALL_ELEMENT_DATA_DICT['generator'],rawfilename,allIncorrectGenRemoteBuses,savLocation,AREALIST)# TO TROUBLESHOOT, uncomment this line and comment out the following try/except block\n                try:\n                    allIncorrectGenRemoteBuses = getIncorrectGenRemoteBuses(ALL_ELEMENT_DATA_DICT['generator'],rawfilename,allIncorrectGenRemoteBuses,savLocation,AREALIST)\n                except"
  },
  {
    "id": "chunk_2553",
    "text": "Buses,savLocation,AREALIST)\n                except:\n                    print('PROBLEM ENCOUNTERED WITH GETTING INCORRECT GENERATOR REMOTE BUSES. PROBLEM ENCOUNTERED WHILLE RUNNING getIncorrectGenRemoteBuses()')\n                    logging.debug('PROBLEM ENCOUNTERED WITH GETTING INCORRECT GENERATOR REMOTE BUSES. PROBLEM ENCOUNTERED WHILLE RUNNING getIncorrectGenRemoteBuses(): ', exc_info=True)\n\n\n    ### Save the reports\n    logging.debug('Processing cases is complete. Now creating reports')\n    "
  },
  {
    "id": "chunk_2554",
    "text": "ing cases is complete. Now creating reports')\n    summaryReport = pd.DataFrame(columns=['Report','Number of Results','Location'])\n    # make excel for CNTB messages\n    if report_dict['CNTB_check']==1:\n        logging.debug('Creating CNTB Report')\n        #CNTB_messages.to_csv(target_output_directory+r'\\all_CNTB_messages.csv')\n        CNTB_excelWriter = pd.ExcelWriter(target_output_directory+r'\\all_CNTB_messages.xlsx')\n        CNTB_errors = CNTB_messages.loc[CNTB_messages['Type']=='ERROR']\n     "
  },
  {
    "id": "chunk_2555",
    "text": "messages.loc[CNTB_messages['Type']=='ERROR']\n        CNTB_warnings = CNTB_messages.loc[CNTB_messages['Type']=='Warning']\n        #CNTB_other = CNTB_messages.loc[CNTB_messages_tmp['Type']=='Other']\n        CNTB_errors.to_excel(CNTB_excelWriter,sheet_name='Errors')\n        CNTB_warnings.to_excel(CNTB_excelWriter,sheet_name='Warnings')\n        #CNTB_other.to_excel(CNTB_excelWriter,sheet_name='Other')\n        CNTB_excelWriter.save()\n        # insert metadata to summaryReport\n        sumData = pd.Dat"
  },
  {
    "id": "chunk_2556",
    "text": "metadata to summaryReport\n        sumData = pd.DataFrame({'Report':['CNTB_errors','CNTB_warnings'],\n        'Number of Results':[CNTB_errors.index.size,CNTB_warnings.index.size],\n        'Location':[target_output_directory+r'\\all_CNTB_messages.xlsx',target_output_directory+r'\\all_CNTB_messages.xlsx']})\n        summaryReport = pd.concat([summaryReport,sumData],ignore_index=True)\n\n    # make excel for PSSE_pf_check_results    \n    if report_dict['PSSE_pf_checks'] == 1:\n        logging.debug('Creat"
  },
  {
    "id": "chunk_2557",
    "text": "SSE_pf_checks'] == 1:\n        logging.debug('Creating PSSE_pf_checks report')\n        PSSEpfCheck_excelWriter = pd.ExcelWriter(target_output_directory+r'\\all_PSSE_pf_checks.xlsx')\n        for checkType in allPFCheckResults.keys():\n            sheet_name_max = checkType[0:30]\n            allPFCheckResults[checkType].to_excel(PSSEpfCheck_excelWriter,sheet_name='{0}'.format(sheet_name_max))\n            # insert metadata to summaryReport\n            sumData = pd.DataFrame({'Report':['PSSE PF Check -"
  },
  {
    "id": "chunk_2558",
    "text": "sumData = pd.DataFrame({'Report':['PSSE PF Check - {0}'.format(checkType)],\n            'Number of Results':[allPFCheckResults[checkType].index.size],\n            'Location':[target_output_directory+r'\\all_PSSE_pf_checks.xlsx']})\n            summaryReport = pd.concat([summaryReport,sumData],ignore_index=True)\n        PSSEpfCheck_excelWriter.save()\n\n    # make excel for check_solvability from allVoltageViolations, allThermalViolations, and allCaseSolveData\n    if report_dict['check_solvability'] "
  },
  {
    "id": "chunk_2559",
    "text": "SolveData\n    if report_dict['check_solvability'] == 1:\n        logging.debug('Creating solvability check excel report')\n        SolCheck_excelWriter = pd.ExcelWriter(target_output_directory+r'\\Solution_checks.xlsx')\n        allCaseSolveData.to_excel(SolCheck_excelWriter,sheet_name='SolvabilityResults')\n        allVoltageViolations.to_excel(SolCheck_excelWriter,sheet_name='VoltageViolations')\n        allThermalViolations.to_excel(SolCheck_excelWriter,sheet_name='ThermalViolations')\n        SolCh"
  },
  {
    "id": "chunk_2560",
    "text": "iter,sheet_name='ThermalViolations')\n        SolCheck_excelWriter.save()\n    \n    # make excel for check_CA_performance from allUnsolvedContingencies and allCAData\n    if report_dict['check_CA_performance'] == 1:\n        logging.debug('Creating CA performance check excel report')\n        CACheck_excelWriter = pd.ExcelWriter(target_output_directory+r'\\CA_performance_checks.xlsx')\n        allCAData.to_excel(CACheck_excelWriter,sheet_name='CA_Results')\n        allUnsolvedContingencies.to_excel(CACh"
  },
  {
    "id": "chunk_2561",
    "text": "s')\n        allUnsolvedContingencies.to_excel(CACheck_excelWriter,sheet_name='Unsolved_Contingencies')\n        CACheck_excelWriter.save()\n                \n\n    # make csv reports for all the other reports\n    report_to_data_dictionary = {'900k_buses':all900k_buses,\\\n                                'disconnected_shunts':alldisconnected_shunts,\\\n                                'disconnected_loads':allDisconnectedLds,\\\n                                'zero_loads':allZeroLds,\\\n                      "
  },
  {
    "id": "chunk_2562",
    "text": "  'zero_loads':allZeroLds,\\\n                                'invalid_Binit_switched_shunts':allSwShuntsWithInvalidBinit,\\\n                                'TREE_islands':allIslands,\\\n                                'br_remote_end_voltage_inconsistencies':allBrTerminalVoltageInconsistencies,\\\n                                'bus_type_inconsistencies':allBusInconsistencies,\\\n                                'all_lds':allLoads,\\\n                                #'check_solvability':allCaseSolveData,\\\n"
  },
  {
    "id": "chunk_2563",
    "text": "          #'check_solvability':allCaseSolveData,\\\n                                'incorrect_shunt_remote_buses':allIncorrectShuntRemoteBuses,\\\n                                'incorrect_gen_remote_buses':allIncorrectGenRemoteBuses,\\\n                                #'check_CA_performance':allCAData,\\\n                                'invalid_setpts_continuous_shunts':allSwShuntsWithInvalidSetpoints,\\\n                                'disconnected_buses':alldisconnected_buses}\n    for report in rep"
  },
  {
    "id": "chunk_2564",
    "text": "uses':alldisconnected_buses}\n    for report in report_to_data_dictionary.keys():\n        if report_dict[report]==1:\n            logging.debug('Creating {0} report'.format(report))\n            report_to_data_dictionary[report].to_csv(target_output_directory+r'\\{0}.csv'.format(report))\n            # insert metadata to summaryReport\n            sumData = pd.DataFrame({'Report':[report],\n            'Number of Results':[report_to_data_dictionary[report].index.size],\n            'Location':[target_ou"
  },
  {
    "id": "chunk_2565",
    "text": "rt].index.size],\n            'Location':[target_output_directory+r'\\{0}.csv'.format(report)]})\n            summaryReport = pd.concat([summaryReport,sumData],ignore_index=True)\n\n    # create summary report\n    logging.debug('Creating summary report.')\n    summaryReport['Location'] = summaryReport['Location'].apply(lambda x: make_clickable(x, x))\n    summaryReport = summaryReport.sort_values(by=['Number of Results'],ascending=False)\n    summary_html = summaryReport.to_html(render_links=True,escape"
  },
  {
    "id": "chunk_2566",
    "text": "l = summaryReport.to_html(render_links=True,escape=False)\n    text_file = open(target_output_directory+r'\\SummaryReport.html','w')\n    text_file.write(summary_html)\n    text_file.close()\n    logging.debug('Reports completed.')\n    logging.debug('Done.')\n    logging.shutdown()\n\n######### LCRA-only functions ########\ndef getallTempLookingSwitches(equipmentData,rawfilename,busData,allTempLookingSwitches,areaList):\n    equipmentData = equipmentData.merge(busData[['ibus','area']].rename(columns={'are"
  },
  {
    "id": "chunk_2567",
    "text": "erge(busData[['ibus','area']].rename(columns={'area':'ibusarea'}),how='left',on='ibus')\n    equipmentData = equipmentData.merge(busData[['ibus','area']].rename(columns={'ibus':'jbus','area':'jbusarea'}),how='left',on='jbus')\n    equipmentData = equipmentData.merge(busData[['ibus','area']].rename(columns={'ibus':'kbus','area':'kbusarea'}),how='left',on='kbus')\n    lookstmp = equipmentData.loc[(equipmentData['equipmentType'].isin(['system switching device','Subswd - GEN','Subswd - CB','Subswd - DS"
  },
  {
    "id": "chunk_2568",
    "text": " device','Subswd - GEN','Subswd - CB','Subswd - DSC']))&\\\n        ((equipmentData['name'].str.upper().str.contains(\"$PS\"))|\\\n        (equipmentData['name'].str.upper().str.contains(\"$TS\"))|\\\n        (equipmentData['name'].str.upper().str.contains(\"TEMP\")))&\\\n        # ((equipmentData['name'].str.split(pat='$',expand=True)[[3]].str.upper().str.contains(\"PS\"))|\\\n        # (equipmentData['name'].str.split(pat='$',expand=True)[[3]].str.upper().str.contains(\"TS\"))|\\\n        # (equipmentData['name'].s"
  },
  {
    "id": "chunk_2569",
    "text": "ntains(\"TS\"))|\\\n        # (equipmentData['name'].str.split(pat='$',expand=True)[[3]].str.upper().str.contains(\"TEMP\")))&\\\n        ((equipmentData['ibusarea'].isin(areaList))|\\\n        (equipmentData['jbusarea'].isin(areaList))|\\\n        (equipmentData['kbusarea'].isin(areaList)))]\n    lookstmp['{0}'.format(rawfilename)] = 'TRUE'\n    if allTempLookingSwitches.empty == True:\n        allTempLookingSwitches = lookstmp\n        allTempLookingSwitches = allTempLookingSwitches.drop_duplicates()\n    else"
  },
  {
    "id": "chunk_2570",
    "text": " allTempLookingSwitches.drop_duplicates()\n    else:\n        allTempLookingSwitches = allTempLookingSwitches.merge(lookstmp,how='outer',\\\n        on=['ibus','jbus','kbus','equipmentType','eqid','name','isub','inode','jsub','jnode','ksub','knode','ibusarea','jbusarea','kbusarea'])\n        allTempLookingSwitches = allTempLookingSwitches.drop_duplicates()\n    return allTempLookingSwitches \n\ndef getallMobileLoads(equipmentData,rawfilename,busData,allMobileLoads,areaList):\n    equipmentData = equipmen"
  },
  {
    "id": "chunk_2571",
    "text": "obileLoads,areaList):\n    equipmentData = equipmentData.merge(busData[['ibus','area']].rename(columns={'area':'ibusarea'}),how='left',on='ibus')\n    equipmentData = equipmentData.merge(busData[['ibus','area']].rename(columns={'ibus':'jbus','area':'jbusarea'}),how='left',on='jbus')\n    equipmentData = equipmentData.merge(busData[['ibus','area']].rename(columns={'ibus':'kbus','area':'kbusarea'}),how='left',on='kbus')\n    lookstmp = equipmentData.loc[(equipmentData['equipmentType'].isin(['load']))&"
  },
  {
    "id": "chunk_2572",
    "text": "c[(equipmentData['equipmentType'].isin(['load']))&\\\n        ((equipmentData['eqid'].str.upper().str.contains(\"M\")))&\\\n        ((equipmentData['ibusarea'].isin(areaList))|\\\n        (equipmentData['jbusarea'].isin(areaList))|\\\n        (equipmentData['kbusarea'].isin(areaList)))]\n    lookstmp['{0}'.format(rawfilename)] = 'TRUE'\n    if allMobileLoads.empty == True:\n        allMobileLoads = lookstmp\n        allMobileLoads = allMobileLoads.drop_duplicates()\n    else:\n        allMobileLoads = allMobile"
  },
  {
    "id": "chunk_2573",
    "text": "tes()\n    else:\n        allMobileLoads = allMobileLoads.merge(lookstmp,how='outer',\\\n        on=['ibus','jbus','kbus','equipmentType','eqid','name','isub','inode','jsub','jnode','ksub','knode','ibusarea','jbusarea','kbusarea'])\n        allMobileLoads = allMobileLoads.drop_duplicates()\n    return allMobileLoads \n\ndef getnon_LCRA_range_LCRA_buses(BusData):\n    \n    non_LCRA_range_LCRA_buses = BusData.loc[((BusData['NUMBER'] < 7000) | ((BusData['NUMBER'] > 7900) & (BusData['NUMBER'] < 71000)) |\\\n  "
  },
  {
    "id": "chunk_2574",
    "text": "BER'] > 7900) & (BusData['NUMBER'] < 71000)) |\\\n         ((BusData['NUMBER'] > 79000) & (BusData['NUMBER'] < 100000)) | ((BusData['NUMBER'] > 200000)&(BusData['NUMBER'] < 700000)))&\\\n        (BusData['AREA'].isin([7,907]))]\n    LCRA_range_NonLCRA_buses = BusData.loc[(((BusData['NUMBER']>=7000)&(BusData['NUMBER']<7900))|((BusData['NUMBER']>=71000)&(BusData['NUMBER']<79000)))&\\\n        (BusData['AREA'].isin([7,907])==False)]\n    busesToReturn = pd.concat([non_LCRA_range_LCRA_buses,LCRA_range_NonLC"
  },
  {
    "id": "chunk_2575",
    "text": "concat([non_LCRA_range_LCRA_buses,LCRA_range_NonLCRA_buses],ignore_index=True)\n    return busesToReturn\n\ndef getincorrect_voltage_bus_limits(BusData):\n    incorrect_voltage_bus_limits = BusData.loc[((BusData['NVLMLO']!=0.95)|(BusData['NVLMHI']!=1.05)|(BusData['EVLMLO']!=0.92)|(BusData['EVLMHI']!=1.05))&\\\n        (((BusData['NUMBER'] >= 7000) & (BusData['NUMBER'] < 8000)) | ((BusData['NUMBER'] >= 71000) & (BusData['NUMBER'] < 80000)))]\n    return incorrect_voltage_bus_limits\n\ndef getUnterminatedE"
  },
  {
    "id": "chunk_2576",
    "text": "incorrect_voltage_bus_limits\n\ndef getUnterminatedElements(all_termable_equip_with_nodes,rawfilename,allUnterminatedLCRAElements):\n    # keep track of which elements are not terminated on a node so that users are aware\n    all_unterminated_elements = all_termable_equip_with_nodes.loc[(all_termable_equip_with_nodes['isub'].isna())\\\n        |((all_termable_equip_with_nodes['jsub'].isna())&(all_termable_equip_with_nodes['jbus'].isna()==False))\\\n        |((all_termable_equip_with_nodes['ksub'].isna()"
  },
  {
    "id": "chunk_2577",
    "text": "   |((all_termable_equip_with_nodes['ksub'].isna())&(all_termable_equip_with_nodes['kbus'].isna()==False))]\n    all_LCRA_unterminated_elements = all_unterminated_elements.loc[\\\n        (((all_unterminated_elements['ibus']>=7000)&(all_unterminated_elements['ibus']<8000))|((all_unterminated_elements['ibus']>=71000)&(all_unterminated_elements['ibus']<79000)))\\\n        |(((all_unterminated_elements['jbus']>=7000)&(all_unterminated_elements['jbus']<8000))|((all_unterminated_elements['jbus']>=71000)&("
  },
  {
    "id": "chunk_2578",
    "text": "00))|((all_unterminated_elements['jbus']>=71000)&(all_unterminated_elements['jbus']<79000)))\\\n        |(((all_unterminated_elements['kbus']>=7000)&(all_unterminated_elements['kbus']<8000))|((all_unterminated_elements['kbus']>=71000)&(all_unterminated_elements['kbus']<79000)))]\n\n    all_LCRA_unterminated_elements['{0}'.format(rawfilename)] = 'TRUE'\n    all_LCRA_unterminated_elements = all_LCRA_unterminated_elements.drop(['EquipmentID'], axis = 1)\n    if allUnterminatedLCRAElements.empty == True:\n"
  },
  {
    "id": "chunk_2579",
    "text": "    if allUnterminatedLCRAElements.empty == True:\n        allUnterminatedLCRAElements = all_LCRA_unterminated_elements\n        allUnterminatedLCRAElements=allUnterminatedLCRAElements.drop_duplicates()\n    else:\n        allUnterminatedLCRAElements = pd.merge(allUnterminatedLCRAElements,all_LCRA_unterminated_elements,how='outer',on=['ibus','jbus','kbus','eqid','equipmentType','type','name','isub','inode','jsub','jnode','ksub','knode','stat','nstat'])\n        allUnterminatedLCRAElements=allUntermin"
  },
  {
    "id": "chunk_2580",
    "text": "])\n        allUnterminatedLCRAElements=allUnterminatedLCRAElements.drop_duplicates()\n    return allUnterminatedLCRAElements\n\ndef getMultiBrOnNode(ibus_node_table, jbus_node_table, kbus_node_table, rawfilename, allBranchesTerminatedOnSameNode):\n    #find where we have multiple bus branch elements terminated on the same node\n    ibus_node_table = ibus_node_table.rename(columns={'isub':'sub','inode':'node'})\n    jbus_node_table = jbus_node_table.rename(columns={'jsub':'sub','jnode':'node'})\n    kbu"
  },
  {
    "id": "chunk_2581",
    "text": "ame(columns={'jsub':'sub','jnode':'node'})\n    kbus_node_table = kbus_node_table.rename(columns={'ksub':'sub','knode':'node'})\n    flattened_node_table = pd.concat([ibus_node_table,jbus_node_table,kbus_node_table],ignore_index=True)\n    flattened_node_table_no_equipment_names = flattened_node_table[['EquipmentID','sub','node']]\n\n    multiple_branches_same_node = flattened_node_table_no_equipment_names.groupby(['sub','node']).agg(['nunique'])\n    multiple_branches_same_node = multiple_branches_sa"
  },
  {
    "id": "chunk_2582",
    "text": "multiple_branches_same_node = multiple_branches_same_node.loc[multiple_branches_same_node[('EquipmentID','nunique')]>1]\n    multiple_branches_same_node = multiple_branches_same_node.merge(flattened_node_table,how='left',on=['sub','node'])\n    multiple_branches_same_node = multiple_branches_same_node.loc[\\\n        (((multiple_branches_same_node['ibus']>=7000)&(multiple_branches_same_node['ibus']<8000))|((multiple_branches_same_node['ibus']>=71000)&(multiple_branches_same_node['ibus']<79000)))\\\n  "
  },
  {
    "id": "chunk_2583",
    "text": "&(multiple_branches_same_node['ibus']<79000)))\\\n        |(((multiple_branches_same_node['jbus']>=7000)&(multiple_branches_same_node['jbus']<8000))|((multiple_branches_same_node['jbus']>=71000)&(multiple_branches_same_node['jbus']<79000)))\\\n        |(((multiple_branches_same_node['kbus']>=7000)&(multiple_branches_same_node['kbus']<8000))|((multiple_branches_same_node['kbus']>=71000)&(multiple_branches_same_node['kbus']<79000)))]\n    multiple_branches_same_node=multiple_branches_same_node.rename(c"
  },
  {
    "id": "chunk_2584",
    "text": "hes_same_node=multiple_branches_same_node.rename(columns={('EquipmentID', 'nunique'):'Number Elements Terminating on Same Node'})\n    multiple_branches_same_node=multiple_branches_same_node[['ibus','jbus','kbus','eqid','equipmentType','name','sub','node','Number Elements Terminating on Same Node']]\n    multiple_branches_same_node['{0}'.format(rawfilename)] = 'TRUE'\n\n\n    if allBranchesTerminatedOnSameNode.empty==True:\n        allBranchesTerminatedOnSameNode = multiple_branches_same_node\n        "
  },
  {
    "id": "chunk_2585",
    "text": "dOnSameNode = multiple_branches_same_node\n        allBranchesTerminatedOnSameNode=allBranchesTerminatedOnSameNode.drop_duplicates()\n    else:\n        allBranchesTerminatedOnSameNode = pd.merge(allBranchesTerminatedOnSameNode,multiple_branches_same_node,how='outer',on=['ibus','jbus','kbus','eqid','equipmentType','name','sub','node','Number Elements Terminating on Same Node'])\n        allBranchesTerminatedOnSameNode=allBranchesTerminatedOnSameNode.drop_duplicates()\n    return allBranchesTerminated"
  },
  {
    "id": "chunk_2586",
    "text": "drop_duplicates()\n    return allBranchesTerminatedOnSameNode\n\ndef getTLDBusUpdates(savLocation,APIbusData,allTLDBusesToAdd,allTLDBusesToRemove,allTLDBusesToUpdate,rawfilename,SUBTERM_data,areaList):\n    busData_tmp = getAllBusData(savLocation)\n    #check for TLD buses that need to be updated\n    busDataForTLDcheck = busData_tmp.loc[(busData_tmp['AREA'].isin(areaList))]\n    subDataForTLDcheck = SUBTERM_data[['isub','ibus']]\n    subDataForTLDcheck = subDataForTLDcheck.drop_duplicates()\n    TLDBuse"
  },
  {
    "id": "chunk_2587",
    "text": "= subDataForTLDcheck.drop_duplicates()\n    TLDBusesUpdateData = APIbusData.merge(busDataForTLDcheck,how='outer',left_on='BusNumber',right_on='NUMBER')\n    TLDBusesUpdateData = TLDBusesUpdateData.merge(subDataForTLDcheck,how='left',left_on='NUMBER',right_on='ibus')\n    #TLDBusesUpdateData.to_csv(target_output_directory+r'\\TLDBusesUpdateData.csv')\n    TLDBusesUpdateData = TLDBusesUpdateData[['BusNumber','BusName','Voltage','ModelStatus',\\\n        'PublishStatus','SSWGSubstationNumber','NAME','BASE"
  },
  {
    "id": "chunk_2588",
    "text": "PublishStatus','SSWGSubstationNumber','NAME','BASE','NUMBER','isub','Display']]\n    TLDBusesToAdd = TLDBusesUpdateData.loc[(TLDBusesUpdateData['Display']!='TRUE')&\\\n        (TLDBusesUpdateData['NUMBER'].isna()==False)&(TLDBusesUpdateData['BusNumber'].isna()==True)]\n    TLDBusesToRemove = TLDBusesUpdateData.loc[(TLDBusesUpdateData['PublishStatus']!='Inactive')&\\\n        (TLDBusesUpdateData['NUMBER'].isna()==True)]\n    TLDBusesToUpdate = TLDBusesUpdateData.loc[\\\n        ((TLDBusesUpdateData['Publi"
  },
  {
    "id": "chunk_2589",
    "text": "dateData.loc[\\\n        ((TLDBusesUpdateData['PublishStatus']!='Inactive')&(TLDBusesUpdateData['NUMBER'].isna()==False))&\n        ((TLDBusesUpdateData['BASE']!=TLDBusesUpdateData['Voltage'])|\n        (TLDBusesUpdateData['NAME']!=TLDBusesUpdateData['BusName'])|\n        ((TLDBusesUpdateData['SSWGSubstationNumber'].isna()==False)&(TLDBusesUpdateData['SSWGSubstationNumber']!=TLDBusesUpdateData['isub'])))]\n    TLDBusesToAdd['{0}'.format(rawfilename)] = 'TRUE'\n    TLDBusesToRemove['{0}'.format(rawfilen"
  },
  {
    "id": "chunk_2590",
    "text": " 'TRUE'\n    TLDBusesToRemove['{0}'.format(rawfilename)] = 'TRUE'\n    TLDBusesToUpdate['{0}'.format(rawfilename)] = 'TRUE'\n    \n    if allTLDBusesToAdd.empty == True:\n        allTLDBusesToAdd = TLDBusesToAdd\n        allTLDBusesToAdd = allTLDBusesToAdd.drop_duplicates()\n    else:\n        allTLDBusesToAdd = allTLDBusesToAdd.merge(TLDBusesToAdd,how='outer',on=['BusNumber','BusName'\\\n        ,'Voltage','ModelStatus','PublishStatus','SSWGSubstationNumber','NAME','BASE','NUMBER','isub','Display'])\n    "
  },
  {
    "id": "chunk_2591",
    "text": "er','NAME','BASE','NUMBER','isub','Display'])\n        allTLDBusesToAdd = allTLDBusesToAdd.drop_duplicates()\n\n    if allTLDBusesToRemove.empty == True:\n        allTLDBusesToRemove = TLDBusesToRemove\n        allTLDBusesToRemove = allTLDBusesToRemove.drop_duplicates()\n    else:\n        allTLDBusesToRemove = allTLDBusesToRemove.merge(TLDBusesToRemove,how='outer',on=['BusNumber','BusName'\\\n        ,'Voltage','ModelStatus','PublishStatus','SSWGSubstationNumber','NAME','BASE','NUMBER','isub','Display']"
  },
  {
    "id": "chunk_2592",
    "text": "onNumber','NAME','BASE','NUMBER','isub','Display'])\n        allTLDBusesToRemove = allTLDBusesToRemove.drop_duplicates()\n\n    if allTLDBusesToUpdate.empty == True:\n        allTLDBusesToUpdate = TLDBusesToUpdate\n        allTLDBusesToUpdate = allTLDBusesToUpdate.drop_duplicates()\n    else:\n        allTLDBusesToUpdate = allTLDBusesToUpdate.merge(TLDBusesToUpdate,how='outer',on=['BusNumber','BusName'\\\n        ,'Voltage','ModelStatus','PublishStatus','SSWGSubstationNumber','NAME','BASE','NUMBER','isub"
  },
  {
    "id": "chunk_2593",
    "text": "SSWGSubstationNumber','NAME','BASE','NUMBER','isub','Display'])\n        allTLDBusesToUpdate = allTLDBusesToUpdate.drop_duplicates()\n    \n    return (allTLDBusesToAdd,allTLDBusesToRemove,allTLDBusesToUpdate)\n\ndef getTLDBusList():\n    # get TLD bus list for QA check\n    url = 'http://ts/api/lines/bus'\n    results = requests.get(url)\n    results_json = json.loads(results.content)\n    resultsdf = pd.DataFrame.from_records(results_json)\n    resultsdf = resultsdf.loc[resultsdf['Display']!='TRUE'] #onl"
  },
  {
    "id": "chunk_2594",
    "text": "= resultsdf.loc[resultsdf['Display']!='TRUE'] #only use the entries where Display is True\n    #activebuses = resultsdf.loc[resultsdf['PublishStatus']!='Inactive']\n    return resultsdf\n\ndef getQAReportsLCRA(CASEDIRECTORY,OUTPUTDIRECTORY,DESIRED_QA_LIST,AREALIST):\n    ### DESIRED_QA_LIST is a list of requested reports to be created, it may include the following entries:\n    ### '900k_buses','CNTB_check','out_of_range_buses','disconnected_shunts','disconnected_loads',\n    ### 'zero_loads', 'multipl"
  },
  {
    "id": "chunk_2595",
    "text": "isconnected_loads',\n    ### 'zero_loads', 'multiple_branches_terminating_on_node', 'invalid_Binit_switched_shunts',\n    ### 'TREE_islands', 'unterminated_elements', 'br_remote_end_voltage_inconsistencies',\n    ### 'bus_type_inconsistencies', 'incorrect_voltage_bus_limits', 'TLD_bus_updates',\n    ### 'check_solvability','check_CA_performance', 'PSSE_pf_checks'\n\n    ### create a dictionary of the request reports\n    available_reports = ['900k_buses','TREE_islands','bus_type_inconsistencies','CNTB_"
  },
  {
    "id": "chunk_2596",
    "text": "','TREE_islands','bus_type_inconsistencies','CNTB_check',\n    'disconnected_shunts', 'invalid_Binit_switched_shunts','invalid_setpts_continuous_shunts',\n    'incorrect_shunt_remote_buses','incorrect_gen_remote_buses','br_remote_end_voltage_inconsistencies',\n    'check_solvability','check_CA_performance','PSSE_pf_checks','all_lds','disconnected_loads',\n    'zero_loads','disconnected_buses',\n    ########## LCRA-ONLY reports ##########\n    'temp_looking_switches','mobile_loads','out_of_range_buses'"
  },
  {
    "id": "chunk_2597",
    "text": "king_switches','mobile_loads','out_of_range_buses',\n    'multiple_branches_terminating_on_node','unterminated_elements','incorrect_voltage_bus_limits','TLD_bus_updates'\n    ########## LCRA-ONLY reports ##########\n    ]\n    report_dict = {}\n    for report in available_reports:\n        if report in DESIRED_QA_LIST:\n            report_dict[report] = 1\n        else:\n            report_dict[report] = 0\n\n    ### Create temp directory for file management ###\n    #TMP_DIR = makeTempDirectory()\n    tempo"
  },
  {
    "id": "chunk_2598",
    "text": "t ###\n    #TMP_DIR = makeTempDirectory()\n    temporary_directory = tempfile.TemporaryDirectory()\n    TMP_DIR = temporary_directory.name\n    print('Created temp directory {0}.'.format(TMP_DIR))\n\n    #### Supress all the PSSE outputs for now\n    suppressAllPSSEOutputs()\n\n    ### Get the list of raw cases to process and define\n    target_directory = CASEDIRECTORY.GetPath()\n    case_list = sorted(glob.glob(target_directory+r'\\*.raw')) #to sort raws by name\n\n    ### Prepare the output directory\n    t"
  },
  {
    "id": "chunk_2599",
    "text": "y name\n\n    ### Prepare the output directory\n    target_output_directory = OUTPUTDIRECTORY.GetPath()+r'\\QA_results_{}'.format(str(datetime.datetime.now().date()))\n    os.makedirs(target_output_directory) #create auto QA check output file\n\n    ### set up logger\n    today_date = str(datetime.date.today())\n    logging.basicConfig(filename='{0}\\log_file'.format(target_output_directory),filemode='a',level=logging.DEBUG,format='%(name)s - %(levelname)s - %(message)s')\n    logging.debug('{0} execute st"
  },
  {
    "id": "chunk_2600",
    "text": " - %(message)s')\n    logging.debug('{0} execute start at {1}'.format(sys.argv[0],datetime.datetime.now()))\n    logging.debug('All required files and directories selected. Now running the following QA reports for the areas {0}:'.format(','.join(map(str,AREALIST))))\n    logging.debug(DESIRED_QA_LIST)\n\n\n    #### try getting the TLD bus list for TLD Bus check, if requested. If the integration is broken, or the program can't reach the API endpoint, don't perform the TLD bus check, but provide a messa"
  },
  {
    "id": "chunk_2601",
    "text": "n't perform the TLD bus check, but provide a message to the user\n    if report_dict['TLD_bus_updates'] == 1:\n        #APIbusData = getTLDBusList() # TO TROUBLESHOOT, uncomment this line and comment out the following try/except block\n        try:\n            APIbusData = getTLDBusList()\n            logging.debug('Data for {} lines returned from getTLDBusList(): '.format(len(APIbusData.index)), exc_info=True)\n        except:\n            failResult = pd.DataFrame({1:['Unable to perform a check on t"
  },
  {
    "id": "chunk_2602",
    "text": "= pd.DataFrame({1:['Unable to perform a check on the TLD bus data. End point http://ts/api/lines/bus unavailable or unreachable.']})\n            failResult.to_csv(target_output_directory+r'\\TLD_BUS_UPDATE_FAILURE.csv')\n            report_dict['TLD_bus_updates'] == 0 # setting this to zero ensures that this report won't be generated.\n            logging.debug('PROBLEM WITH GETTING TLD BUS LIST. PROBLEM ENCOUNTERED WHILE RUNNING getTLDBusList(): ', exc_info=True)\n\n    ### Prepare blank dataframes "
  },
  {
    "id": "chunk_2603",
    "text": " exc_info=True)\n\n    ### Prepare blank dataframes for results\n    CNTB_messages = pd.DataFrame()\n    BusData = pd.DataFrame()   \n    allBusInconsistencies = pd.DataFrame()\n    allIslands = pd.DataFrame()\n    allBrTerminalVoltageInconsistencies = pd.DataFrame()\n    allDisconnectedLds = pd.DataFrame()\n    allZeroLds = pd.DataFrame()\n    allLoads = pd.DataFrame()\n    allLoadsWithTotalsColumn = pd.DataFrame()    \n    allSwShuntsWithInvalidBinit = pd.DataFrame()\n    alldisconnected_shunts = pd.DataFr"
  },
  {
    "id": "chunk_2604",
    "text": "DataFrame()\n    alldisconnected_shunts = pd.DataFrame()\n    all900k_buses = pd.DataFrame()   \n    alldisconnectedBuses = pd.DataFrame()   \n    allCaseSolveData = pd.DataFrame()\n    allVoltageViolations = pd.DataFrame()\n    allThermalViolations = pd.DataFrame()\n    allIncorrectShuntRemoteBuses = pd.DataFrame()\n    allIncorrectGenRemoteBuses = pd.DataFrame()\n    allCAData = pd.DataFrame()\n    allUnsolvedContingencies = pd.DataFrame()\n    allSwShuntsWithInvalidSetpoints = pd.DataFrame()\n    # PSSE "
  },
  {
    "id": "chunk_2605",
    "text": "sWithInvalidSetpoints = pd.DataFrame()\n    # PSSE check powerflow data dataframes\n    allPFCheckTypes = {'bus data':1,'load data':2,'plant data':3,'generator unit data':4,\n    'induction machine data':5,'fixed bus shunt data':6,'switched shunt data':7,\n    'non-transformer branch data':8,'two-winding transformer data':9,\n    'three-winding transformer data':10,'transformer impedance table correciton data':11,\n    'two-terminal dc line data':13,'multi-terminal dc line data':14,\n    'VSC dc line d"
  },
  {
    "id": "chunk_2606",
    "text": "ulti-terminal dc line data':14,\n    'VSC dc line data':15,'FACTS device data':16,'GNE device data':17,\n    'area interchange data':18,'owner data':19,'zone data':20}\n    allPFCheckResults = {}\n    for checkType in allPFCheckTypes:\n        allPFCheckResults[checkType] = pd.DataFrame()\n\n    ########## LCRA-ONLY reports ##########\n    allTempLookingSwitches = pd.DataFrame()\n    allMobileLoads = pd.DataFrame()\n    non_LCRA_range_LCRA_buses = pd.DataFrame()\n    incorrect_voltage_bus_limits = pd.DataF"
  },
  {
    "id": "chunk_2607",
    "text": "rame()\n    incorrect_voltage_bus_limits = pd.DataFrame()\n    allUnterminatedLCRAElements = pd.DataFrame()\n    allBranchesTerminatedOnSameNode = pd.DataFrame()\n    allTLDBusesToAdd = pd.DataFrame()\n    allTLDBusesToRemove = pd.DataFrame()\n    allTLDBusesToUpdate = pd.DataFrame()\n\n    ### Process all raw files according to which reports were requested\n    counter = 1\n    for case in case_list:\n        ### read in the raw file\n        print('processesing case {0} out of {1}'.format(counter,len(case"
  },
  {
    "id": "chunk_2608",
    "text": "esing case {0} out of {1}'.format(counter,len(case_list)))   \n        rawfilename = os.path.splitext(os.path.basename(case))[0]\n        logging.debug('processesing raw {0} -- case {1} out of {2}'.format(rawfilename,counter,len(case_list)))\n        counter = counter+1\n        psspy.read(0,case) # open case\n\n        ### save the open case as a sav\n        savLocation = target_output_directory+r'\\{0}.sav'.format(rawfilename)\n        PSSESaveCase(savLocation)\n\n        ### if no areas were chosen by "
  },
  {
    "id": "chunk_2609",
    "text": "Location)\n\n        ### if no areas were chosen by the user, get a list of all areas in the open case\n        if AREALIST == []:\n            int_data_desired = ['NUMBER']\n            int_ierr, iarray = psspy.aareaint(-1, 2, int_data_desired)\n            allAreas = iarray[0]\n            AREALIST = allAreas\n        \n\n        ### if requested, do the solvability check. If the solvability check indicates that the case did not solve, then do not attempt CA check\n        if (report_dict['check_solvabil"
  },
  {
    "id": "chunk_2610",
    "text": "t CA check\n        if (report_dict['check_solvability'] == 1)|(report_dict['check_CA_performance'] == 1):\n            #allCaseSolveData = getSolutionData(rawfilename,allCaseSolveData)# TO TROUBLESHOOT, uncomment this line and comment out the following try/except block\n            try:\n                psspy.case(savLocation) #re-open case in psse\n                int_data_desired = ['NUMBER']\n                int_ierr, iarray = psspy.aareaint(-1, 2, int_data_desired)\n                allAreas = iarr"
  },
  {
    "id": "chunk_2611",
    "text": " int_data_desired)\n                allAreas = iarray[0]\n                AllBusArea = getBusData(savLocation,target_output_directory,rawfilename,BusData,allAreas)[['NUMBER','AREA']] #get bus data for reports to join area to report results\n                allCaseSolveData,allVoltageViolations,allThermalViolations = getSolutionData(rawfilename,allCaseSolveData,AREALIST,allVoltageViolations,allThermalViolations,TMP_DIR,AllBusArea)\n                \n            except:\n                print('PROBLEM W"
  },
  {
    "id": "chunk_2612",
    "text": "          except:\n                print('PROBLEM WITH CHECK SOLVABILITY. PROBLEM ENCOUNTERED WHILE RUNNING getSolutionData().')\n                logging.debug('PROBLEM WITH CHECK SOLVABILITY. PROBLEM ENCOUNTERED WHILE RUNNING getSolutionData(): ', exc_info=True)\n\n\n        ### if requested, do the CA check. If the solvability check indicates that the case did not solve, then this will not be attempted.\n        if report_dict['check_CA_performance'] == 1:\n            # check last powerflow solution"
  },
  {
    "id": "chunk_2613",
    "text": " == 1:\n            # check last powerflow solution\n            latestSolution = allCaseSolveData.loc[(allCaseSolveData['Case']==rawfilename)&(allCaseSolveData['Step']==3)]\n            latestSolution = latestSolution.reset_index()\n            if (latestSolution.at[0,'Solution Str'] != 'Met convergence tolerances                      '):\n                noData = pd.DataFrame({'Case':[rawfilename],'CANotAttemptedDuetoNon-SolvedRAW':['True']})\n                allCAData = pd.concat([allCAData,noData]"
  },
  {
    "id": "chunk_2614",
    "text": "          allCAData = pd.concat([allCAData,noData],ignore_index=True)\n            else:\n                #allCAData = getCAConvergenceData(savLocation,rawfilename,allCAData,AREALIST,TMP_DIR) # TO TROUBLESHOOT, uncomment this line and comment out the following try/except block\n                try:\n                    psspy.case(savLocation) #re-open case in psse\n                    allCAData, allUnsolvedContingencies = getCAConvergenceData(savLocation,rawfilename,allCAData,AREALIST,TMP_DIR,allUnso"
  },
  {
    "id": "chunk_2615",
    "text": "ion,rawfilename,allCAData,AREALIST,TMP_DIR,allUnsolvedContingencies)\n                except:\n                    print('PROBLEM WITH GETTING CA CONVERGENCE. PROBLEM ENCOUNTERED WHILE RUNNING getCAConvergenceData().')\n                    logging.debug('PROBLEM WITH GETTING CA CONVERGENCE. PROBLEM ENCOUNTERED WHILE RUNNING getCAConvergenceData(): ', exc_info=True)\n\n        ### if requested, do the CNTB check\n        if report_dict['CNTB_check'] == 1:\n            #CNTB_messages = getCNTBCheckData(T"
  },
  {
    "id": "chunk_2616",
    "text": "1:\n            #CNTB_messages = getCNTBCheckData(TMP_DIR,savLocation,target_output_directory,rawfilename,CNTB_messages) # TO TROUBLESHOOT, uncomment this line and comment out the following try/except block\n            try:\n                CNTB_messages = getCNTBCheckData(TMP_DIR,savLocation,target_output_directory,rawfilename,CNTB_messages,AREALIST)\n            except:\n                print('PROBLEM WITH GETTING CNTB REPORT. PROBLEM ENCOUNTERED WHILE RUNNING getCNTBCheckData().')\n               "
  },
  {
    "id": "chunk_2617",
    "text": "HILE RUNNING getCNTBCheckData().')\n                logging.debug('PROBLEM WITH GETTING CNTB REPORT. PROBLEM ENCOUNTERED WHILE RUNNING getCNTBCheckData(): ', exc_info=True)\n        \n        \n        ### if any bus-related reports requested, get the LCRA bus data and extract the relevant data\n        #if (report_dict['900k_buses'] == 1): # for ERCOT-only distribution\n        if (report_dict['900k_buses'] == 1) | (report_dict['disconnected_buses'] == 1) | (report_dict['out_of_range_buses'] == 1) | "
  },
  {
    "id": "chunk_2618",
    "text": "= 1) | (report_dict['out_of_range_buses'] == 1) | (report_dict['incorrect_voltage_bus_limits'] == 1):\n            #LCRA_Buses = getBusData(savLocation,target_output_directory,rawfilename,LCRA_Buses,AREALIST) # TO TROUBLESHOOT, uncomment this line and comment out the following try/except block\n            try:\n                BusData = getBusData(savLocation,target_output_directory,rawfilename,BusData,AREALIST)\n            except:\n                print('PROBLEM ENCOUNTERED WITH GETTING BUS DATA. "
  },
  {
    "id": "chunk_2619",
    "text": "print('PROBLEM ENCOUNTERED WITH GETTING BUS DATA. PROBLEM ENCOUNTERED WHILE RUNNING getBusData().')\n                logging.debug('PROBLEM ENCOUNTERED WITH GETTING BUS DATA. PROBLEM ENCOUNTERED WHILE RUNNING getBusData(): ', exc_info=True)\n            if (report_dict['900k_buses'] == 1) & (BusData.empty == False):\n                #all900k_buses = get900kBuses(BusData) #to troubleshoot, uncomment this line and comment out the following try/except block\n                try:\n                    all"
  },
  {
    "id": "chunk_2620",
    "text": "block\n                try:\n                    all900k_buses = get900kBuses(BusData)\n                except:\n                    print('PROBLEM ENCOUNTERED WHILE RUNNING get900kBuses().')\n                    logging.debug('PROBLEM ENCOUNTERED WHILE RUNNING get900kBuses().', exc_info=True)\n            if (report_dict['disconnected_buses'] == 1) & (BusData.empty == False):\n                #alldisconnected_buses = getDisconnectedBuses(BusData) #to troubleshoot, uncomment this line and comment out t"
  },
  {
    "id": "chunk_2621",
    "text": "roubleshoot, uncomment this line and comment out the following try/except block\n                try:\n                    alldisconnected_buses = getDisconnectedBuses(BusData)\n                except:\n                    print('PROBLEM ENCOUNTERED WHILE RUNNING getDisconnectedBuses().')\n                    logging.debug('PROBLEM ENCOUNTERED WHILE RUNNING getDisconnectedBuses().', exc_info=True) \n\n            ############################## LCRA-only reports ##############################\n          "
  },
  {
    "id": "chunk_2622",
    "text": " reports ##############################\n            if (report_dict['out_of_range_buses'] == 1)& (BusData.empty == False):\n                #non_LCRA_range_LCRA_buses = getnon_LCRA_range_LCRA_buses(LCRA_Buses) #TO TROUBLESHOOT, uncomment this line and comment out the following try/except block\n                try:\n                    int_data_desired = ['NUMBER']\n                    int_ierr, iarray = psspy.aareaint(-1, 2, int_data_desired)\n                    allAreas = iarray[0]\n               "
  },
  {
    "id": "chunk_2623",
    "text": "              allAreas = iarray[0]\n                    ALLAREALIST = allAreas\n                    AllBusData = getBusData(savLocation,target_output_directory,rawfilename,BusData,ALLAREALIST)\n                    non_LCRA_range_LCRA_buses = getnon_LCRA_range_LCRA_buses(AllBusData)\n                except:\n                    print('PROBLEM ENCOUNTERED WHILE RUNNING getnon_LCRA_range_LCRA_buses().')\n                    logging.debug('PROBLEM ENCOUNTERED WHILE RUNNING getnon_LCRA_range_LCRA_buses(): "
  },
  {
    "id": "chunk_2624",
    "text": "RED WHILE RUNNING getnon_LCRA_range_LCRA_buses(): ', exc_info=True)\n            if (report_dict['incorrect_voltage_bus_limits'] == 1)& (BusData.empty == False):\n                #incorrect_voltage_bus_limits = getincorrect_voltage_bus_limits(LCRA_Buses) #TO TROUBLESHOOT, uncomment this line and comment out following try/except block\n                try:\n                    incorrect_voltage_bus_limits = getincorrect_voltage_bus_limits(BusData)\n                except:\n                    print('PR"
  },
  {
    "id": "chunk_2625",
    "text": "             except:\n                    print('PROBLEM ENCOUNTERED WHILE RUNNING getincorrect_voltage_bus_limits().')\n                    logging.debug('PROBLEM ENCOUNTERED WHILE RUNNING getincorrect_voltage_bus_limits(): ', exc_info=True)\n            ##########################################################################################\n            \n\n        ### if requested, get all the load data\n        if (report_dict['all_lds'] == 1)|(report_dict['disconnected_loads'] == 1)|(report_dict"
  },
  {
    "id": "chunk_2626",
    "text": "port_dict['disconnected_loads'] == 1)|(report_dict['zero_loads'] == 1):\n            #thisCaseLoadData = getLdData(savLocation,allLoads,rawfilename,AREALIST) #FOR TROUBLESHOOTING, uncomment this line and comment out the following try/except block\n            try:\n                thisCaseAllLoadData = getLdDataTotalsReportedInCaseColumn(savLocation,allLoads,rawfilename,AREALIST)\n                if allLoads.empty == True:\n                    allLoads = thisCaseAllLoadData\n                    allLoa"
  },
  {
    "id": "chunk_2627",
    "text": "s = thisCaseAllLoadData\n                    allLoads = allLoads.drop_duplicates()\n                else:\n                    allLoads = allLoads.merge(thisCaseAllLoadData,how='outer',on=['ID','NAME','LODTYPE','NUMBER','STATION','AREA','ZONE','STATUS','OWNER'])\n                    allLoads = allLoads.drop_duplicates()\n\n            except:\n                print('PROBLEM ENCOUNTERED WITH GETTING LOAD DATA. PROBLEM ENCOUNTERED WHILE RUNNING getLdDataTotalsReportedInCaseColumn()')\n                logg"
  },
  {
    "id": "chunk_2628",
    "text": "otalsReportedInCaseColumn()')\n                logging.debug('PROBLEM ENCOUNTERED WITH GETTING LOAD DATA. PROBLEM ENCOUNTERED WHILE RUNNING getLdDataTotalsReportedInCaseColumn(): ', exc_info=True)\n            \n            #thisCaseLoadData = getLdData(savLocation,allLoads,rawfilename,AREALIST) #FOR TROUBLESHOOTING, uncomment this line and comment out the following try/except block\n            try:\n                thisCaseLoadData = getLdData(savLocation,allLoadsWithTotalsColumn,rawfilename,AREALI"
  },
  {
    "id": "chunk_2629",
    "text": "cation,allLoadsWithTotalsColumn,rawfilename,AREALIST)\n                if allLoadsWithTotalsColumn.empty == True:\n                    allLoadsWithTotalsColumn = thisCaseLoadData\n                    allLoadsWithTotalsColumn = allLoadsWithTotalsColumn.drop_duplicates()\n                else:\n                    allLoadsWithTotalsColumn = allLoadsWithTotalsColumn.merge(thisCaseLoadData,how='outer',on=['ID','NAME','LODTYPE','TOTALACT','NUMBER','STATION','AREA','ZONE','STATUS','OWNER'])\n               "
  },
  {
    "id": "chunk_2630",
    "text": "','AREA','ZONE','STATUS','OWNER'])\n                    allLoadsWithTotalsColumn = allLoadsWithTotalsColumn.drop_duplicates()\n            except:\n                print('PROBLEM ENCOUNTERED WITH GETTING LOAD DATA. PROBLEM ENCOUNTERED WHILE RUNNING getLdData()')\n                logging.debug('PROBLEM ENCOUNTERED WITH GETTING LOAD DATA. PROBLEM ENCOUNTERED WHILE RUNNING getLdData(): ', exc_info=True)\n\n            if report_dict['disconnected_loads'] == 1:\n                #allDisconnectedLds = getDis"
  },
  {
    "id": "chunk_2631",
    "text": "== 1:\n                #allDisconnectedLds = getDisconnectedLoads(thisCaseLoadData,allDisconnectedLds) #FOR TROUBLESHOOTING, uncomment this line and comment out the following try/except block\n                try:\n                    allDisconnectedLds = getDisconnectedLoads(thisCaseLoadData,allDisconnectedLds)\n                except:\n                    print('PROBLEM ENCOUNTERED WHILE RUNNING getDisconnectedLoads()')\n                    logging.debug('PROBLEM ENCOUNTERED WHILE RUNNING getDisconn"
  },
  {
    "id": "chunk_2632",
    "text": "ebug('PROBLEM ENCOUNTERED WHILE RUNNING getDisconnectedLoads(): ', exc_info=True)\n            if report_dict['zero_loads'] == 1:\n                #allZeroLds = getZeroLoads(thisCaseLoadData,allZeroLds) #TO TROUBLESHOOT, uncomment this line and comment out the following try/except block\n                try:\n                    allZeroLds = getZeroLoads(thisCaseLoadData,allZeroLds)\n                except:\n                    print('PROBLEM ENCOUNTERED WHILE RUNNING getZeroLoads().')\n               "
  },
  {
    "id": "chunk_2633",
    "text": "ED WHILE RUNNING getZeroLoads().')\n                    logging.debug('PROBLEM ENCOUNTERED WHILE RUNNING getZeroLoads(): ', exc_info=True)\n            \n\n        ### if requested, get the disconnected shunts\n        if report_dict['disconnected_shunts'] == 1:\n            #alldisconnected_shunts = getDisconnectedShunts(savLocation,rawfilename,alldisconnected_shunts,AREALIST) # TO TROUBLESHOOT, uncomment this line and comment out the following try/except block\n            try:\n                alldis"
  },
  {
    "id": "chunk_2634",
    "text": "cept block\n            try:\n                alldisconnected_shunts = getDisconnectedShunts(savLocation,rawfilename,alldisconnected_shunts,AREALIST)\n            except:\n                print('PROBLEM ENCOUNTERED WITH GETTING SHUNT DATA. PROBLEM ENCOUNTERED WHILE RUNNING getDisconnectedShunts().')\n                logging.debug('PROBLEM ENCOUNTERED WITH GETTING SHUNT DATA. PROBLEM ENCOUNTERED WHILE RUNNING getDisconnectedShunts(): ', exc_info=True)\n\n        ### if requested, get the bus inconsisten"
  },
  {
    "id": "chunk_2635",
    "text": "\n        ### if requested, get the bus inconsistencies\n        if report_dict['bus_type_inconsistencies'] == 1:\n            #allBusInconsistencies = getAllBusInconsistencies(rawfilename,allBusInconsistencies) # TO TROUBLESHOOT, uncomment this line and comment out the following try/except block\n            try:\n                psspy.case(savLocation) #re-open case in psse\n                allBusInconsistencies = getAllBusInconsistencies(rawfilename,allBusInconsistencies)\n            except:\n      "
  },
  {
    "id": "chunk_2636",
    "text": ",allBusInconsistencies)\n            except:\n                print('PROBLEM ENCOUNTERED WITH GETTING BUS INCONSISTENCIES. PROBLEM ENCOUNTERED WHILE RUNNING getAllBusInconsistencies()')\n                logging.debug('PROBLEM ENCOUNTERED WITH GETTING BUS INCONSISTENCIES. PROBLEM ENCOUNTERED WHILE RUNNING getAllBusInconsistencies(): ', exc_info=True)\n\n    \n        ### if requested, get the islands from TREE\n        if report_dict['TREE_islands'] == 1:\n            #allIslands = getTREEIslands(TMP_DIR"
  },
  {
    "id": "chunk_2637",
    "text": ":\n            #allIslands = getTREEIslands(TMP_DIR,rawfilename,allIslands) # TO TROUBLESHOOT, uncomment this line and comment out the following try/except block\n            try:\n                psspy.case(savLocation) #re-open case in psse\n                allIslands = getTREEIslands(TMP_DIR,rawfilename,allIslands)\n            except:\n                print('PROBLEM ENCOUNTERED WITH GETTING ISLAND DATA. PROBLEM ENCOUNTERED WHILE RUNNING getTREEIslands()')\n                logging.debug('PROBLEM ENC"
  },
  {
    "id": "chunk_2638",
    "text": "nds()')\n                logging.debug('PROBLEM ENCOUNTERED WITH GETTING ISLAND DATA. PROBLEM ENCOUNTERED WHILE RUNNING getTREEIslands(): ', exc_info=True)\n        ### if requested, get the PSSE pf check reports\n        if report_dict['PSSE_pf_checks'] == 1:\n            #allPFCheckResults = getPSSEpfChecks(TMP_DIR,rawfilename,allPFCheckResults,allPFCheckTypes,AREALIST) # TO TROUBLESHOOT, uncomment this line and comment out the following try/except block\n            try:\n                psspy.case"
  },
  {
    "id": "chunk_2639",
    "text": " block\n            try:\n                psspy.case(savLocation) #re-open case in psse\n                allPFCheckResults = getPSSEpfChecks(TMP_DIR,rawfilename,allPFCheckResults,allPFCheckTypes,AREALIST)\n            except:\n                print('PROBLEM ENCOUNTERED WITH GETTING PSSE PF CHECKS. PROBLEM ENCOUNTERED WHILE RUNNING getPSSEpfChecks()')\n                logging.debug('PROBLEM ENCOUNTERED WITH GETTING PSSE PF CHECKS. PROBLEM ENCOUNTERED WHILE RUNNING getPSSEpfChecks(): ', exc_info=True)\n\n"
  },
  {
    "id": "chunk_2640",
    "text": "ILE RUNNING getPSSEpfChecks(): ', exc_info=True)\n\n        ### if requested, get the branch remote end voltage inconsistencies\n        if report_dict['br_remote_end_voltage_inconsistencies'] == 1:\n            #allBrTerminalVoltageInconsistencies = getBrEndVoltageInconsistencies(savLocation,rawfilename,allBrTerminalVoltageInconsistencies,AREALIST)# TO TROUBLESHOOT, uncomment this line and comment out the following try/except block\n            try:\n                allBrTerminalVoltageInconsistencie"
  },
  {
    "id": "chunk_2641",
    "text": "                allBrTerminalVoltageInconsistencies = getBrEndVoltageInconsistencies(savLocation,rawfilename,allBrTerminalVoltageInconsistencies,AREALIST)\n            except:\n                print('PROBLEM ENCOUNTERED WITH GETTING BRANCH TERMINAL VOLTAGE INCONSISTENCIES. PROBLEM ENCOUNTERED WHEN RUNNING getBrEndVoltageInconsistencies()')\n                logging.debug('PROBLEM ENCOUNTERED WITH GETTING BRANCH TERMINAL VOLTAGE INCONSISTENCIES. PROBLEM ENCOUNTERED WHEN RUNNING getBrEndVoltageInconsi"
  },
  {
    "id": "chunk_2642",
    "text": "EM ENCOUNTERED WHEN RUNNING getBrEndVoltageInconsistencies(): ', exc_info=True)\n\n        ### if any node-breaker checks are required, get the raw model in JSON format and extract the node breaker data\n        # this is the if statement for the ERCOT-distributed version\n        # if ((report_dict['invalid_Binit_switched_shunts'] == 1)\\\n        #     | (report_dict['incorrect_shunt_remote_buses'] == 1) | (report_dict['incorrect_gen_remote_buses'] == 1) \\\n        #     | (report_dict['invalid_setpt"
  },
  {
    "id": "chunk_2643",
    "text": "= 1) \\\n        #     | (report_dict['invalid_setpts_continuous_shunts'] == 1):\n        if (report_dict['multiple_branches_terminating_on_node'] == 1) | (report_dict['unterminated_elements'] == 1) | (report_dict['invalid_Binit_switched_shunts'] == 1)\\\n            | (report_dict['incorrect_shunt_remote_buses'] == 1) | (report_dict['incorrect_gen_remote_buses'] == 1) \\\n            | (report_dict['temp_looking_switches'] == 1) | (report_dict['mobile_loads'] == 1) | (report_dict['TLD_bus_updates'] =="
  },
  {
    "id": "chunk_2644",
    "text": "loads'] == 1) | (report_dict['TLD_bus_updates'] == 1) \\\n            | (report_dict['invalid_setpts_continuous_shunts'] == 1):\n            #RAW_JSON = getRawxJSON(TMP_DIR,rawfilename) # TO TROUBLESHOOT, uncomment this line and comment out the following try/except block\n            try:\n                psspy.case(savLocation) #re-open case in psse\n                RAW_JSON = getRawxJSON(TMP_DIR,rawfilename)\n            except:\n                print('PROBLEM ENCOUNTERED WHEN GETTING RAWX DATA FROM C"
  },
  {
    "id": "chunk_2645",
    "text": "'PROBLEM ENCOUNTERED WHEN GETTING RAWX DATA FROM CASE. PROBLEM ENCOUNTERED WHILE RUNNING getRawxJSON()')\n                logging.debug('PROBLEM ENCOUNTERED WHEN GETTING RAWX DATA FROM CASE. PROBLEM ENCOUNTERED WHILE RUNNING getRawxJSON(): ', exc_info=True)\n            #IBUS_NODE_DATA, JBUS_NODE_DATA, KBUS_NODE_DATA, ALL_TERMABLE_EQUIP_W_NODE_DATA, ALL_ELEMENT_DATA_DICT = getNodeBreakerData(RAW_JSON)# TO TROUBLESHOOT, uncomment this line and comment out the following try/except block\n            "
  },
  {
    "id": "chunk_2646",
    "text": "nt out the following try/except block\n            try:\n                IBUS_NODE_DATA, JBUS_NODE_DATA, KBUS_NODE_DATA, ALL_TERMABLE_EQUIP_W_NODE_DATA, \\\n                    ALL_ELEMENT_DATA_DICT, ALL_TERMABLE_EQUIP_W_NODE_DATA_INCL_SUBSWDS = getNodeBreakerData(RAW_JSON)\n            except:\n                print('PROBLEM ENCOUNTERED WITH PROCESSESING NODE-BREAKER DATA. PROBLEM ENCOUNTERED WHILE RUNNING getNodeBreakerData()')\n                logging.debug('PROBLEM ENCOUNTERED WITH PROCESSESING NOD"
  },
  {
    "id": "chunk_2647",
    "text": "g.debug('PROBLEM ENCOUNTERED WITH PROCESSESING NODE-BREAKER DATA. PROBLEM ENCOUNTERED WHILE RUNNING getNodeBreakerData(): ', exc_info=True)\n           \n            if report_dict['invalid_Binit_switched_shunts'] == 1:\n                #allSwShuntsWithInvalidBinit = getInvalidBinitShunts(ALL_ELEMENT_DATA_DICT['swshunt'],rawfilename,allSwShuntsWithInvalidBinit,savLocation,AREALIST)# TO TROUBLESHOOT, uncomment this line and comment out the following try/except block\n                try:\n            "
  },
  {
    "id": "chunk_2648",
    "text": "try/except block\n                try:\n                    allSwShuntsWithInvalidBinit = getInvalidBinitShunts(ALL_ELEMENT_DATA_DICT['swshunt'],rawfilename,allSwShuntsWithInvalidBinit,savLocation,AREALIST)\n                except:\n                    print('PROBLEM ENCOUNTERED WITH GETTING INVALID BINIT VALUES. PROBLEM ENCOUNTERED WHILE RUNNING getInvalidBinitShunts()')\n                    logging.debug('PROBLEM ENCOUNTERED WITH GETTING INVALID BINIT VALUES. PROBLEM ENCOUNTERED WHILE RUNNING getIn"
  },
  {
    "id": "chunk_2649",
    "text": "IT VALUES. PROBLEM ENCOUNTERED WHILE RUNNING getInvalidBinitShunts(): ', exc_info=True)\n            if report_dict['invalid_setpts_continuous_shunts'] == 1:\n                #allSwShuntsWithInvalidSetpoints = getInvalidSetpointsContinuousShunts(ALL_ELEMENT_DATA_DICT['swshunt'],rawfilename,allSwShuntsWithInvalidSetpoints,savLocation,AREALIST)# TO TROUBLESHOOT, uncomment this line and comment out the following try/except block\n                try:\n                    allSwShuntsWithInvalidSetpoints"
  },
  {
    "id": "chunk_2650",
    "text": "                   allSwShuntsWithInvalidSetpoints = getInvalidSetpointsContinuousShunts(ALL_ELEMENT_DATA_DICT['swshunt'],rawfilename,allSwShuntsWithInvalidSetpoints,savLocation,AREALIST)\n                except:\n                    print('PROBLEM ENCOUNTERED WITH GETTING INVALID SHUNT SETPOINT VALUES. PROBLEM ENCOUNTERED WHILE RUNNING getInvalidSetpointsContinuousShunts()')\n                    logging.debug('PROBLEM ENCOUNTERED WITH GETTING INVALID SHUNT SETPOINT VALUES. PROBLEM ENCOUNTERED WHIL"
  },
  {
    "id": "chunk_2651",
    "text": "ID SHUNT SETPOINT VALUES. PROBLEM ENCOUNTERED WHILE RUNNING getInvalidSetpointsContinuousShunts(): ', exc_info=True)\n            ### if requested, get the incorrect switched shun remote bus report\n            if report_dict['incorrect_shunt_remote_buses'] == 1:\n                #allIncorrectShuntRemoteBuses = getIncorrectShuntRemoteBuses(ALL_ELEMENT_DATA_DICT['swshunt'],rawfilename,allIncorrectShuntRemoteBuses,savLocation,AREALIST)# TO TROUBLESHOOT, uncomment this line and comment out the followi"
  },
  {
    "id": "chunk_2652",
    "text": "T, uncomment this line and comment out the following try/except block\n                try:\n                    allIncorrectShuntRemoteBuses = getIncorrectShuntRemoteBuses(ALL_ELEMENT_DATA_DICT['swshunt'],rawfilename,allIncorrectShuntRemoteBuses,savLocation,AREALIST)\n                except:\n                    print('PROBLEM ENCOUNTERED WITH GETTING INCORRECT SHUNT REMOTE BUSES. PROBLEM ENCOUNTERED WHILLE RUNNING getIncorrectShuntRemoteBuses()')\n                    logging.debug('PROBLEM ENCOUNTE"
  },
  {
    "id": "chunk_2653",
    "text": "                   logging.debug('PROBLEM ENCOUNTERED WITH GETTING INCORRECT SHUNT REMOTE BUSES. PROBLEM ENCOUNTERED WHILLE RUNNING getIncorrectShuntRemoteBuses(): ', exc_info=True)\n            ### if requested, get the incorrect generator remote bus report\n            if report_dict['incorrect_gen_remote_buses'] == 1:\n                #allIncorrectGenRemoteBuses = getIncorrectGenRemoteBuses(ALL_ELEMENT_DATA_DICT['generator'],rawfilename,allIncorrectGenRemoteBuses,savLocation,AREALIST)# TO TROUBL"
  },
  {
    "id": "chunk_2654",
    "text": "ectGenRemoteBuses,savLocation,AREALIST)# TO TROUBLESHOOT, uncomment this line and comment out the following try/except block\n                try:\n                    allIncorrectGenRemoteBuses = getIncorrectGenRemoteBuses(ALL_ELEMENT_DATA_DICT['generator'],rawfilename,allIncorrectGenRemoteBuses,savLocation,AREALIST)\n                except:\n                    print('PROBLEM ENCOUNTERED WITH GETTING INCORRECT GENERATOR REMOTE BUSES. PROBLEM ENCOUNTERED WHILLE RUNNING getIncorrectGenRemoteBuses()'"
  },
  {
    "id": "chunk_2655",
    "text": "TERED WHILLE RUNNING getIncorrectGenRemoteBuses()')\n                    logging.debug('PROBLEM ENCOUNTERED WITH GETTING INCORRECT GENERATOR REMOTE BUSES. PROBLEM ENCOUNTERED WHILLE RUNNING getIncorrectGenRemoteBuses(): ', exc_info=True)\n            \n            ############################## LCRA-only reports ##############################\n            if report_dict['multiple_branches_terminating_on_node'] == 1:\n                #allBranchesTerminatedOnSameNode = getMultiBrOnNode(IBUS_NODE_DATA,J"
  },
  {
    "id": "chunk_2656",
    "text": "atedOnSameNode = getMultiBrOnNode(IBUS_NODE_DATA,JBUS_NODE_DATA,KBUS_NODE_DATA, rawfilename, allBranchesTerminatedOnSameNode)# TO TROUBLESHOOT, uncomment this line and comment out the following try/except block\n                try:\n                    allBranchesTerminatedOnSameNode = getMultiBrOnNode(IBUS_NODE_DATA,JBUS_NODE_DATA,KBUS_NODE_DATA, rawfilename, allBranchesTerminatedOnSameNode)\n                except:\n                    print('PROBLEM ENCOUNTERED WITH GETTING MULTI BRANCH NODES. P"
  },
  {
    "id": "chunk_2657",
    "text": "LEM ENCOUNTERED WITH GETTING MULTI BRANCH NODES. PROBLEM ENCOUNTERED WHILE RUNNING getMultiBrOnNode()')\n                    logging.debug('PROBLEM ENCOUNTERED WITH GETTING MULTI BRANCH NODES. PROBLEM ENCOUNTERED WHILE RUNNING getMultiBrOnNode(): ', exc_info=True)\n            if report_dict['unterminated_elements'] == 1:\n                #allUnterminatedLCRAElements = getUnterminatedElements(ALL_TERMABLE_EQUIP_W_NODE_DATA,rawfilename,allUnterminatedLCRAElements)# TO TROUBLESHOOT, uncomment this li"
  },
  {
    "id": "chunk_2658",
    "text": "dLCRAElements)# TO TROUBLESHOOT, uncomment this line and comment out the following try/except block\n                try:\n                    allUnterminatedLCRAElements = getUnterminatedElements(ALL_TERMABLE_EQUIP_W_NODE_DATA,rawfilename,allUnterminatedLCRAElements)\n                except:\n                    print('PROBLEM ENCOUNTERED WITH GETTING UNTERMINATED ELEMENTS. PROBLEM ENCOUNTERED WHILE RUNNING getUnterminatedElements()')\n                    logging.debug('PROBLEM ENCOUNTERED WITH GETT"
  },
  {
    "id": "chunk_2659",
    "text": "      logging.debug('PROBLEM ENCOUNTERED WITH GETTING UNTERMINATED ELEMENTS. PROBLEM ENCOUNTERED WHILE RUNNING getUnterminatedElements(): ', exc_info=True)\n            \n            if report_dict['temp_looking_switches'] == 1:\n\n                try:\n                    allTempLookingSwitches = getallTempLookingSwitches(ALL_TERMABLE_EQUIP_W_NODE_DATA_INCL_SUBSWDS[['ibus','jbus','kbus','equipmentType',\\\n                        'eqid','name','isub','inode','jsub','jnode','ksub','knode']],rawfilename"
  },
  {
    "id": "chunk_2660",
    "text": "inode','jsub','jnode','ksub','knode']],rawfilename,ALL_ELEMENT_DATA_DICT['bus'],allTempLookingSwitches,AREALIST)\n                except:\n                    print('PROBLEM ENCOUNTERED WITH GETTING TEMPORARY-LOOKING SWITCHES. PROBLEM ENCOUNTERED WHILLE RUNNING getallTempLookingSwitches()')\n                    logging.debug('PROBLEM ENCOUNTERED WITH GETTING TEMPORARY-LOOKING SWITCHES. PROBLEM ENCOUNTERED WHILLE RUNNING getallTempLookingSwitches(): ', exc_info=True)\n            ### if requested, ge"
  },
  {
    "id": "chunk_2661",
    "text": "', exc_info=True)\n            ### if requested, get the MOBILE LOADS report\n            if report_dict['mobile_loads'] == 1:\n                try:\n                    allMobileLoads = getallMobileLoads(ALL_TERMABLE_EQUIP_W_NODE_DATA_INCL_SUBSWDS[['ibus','jbus','kbus','equipmentType','eqid','name','isub',\\\n                        'inode','jsub','jnode','ksub','knode']],rawfilename,ALL_ELEMENT_DATA_DICT['bus'],allMobileLoads,AREALIST)\n                except:\n                    print('PROBLEM ENCOU"
  },
  {
    "id": "chunk_2662",
    "text": "  except:\n                    print('PROBLEM ENCOUNTERED WITH GETTING MOBILE. PROBLEM ENCOUNTERED WHILLE RUNNING getallMobileLoads()')\n                    logging.debug('PROBLEM ENCOUNTERED WITH GETTING MOBILE. PROBLEM ENCOUNTERED WHILLE RUNNING getallMobileLoads(): ', exc_info=True)\n            \n            ### if requested, get the TLD bus update report\n        if report_dict['TLD_bus_updates'] == 1:\n            #allTLDBusesToAdd,allTLDBusesToRemove,allTLDBusesToUpdate = getTLDBusUpdates(savLo"
  },
  {
    "id": "chunk_2663",
    "text": "emove,allTLDBusesToUpdate = getTLDBusUpdates(savLocation,APIbusData,allTLDBusesToAdd,allTLDBusesToRemove,allTLDBusesToUpdate,rawfilename,ALL_ELEMENT_DATA_DICT['subterm'],AREALIST)# TO TROUBLESHOOT, uncomment this line and comment out the following try/except block\n            try:\n                allTLDBusesToAdd,allTLDBusesToRemove,allTLDBusesToUpdate = getTLDBusUpdates(savLocation,APIbusData,allTLDBusesToAdd,allTLDBusesToRemove,allTLDBusesToUpdate,rawfilename,ALL_ELEMENT_DATA_DICT['subterm'],A"
  },
  {
    "id": "chunk_2664",
    "text": "ate,rawfilename,ALL_ELEMENT_DATA_DICT['subterm'],AREALIST)\n            except:\n                print('PROBLEM ENCOUNTERED WITH GETTING THE TLD UPDATE LISTS. PROBLEM ENCOUNTERED WHILE RUNNING getTLDBusUpdates()')\n                logging.debug('PROBLEM ENCOUNTERED WITH GETTING THE TLD UPDATE LISTS. PROBLEM ENCOUNTERED WHILE RUNNING getTLDBusUpdates(): ', exc_info=True)\n            ######################################################################################################################"
  },
  {
    "id": "chunk_2665",
    "text": "####################################################\n        ### Save the reports\n    logging.debug('Processing cases is complete. Now creating reports')\n    summaryReport = pd.DataFrame(columns=['Report','Number of Results','Location'])\n    # make excel for CNTB messages\n    if report_dict['CNTB_check']==1:\n        logging.debug('Creating CNTB Report')\n        #CNTB_messages.to_csv(target_output_directory+r'\\all_CNTB_messages.csv')\n        CNTB_excelWriter = pd.ExcelWriter(target_output_directo"
  },
  {
    "id": "chunk_2666",
    "text": "excelWriter = pd.ExcelWriter(target_output_directory+r'\\all_CNTB_messages.xlsx')\n        CNTB_errors = CNTB_messages.loc[CNTB_messages['Type']=='ERROR']\n        CNTB_warnings = CNTB_messages.loc[CNTB_messages['Type']=='Warning']\n        #CNTB_other = CNTB_messages.loc[CNTB_messages_tmp['Type']=='Other']\n        CNTB_errors.to_excel(CNTB_excelWriter,sheet_name='Errors')\n        CNTB_warnings.to_excel(CNTB_excelWriter,sheet_name='Warnings')\n        #CNTB_other.to_excel(CNTB_excelWriter,sheet_name="
  },
  {
    "id": "chunk_2667",
    "text": " #CNTB_other.to_excel(CNTB_excelWriter,sheet_name='Other')\n        CNTB_excelWriter.save()\n        # insert metadata to summaryReport\n        sumData = pd.DataFrame({'Report':['CNTB_errors','CNTB_warnings'],\n        'Number of Results':[CNTB_errors.index.size,CNTB_warnings.index.size],\n        'Location':[target_output_directory+r'\\all_CNTB_messages.xlsx',target_output_directory+r'\\all_CNTB_messages.xlsx']})\n        summaryReport = pd.concat([summaryReport,sumData],ignore_index=True)\n\n    # make"
  },
  {
    "id": "chunk_2668",
    "text": "maryReport,sumData],ignore_index=True)\n\n    # make excel for PSSE_pf_check_results    \n    if report_dict['PSSE_pf_checks'] == 1:\n        logging.debug('Creating PSSE_pf_checks report')\n        PSSEpfCheck_excelWriter = pd.ExcelWriter(target_output_directory+r'\\all_PSSE_pf_checks.xlsx')\n        for checkType in allPFCheckResults.keys():\n            sheet_name_max = checkType[0:30]\n            allPFCheckResults[checkType].to_excel(PSSEpfCheck_excelWriter,sheet_name='{0}'.format(sheet_name_max))\n "
  },
  {
    "id": "chunk_2669",
    "text": "lWriter,sheet_name='{0}'.format(sheet_name_max))\n            # insert metadata to summaryReport\n            sumData = pd.DataFrame({'Report':['PSSE PF Check - {0}'.format(checkType)],\n            'Number of Results':[allPFCheckResults[checkType].index.size],\n            'Location':[target_output_directory+r'\\all_PSSE_pf_checks.xlsx']})\n            summaryReport = pd.concat([summaryReport,sumData],ignore_index=True)\n        PSSEpfCheck_excelWriter.save()\n\n    # make excel for check_solvability fr"
  },
  {
    "id": "chunk_2670",
    "text": ".save()\n\n    # make excel for check_solvability from allVoltageViolations, allThermalViolations, and allCaseSolveData\n    if report_dict['check_solvability'] == 1:\n        logging.debug('Creating solvability check excel report')\n        SolCheck_excelWriter = pd.ExcelWriter(target_output_directory+r'\\Solution_checks.xlsx')\n        allCaseSolveData.to_excel(SolCheck_excelWriter,sheet_name='SolvabilityResults')\n        allVoltageViolations.to_excel(SolCheck_excelWriter,sheet_name='VoltageViolation"
  },
  {
    "id": "chunk_2671",
    "text": "(SolCheck_excelWriter,sheet_name='VoltageViolations')\n        allThermalViolations.to_excel(SolCheck_excelWriter,sheet_name='ThermalViolations')\n        SolCheck_excelWriter.save()\n            \n    # make excel for check_CA_performance from allUnsolvedContingencies and allCAData\n    if report_dict['check_CA_performance'] == 1:\n        logging.debug('Creating CA performance check excel report')\n        CACheck_excelWriter = pd.ExcelWriter(target_output_directory+r'\\CA_performance_checks.xlsx')\n  "
  },
  {
    "id": "chunk_2672",
    "text": "utput_directory+r'\\CA_performance_checks.xlsx')\n        allCAData.to_excel(CACheck_excelWriter,sheet_name='CA_Results')\n        allUnsolvedContingencies.to_excel(CACheck_excelWriter,sheet_name='Unsolved_Contingencies')\n        CACheck_excelWriter.save()\n\n    # make csv reports for all the other reports\n    report_to_data_dictionary = {'900k_buses':all900k_buses,\\\n                                'disconnected_shunts':alldisconnected_shunts,\\\n                                'disconnected_loads':al"
  },
  {
    "id": "chunk_2673",
    "text": "                           'disconnected_loads':allDisconnectedLds,\\\n                                'zero_loads':allZeroLds,\\\n                                'invalid_Binit_switched_shunts':allSwShuntsWithInvalidBinit,\\\n                                'TREE_islands':allIslands,\\\n                                'br_remote_end_voltage_inconsistencies':allBrTerminalVoltageInconsistencies,\\\n                                'bus_type_inconsistencies':allBusInconsistencies,\\\n                          "
  },
  {
    "id": "chunk_2674",
    "text": "allBusInconsistencies,\\\n                                'all_lds':allLoads,\\\n                                #'check_solvability':allCaseSolveData,\\\n                                'incorrect_shunt_remote_buses':allIncorrectShuntRemoteBuses,\\\n                                'incorrect_gen_remote_buses':allIncorrectGenRemoteBuses,\\\n                                #'check_CA_performance':allCAData,\\\n                                'invalid_setpts_continuous_shunts':allSwShuntsWithInvalidSetpoints,"
  },
  {
    "id": "chunk_2675",
    "text": "ontinuous_shunts':allSwShuntsWithInvalidSetpoints,\\\n                                'disconnected_buses':alldisconnected_buses}\n    for report in report_to_data_dictionary.keys():\n        if report_dict[report]==1:\n            logging.debug('Creating {0} report'.format(report))\n            report_to_data_dictionary[report].to_csv(target_output_directory+r'\\{0}.csv'.format(report))\n            # insert metadata to summaryReport\n            sumData = pd.DataFrame({'Report':[report],\n            'N"
  },
  {
    "id": "chunk_2676",
    "text": " = pd.DataFrame({'Report':[report],\n            'Number of Results':[report_to_data_dictionary[report].index.size],\n            'Location':[target_output_directory+r'\\{0}.csv'.format(report)]})\n            summaryReport = pd.concat([summaryReport,sumData],ignore_index=True)\n    \n    # make excel for the TLD Bus updates\n    logging.debug('Creating TLD Bus Update report')\n    if report_dict['TLD_bus_updates'] == 1:\n        TLDBusUpdates_excelWriter = pd.ExcelWriter(target_output_directory+r'\\TLDBu"
  },
  {
    "id": "chunk_2677",
    "text": " = pd.ExcelWriter(target_output_directory+r'\\TLDBusUpdates.xlsx')\n        allTLDBusesToAdd.to_excel(TLDBusUpdates_excelWriter,sheet_name='allTLDBusesToAdd')\n        allTLDBusesToRemove.to_excel(TLDBusUpdates_excelWriter,sheet_name='allTLDBusesToRemove')\n        allTLDBusesToUpdate.to_excel(TLDBusUpdates_excelWriter,sheet_name='allTLDBusesToUpdate')\n        TLDBusUpdates_excelWriter.save()\n        # insert metadata to summaryReport\n        sumData = pd.DataFrame({'Report':['allTLDBusesToAdd','all"
  },
  {
    "id": "chunk_2678",
    "text": " = pd.DataFrame({'Report':['allTLDBusesToAdd','allTLDBusesToRemove','allTLDBusesToUpdate'],\n        'Number of Results':[allTLDBusesToAdd.index.size,allTLDBusesToRemove.index.size,allTLDBusesToUpdate.index.size],\n        'Location':[target_output_directory+r'\\TLDBusUpdates.xlsx',target_output_directory+r'\\TLDBusUpdates.xlsx',target_output_directory+r'\\TLDBusUpdates.xlsx']})\n        summaryReport = pd.concat([summaryReport,sumData],ignore_index=True)\n    \n    # make csv reports for all the other "
  },
  {
    "id": "chunk_2679",
    "text": "ue)\n    \n    # make csv reports for all the other reports\n    LCRA_report_to_data_dictionary = {'temp_looking_switches':allTempLookingSwitches,\\\n                                'mobile_loads':allMobileLoads,\\\n                                'out_of_range_buses':non_LCRA_range_LCRA_buses,\\\n                                'multiple_branches_terminating_on_node':allBranchesTerminatedOnSameNode,\\\n                                'unterminated_elements':allUnterminatedLCRAElements,\\\n                  "
  },
  {
    "id": "chunk_2680",
    "text": "':allUnterminatedLCRAElements,\\\n                                'incorrect_voltage_bus_limits':incorrect_voltage_bus_limits}\n    for report in LCRA_report_to_data_dictionary.keys():\n        if report_dict[report]==1:\n            logging.debug('Creating {0} report'.format(report))\n            LCRA_report_to_data_dictionary[report].to_csv(target_output_directory+r'\\{0}.csv'.format(report))\n            # insert metadata to summaryReport\n            sumData = pd.DataFrame({'Report':[report],\n       "
  },
  {
    "id": "chunk_2681",
    "text": "sumData = pd.DataFrame({'Report':[report],\n            'Number of Results':[LCRA_report_to_data_dictionary[report].index.size],\n            'Location':[target_output_directory+r'\\{0}.csv'.format(report)]})\n            summaryReport = pd.concat([summaryReport,sumData],ignore_index=True)\n\n    # create summary report\n    logging.debug('Creating summary report.')\n    summaryReport['Location'] = summaryReport['Location'].apply(lambda x: make_clickable(x, x))\n    summaryReport = summaryReport.sort_val"
  },
  {
    "id": "chunk_2682",
    "text": "(x, x))\n    summaryReport = summaryReport.sort_values(by=['Number of Results'],ascending=False)\n    summary_html = summaryReport.to_html(render_links=True,escape=False)\n    text_file = open(target_output_directory+r'\\SummaryReport.html','w')\n    text_file.write(summary_html)\n    text_file.close()\n    logging.debug('Reports completed.')\n    logging.debug('Done.')\n    logging.shutdown()\n########### CLASS DEFINITIONS ##############\nclass SSWGCaseQA(wx.Frame):\n    def __init__(self):\n        self.Se"
  },
  {
    "id": "chunk_2683",
    "text": "wx.Frame):\n    def __init__(self):\n        self.SelectedAreas = []\n        self.SelectedBuses = []\n        self.AllAreas = [] # replace with real data from case when the corresponding button is selected\n        self.AllBuses = [] # replace with real data from case when the corresponding button is selected\n        self.chosenAreas = []\n        self.chosenBuses = []\n        wx.Frame.__init__(self,None,wx.ID_ANY,\"Perform quality assurance checks on raw file(s).\",size =(1000,600))\n        self.panel"
  },
  {
    "id": "chunk_2684",
    "text": "raw file(s).\",size =(1000,600))\n        self.panel = wx.Panel(self, wx.ID_ANY)\n\n        # make wrapper\n        self.wrapper = wx.FlexGridSizer(4,1,20,20) # wx.FlexGridSizer(2,1,20,20)\n        self.wrapper.AddGrowableCol(0)\n\n\n        #select an SSWG cases directory\n        self.label1 = wx.StaticText(self.panel)\n        self.caseDirectory = wx.DirPickerCtrl(self.panel, size=(800,25))\n        row1 = wx.StaticBoxSizer(wx.StaticBox(self.panel, 1, 'Please select the SSWG raw case directory (all .raw "
  },
  {
    "id": "chunk_2685",
    "text": "ease select the SSWG raw case directory (all .raw files in the selected directory will be analyzed):'), orient=wx.HORIZONTAL)\n        row1.Add(self.label1,0,wx.TOP | wx.RIGHT,10)\n        row1.Add(self.caseDirectory)\n\n        self.wrapper.Add(row1,50,wx.TOP | wx.LEFT | wx.RIGHT | wx.ALIGN_CENTER,20)\n\n        #select model areas for report generation\n        self.label3 = wx.StaticText(self.panel)\n        #self.conFile = wx.FilePickerCtrl(self.panel, size=(800,25),wildcard=\"*.con\")\n        self.re"
  },
  {
    "id": "chunk_2686",
    "text": "l, size=(800,25),wildcard=\"*.con\")\n        self.reportAreas = wx.TextCtrl(self.panel, size=(800,25),value=\"\")\n        row3 = wx.StaticBoxSizer(wx.StaticBox(self.panel, 1, 'Please provide a comma-separated list of areas for reporting (leave blank to get results for entire model):'), orient=wx.HORIZONTAL)\n        row3.Add(self.label3,0,wx.TOP | wx.RIGHT,10)\n        row3.Add(self.reportAreas)\n        self.wrapper.Add(row3,50,wx.TOP | wx.LEFT | wx.RIGHT | wx.ALIGN_CENTER,20)\n        # self.panel.Set"
  },
  {
    "id": "chunk_2687",
    "text": "GHT | wx.ALIGN_CENTER,20)\n        # self.panel.SetSizerAndFit(wrapper)\n        # self.Centre()\n\n        #select an output directory\n        self.label2 = wx.StaticText(self.panel)\n        self.dirCtrl = wx.DirPickerCtrl(self.panel, size=(800,25))\n        row2 = wx.StaticBoxSizer(wx.StaticBox(self.panel, 1, 'Please select the output location for reports:'), orient=wx.HORIZONTAL)\n        row2.Add(self.label2,0,wx.TOP | wx.RIGHT,10)\n        row2.Add(self.dirCtrl)\n\n        self.wrapper.Add(row2,50,w"
  },
  {
    "id": "chunk_2688",
    "text": "(self.dirCtrl)\n\n        self.wrapper.Add(row2,50,wx.TOP | wx.LEFT | wx.RIGHT | wx.ALIGN_CENTER,20)\n        self.panel.SetSizerAndFit(self.wrapper)\n        self.Centre()\n\n        # report selection radio buttons\n        self.RB_900k_buses = wx.CheckBox(self.panel,11,label='900k+ buses',pos =(100,275))\n        self.RB_900k_buses.SetValue(True)\n        self.RB_TREE_islands = wx.CheckBox(self.panel,22,label='TREE_islands',pos =(300,275))\n        self.RB_TREE_islands.SetValue(True)\n        self.RB_bu"
  },
  {
    "id": "chunk_2689",
    "text": ".RB_TREE_islands.SetValue(True)\n        self.RB_bus_type_inconsistencies = wx.CheckBox(self.panel,33,label='Bus type inconsistencies',pos =(500,275))\n        self.RB_bus_type_inconsistencies.SetValue(True)\n        self.RB_CNTB_check = wx.CheckBox(self.panel,33,label='CNTB check',pos =(700,275))\n        self.RB_CNTB_check.SetValue(True)\n        self.RB_disconnected_shunts = wx.CheckBox(self.panel,44,label='Disconnected shunts',pos =(100,300))\n        self.RB_disconnected_shunts.SetValue(True)\n   "
  },
  {
    "id": "chunk_2690",
    "text": "    self.RB_disconnected_shunts.SetValue(True)\n        self.RB_invalid_Binit_switched_shunts = wx.CheckBox(self.panel,55,label='Invalid Binit sw. shunts',pos =(300,300))\n        self.RB_invalid_Binit_switched_shunts.SetValue(True)\n        self.RB_invalid_setpts_continuous_shunts = wx.CheckBox(self.panel,66,label='Invalid VHi-VLo cont. ctrl. shunts',pos =(500,300))\n        self.RB_invalid_setpts_continuous_shunts.SetValue(True)\n        self.RB_incorrect_shunt_remote_buses = wx.CheckBox(self.panel"
  },
  {
    "id": "chunk_2691",
    "text": "orrect_shunt_remote_buses = wx.CheckBox(self.panel,77,label='Non-POI Shunt Remote Bus',pos =(700,300))\n        self.RB_incorrect_shunt_remote_buses.SetValue(True)\n        self.RB_incorrect_gen_remote_buses = wx.CheckBox(self.panel,88,label='Non-POI Gen Remote Bus',pos =(100,325))\n        self.RB_incorrect_gen_remote_buses.SetValue(True)\n        self.RB_br_remote_end_voltage_inconsistencies = wx.CheckBox(self.panel,99,label='Inconsistent line end voltages',pos =(300,325))\n        self.RB_br_remot"
  },
  {
    "id": "chunk_2692",
    "text": "voltages',pos =(300,325))\n        self.RB_br_remote_end_voltage_inconsistencies.SetValue(True)\n        self.RB_check_solvability = wx.CheckBox(self.panel,111,label='Check solvability',pos =(500,325))\n        self.RB_check_solvability.SetValue(True)\n        self.RB_check_CA_performance = wx.CheckBox(self.panel,222,label='Check CA performance (sng. br. elem)',pos =(700,325))\n        self.RB_check_CA_performance.SetValue(True)\n        self.RB_PSSE_pf_checks = wx.CheckBox(self.panel,333,label='PSSE "
  },
  {
    "id": "chunk_2693",
    "text": "f_checks = wx.CheckBox(self.panel,333,label='PSSE pf checks',pos =(100,350))\n        self.RB_PSSE_pf_checks.SetValue(True)\n        self.RB_all_lds = wx.CheckBox(self.panel,444,label='All loads report',pos =(300,350))\n        self.RB_all_lds.SetValue(True)\n        self.RB_disconnected_loads = wx.CheckBox(self.panel,555,label='Disconnected loads',pos =(500,350))\n        self.RB_disconnected_loads.SetValue(True)\n        self.RB_zero_loads = wx.CheckBox(self.panel,666,label='0 MVA loads',pos =(700,3"
  },
  {
    "id": "chunk_2694",
    "text": "Box(self.panel,666,label='0 MVA loads',pos =(700,350))\n        self.RB_zero_loads.SetValue(True)\n        self.RB_disconnected_buses = wx.CheckBox(self.panel,777,label='Disconnected buses',pos =(100,375))\n        self.RB_disconnected_buses.SetValue(True)\n\n        # button push\n        self.generateQAReports = wx.Button(self.panel,-1, \"Generate Selected QA Reports\", pos=(400, 450))\n        self.generateQAReports.Bind(wx.EVT_BUTTON, self.generateQAReportsBtnEvent, self.generateQAReports)\n\n    def g"
  },
  {
    "id": "chunk_2695",
    "text": "eportsBtnEvent, self.generateQAReports)\n\n    def generateQAReportsBtnEvent(self, event):\n        if self.caseDirectory.GetPath() == '':\n            self.nocaseDirectoryChosenMessage = wx.MessageBox('Choose a valid SSWG case directory to read the unprocessed raw files from.')\n            return\n        if self.dirCtrl.GetPath() == '':\n            self.nooutputDirectoryChosenMessage = wx.MessageBox('Choose an output directory for the output reports.')\n            return\n        if self.reportAreas"
  },
  {
    "id": "chunk_2696",
    "text": ".')\n            return\n        if self.reportAreas.GetLineText(0) == '':\n            areaList = []\n        else:\n            try:\n                areaList = self.reportAreas.GetLineText(0).split(\",\")\n                areaList = [int(x) for x in areaList]\n            except:\n                areaList = None\n        if areaList == None:\n            self.areaErrorMessage = wx.MessageBox('Type a comma-separated list of areas for which to run the QA checks. (For example: \"1, 2, 3\"). Do not enter any ne"
  },
  {
    "id": "chunk_2697",
    "text": "cks. (For example: \"1, 2, 3\"). Do not enter any newline characters. Leave this blank if you want to run the reports for the entire model, regardless of area.')\n        runAllReportsList = ['900k_buses','TREE_islands','bus_type_inconsistencies','CNTB_check',\n        'disconnected_shunts', 'invalid_Binit_switched_shunts','invalid_setpts_continuous_shunts',\n        'incorrect_shunt_remote_buses','incorrect_gen_remote_buses','br_remote_end_voltage_inconsistencies',\n        'check_solvability','check"
  },
  {
    "id": "chunk_2698",
    "text": "consistencies',\n        'check_solvability','check_CA_performance','PSSE_pf_checks','all_lds','disconnected_loads',\n        'zero_loads','disconnected_buses']\n        reportSelections = [self.RB_900k_buses.GetValue(),\n        self.RB_TREE_islands.GetValue(),\n        self.RB_bus_type_inconsistencies.GetValue(),\n        self.RB_CNTB_check.GetValue(),\n        self.RB_disconnected_shunts.GetValue(),\n        self.RB_invalid_Binit_switched_shunts.GetValue(),\n        self.RB_invalid_setpts_continuous_s"
  },
  {
    "id": "chunk_2699",
    "text": "lue(),\n        self.RB_invalid_setpts_continuous_shunts.GetValue(),\n        self.RB_incorrect_shunt_remote_buses.GetValue(),\n        self.RB_incorrect_gen_remote_buses.GetValue(),\n        self.RB_br_remote_end_voltage_inconsistencies.GetValue(),\n        self.RB_check_solvability.GetValue(),\n        self.RB_check_CA_performance.GetValue(),\n        self.RB_PSSE_pf_checks.GetValue(),\n        self.RB_all_lds.GetValue(),\n        self.RB_disconnected_loads.GetValue(),\n        self.RB_zero_loads.GetVal"
  },
  {
    "id": "chunk_2700",
    "text": "oads.GetValue(),\n        self.RB_zero_loads.GetValue(),\n        self.RB_disconnected_buses.GetValue()]\n        AllReportsDict = dict(zip(runAllReportsList,reportSelections))\n        RequestedReportsDict = {key: value for key, value in AllReportsDict.items() if value == True}\n        \n        \n        #trigger the report creation\n\n        print('All required files and directories selected. Now running the following QA reports:')\n        print(list(RequestedReportsDict.keys()))\n        \n\n        g"
  },
  {
    "id": "chunk_2701",
    "text": "(RequestedReportsDict.keys()))\n        \n\n        getQAReports(CASEDIRECTORY=self.caseDirectory,OUTPUTDIRECTORY=self.dirCtrl,DESIRED_QA_LIST=list(RequestedReportsDict.keys()),AREALIST=areaList)\n        print('Done!')\n\n        self.QAReportsComplete = wx.MessageBox('SSWG QA reports complete. Go to {} to see results.'.format(self.dirCtrl.GetPath()))\n\n##### LCRA only Class Definitions #####\nclass LCRASSWGCaseQA(wx.Frame):\n    def __init__(self):\n        self.SelectedAreas = []\n        self.SelectedB"
  },
  {
    "id": "chunk_2702",
    "text": "    self.SelectedAreas = []\n        self.SelectedBuses = []\n        self.AllAreas = [] # replace with real data from case when the corresponding button is selected\n        self.AllBuses = [] # replace with real data from case when the corresponding button is selected\n        self.chosenAreas = []\n        self.chosenBuses = []\n        wx.Frame.__init__(self,None,wx.ID_ANY,\"Perform quality assurance checks on raw file(s).\",size =(1000,600))\n        self.panel = wx.Panel(self, wx.ID_ANY)\n\n        #"
  },
  {
    "id": "chunk_2703",
    "text": " self.panel = wx.Panel(self, wx.ID_ANY)\n\n        # make wrapper\n        self.wrapper = wx.FlexGridSizer(4,1,20,20) # wx.FlexGridSizer(2,1,20,20)\n        self.wrapper.AddGrowableCol(0)\n\n\n        #select an SSWG cases directory\n        self.label1 = wx.StaticText(self.panel)\n        self.caseDirectory = wx.DirPickerCtrl(self.panel, size=(800,25))\n        row1 = wx.StaticBoxSizer(wx.StaticBox(self.panel, 1, 'Please select the SSWG raw case directory (all .raw files in the selected directory will be"
  },
  {
    "id": "chunk_2704",
    "text": " (all .raw files in the selected directory will be analyzed):'), orient=wx.HORIZONTAL)\n        row1.Add(self.label1,0,wx.TOP | wx.RIGHT,10)\n        row1.Add(self.caseDirectory)\n\n        self.wrapper.Add(row1,50,wx.TOP | wx.LEFT | wx.RIGHT | wx.ALIGN_CENTER,20)\n\n        #select model areas for report generation\n        self.label3 = wx.StaticText(self.panel)\n        #self.conFile = wx.FilePickerCtrl(self.panel, size=(800,25),wildcard=\"*.con\")\n        self.reportAreas = wx.TextCtrl(self.panel, siz"
  },
  {
    "id": "chunk_2705",
    "text": "    self.reportAreas = wx.TextCtrl(self.panel, size=(800,25),value=\"7, 907\")\n        row3 = wx.StaticBoxSizer(wx.StaticBox(self.panel, 1, 'Please provide a comma-separated list of areas for reporting (leave blank to get results for entire model):'), orient=wx.HORIZONTAL)\n        row3.Add(self.label3,0,wx.TOP | wx.RIGHT,10)\n        row3.Add(self.reportAreas)\n        self.wrapper.Add(row3,50,wx.TOP | wx.LEFT | wx.RIGHT | wx.ALIGN_CENTER,20)\n        # self.panel.SetSizerAndFit(wrapper)\n        # se"
  },
  {
    "id": "chunk_2706",
    "text": " # self.panel.SetSizerAndFit(wrapper)\n        # self.Centre()\n\n        #select an output directory\n        self.label2 = wx.StaticText(self.panel)\n        self.dirCtrl = wx.DirPickerCtrl(self.panel, size=(800,25))\n        row2 = wx.StaticBoxSizer(wx.StaticBox(self.panel, 1, 'Please select the output location for reports:'), orient=wx.HORIZONTAL)\n        row2.Add(self.label2,0,wx.TOP | wx.RIGHT,10)\n        row2.Add(self.dirCtrl)\n\n        self.wrapper.Add(row2,50,wx.TOP | wx.LEFT | wx.RIGHT | wx.A"
  },
  {
    "id": "chunk_2707",
    "text": "per.Add(row2,50,wx.TOP | wx.LEFT | wx.RIGHT | wx.ALIGN_CENTER,20)\n        self.panel.SetSizerAndFit(self.wrapper)\n        self.Centre()\n\n        # report selection radio buttons\n        self.RB_900k_buses = wx.CheckBox(self.panel,11,label='900k+ buses',pos =(100,275))\n        self.RB_900k_buses.SetValue(True)\n        self.RB_TREE_islands = wx.CheckBox(self.panel,22,label='TREE_islands',pos =(300,275))\n        self.RB_TREE_islands.SetValue(True)\n        self.RB_bus_type_inconsistencies = wx.Check"
  },
  {
    "id": "chunk_2708",
    "text": "       self.RB_bus_type_inconsistencies = wx.CheckBox(self.panel,33,label='Bus type inconsistencies',pos =(500,275))\n        self.RB_bus_type_inconsistencies.SetValue(True)\n        self.RB_CNTB_check = wx.CheckBox(self.panel,33,label='CNTB check',pos =(700,275))\n        self.RB_CNTB_check.SetValue(True)\n        self.RB_disconnected_shunts = wx.CheckBox(self.panel,44,label='Disconnected shunts',pos =(100,300))\n        self.RB_disconnected_shunts.SetValue(True)\n        self.RB_invalid_Binit_switch"
  },
  {
    "id": "chunk_2709",
    "text": "etValue(True)\n        self.RB_invalid_Binit_switched_shunts = wx.CheckBox(self.panel,55,label='Invalid Binit sw. shunts',pos =(300,300))\n        self.RB_invalid_Binit_switched_shunts.SetValue(True)\n        self.RB_invalid_setpts_continuous_shunts = wx.CheckBox(self.panel,66,label='Invalid VHi-VLo cont. ctrl. shunts',pos =(500,300))\n        self.RB_invalid_setpts_continuous_shunts.SetValue(True)\n        self.RB_incorrect_shunt_remote_buses = wx.CheckBox(self.panel,77,label='Non-POI Shunt Remote B"
  },
  {
    "id": "chunk_2710",
    "text": "eckBox(self.panel,77,label='Non-POI Shunt Remote Bus',pos =(700,300))\n        self.RB_incorrect_shunt_remote_buses.SetValue(True)\n        self.RB_incorrect_gen_remote_buses = wx.CheckBox(self.panel,88,label='Non-POI Gen Remote Bus',pos =(100,325))\n        self.RB_incorrect_gen_remote_buses.SetValue(True)\n        self.RB_br_remote_end_voltage_inconsistencies = wx.CheckBox(self.panel,99,label='Inconsistent line end voltages',pos =(300,325))\n        self.RB_br_remote_end_voltage_inconsistencies.Set"
  },
  {
    "id": "chunk_2711",
    "text": " self.RB_br_remote_end_voltage_inconsistencies.SetValue(True)\n        self.RB_check_solvability = wx.CheckBox(self.panel,111,label='Check solvability',pos =(500,325))\n        self.RB_check_solvability.SetValue(True)\n        self.RB_check_CA_performance = wx.CheckBox(self.panel,222,label='Check CA performance (sng. br. elem)',pos =(700,325))\n        self.RB_check_CA_performance.SetValue(True)\n        self.RB_PSSE_pf_checks = wx.CheckBox(self.panel,333,label='PSSE pf checks',pos =(100,350))\n      "
  },
  {
    "id": "chunk_2712",
    "text": ",333,label='PSSE pf checks',pos =(100,350))\n        self.RB_PSSE_pf_checks.SetValue(True)\n        self.RB_all_lds = wx.CheckBox(self.panel,444,label='All loads report',pos =(300,350))\n        self.RB_all_lds.SetValue(True)\n        self.RB_disconnected_loads = wx.CheckBox(self.panel,555,label='Disconnected loads',pos =(500,350))\n        self.RB_disconnected_loads.SetValue(True)\n        self.RB_zero_loads = wx.CheckBox(self.panel,666,label='0 MVA loads',pos =(700,350))\n        self.RB_zero_loads.S"
  },
  {
    "id": "chunk_2713",
    "text": "oads',pos =(700,350))\n        self.RB_zero_loads.SetValue(True)\n        ### LCRA-Only\n        self.RB_temp_looking_switches = wx.CheckBox(self.panel,777,label='Temp-looking switches',pos =(100,400))\n        self.RB_temp_looking_switches.SetValue(True)\n        self.RB_mobile_loads = wx.CheckBox(self.panel,888,label='Mobile loads',pos =(300,400))\n        self.RB_mobile_loads.SetValue(True)\n        self.RB_out_of_range_buses = wx.CheckBox(self.panel,999,label='Out-of-range buses',pos =(500,400))\n  "
  },
  {
    "id": "chunk_2714",
    "text": ",999,label='Out-of-range buses',pos =(500,400))\n        self.RB_out_of_range_buses.SetValue(True)\n        self.RB_multiple_branches_terminating_on_node = wx.CheckBox(self.panel,1111,label='Nodes with multiple br term.',pos =(700,400))\n        self.RB_multiple_branches_terminating_on_node.SetValue(True)\n        self.RB_unterminated_elements = wx.CheckBox(self.panel,2222,label='Unterminated elements',pos =(100,425))\n        self.RB_unterminated_elements.SetValue(True)\n        self.RB_incorrect_vol"
  },
  {
    "id": "chunk_2715",
    "text": "ments.SetValue(True)\n        self.RB_incorrect_voltage_bus_limits = wx.CheckBox(self.panel,3333,label='Incorrect voltage bus limits',pos =(300,425))\n        self.RB_incorrect_voltage_bus_limits.SetValue(True)\n        self.RB_TLD_bus_updates = wx.CheckBox(self.panel,3333,label='TLD Bus Updates',pos =(500,425))\n        self.RB_TLD_bus_updates.SetValue(True)\n        self.RB_disconnected_buses = wx.CheckBox(self.panel,777,label='Disconnected buses',pos =(100,375))\n        self.RB_disconnected_buses."
  },
  {
    "id": "chunk_2716",
    "text": "os =(100,375))\n        self.RB_disconnected_buses.SetValue(True)\n\n        # button push\n        self.generateQAReports = wx.Button(self.panel,-1, \"Generate Selected QA Reports\", pos=(400, 450))\n        self.generateQAReports.Bind(wx.EVT_BUTTON, self.generateQAReportsBtnEvent, self.generateQAReports)\n\n    def generateQAReportsBtnEvent(self, event):\n        if self.caseDirectory.GetPath() == '':\n            self.nocaseDirectoryChosenMessage = wx.MessageBox('Choose a valid SSWG case directory to re"
  },
  {
    "id": "chunk_2717",
    "text": "ssageBox('Choose a valid SSWG case directory to read the unprocessed raw files from.')\n            return\n        if self.dirCtrl.GetPath() == '':\n            self.nooutputDirectoryChosenMessage = wx.MessageBox('Choose an output directory for the output reports.')\n            return\n        if self.reportAreas.GetLineText(0) == '':\n            areaList = []\n        else:\n            try:\n                areaList = self.reportAreas.GetLineText(0).split(\",\")\n                areaList = [int(x) for "
  },
  {
    "id": "chunk_2718",
    "text": "split(\",\")\n                areaList = [int(x) for x in areaList]\n            except:\n                areaList = None\n        if areaList == None:\n            self.areaErrorMessage = wx.MessageBox('Type a comma-separated list of areas for which to run the QA checks. (For example: \"1, 2, 3\"). Do not enter any newline characters. Leave this blank if you want to run the reports for the entire model, regardless of area.')\n        runAllReportsList = ['900k_buses','TREE_islands','bus_type_inconsistenc"
  },
  {
    "id": "chunk_2719",
    "text": "'900k_buses','TREE_islands','bus_type_inconsistencies','CNTB_check',\n        'disconnected_shunts', 'invalid_Binit_switched_shunts','invalid_setpts_continuous_shunts',\n        'incorrect_shunt_remote_buses','incorrect_gen_remote_buses','br_remote_end_voltage_inconsistencies',\n        'check_solvability','check_CA_performance','PSSE_pf_checks','all_lds','disconnected_loads',\n        'zero_loads','disconnected_buses',\n        # LCRA-only Reports\n        'temp_looking_switches','mobile_loads','out_"
  },
  {
    "id": "chunk_2720",
    "text": "      'temp_looking_switches','mobile_loads','out_of_range_buses',\n        'multiple_branches_terminating_on_node','unterminated_elements','incorrect_voltage_bus_limits','TLD_bus_updates']\n        reportSelections = [self.RB_900k_buses.GetValue(),\n        self.RB_TREE_islands.GetValue(),\n        self.RB_bus_type_inconsistencies.GetValue(),\n        self.RB_CNTB_check.GetValue(),\n        self.RB_disconnected_shunts.GetValue(),\n        self.RB_invalid_Binit_switched_shunts.GetValue(),\n        self."
  },
  {
    "id": "chunk_2721",
    "text": "id_Binit_switched_shunts.GetValue(),\n        self.RB_invalid_setpts_continuous_shunts.GetValue(),\n        self.RB_incorrect_shunt_remote_buses.GetValue(),\n        self.RB_incorrect_gen_remote_buses.GetValue(),\n        self.RB_br_remote_end_voltage_inconsistencies.GetValue(),\n        self.RB_check_solvability.GetValue(),\n        self.RB_check_CA_performance.GetValue(),\n        self.RB_PSSE_pf_checks.GetValue(),\n        self.RB_all_lds.GetValue(),\n        self.RB_disconnected_loads.GetValue(),\n   "
  },
  {
    "id": "chunk_2722",
    "text": "        self.RB_disconnected_loads.GetValue(),\n        self.RB_zero_loads.GetValue(),\n        self.RB_disconnected_buses.GetValue(), \n\n        self.RB_temp_looking_switches.GetValue(),\n        self.RB_mobile_loads.GetValue(),\n        self.RB_out_of_range_buses.GetValue(),\n        self.RB_multiple_branches_terminating_on_node.GetValue(),\n        self.RB_unterminated_elements.GetValue(),\n        self.RB_incorrect_voltage_bus_limits.GetValue(),\n        self.RB_TLD_bus_updates.GetValue()]\n        Al"
  },
  {
    "id": "chunk_2723",
    "text": "    self.RB_TLD_bus_updates.GetValue()]\n        AllReportsDict = dict(zip(runAllReportsList,reportSelections))\n        RequestedReportsDict = {key: value for key, value in AllReportsDict.items() if value == True}\n        \n        \n        #trigger the report creation\n\n        print('All required files and directories selected. Now running the following QA reports:')\n        print(list(RequestedReportsDict.keys()))\n        \n\n        getQAReportsLCRA(CASEDIRECTORY=self.caseDirectory,OUTPUTDIRECTOR"
  },
  {
    "id": "chunk_2724",
    "text": "RA(CASEDIRECTORY=self.caseDirectory,OUTPUTDIRECTORY=self.dirCtrl,DESIRED_QA_LIST=list(RequestedReportsDict.keys()),AREALIST=areaList)\n        print('Done!')\n\n        self.QAReportsComplete = wx.MessageBox('SSWG QA reports complete. Go to {} to see results.'.format(self.dirCtrl.GetPath()))\n\n############ MAIN ###############\nif __name__ == \"__main__\":\n    app = wx.App(False)\n    frame = LCRASSWGCaseQA()\n    #frame = SSWGCaseQA() # for general SSWG distribution\n    frame.Show()\n    app.MainLoop()\n\n"
  },
  {
    "id": "chunk_2725",
    "text": "distribution\n    frame.Show()\n    app.MainLoop()\n\n\n\n    \n\n"
  }
]